{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/GeorgeSherif/NLP-ChatEGP/blob/main/Model%20After%20Preprocessing.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OAw4nlDbEZUQ"
      },
      "source": [
        "# **Installing & Importing the Necessary Libraries and Mounting the drive**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "SDVJd_TDyswW",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d6b74f73-02f9-497a-ebed-f9d27c117b46"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting transformers\n",
            "  Downloading transformers-4.29.2-py3-none-any.whl (7.1 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m7.1/7.1 MB\u001b[0m \u001b[31m63.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting sentencepiece\n",
            "  Downloading sentencepiece-0.1.99-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.3 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.3/1.3 MB\u001b[0m \u001b[31m72.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: protobuf in /usr/local/lib/python3.10/dist-packages (3.20.3)\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.10/dist-packages (2.0.0+cu118)\n",
            "Collecting pygal\n",
            "  Downloading pygal-3.0.0-py2.py3-none-any.whl (129 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m129.4/129.4 kB\u001b[0m \u001b[31m17.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: torchvision in /usr/local/lib/python3.10/dist-packages (0.15.1+cu118)\n",
            "Collecting sacremoses\n",
            "  Downloading sacremoses-0.0.53.tar.gz (880 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m880.6/880.6 kB\u001b[0m \u001b[31m67.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from transformers) (3.12.0)\n",
            "Collecting huggingface-hub<1.0,>=0.14.1 (from transformers)\n",
            "  Downloading huggingface_hub-0.14.1-py3-none-any.whl (224 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m224.5/224.5 kB\u001b[0m \u001b[31m25.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (1.22.4)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from transformers) (23.1)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (6.0)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (2022.10.31)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from transformers) (2.27.1)\n",
            "Collecting tokenizers!=0.11.3,<0.14,>=0.11.1 (from transformers)\n",
            "  Downloading tokenizers-0.13.3-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (7.8 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m7.8/7.8 MB\u001b[0m \u001b[31m29.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.10/dist-packages (from transformers) (4.65.0)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.10/dist-packages (from torch) (4.5.0)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch) (1.11.1)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch) (3.1)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch) (3.1.2)\n",
            "Requirement already satisfied: triton==2.0.0 in /usr/local/lib/python3.10/dist-packages (from torch) (2.0.0)\n",
            "Requirement already satisfied: cmake in /usr/local/lib/python3.10/dist-packages (from triton==2.0.0->torch) (3.25.2)\n",
            "Requirement already satisfied: lit in /usr/local/lib/python3.10/dist-packages (from triton==2.0.0->torch) (16.0.3)\n",
            "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in /usr/local/lib/python3.10/dist-packages (from torchvision) (8.4.0)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.10/dist-packages (from sacremoses) (1.16.0)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.10/dist-packages (from sacremoses) (8.1.3)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.10/dist-packages (from sacremoses) (1.2.0)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.14.1->transformers) (2023.4.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch) (2.1.2)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (1.26.15)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2022.12.7)\n",
            "Requirement already satisfied: charset-normalizer~=2.0.0 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2.0.12)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (3.4)\n",
            "Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->torch) (1.3.0)\n",
            "Building wheels for collected packages: sacremoses\n",
            "  Building wheel for sacremoses (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for sacremoses: filename=sacremoses-0.0.53-py3-none-any.whl size=895241 sha256=7cc6c5012e27f6f297b4b0c43e5ebc725684be86e58ff7c7ccf397b3f6be8871\n",
            "  Stored in directory: /root/.cache/pip/wheels/00/24/97/a2ea5324f36bc626e1ea0267f33db6aa80d157ee977e9e42fb\n",
            "Successfully built sacremoses\n",
            "Installing collected packages: tokenizers, sentencepiece, pygal, sacremoses, huggingface-hub, transformers\n",
            "Successfully installed huggingface-hub-0.14.1 pygal-3.0.0 sacremoses-0.0.53 sentencepiece-0.1.99 tokenizers-0.13.3 transformers-4.29.2\n"
          ]
        }
      ],
      "source": [
        "!pip3 install transformers sentencepiece protobuf torch pygal torchvision sacremoses\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "9UP_-BDdA37e",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7bb5bff2-2eb4-484d-ea41-2bf3ef8de62c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/gdrive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "from IPython.display import display # Allows the use of display() for DataFrames\n",
        "drive.mount('/content/gdrive')\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "8eiG5KriE7bY"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import os\n",
        "import warnings\n",
        "import csv\n",
        "import re\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt \n",
        "import plotly.express as px\n",
        "import plotly.graph_objects as go\n",
        "import pygal as py\n",
        "import matplotlib\n",
        "plt.rcParams[\"figure.figsize\"] = (8,5)\n",
        "matplotlib.rc('xtick', labelsize=7) \n",
        "matplotlib.rc('ytick', labelsize=7) \n",
        "\n",
        "import torch\n",
        "import torchvision\n",
        "\n",
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "\n",
        "warnings.filterwarnings(\"ignore\", category=FutureWarning)\n",
        "%matplotlib inline "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "Ah5YDfy94Jqg"
      },
      "outputs": [],
      "source": [
        "if torch.cuda.is_available():\n",
        "    device = torch.device('cuda')\n",
        "else:\n",
        "    device = torch.device('cpu')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "haDPqEitD7k7"
      },
      "source": [
        "# **Approach 1: Evaluate the English Model (BERT)**\n",
        "\n",
        "\n",
        "*   English Train Data\n",
        "*   Arabic Test Data\n",
        "*   Train with the English Dataset\n",
        "*   Translate the Arabic Dataset\n",
        "*   Evaluate Model\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PcdWNYwxG7b8"
      },
      "source": [
        "### Load the English Dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GHd4hXPPG6Rn",
        "outputId": "d70ca88c-6df5-4f84-aab1-cbe662ca32e9"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2879\n"
          ]
        }
      ],
      "source": [
        "#df = pd.read_csv('/content/gdrive/MyDrive/NLP/English Dataset.csv' ,engine=\"python\", encoding = \"ISO-8859-1\")\n",
        "df = pd.read_csv('/content/gdrive/MyDrive/NLP/Preprocessed.csv' ,engine=\"python\", encoding = \"ISO-8859-1\")\n",
        "print((df['Sentiment'] == 'neutral').sum())\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "num_entries_to_remove_positive = (df['Sentiment'] == 'positive').sum() - (df['Sentiment'] == 'negative').sum()\n",
        "num_entries_to_remove_neutral = (df['Sentiment'] == 'neutral').sum() - (df['Sentiment'] == 'negative').sum()\n",
        "print(num_entries_to_remove_neutral)\n",
        "\n",
        "\n",
        "indices_to_remove = df[df['Sentiment'] == 'positive'].sample(num_entries_to_remove_positive).index\n",
        "dfPositive = df[df['Sentiment'] == 'positive'].drop(indices_to_remove)\n",
        "\n",
        "indices_to_remove = df[df['Sentiment'] == 'neutral'].sample(num_entries_to_remove_neutral).index\n",
        "dfNeutral = df[df['Sentiment'] == 'neutral'].drop(indices_to_remove)\n",
        "\n",
        "indices_to_remove = df[df['Sentiment'] == 'negative'].sample(0).index\n",
        "dfNegative = df[df['Sentiment'] == 'negative'].drop(indices_to_remove)\n",
        "\n",
        "print(dfNegative)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mvni0Nfgo1e8",
        "outputId": "d49c5df0-8301-4f72-e7ee-bb9e9c1d3041"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2275\n",
            "     Sentiment                                           Sentence\n",
            "2     negative    The international electronic industry compan...\n",
            "415   negative    A tinyurl link takes users scamming site pro...\n",
            "421   negative    Compared FTSE 100 index rose 36.7 points ( 0...\n",
            "423   negative    Compared FTSE 100 index rose 94.9 points ( 1...\n",
            "500   negative    One challenges oil production North Sea scal...\n",
            "...        ...                                                ...\n",
            "4840  negative    HELSINKI Thomson Financial - Shares Cargotec...\n",
            "4841  negative    LONDON MarketWatch -- Share prices ended low...\n",
            "4843  negative    Operating profit fell EUR 35.4 mn EUR 68.8 m...\n",
            "4844  negative    Net sales Paper segment decreased EUR 221.6 ...\n",
            "4845  negative    Sales Finland decreased 10.5 % January sales...\n",
            "\n",
            "[604 rows x 2 columns]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "dfNew = pd.concat((dfNegative, dfNeutral, dfPositive), axis = 0)\n",
        "dfNew\n",
        "df = dfNew"
      ],
      "metadata": {
        "id": "ceiz6xnyqKde"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df['Sentiment'] = df['Sentiment'].replace(['negative','neutral','positive'],[0,1,2])\n",
        "df"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 423
        },
        "id": "mEEYIAVdptnR",
        "outputId": "738f9f40-3d1f-4624-a62a-2ac3ef569c4a"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "      Sentiment                                           Sentence\n",
              "2             0    The international electronic industry compan...\n",
              "415           0    A tinyurl link takes users scamming site pro...\n",
              "421           0    Compared FTSE 100 index rose 36.7 points ( 0...\n",
              "423           0    Compared FTSE 100 index rose 94.9 points ( 1...\n",
              "500           0    One challenges oil production North Sea scal...\n",
              "...         ...                                                ...\n",
              "4536          2    Key shareholders Finnish IT services provide...\n",
              "4575          2    As part transaction M-real Sappi also signed...\n",
              "4774          2    `` I extremely delighted project continuatio...\n",
              "4786          2    Danske Bank A-S DANSKE DC jumped 3.7 percent...\n",
              "4787          2    Our superior customer centricity expertise d...\n",
              "\n",
              "[1812 rows x 2 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-b78febc7-6b3f-4bcb-9df0-375991e9ccf7\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Sentiment</th>\n",
              "      <th>Sentence</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0</td>\n",
              "      <td>The international electronic industry compan...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>415</th>\n",
              "      <td>0</td>\n",
              "      <td>A tinyurl link takes users scamming site pro...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>421</th>\n",
              "      <td>0</td>\n",
              "      <td>Compared FTSE 100 index rose 36.7 points ( 0...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>423</th>\n",
              "      <td>0</td>\n",
              "      <td>Compared FTSE 100 index rose 94.9 points ( 1...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>500</th>\n",
              "      <td>0</td>\n",
              "      <td>One challenges oil production North Sea scal...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4536</th>\n",
              "      <td>2</td>\n",
              "      <td>Key shareholders Finnish IT services provide...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4575</th>\n",
              "      <td>2</td>\n",
              "      <td>As part transaction M-real Sappi also signed...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4774</th>\n",
              "      <td>2</td>\n",
              "      <td>`` I extremely delighted project continuatio...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4786</th>\n",
              "      <td>2</td>\n",
              "      <td>Danske Bank A-S DANSKE DC jumped 3.7 percent...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4787</th>\n",
              "      <td>2</td>\n",
              "      <td>Our superior customer centricity expertise d...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>1812 rows × 2 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-b78febc7-6b3f-4bcb-9df0-375991e9ccf7')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-b78febc7-6b3f-4bcb-9df0-375991e9ccf7 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-b78febc7-6b3f-4bcb-9df0-375991e9ccf7');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 478
        },
        "id": "r5E8aFGXG6Zl",
        "outputId": "bea41356-d0e4-44ff-c68a-ecc3fed16331"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<Axes: xlabel='count', ylabel='Sentiment'>"
            ]
          },
          "metadata": {},
          "execution_count": 12
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 800x500 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ],
      "source": [
        "sns.countplot(y=\"Sentiment\",data=df)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 423
        },
        "id": "yIn3Q46wlVV6",
        "outputId": "d3393109-785f-4680-852b-f4bb1e0863a2"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "      Sentiment                                           Sentence\n",
              "2             0    The international electronic industry compan...\n",
              "415           0    A tinyurl link takes users scamming site pro...\n",
              "421           0    Compared FTSE 100 index rose 36.7 points ( 0...\n",
              "423           0    Compared FTSE 100 index rose 94.9 points ( 1...\n",
              "500           0    One challenges oil production North Sea scal...\n",
              "...         ...                                                ...\n",
              "4536          2    Key shareholders Finnish IT services provide...\n",
              "4575          2    As part transaction M-real Sappi also signed...\n",
              "4774          2    `` I extremely delighted project continuatio...\n",
              "4786          2    Danske Bank A-S DANSKE DC jumped 3.7 percent...\n",
              "4787          2    Our superior customer centricity expertise d...\n",
              "\n",
              "[1812 rows x 2 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-1020729a-d5ca-45c8-9fc3-099a52f8ddc0\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Sentiment</th>\n",
              "      <th>Sentence</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0</td>\n",
              "      <td>The international electronic industry compan...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>415</th>\n",
              "      <td>0</td>\n",
              "      <td>A tinyurl link takes users scamming site pro...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>421</th>\n",
              "      <td>0</td>\n",
              "      <td>Compared FTSE 100 index rose 36.7 points ( 0...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>423</th>\n",
              "      <td>0</td>\n",
              "      <td>Compared FTSE 100 index rose 94.9 points ( 1...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>500</th>\n",
              "      <td>0</td>\n",
              "      <td>One challenges oil production North Sea scal...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4536</th>\n",
              "      <td>2</td>\n",
              "      <td>Key shareholders Finnish IT services provide...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4575</th>\n",
              "      <td>2</td>\n",
              "      <td>As part transaction M-real Sappi also signed...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4774</th>\n",
              "      <td>2</td>\n",
              "      <td>`` I extremely delighted project continuatio...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4786</th>\n",
              "      <td>2</td>\n",
              "      <td>Danske Bank A-S DANSKE DC jumped 3.7 percent...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4787</th>\n",
              "      <td>2</td>\n",
              "      <td>Our superior customer centricity expertise d...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>1812 rows × 2 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-1020729a-d5ca-45c8-9fc3-099a52f8ddc0')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-1020729a-d5ca-45c8-9fc3-099a52f8ddc0 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-1020729a-d5ca-45c8-9fc3-099a52f8ddc0');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 13
        }
      ],
      "source": [
        "df.drop_duplicates(subset=['Sentence'],keep='first',inplace=True)\n",
        "df"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "u_LkJij6lsOf"
      },
      "source": [
        "### Sentiment Analysis using BERT"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 41,
      "metadata": {
        "id": "7fS-iD5jlygM"
      },
      "outputs": [],
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "X_features = df[\"Sentence\"]\n",
        "Y_features = df[\"Sentiment\"]\n",
        "X_train, X_val, y_train, y_val = train_test_split(df.index.values, df.Sentiment.values, test_size=0.2, random_state=42, shuffle=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 42,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NFqRzcKbntvM",
        "outputId": "0aa33777-250a-47f5-f32c-0e5c87cc8937"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertForSequenceClassification: ['cls.predictions.transform.dense.weight', 'cls.predictions.decoder.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.bias', 'cls.predictions.transform.dense.bias', 'cls.seq_relationship.bias', 'cls.seq_relationship.weight', 'cls.predictions.transform.LayerNorm.weight']\n",
            "- This IS expected if you are initializing BertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing BertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        }
      ],
      "source": [
        "from transformers import BertTokenizer,BertForSequenceClassification\n",
        "\n",
        "tokenizer = BertTokenizer.from_pretrained(\"bert-base-uncased\")\n",
        "model = BertForSequenceClassification.from_pretrained('bert-base-uncased',\n",
        "                                                      num_labels = 3,\n",
        "                                                      id2label={0: 'negative', 1: 'neutral', 2: 'positive'},\n",
        "                                                      output_attentions = False,\n",
        "                                                      output_hidden_states = False).to(device)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 43,
      "metadata": {
        "id": "XvfkG7kv0MX1",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "72a73daa-4971-44c9-d368-9c81e1143454"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array(['  The international electronic industry company Elcoteq laid tens employees Tallinn facility contrary earlier layoffs company contracted ranks office workers daily Postimees reported',\n",
              "       '  A tinyurl link takes users scamming site promising users earn thousands dollars becoming Google ( NASDAQ GOOG ) Cash advertiser',\n",
              "       '  Compared FTSE 100 index rose 36.7 points ( 0.6 % ) day relative price change -0.2 %',\n",
              "       ...,\n",
              "       '  `` I extremely delighted project continuation cooperation Viking Line',\n",
              "       '  Danske Bank A-S DANSKE DC jumped 3.7 percent 133.4 kroner rebounding yesterday 3.5 percent slide',\n",
              "       '  Our superior customer centricity expertise digital services set us apart competitors'],\n",
              "      dtype=object)"
            ]
          },
          "metadata": {},
          "execution_count": 43
        }
      ],
      "source": [
        "df['data_type'] = ['not_set'] * df.shape[0]\n",
        "\n",
        "df.loc[X_train, 'data_type'] = 'train'\n",
        "df.loc[X_val, 'data_type'] = 'val'\n",
        "\n",
        "#groupby count\n",
        "df.groupby([ 'Sentiment', 'data_type']).count()\n",
        "#df = df.rename(columns={'Review Text': 'Sentence'})\n",
        "df[df.data_type == 'train'].Sentence.values\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 31,
      "metadata": {
        "id": "_t00AHGuvgAo"
      },
      "outputs": [],
      "source": [
        "#encode train set\n",
        "encoded_data_train = tokenizer.batch_encode_plus(df[df.data_type == 'train'].Sentence.values,\n",
        "                                                add_special_tokens = True,\n",
        "                                                return_attention_mask = True,\n",
        "                                                pad_to_max_length = True,\n",
        "                                                max_length = 150,\n",
        "                                                truncation=True,\n",
        "                                                return_tensors = 'pt')\n",
        "                                                \n",
        "#encode validation set\n",
        "encoded_data_val = tokenizer.batch_encode_plus( df[df.data_type == 'val'].Sentence.values,\n",
        "                                                add_special_tokens = True,\n",
        "                                                return_attention_mask = True,\n",
        "                                                pad_to_max_length = True,\n",
        "                                                max_length = 150,\n",
        "                                                truncation=True,\n",
        "                                                return_tensors = 'pt')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 32,
      "metadata": {
        "id": "-J5twuCRxA7O"
      },
      "outputs": [],
      "source": [
        "#train set\n",
        "input_ids_train = encoded_data_train['input_ids']\n",
        "attention_masks_train = encoded_data_train['attention_mask']\n",
        "labels_train = torch.tensor(df[df.data_type == 'train'].Sentiment.values)\n",
        "\n",
        "#validation set\n",
        "input_ids_val = encoded_data_val['input_ids']\n",
        "attention_masks_val = encoded_data_val['attention_mask']\n",
        "labels_val = torch.tensor(df[df.data_type == 'val'].Sentiment.values)\n",
        "     "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 33,
      "metadata": {
        "id": "joRW8_E34QX3"
      },
      "outputs": [],
      "source": [
        "from torch.utils.data import TensorDataset\n",
        "\n",
        "#train set\n",
        "dataset_train = TensorDataset(input_ids_train, \n",
        "                              attention_masks_train,\n",
        "                              labels_train)\n",
        "\n",
        "#validation set\n",
        "dataset_val = TensorDataset(input_ids_val, \n",
        "                             attention_masks_val, \n",
        "                             labels_val)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 34,
      "metadata": {
        "id": "kue1cFIC4QaZ"
      },
      "outputs": [],
      "source": [
        "from torch.utils.data import DataLoader, RandomSampler, SequentialSampler\n",
        "\n",
        "batch_size = 8\n",
        "\n",
        "#train set\n",
        "dataloader_train = DataLoader(dataset_train,\n",
        "                              sampler = RandomSampler(dataset_train),\n",
        "                              batch_size = batch_size)\n",
        "\n",
        "#validation set\n",
        "dataloader_val = DataLoader(dataset_val,\n",
        "                              sampler = RandomSampler(dataset_val),\n",
        "                              batch_size = batch_size) #since we don't have to do backpropagation for this step"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 35,
      "metadata": {
        "id": "nfrQRiNf4Qc1"
      },
      "outputs": [],
      "source": [
        "from transformers import AdamW, get_linear_schedule_with_warmup\n",
        "\n",
        "optimizer = AdamW(model.parameters(),\n",
        "                 lr = 1e-5,\n",
        "                 eps = 1e-7) #2e-5 > 5e-5\n",
        "                 \n",
        "epochs = 8\n",
        "\n",
        "scheduler = get_linear_schedule_with_warmup(optimizer,\n",
        "                                           num_warmup_steps = 0,\n",
        "                                           num_training_steps =len(dataloader_train)*epochs)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 36,
      "metadata": {
        "id": "_hTFuvA04Xg_"
      },
      "outputs": [],
      "source": [
        "def evaluate(dataloader_val):\n",
        "\n",
        "    #evaluation mode \n",
        "    model.eval()\n",
        "    \n",
        "    #tracking variables\n",
        "    loss_val_total = 0\n",
        "    predictions, true_vals = [], []\n",
        "    \n",
        "    for batch in tqdm(dataloader_val):\n",
        "        \n",
        "        #load into GPU\n",
        "        batch = tuple(b.to(device) for b in batch)\n",
        "        \n",
        "        #define inputs\n",
        "        inputs = {'input_ids':      batch[0],\n",
        "                  'attention_mask': batch[1],\n",
        "                  'labels':         batch[2]}\n",
        "\n",
        "        #compute logits\n",
        "        with torch.no_grad():        \n",
        "            outputs = model(**inputs)\n",
        "        \n",
        "        #compute loss\n",
        "        loss = outputs[0]\n",
        "        logits = outputs[1]\n",
        "        loss_val_total += loss.item()\n",
        "\n",
        "        #compute accuracy\n",
        "        logits = logits.detach().cpu().numpy()\n",
        "        label_ids = inputs['labels'].cpu().numpy()\n",
        "        predictions.append(logits)\n",
        "        true_vals.append(label_ids)\n",
        "    \n",
        "    #compute average loss\n",
        "    loss_val_avg = loss_val_total/len(dataloader_val) \n",
        "    \n",
        "    predictions = np.concatenate(predictions, axis=0)\n",
        "    true_vals = np.concatenate(true_vals, axis=0)\n",
        "            \n",
        "    return loss_val_avg, predictions, true_vals"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 37,
      "metadata": {
        "id": "sIzdaLGr4ara"
      },
      "outputs": [],
      "source": [
        "from sklearn.metrics import f1_score\n",
        "\n",
        "def f1_score_func(preds, labels):\n",
        "    preds_flat = np.argmax(preds, axis = 1).flatten()\n",
        "    labels_flat = labels.flatten()\n",
        "    return f1_score(labels_flat, preds_flat, average = 'weighted')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 38,
      "metadata": {
        "id": "Z9CCDzC14dMH"
      },
      "outputs": [],
      "source": [
        "#accuracy score\n",
        "def accuracy_per_class(preds, labels):\n",
        "    #label_dict_inverse = {v: k for k, v in label_dict.items()}\n",
        "    \n",
        "    #make prediction\n",
        "    preds_flat = np.argmax(preds, axis=1).flatten()\n",
        "    labels_flat = labels.flatten()\n",
        "    \n",
        "    correct = 0\n",
        "    total = 0\n",
        "\n",
        "    for label in np.unique(labels_flat):\n",
        "        y_preds = preds_flat[labels_flat==label]\n",
        "        y_true = labels_flat[labels_flat==label]\n",
        "        #print(f'Class: {label_dict_inverse[label]}')\n",
        "        print(f'Accuracy:{len(y_preds[y_preds==label])}/{len(y_true)}\\n -> {len(y_preds[y_preds==label]) / len(y_true)}')\n",
        "        correct = correct + len(y_preds[y_preds==label])\n",
        "        total = total + len(y_true)\n",
        "    return correct / total"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 39,
      "metadata": {
        "id": "OehAW6vX4e7B"
      },
      "outputs": [],
      "source": [
        "import random\n",
        "\n",
        "seed_val = 17\n",
        "random.seed(seed_val)\n",
        "np.random.seed(seed_val)\n",
        "torch.manual_seed(seed_val)\n",
        "torch.cuda.manual_seed_all(seed_val)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 40,
      "metadata": {
        "id": "d5EMKCDo4hmk",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "93f3b706-76ce-485d-c8a3-ded544bbb2b1"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "  0%|          | 0/8 [00:00<?, ?it/s]\n",
            "Epoch 1:   0%|          | 0/182 [00:00<?, ?it/s]\u001b[A\n",
            "Epoch 1:   0%|          | 0/182 [00:14<?, ?it/s, training_loss=0.376]\u001b[A\n",
            "Epoch 1:   1%|          | 1/182 [00:14<42:20, 14.03s/it, training_loss=0.376]\u001b[A\n",
            "Epoch 1:   1%|          | 1/182 [00:26<42:20, 14.03s/it, training_loss=0.330]\u001b[A\n",
            "Epoch 1:   1%|          | 2/182 [00:26<39:53, 13.30s/it, training_loss=0.330]\u001b[A\n",
            "Epoch 1:   1%|          | 2/182 [00:39<39:53, 13.30s/it, training_loss=0.475]\u001b[A\n",
            "Epoch 1:   2%|▏         | 3/182 [00:39<39:04, 13.10s/it, training_loss=0.475]\u001b[A\n",
            "Epoch 1:   2%|▏         | 3/182 [00:50<39:04, 13.10s/it, training_loss=0.361]\u001b[A\n",
            "Epoch 1:   2%|▏         | 4/182 [00:50<35:56, 12.12s/it, training_loss=0.361]\u001b[A\n",
            "Epoch 1:   2%|▏         | 4/182 [01:02<35:56, 12.12s/it, training_loss=0.403]\u001b[A\n",
            "Epoch 1:   3%|▎         | 5/182 [01:02<35:41, 12.10s/it, training_loss=0.403]\u001b[A\n",
            "Epoch 1:   3%|▎         | 5/182 [01:14<35:41, 12.10s/it, training_loss=0.362]\u001b[A\n",
            "Epoch 1:   3%|▎         | 6/182 [01:14<35:51, 12.23s/it, training_loss=0.362]\u001b[A\n",
            "Epoch 1:   3%|▎         | 6/182 [01:27<35:51, 12.23s/it, training_loss=0.394]\u001b[A\n",
            "Epoch 1:   4%|▍         | 7/182 [01:27<35:55, 12.32s/it, training_loss=0.394]\u001b[A\n",
            "Epoch 1:   4%|▍         | 7/182 [01:37<35:55, 12.32s/it, training_loss=0.341]\u001b[A\n",
            "Epoch 1:   4%|▍         | 8/182 [01:37<34:08, 11.77s/it, training_loss=0.341]\u001b[A\n",
            "Epoch 1:   4%|▍         | 8/182 [01:49<34:08, 11.77s/it, training_loss=0.319]\u001b[A\n",
            "Epoch 1:   5%|▍         | 9/182 [01:49<34:06, 11.83s/it, training_loss=0.319]\u001b[A\n",
            "Epoch 1:   5%|▍         | 9/182 [02:02<34:06, 11.83s/it, training_loss=0.361]\u001b[A\n",
            "Epoch 1:   5%|▌         | 10/182 [02:02<34:29, 12.03s/it, training_loss=0.361]\u001b[A\n",
            "Epoch 1:   5%|▌         | 10/182 [02:14<34:29, 12.03s/it, training_loss=0.388]\u001b[A\n",
            "Epoch 1:   6%|▌         | 11/182 [02:14<34:42, 12.18s/it, training_loss=0.388]\u001b[A\n",
            "Epoch 1:   6%|▌         | 11/182 [02:25<34:42, 12.18s/it, training_loss=0.369]\u001b[A\n",
            "Epoch 1:   7%|▋         | 12/182 [02:25<33:10, 11.71s/it, training_loss=0.369]\u001b[A\n",
            "Epoch 1:   7%|▋         | 12/182 [02:37<33:10, 11.71s/it, training_loss=0.332]\u001b[A\n",
            "Epoch 1:   7%|▋         | 13/182 [02:37<33:03, 11.73s/it, training_loss=0.332]\u001b[A\n",
            "Epoch 1:   7%|▋         | 13/182 [02:49<33:03, 11.73s/it, training_loss=0.391]\u001b[A\n",
            "Epoch 1:   8%|▊         | 14/182 [02:49<33:28, 11.96s/it, training_loss=0.391]\u001b[A\n",
            "Epoch 1:   8%|▊         | 14/182 [03:02<33:28, 11.96s/it, training_loss=0.350]\u001b[A\n",
            "Epoch 1:   8%|▊         | 15/182 [03:02<33:46, 12.13s/it, training_loss=0.350]\u001b[A\n",
            "Epoch 1:   8%|▊         | 15/182 [03:13<33:46, 12.13s/it, training_loss=0.353]\u001b[A\n",
            "Epoch 1:   9%|▉         | 16/182 [03:13<32:26, 11.73s/it, training_loss=0.353]\u001b[A\n",
            "Epoch 1:   9%|▉         | 16/182 [03:24<32:26, 11.73s/it, training_loss=0.386]\u001b[A\n",
            "Epoch 1:   9%|▉         | 17/182 [03:24<32:09, 11.70s/it, training_loss=0.386]\u001b[A\n",
            "Epoch 1:   9%|▉         | 17/182 [03:39<32:09, 11.70s/it, training_loss=0.370]\u001b[A\n",
            "Epoch 1:  10%|▉         | 18/182 [03:39<34:41, 12.69s/it, training_loss=0.370]\u001b[A\n",
            "Epoch 1:  10%|▉         | 18/182 [03:53<34:41, 12.69s/it, training_loss=0.330]\u001b[A\n",
            "Epoch 1:  10%|█         | 19/182 [03:53<35:37, 13.11s/it, training_loss=0.330]\u001b[A\n",
            "Epoch 1:  10%|█         | 19/182 [04:04<35:37, 13.11s/it, training_loss=0.359]\u001b[A\n",
            "Epoch 1:  11%|█         | 20/182 [04:04<33:18, 12.33s/it, training_loss=0.359]\u001b[A\n",
            "Epoch 1:  11%|█         | 20/182 [04:16<33:18, 12.33s/it, training_loss=0.376]\u001b[A\n",
            "Epoch 1:  12%|█▏        | 21/182 [04:16<32:48, 12.23s/it, training_loss=0.376]\u001b[A\n",
            "Epoch 1:  12%|█▏        | 21/182 [04:28<32:48, 12.23s/it, training_loss=0.374]\u001b[A\n",
            "Epoch 1:  12%|█▏        | 22/182 [04:28<32:50, 12.32s/it, training_loss=0.374]\u001b[A\n",
            "Epoch 1:  12%|█▏        | 22/182 [04:41<32:50, 12.32s/it, training_loss=0.341]\u001b[A\n",
            "Epoch 1:  13%|█▎        | 23/182 [04:41<32:47, 12.37s/it, training_loss=0.341]\u001b[A\n",
            "Epoch 1:  13%|█▎        | 23/182 [04:51<32:47, 12.37s/it, training_loss=0.388]\u001b[A\n",
            "Epoch 1:  13%|█▎        | 24/182 [04:51<31:06, 11.81s/it, training_loss=0.388]\u001b[A\n",
            "Epoch 1:  13%|█▎        | 24/182 [05:03<31:06, 11.81s/it, training_loss=0.357]\u001b[A\n",
            "Epoch 1:  14%|█▎        | 25/182 [05:03<31:00, 11.85s/it, training_loss=0.357]\u001b[A\n",
            "Epoch 1:  14%|█▎        | 25/182 [05:16<31:00, 11.85s/it, training_loss=0.369]\u001b[A\n",
            "Epoch 1:  14%|█▍        | 26/182 [05:16<31:19, 12.05s/it, training_loss=0.369]\u001b[A\n",
            "Epoch 1:  14%|█▍        | 26/182 [05:28<31:19, 12.05s/it, training_loss=0.361]\u001b[A\n",
            "Epoch 1:  15%|█▍        | 27/182 [05:28<31:32, 12.21s/it, training_loss=0.361]\u001b[A\n",
            "Epoch 1:  15%|█▍        | 27/182 [05:39<31:32, 12.21s/it, training_loss=0.355]\u001b[A\n",
            "Epoch 1:  15%|█▌        | 28/182 [05:39<30:12, 11.77s/it, training_loss=0.355]\u001b[A\n",
            "Epoch 1:  15%|█▌        | 28/182 [05:51<30:12, 11.77s/it, training_loss=0.365]\u001b[A\n",
            "Epoch 1:  16%|█▌        | 29/182 [05:51<30:02, 11.78s/it, training_loss=0.365]\u001b[A\n",
            "Epoch 1:  16%|█▌        | 29/182 [06:05<30:02, 11.78s/it, training_loss=0.324]\u001b[A\n",
            "Epoch 1:  16%|█▋        | 30/182 [06:05<31:52, 12.58s/it, training_loss=0.324]\u001b[A\n",
            "Epoch 1:  16%|█▋        | 30/182 [06:18<31:52, 12.58s/it, training_loss=0.388]\u001b[A\n",
            "Epoch 1:  17%|█▋        | 31/182 [06:18<31:37, 12.57s/it, training_loss=0.388]\u001b[A\n",
            "Epoch 1:  17%|█▋        | 31/182 [06:29<31:37, 12.57s/it, training_loss=0.337]\u001b[A\n",
            "Epoch 1:  18%|█▊        | 32/182 [06:29<30:10, 12.07s/it, training_loss=0.337]\u001b[A\n",
            "Epoch 1:  18%|█▊        | 32/182 [06:40<30:10, 12.07s/it, training_loss=0.331]\u001b[A\n",
            "Epoch 1:  18%|█▊        | 33/182 [06:41<29:39, 11.94s/it, training_loss=0.331]\u001b[A\n",
            "Epoch 1:  18%|█▊        | 33/182 [06:58<29:39, 11.94s/it, training_loss=0.330]\u001b[A\n",
            "Epoch 1:  19%|█▊        | 34/182 [06:58<33:18, 13.51s/it, training_loss=0.330]\u001b[A\n",
            "Epoch 1:  19%|█▊        | 34/182 [07:10<33:18, 13.51s/it, training_loss=0.388]\u001b[A\n",
            "Epoch 1:  19%|█▉        | 35/182 [07:10<32:20, 13.20s/it, training_loss=0.388]\u001b[A\n",
            "Epoch 1:  19%|█▉        | 35/182 [07:23<32:20, 13.20s/it, training_loss=0.374]\u001b[A\n",
            "Epoch 1:  20%|█▉        | 36/182 [07:23<31:35, 12.98s/it, training_loss=0.374]\u001b[A\n",
            "Epoch 1:  20%|█▉        | 36/182 [07:34<31:35, 12.98s/it, training_loss=0.366]\u001b[A\n",
            "Epoch 1:  20%|██        | 37/182 [07:34<30:24, 12.58s/it, training_loss=0.366]\u001b[A\n",
            "Epoch 1:  20%|██        | 37/182 [07:46<30:24, 12.58s/it, training_loss=0.389]\u001b[A\n",
            "Epoch 1:  21%|██        | 38/182 [07:46<29:25, 12.26s/it, training_loss=0.389]\u001b[A\n",
            "Epoch 1:  21%|██        | 38/182 [08:10<29:25, 12.26s/it, training_loss=0.356]\u001b[A\n",
            "Epoch 1:  21%|██▏       | 39/182 [08:10<37:40, 15.81s/it, training_loss=0.356]\u001b[A\n",
            "Epoch 1:  21%|██▏       | 39/182 [08:25<37:40, 15.81s/it, training_loss=0.353]\u001b[A\n",
            "Epoch 1:  22%|██▏       | 40/182 [08:25<36:53, 15.59s/it, training_loss=0.353]\u001b[A\n",
            "Epoch 1:  22%|██▏       | 40/182 [08:36<36:53, 15.59s/it, training_loss=0.335]\u001b[A\n",
            "Epoch 1:  23%|██▎       | 41/182 [08:36<33:42, 14.34s/it, training_loss=0.335]\u001b[A\n",
            "Epoch 1:  23%|██▎       | 41/182 [08:50<33:42, 14.34s/it, training_loss=0.356]\u001b[A\n",
            "Epoch 1:  23%|██▎       | 42/182 [08:50<32:56, 14.12s/it, training_loss=0.356]\u001b[A\n",
            "Epoch 1:  23%|██▎       | 42/182 [09:04<32:56, 14.12s/it, training_loss=0.387]\u001b[A\n",
            "Epoch 1:  24%|██▎       | 43/182 [09:04<32:19, 13.95s/it, training_loss=0.387]\u001b[A\n",
            "Epoch 1:  24%|██▎       | 43/182 [09:16<32:19, 13.95s/it, training_loss=0.333]\u001b[A\n",
            "Epoch 1:  24%|██▍       | 44/182 [09:16<31:06, 13.52s/it, training_loss=0.333]\u001b[A\n",
            "Epoch 1:  24%|██▍       | 44/182 [09:29<31:06, 13.52s/it, training_loss=0.315]\u001b[A\n",
            "Epoch 1:  25%|██▍       | 45/182 [09:29<30:39, 13.42s/it, training_loss=0.315]\u001b[A\n",
            "Epoch 1:  25%|██▍       | 45/182 [09:40<30:39, 13.42s/it, training_loss=0.327]\u001b[A\n",
            "Epoch 1:  25%|██▌       | 46/182 [09:40<28:50, 12.72s/it, training_loss=0.327]\u001b[A\n",
            "Epoch 1:  25%|██▌       | 46/182 [09:53<28:50, 12.72s/it, training_loss=0.306]\u001b[A\n",
            "Epoch 1:  26%|██▌       | 47/182 [09:53<28:27, 12.65s/it, training_loss=0.306]\u001b[A\n",
            "Epoch 1:  26%|██▌       | 47/182 [10:05<28:27, 12.65s/it, training_loss=0.321]\u001b[A\n",
            "Epoch 1:  26%|██▋       | 48/182 [10:05<28:10, 12.61s/it, training_loss=0.321]\u001b[A\n",
            "Epoch 1:  26%|██▋       | 48/182 [10:17<28:10, 12.61s/it, training_loss=0.370]\u001b[A\n",
            "Epoch 1:  27%|██▋       | 49/182 [10:17<27:18, 12.32s/it, training_loss=0.370]\u001b[A\n",
            "Epoch 1:  27%|██▋       | 49/182 [10:28<27:18, 12.32s/it, training_loss=0.327]\u001b[A\n",
            "Epoch 1:  27%|██▋       | 50/182 [10:28<26:05, 11.86s/it, training_loss=0.327]\u001b[A\n",
            "Epoch 1:  27%|██▋       | 50/182 [10:40<26:05, 11.86s/it, training_loss=0.356]\u001b[A\n",
            "Epoch 1:  28%|██▊       | 51/182 [10:40<26:17, 12.05s/it, training_loss=0.356]\u001b[A\n",
            "Epoch 1:  28%|██▊       | 51/182 [10:53<26:17, 12.05s/it, training_loss=0.343]\u001b[A\n",
            "Epoch 1:  29%|██▊       | 52/182 [10:53<26:25, 12.20s/it, training_loss=0.343]\u001b[A\n",
            "Epoch 1:  29%|██▊       | 52/182 [11:04<26:25, 12.20s/it, training_loss=0.309]\u001b[A\n",
            "Epoch 1:  29%|██▉       | 53/182 [11:04<25:53, 12.04s/it, training_loss=0.309]\u001b[A\n",
            "Epoch 1:  29%|██▉       | 53/182 [11:15<25:53, 12.04s/it, training_loss=0.273]\u001b[A\n",
            "Epoch 1:  30%|██▉       | 54/182 [11:15<25:00, 11.72s/it, training_loss=0.273]\u001b[A\n",
            "Epoch 1:  30%|██▉       | 54/182 [11:28<25:00, 11.72s/it, training_loss=0.358]\u001b[A\n",
            "Epoch 1:  30%|███       | 55/182 [11:28<25:18, 11.96s/it, training_loss=0.358]\u001b[A\n",
            "Epoch 1:  30%|███       | 55/182 [11:41<25:18, 11.96s/it, training_loss=0.335]\u001b[A\n",
            "Epoch 1:  31%|███       | 56/182 [11:41<25:29, 12.14s/it, training_loss=0.335]\u001b[A\n",
            "Epoch 1:  31%|███       | 56/182 [11:53<25:29, 12.14s/it, training_loss=0.300]\u001b[A\n",
            "Epoch 1:  31%|███▏      | 57/182 [11:53<25:18, 12.15s/it, training_loss=0.300]\u001b[A\n",
            "Epoch 1:  31%|███▏      | 57/182 [12:03<25:18, 12.15s/it, training_loss=0.315]\u001b[A\n",
            "Epoch 1:  32%|███▏      | 58/182 [12:03<24:11, 11.71s/it, training_loss=0.315]\u001b[A\n",
            "Epoch 1:  32%|███▏      | 58/182 [12:18<24:11, 11.71s/it, training_loss=0.362]\u001b[A\n",
            "Epoch 1:  32%|███▏      | 59/182 [12:18<26:05, 12.72s/it, training_loss=0.362]\u001b[A\n",
            "Epoch 1:  32%|███▏      | 59/182 [12:31<26:05, 12.72s/it, training_loss=0.334]\u001b[A\n",
            "Epoch 1:  33%|███▎      | 60/182 [12:31<25:50, 12.71s/it, training_loss=0.334]\u001b[A\n",
            "Epoch 1:  33%|███▎      | 60/182 [12:43<25:50, 12.71s/it, training_loss=0.323]\u001b[A\n",
            "Epoch 1:  34%|███▎      | 61/182 [12:43<25:15, 12.53s/it, training_loss=0.323]\u001b[A\n",
            "Epoch 1:  34%|███▎      | 61/182 [12:54<25:15, 12.53s/it, training_loss=0.337]\u001b[A\n",
            "Epoch 1:  34%|███▍      | 62/182 [12:54<23:55, 11.96s/it, training_loss=0.337]\u001b[A\n",
            "Epoch 1:  34%|███▍      | 62/182 [13:06<23:55, 11.96s/it, training_loss=0.325]\u001b[A\n",
            "Epoch 1:  35%|███▍      | 63/182 [13:06<24:04, 12.14s/it, training_loss=0.325]\u001b[A\n",
            "Epoch 1:  35%|███▍      | 63/182 [13:19<24:04, 12.14s/it, training_loss=0.374]\u001b[A\n",
            "Epoch 1:  35%|███▌      | 64/182 [13:19<24:07, 12.27s/it, training_loss=0.374]\u001b[A\n",
            "Epoch 1:  35%|███▌      | 64/182 [13:31<24:07, 12.27s/it, training_loss=0.359]\u001b[A\n",
            "Epoch 1:  36%|███▌      | 65/182 [13:31<23:56, 12.28s/it, training_loss=0.359]\u001b[A\n",
            "Epoch 1:  36%|███▌      | 65/182 [13:42<23:56, 12.28s/it, training_loss=0.351]\u001b[A\n",
            "Epoch 1:  36%|███▋      | 66/182 [13:42<22:57, 11.88s/it, training_loss=0.351]\u001b[A\n",
            "Epoch 1:  36%|███▋      | 66/182 [13:55<22:57, 11.88s/it, training_loss=0.278]\u001b[A\n",
            "Epoch 1:  37%|███▋      | 67/182 [13:55<23:29, 12.26s/it, training_loss=0.278]\u001b[A\n",
            "Epoch 1:  37%|███▋      | 67/182 [14:08<23:29, 12.26s/it, training_loss=0.313]\u001b[A\n",
            "Epoch 1:  37%|███▋      | 68/182 [14:08<23:31, 12.38s/it, training_loss=0.313]\u001b[A\n",
            "Epoch 1:  37%|███▋      | 68/182 [14:21<23:31, 12.38s/it, training_loss=0.332]\u001b[A\n",
            "Epoch 1:  38%|███▊      | 69/182 [14:21<23:26, 12.45s/it, training_loss=0.332]\u001b[A\n",
            "Epoch 1:  38%|███▊      | 69/182 [14:31<23:26, 12.45s/it, training_loss=0.316]\u001b[A\n",
            "Epoch 1:  38%|███▊      | 70/182 [14:31<22:19, 11.96s/it, training_loss=0.316]\u001b[A\n",
            "Epoch 1:  38%|███▊      | 70/182 [14:43<22:19, 11.96s/it, training_loss=0.361]\u001b[A\n",
            "Epoch 1:  39%|███▉      | 71/182 [14:43<22:05, 11.94s/it, training_loss=0.361]\u001b[A\n",
            "Epoch 1:  39%|███▉      | 71/182 [14:56<22:05, 11.94s/it, training_loss=0.347]\u001b[A\n",
            "Epoch 1:  40%|███▉      | 72/182 [14:56<22:13, 12.12s/it, training_loss=0.347]\u001b[A\n",
            "Epoch 1:  40%|███▉      | 72/182 [15:09<22:13, 12.12s/it, training_loss=0.333]\u001b[A\n",
            "Epoch 1:  40%|████      | 73/182 [15:09<22:16, 12.27s/it, training_loss=0.333]\u001b[A\n",
            "Epoch 1:  40%|████      | 73/182 [15:20<22:16, 12.27s/it, training_loss=0.298]\u001b[A\n",
            "Epoch 1:  41%|████      | 74/182 [15:20<21:30, 11.95s/it, training_loss=0.298]\u001b[A\n",
            "Epoch 1:  41%|████      | 74/182 [15:31<21:30, 11.95s/it, training_loss=0.333]\u001b[A\n",
            "Epoch 1:  41%|████      | 75/182 [15:31<21:04, 11.82s/it, training_loss=0.333]\u001b[A\n",
            "Epoch 1:  41%|████      | 75/182 [15:44<21:04, 11.82s/it, training_loss=0.322]\u001b[A\n",
            "Epoch 1:  42%|████▏     | 76/182 [15:44<21:20, 12.08s/it, training_loss=0.322]\u001b[A\n",
            "Epoch 1:  42%|████▏     | 76/182 [15:57<21:20, 12.08s/it, training_loss=0.372]\u001b[A\n",
            "Epoch 1:  42%|████▏     | 77/182 [15:57<21:24, 12.24s/it, training_loss=0.372]\u001b[A\n",
            "Epoch 1:  42%|████▏     | 77/182 [16:08<21:24, 12.24s/it, training_loss=0.310]\u001b[A\n",
            "Epoch 1:  43%|████▎     | 78/182 [16:08<20:54, 12.06s/it, training_loss=0.310]\u001b[A\n",
            "Epoch 1:  43%|████▎     | 78/182 [16:19<20:54, 12.06s/it, training_loss=0.324]\u001b[A\n",
            "Epoch 1:  43%|████▎     | 79/182 [16:19<20:09, 11.74s/it, training_loss=0.324]\u001b[A\n",
            "Epoch 1:  43%|████▎     | 79/182 [16:34<20:09, 11.74s/it, training_loss=0.307]\u001b[A\n",
            "Epoch 1:  44%|████▍     | 80/182 [16:34<21:30, 12.65s/it, training_loss=0.307]\u001b[A\n",
            "Epoch 1:  44%|████▍     | 80/182 [16:46<21:30, 12.65s/it, training_loss=0.288]\u001b[A\n",
            "Epoch 1:  45%|████▍     | 81/182 [16:47<21:14, 12.62s/it, training_loss=0.288]\u001b[A\n",
            "Epoch 1:  45%|████▍     | 81/182 [16:59<21:14, 12.62s/it, training_loss=0.312]\u001b[A\n",
            "Epoch 1:  45%|████▌     | 82/182 [16:59<21:01, 12.61s/it, training_loss=0.312]\u001b[A\n",
            "Epoch 1:  45%|████▌     | 82/182 [17:10<21:01, 12.61s/it, training_loss=0.334]\u001b[A\n",
            "Epoch 1:  46%|████▌     | 83/182 [17:10<20:09, 12.21s/it, training_loss=0.334]\u001b[A\n",
            "Epoch 1:  46%|████▌     | 83/182 [17:22<20:09, 12.21s/it, training_loss=0.319]\u001b[A\n",
            "Epoch 1:  46%|████▌     | 84/182 [17:22<19:31, 11.96s/it, training_loss=0.319]\u001b[A\n",
            "Epoch 1:  46%|████▌     | 84/182 [17:34<19:31, 11.96s/it, training_loss=0.335]\u001b[A\n",
            "Epoch 1:  47%|████▋     | 85/182 [17:34<19:37, 12.14s/it, training_loss=0.335]\u001b[A\n",
            "Epoch 1:  47%|████▋     | 85/182 [17:47<19:37, 12.14s/it, training_loss=0.307]\u001b[A\n",
            "Epoch 1:  47%|████▋     | 86/182 [17:47<19:41, 12.31s/it, training_loss=0.307]\u001b[A\n",
            "Epoch 1:  47%|████▋     | 86/182 [17:59<19:41, 12.31s/it, training_loss=0.299]\u001b[A\n",
            "Epoch 1:  48%|████▊     | 87/182 [17:59<19:09, 12.10s/it, training_loss=0.299]\u001b[A\n",
            "Epoch 1:  48%|████▊     | 87/182 [18:10<19:09, 12.10s/it, training_loss=0.283]\u001b[A\n",
            "Epoch 1:  48%|████▊     | 88/182 [18:10<18:28, 11.79s/it, training_loss=0.283]\u001b[A\n",
            "Epoch 1:  48%|████▊     | 88/182 [18:22<18:28, 11.79s/it, training_loss=0.287]\u001b[A\n",
            "Epoch 1:  49%|████▉     | 89/182 [18:22<18:37, 12.02s/it, training_loss=0.287]\u001b[A\n",
            "Epoch 1:  49%|████▉     | 89/182 [18:35<18:37, 12.02s/it, training_loss=0.290]\u001b[A\n",
            "Epoch 1:  49%|████▉     | 90/182 [18:35<18:40, 12.18s/it, training_loss=0.290]\u001b[A\n",
            "Epoch 1:  49%|████▉     | 90/182 [18:47<18:40, 12.18s/it, training_loss=0.323]\u001b[A\n",
            "Epoch 1:  50%|█████     | 91/182 [18:47<18:23, 12.13s/it, training_loss=0.323]\u001b[A\n",
            "Epoch 1:  50%|█████     | 91/182 [18:58<18:23, 12.13s/it, training_loss=0.289]\u001b[A\n",
            "Epoch 1:  51%|█████     | 92/182 [18:58<17:37, 11.75s/it, training_loss=0.289]\u001b[A\n",
            "Epoch 1:  51%|█████     | 92/182 [19:10<17:37, 11.75s/it, training_loss=0.328]\u001b[A\n",
            "Epoch 1:  51%|█████     | 93/182 [19:10<17:48, 12.00s/it, training_loss=0.328]\u001b[A\n",
            "Epoch 1:  51%|█████     | 93/182 [19:24<17:48, 12.00s/it, training_loss=0.271]\u001b[A\n",
            "Epoch 1:  52%|█████▏    | 94/182 [19:24<18:28, 12.60s/it, training_loss=0.271]\u001b[A\n",
            "Epoch 1:  52%|█████▏    | 94/182 [19:37<18:28, 12.60s/it, training_loss=0.252]\u001b[A\n",
            "Epoch 1:  52%|█████▏    | 95/182 [19:37<18:22, 12.67s/it, training_loss=0.252]\u001b[A\n",
            "Epoch 1:  52%|█████▏    | 95/182 [19:48<18:22, 12.67s/it, training_loss=0.342]\u001b[A\n",
            "Epoch 1:  53%|█████▎    | 96/182 [19:48<17:24, 12.15s/it, training_loss=0.342]\u001b[A\n",
            "Epoch 1:  53%|█████▎    | 96/182 [20:00<17:24, 12.15s/it, training_loss=0.296]\u001b[A\n",
            "Epoch 1:  53%|█████▎    | 97/182 [20:00<17:03, 12.05s/it, training_loss=0.296]\u001b[A\n",
            "Epoch 1:  53%|█████▎    | 97/182 [20:12<17:03, 12.05s/it, training_loss=0.308]\u001b[A\n",
            "Epoch 1:  54%|█████▍    | 98/182 [20:12<17:05, 12.21s/it, training_loss=0.308]\u001b[A\n",
            "Epoch 1:  54%|█████▍    | 98/182 [20:25<17:05, 12.21s/it, training_loss=0.268]\u001b[A\n",
            "Epoch 1:  54%|█████▍    | 99/182 [20:25<17:03, 12.34s/it, training_loss=0.268]\u001b[A\n",
            "Epoch 1:  54%|█████▍    | 99/182 [20:36<17:03, 12.34s/it, training_loss=0.347]\u001b[A\n",
            "Epoch 1:  55%|█████▍    | 100/182 [20:36<16:25, 12.01s/it, training_loss=0.347]\u001b[A\n",
            "Epoch 1:  55%|█████▍    | 100/182 [20:49<16:25, 12.01s/it, training_loss=0.315]\u001b[A\n",
            "Epoch 1:  55%|█████▌    | 101/182 [20:49<16:39, 12.34s/it, training_loss=0.315]\u001b[A\n",
            "Epoch 1:  55%|█████▌    | 101/182 [21:03<16:39, 12.34s/it, training_loss=0.302]\u001b[A\n",
            "Epoch 1:  56%|█████▌    | 102/182 [21:03<16:45, 12.57s/it, training_loss=0.302]\u001b[A\n",
            "Epoch 1:  56%|█████▌    | 102/182 [21:15<16:45, 12.57s/it, training_loss=0.354]\u001b[A\n",
            "Epoch 1:  57%|█████▋    | 103/182 [21:15<16:35, 12.60s/it, training_loss=0.354]\u001b[A\n",
            "Epoch 1:  57%|█████▋    | 103/182 [21:28<16:35, 12.60s/it, training_loss=0.277]\u001b[A\n",
            "Epoch 1:  57%|█████▋    | 104/182 [21:28<16:16, 12.52s/it, training_loss=0.277]\u001b[A\n",
            "Epoch 1:  57%|█████▋    | 104/182 [21:38<16:16, 12.52s/it, training_loss=0.210]\u001b[A\n",
            "Epoch 1:  58%|█████▊    | 105/182 [21:38<15:22, 11.98s/it, training_loss=0.210]\u001b[A\n",
            "Epoch 1:  58%|█████▊    | 105/182 [21:51<15:22, 11.98s/it, training_loss=0.261]\u001b[A\n",
            "Epoch 1:  58%|█████▊    | 106/182 [21:51<15:26, 12.20s/it, training_loss=0.261]\u001b[A\n",
            "Epoch 1:  58%|█████▊    | 106/182 [22:04<15:26, 12.20s/it, training_loss=0.277]\u001b[A\n",
            "Epoch 1:  59%|█████▉    | 107/182 [22:04<15:24, 12.33s/it, training_loss=0.277]\u001b[A\n",
            "Epoch 1:  59%|█████▉    | 107/182 [22:16<15:24, 12.33s/it, training_loss=0.260]\u001b[A\n",
            "Epoch 1:  59%|█████▉    | 108/182 [22:16<15:17, 12.39s/it, training_loss=0.260]\u001b[A\n",
            "Epoch 1:  59%|█████▉    | 108/182 [22:27<15:17, 12.39s/it, training_loss=0.238]\u001b[A\n",
            "Epoch 1:  60%|█████▉    | 109/182 [22:27<14:23, 11.83s/it, training_loss=0.238]\u001b[A\n",
            "Epoch 1:  60%|█████▉    | 109/182 [22:39<14:23, 11.83s/it, training_loss=0.294]\u001b[A\n",
            "Epoch 1:  60%|██████    | 110/182 [22:39<14:19, 11.93s/it, training_loss=0.294]\u001b[A\n",
            "Epoch 1:  60%|██████    | 110/182 [22:51<14:19, 11.93s/it, training_loss=0.295]\u001b[A\n",
            "Epoch 1:  61%|██████    | 111/182 [22:51<14:21, 12.14s/it, training_loss=0.295]\u001b[A\n",
            "Epoch 1:  61%|██████    | 111/182 [23:04<14:21, 12.14s/it, training_loss=0.333]\u001b[A\n",
            "Epoch 1:  62%|██████▏   | 112/182 [23:04<14:19, 12.28s/it, training_loss=0.333]\u001b[A\n",
            "Epoch 1:  62%|██████▏   | 112/182 [23:15<14:19, 12.28s/it, training_loss=0.395]\u001b[A\n",
            "Epoch 1:  62%|██████▏   | 113/182 [23:15<13:33, 11.79s/it, training_loss=0.395]\u001b[A\n",
            "Epoch 1:  62%|██████▏   | 113/182 [23:27<13:33, 11.79s/it, training_loss=0.307]\u001b[A\n",
            "Epoch 1:  63%|██████▎   | 114/182 [23:27<13:24, 11.83s/it, training_loss=0.307]\u001b[A\n",
            "Epoch 1:  63%|██████▎   | 114/182 [23:39<13:24, 11.83s/it, training_loss=0.286]\u001b[A\n",
            "Epoch 1:  63%|██████▎   | 115/182 [23:39<13:27, 12.05s/it, training_loss=0.286]\u001b[A\n",
            "Epoch 1:  63%|██████▎   | 115/182 [23:52<13:27, 12.05s/it, training_loss=0.313]\u001b[A\n",
            "Epoch 1:  64%|██████▎   | 116/182 [23:52<13:26, 12.23s/it, training_loss=0.313]\u001b[A\n",
            "Epoch 1:  64%|██████▎   | 116/182 [24:03<13:26, 12.23s/it, training_loss=0.328]\u001b[A\n",
            "Epoch 1:  64%|██████▍   | 117/182 [24:03<12:47, 11.81s/it, training_loss=0.328]\u001b[A\n",
            "Epoch 1:  64%|██████▍   | 117/182 [24:14<12:47, 11.81s/it, training_loss=0.210]\u001b[A\n",
            "Epoch 1:  65%|██████▍   | 118/182 [24:14<12:32, 11.76s/it, training_loss=0.210]\u001b[A\n",
            "Epoch 1:  65%|██████▍   | 118/182 [24:27<12:32, 11.76s/it, training_loss=0.338]\u001b[A\n",
            "Epoch 1:  65%|██████▌   | 119/182 [24:27<12:35, 11.99s/it, training_loss=0.338]\u001b[A\n",
            "Epoch 1:  65%|██████▌   | 119/182 [24:39<12:35, 11.99s/it, training_loss=0.267]\u001b[A\n",
            "Epoch 1:  66%|██████▌   | 120/182 [24:39<12:34, 12.17s/it, training_loss=0.267]\u001b[A\n",
            "Epoch 1:  66%|██████▌   | 120/182 [24:51<12:34, 12.17s/it, training_loss=0.261]\u001b[A\n",
            "Epoch 1:  66%|██████▋   | 121/182 [24:51<12:03, 11.87s/it, training_loss=0.261]\u001b[A\n",
            "Epoch 1:  66%|██████▋   | 121/182 [25:02<12:03, 11.87s/it, training_loss=0.358]\u001b[A\n",
            "Epoch 1:  67%|██████▋   | 122/182 [25:02<11:43, 11.72s/it, training_loss=0.358]\u001b[A\n",
            "Epoch 1:  67%|██████▋   | 122/182 [25:17<11:43, 11.72s/it, training_loss=0.279]\u001b[A\n",
            "Epoch 1:  68%|██████▊   | 123/182 [25:17<12:30, 12.71s/it, training_loss=0.279]\u001b[A\n",
            "Epoch 1:  68%|██████▊   | 123/182 [25:29<12:30, 12.71s/it, training_loss=0.297]\u001b[A\n",
            "Epoch 1:  68%|██████▊   | 124/182 [25:29<12:01, 12.44s/it, training_loss=0.297]\u001b[A\n",
            "Epoch 1:  68%|██████▊   | 124/182 [25:40<12:01, 12.44s/it, training_loss=0.246]\u001b[A\n",
            "Epoch 1:  69%|██████▊   | 125/182 [25:40<11:24, 12.00s/it, training_loss=0.246]\u001b[A\n",
            "Epoch 1:  69%|██████▊   | 125/182 [25:52<11:24, 12.00s/it, training_loss=0.347]\u001b[A\n",
            "Epoch 1:  69%|██████▉   | 126/182 [25:52<11:22, 12.19s/it, training_loss=0.347]\u001b[A\n",
            "Epoch 1:  69%|██████▉   | 126/182 [26:05<11:22, 12.19s/it, training_loss=0.235]\u001b[A\n",
            "Epoch 1:  70%|██████▉   | 127/182 [26:05<11:18, 12.34s/it, training_loss=0.235]\u001b[A\n",
            "Epoch 1:  70%|██████▉   | 127/182 [26:17<11:18, 12.34s/it, training_loss=0.252]\u001b[A\n",
            "Epoch 1:  70%|███████   | 128/182 [26:17<11:02, 12.27s/it, training_loss=0.252]\u001b[A\n",
            "Epoch 1:  70%|███████   | 128/182 [26:28<11:02, 12.27s/it, training_loss=0.295]\u001b[A\n",
            "Epoch 1:  71%|███████   | 129/182 [26:28<10:25, 11.79s/it, training_loss=0.295]\u001b[A\n",
            "Epoch 1:  71%|███████   | 129/182 [26:40<10:25, 11.79s/it, training_loss=0.258]\u001b[A\n",
            "Epoch 1:  71%|███████▏  | 130/182 [26:40<10:24, 12.02s/it, training_loss=0.258]\u001b[A\n",
            "Epoch 1:  71%|███████▏  | 130/182 [26:53<10:24, 12.02s/it, training_loss=0.223]\u001b[A\n",
            "Epoch 1:  72%|███████▏  | 131/182 [26:53<10:22, 12.20s/it, training_loss=0.223]\u001b[A\n",
            "Epoch 1:  72%|███████▏  | 131/182 [27:05<10:22, 12.20s/it, training_loss=0.217]\u001b[A\n",
            "Epoch 1:  73%|███████▎  | 132/182 [27:05<10:12, 12.25s/it, training_loss=0.217]\u001b[A\n",
            "Epoch 1:  73%|███████▎  | 132/182 [27:16<10:12, 12.25s/it, training_loss=0.294]\u001b[A\n",
            "Epoch 1:  73%|███████▎  | 133/182 [27:16<09:33, 11.69s/it, training_loss=0.294]\u001b[A\n",
            "Epoch 1:  73%|███████▎  | 133/182 [27:28<09:33, 11.69s/it, training_loss=0.217]\u001b[A\n",
            "Epoch 1:  74%|███████▎  | 134/182 [27:28<09:33, 11.95s/it, training_loss=0.217]\u001b[A\n",
            "Epoch 1:  74%|███████▎  | 134/182 [27:41<09:33, 11.95s/it, training_loss=0.214]\u001b[A\n",
            "Epoch 1:  74%|███████▍  | 135/182 [27:41<09:31, 12.15s/it, training_loss=0.214]\u001b[A\n",
            "Epoch 1:  74%|███████▍  | 135/182 [27:54<09:31, 12.15s/it, training_loss=0.261]\u001b[A\n",
            "Epoch 1:  75%|███████▍  | 136/182 [27:54<09:24, 12.26s/it, training_loss=0.261]\u001b[A\n",
            "Epoch 1:  75%|███████▍  | 136/182 [28:04<09:24, 12.26s/it, training_loss=0.254]\u001b[A\n",
            "Epoch 1:  75%|███████▌  | 137/182 [28:04<08:46, 11.70s/it, training_loss=0.254]\u001b[A\n",
            "Epoch 1:  75%|███████▌  | 137/182 [28:16<08:46, 11.70s/it, training_loss=0.233]\u001b[A\n",
            "Epoch 1:  76%|███████▌  | 138/182 [28:16<08:42, 11.87s/it, training_loss=0.233]\u001b[A\n",
            "Epoch 1:  76%|███████▌  | 138/182 [28:29<08:42, 11.87s/it, training_loss=0.175]\u001b[A\n",
            "Epoch 1:  76%|███████▋  | 139/182 [28:29<08:39, 12.07s/it, training_loss=0.175]\u001b[A\n",
            "Epoch 1:  76%|███████▋  | 139/182 [28:41<08:39, 12.07s/it, training_loss=0.268]\u001b[A\n",
            "Epoch 1:  77%|███████▋  | 140/182 [28:41<08:32, 12.20s/it, training_loss=0.268]\u001b[A\n",
            "Epoch 1:  77%|███████▋  | 140/182 [28:52<08:32, 12.20s/it, training_loss=0.275]\u001b[A\n",
            "Epoch 1:  77%|███████▋  | 141/182 [28:52<07:57, 11.65s/it, training_loss=0.275]\u001b[A\n",
            "Epoch 1:  77%|███████▋  | 141/182 [29:04<07:57, 11.65s/it, training_loss=0.194]\u001b[A\n",
            "Epoch 1:  78%|███████▊  | 142/182 [29:04<07:52, 11.80s/it, training_loss=0.194]\u001b[A\n",
            "Epoch 1:  78%|███████▊  | 142/182 [29:16<07:52, 11.80s/it, training_loss=0.277]\u001b[A\n",
            "Epoch 1:  79%|███████▊  | 143/182 [29:16<07:50, 12.07s/it, training_loss=0.277]\u001b[A\n",
            "Epoch 1:  79%|███████▊  | 143/182 [29:30<07:50, 12.07s/it, training_loss=0.253]\u001b[A\n",
            "Epoch 1:  79%|███████▉  | 144/182 [29:30<07:57, 12.56s/it, training_loss=0.253]\u001b[A\n",
            "Epoch 1:  79%|███████▉  | 144/182 [29:42<07:57, 12.56s/it, training_loss=0.231]\u001b[A\n",
            "Epoch 1:  80%|███████▉  | 145/182 [29:42<07:33, 12.26s/it, training_loss=0.231]\u001b[A\n",
            "Epoch 1:  80%|███████▉  | 145/182 [29:54<07:33, 12.26s/it, training_loss=0.232]\u001b[A\n",
            "Epoch 1:  80%|████████  | 146/182 [29:54<07:24, 12.34s/it, training_loss=0.232]\u001b[A\n",
            "Epoch 1:  80%|████████  | 146/182 [30:07<07:24, 12.34s/it, training_loss=0.306]\u001b[A\n",
            "Epoch 1:  81%|████████  | 147/182 [30:07<07:14, 12.40s/it, training_loss=0.306]\u001b[A\n",
            "Epoch 1:  81%|████████  | 147/182 [30:18<07:14, 12.40s/it, training_loss=0.216]\u001b[A\n",
            "Epoch 1:  81%|████████▏ | 148/182 [30:18<06:52, 12.12s/it, training_loss=0.216]\u001b[A\n",
            "Epoch 1:  81%|████████▏ | 148/182 [30:29<06:52, 12.12s/it, training_loss=0.205]\u001b[A\n",
            "Epoch 1:  82%|████████▏ | 149/182 [30:29<06:29, 11.80s/it, training_loss=0.205]\u001b[A\n",
            "Epoch 1:  82%|████████▏ | 149/182 [30:42<06:29, 11.80s/it, training_loss=0.295]\u001b[A\n",
            "Epoch 1:  82%|████████▏ | 150/182 [30:42<06:24, 12.00s/it, training_loss=0.295]\u001b[A\n",
            "Epoch 1:  82%|████████▏ | 150/182 [30:54<06:24, 12.00s/it, training_loss=0.253]\u001b[A\n",
            "Epoch 1:  83%|████████▎ | 151/182 [30:54<06:16, 12.14s/it, training_loss=0.253]\u001b[A\n",
            "Epoch 1:  83%|████████▎ | 151/182 [31:06<06:16, 12.14s/it, training_loss=0.198]\u001b[A\n",
            "Epoch 1:  84%|████████▎ | 152/182 [31:06<06:00, 12.00s/it, training_loss=0.198]\u001b[A\n",
            "Epoch 1:  84%|████████▎ | 152/182 [31:17<06:00, 12.00s/it, training_loss=0.152]\u001b[A\n",
            "Epoch 1:  84%|████████▍ | 153/182 [31:17<05:38, 11.69s/it, training_loss=0.152]\u001b[A\n",
            "Epoch 1:  84%|████████▍ | 153/182 [31:29<05:38, 11.69s/it, training_loss=0.309]\u001b[A\n",
            "Epoch 1:  85%|████████▍ | 154/182 [31:29<05:34, 11.96s/it, training_loss=0.309]\u001b[A\n",
            "Epoch 1:  85%|████████▍ | 154/182 [31:42<05:34, 11.96s/it, training_loss=0.211]\u001b[A\n",
            "Epoch 1:  85%|████████▌ | 155/182 [31:42<05:28, 12.16s/it, training_loss=0.211]\u001b[A\n",
            "Epoch 1:  85%|████████▌ | 155/182 [31:54<05:28, 12.16s/it, training_loss=0.231]\u001b[A\n",
            "Epoch 1:  86%|████████▌ | 156/182 [31:54<05:15, 12.14s/it, training_loss=0.231]\u001b[A\n",
            "Epoch 1:  86%|████████▌ | 156/182 [32:05<05:15, 12.14s/it, training_loss=0.209]\u001b[A\n",
            "Epoch 1:  86%|████████▋ | 157/182 [32:05<04:52, 11.70s/it, training_loss=0.209]\u001b[A\n",
            "Epoch 1:  86%|████████▋ | 157/182 [32:17<04:52, 11.70s/it, training_loss=0.271]\u001b[A\n",
            "Epoch 1:  87%|████████▋ | 158/182 [32:17<04:46, 11.93s/it, training_loss=0.271]\u001b[A\n",
            "Epoch 1:  87%|████████▋ | 158/182 [32:30<04:46, 11.93s/it, training_loss=0.307]\u001b[A\n",
            "Epoch 1:  87%|████████▋ | 159/182 [32:30<04:38, 12.12s/it, training_loss=0.307]\u001b[A\n",
            "Epoch 1:  87%|████████▋ | 159/182 [32:42<04:38, 12.12s/it, training_loss=0.181]\u001b[A\n",
            "Epoch 1:  88%|████████▊ | 160/182 [32:42<04:27, 12.14s/it, training_loss=0.181]\u001b[A\n",
            "Epoch 1:  88%|████████▊ | 160/182 [32:53<04:27, 12.14s/it, training_loss=0.280]\u001b[A\n",
            "Epoch 1:  88%|████████▊ | 161/182 [32:53<04:05, 11.68s/it, training_loss=0.280]\u001b[A\n",
            "Epoch 1:  88%|████████▊ | 161/182 [33:05<04:05, 11.68s/it, training_loss=0.213]\u001b[A\n",
            "Epoch 1:  89%|████████▉ | 162/182 [33:05<03:58, 11.93s/it, training_loss=0.213]\u001b[A\n",
            "Epoch 1:  89%|████████▉ | 162/182 [33:18<03:58, 11.93s/it, training_loss=0.225]\u001b[A\n",
            "Epoch 1:  90%|████████▉ | 163/182 [33:18<03:50, 12.13s/it, training_loss=0.225]\u001b[A\n",
            "Epoch 1:  90%|████████▉ | 163/182 [33:30<03:50, 12.13s/it, training_loss=0.180]\u001b[A\n",
            "Epoch 1:  90%|█████████ | 164/182 [33:30<03:40, 12.24s/it, training_loss=0.180]\u001b[A\n",
            "Epoch 1:  90%|█████████ | 164/182 [33:41<03:40, 12.24s/it, training_loss=0.218]\u001b[A\n",
            "Epoch 1:  91%|█████████ | 165/182 [33:41<03:19, 11.72s/it, training_loss=0.218]\u001b[A\n",
            "Epoch 1:  91%|█████████ | 165/182 [33:56<03:19, 11.72s/it, training_loss=0.282]\u001b[A\n",
            "Epoch 1:  91%|█████████ | 166/182 [33:56<03:23, 12.69s/it, training_loss=0.282]\u001b[A\n",
            "Epoch 1:  91%|█████████ | 166/182 [34:08<03:23, 12.69s/it, training_loss=0.267]\u001b[A\n",
            "Epoch 1:  92%|█████████▏| 167/182 [34:08<03:09, 12.64s/it, training_loss=0.267]\u001b[A\n",
            "Epoch 1:  92%|█████████▏| 167/182 [34:19<03:09, 12.64s/it, training_loss=0.168]\u001b[A\n",
            "Epoch 1:  92%|█████████▏| 168/182 [34:19<02:48, 12.03s/it, training_loss=0.168]\u001b[A\n",
            "Epoch 1:  92%|█████████▏| 168/182 [34:31<02:48, 12.03s/it, training_loss=0.366]\u001b[A\n",
            "Epoch 1:  93%|█████████▎| 169/182 [34:31<02:36, 12.02s/it, training_loss=0.366]\u001b[A\n",
            "Epoch 1:  93%|█████████▎| 169/182 [34:43<02:36, 12.02s/it, training_loss=0.149]\u001b[A\n",
            "Epoch 1:  93%|█████████▎| 170/182 [34:43<02:26, 12.17s/it, training_loss=0.149]\u001b[A\n",
            "Epoch 1:  93%|█████████▎| 170/182 [34:56<02:26, 12.17s/it, training_loss=0.210]\u001b[A\n",
            "Epoch 1:  94%|█████████▍| 171/182 [34:56<02:15, 12.30s/it, training_loss=0.210]\u001b[A\n",
            "Epoch 1:  94%|█████████▍| 171/182 [35:07<02:15, 12.30s/it, training_loss=0.140]\u001b[A\n",
            "Epoch 1:  95%|█████████▍| 172/182 [35:07<01:58, 11.87s/it, training_loss=0.140]\u001b[A\n",
            "Epoch 1:  95%|█████████▍| 172/182 [35:19<01:58, 11.87s/it, training_loss=0.293]\u001b[A\n",
            "Epoch 1:  95%|█████████▌| 173/182 [35:19<01:46, 11.81s/it, training_loss=0.293]\u001b[A\n",
            "Epoch 1:  95%|█████████▌| 173/182 [35:31<01:46, 11.81s/it, training_loss=0.144]\u001b[A\n",
            "Epoch 1:  96%|█████████▌| 174/182 [35:31<01:36, 12.04s/it, training_loss=0.144]\u001b[A\n",
            "Epoch 1:  96%|█████████▌| 174/182 [35:44<01:36, 12.04s/it, training_loss=0.212]\u001b[A\n",
            "Epoch 1:  96%|█████████▌| 175/182 [35:44<01:25, 12.21s/it, training_loss=0.212]\u001b[A\n",
            "Epoch 1:  96%|█████████▌| 175/182 [35:55<01:25, 12.21s/it, training_loss=0.185]\u001b[A\n",
            "Epoch 1:  97%|█████████▋| 176/182 [35:55<01:11, 11.85s/it, training_loss=0.185]\u001b[A\n",
            "Epoch 1:  97%|█████████▋| 176/182 [36:06<01:11, 11.85s/it, training_loss=0.169]\u001b[A\n",
            "Epoch 1:  97%|█████████▋| 177/182 [36:06<00:58, 11.77s/it, training_loss=0.169]\u001b[A\n",
            "Epoch 1:  97%|█████████▋| 177/182 [36:19<00:58, 11.77s/it, training_loss=0.175]\u001b[A\n",
            "Epoch 1:  98%|█████████▊| 178/182 [36:19<00:48, 12.01s/it, training_loss=0.175]\u001b[A\n",
            "Epoch 1:  98%|█████████▊| 178/182 [36:32<00:48, 12.01s/it, training_loss=0.239]\u001b[A\n",
            "Epoch 1:  98%|█████████▊| 179/182 [36:32<00:36, 12.20s/it, training_loss=0.239]\u001b[A\n",
            "Epoch 1:  98%|█████████▊| 179/182 [36:43<00:36, 12.20s/it, training_loss=0.212]\u001b[A\n",
            "Epoch 1:  99%|█████████▉| 180/182 [36:43<00:23, 11.96s/it, training_loss=0.212]\u001b[A\n",
            "Epoch 1:  99%|█████████▉| 180/182 [36:54<00:23, 11.96s/it, training_loss=0.221]\u001b[A\n",
            "Epoch 1:  99%|█████████▉| 181/182 [36:54<00:11, 11.75s/it, training_loss=0.221]\u001b[A\n",
            "Epoch 1:  99%|█████████▉| 181/182 [36:56<00:11, 11.75s/it, training_loss=0.139]\u001b[A\n",
            "Epoch 1: 100%|██████████| 182/182 [36:56<00:00,  8.88s/it, training_loss=0.139]\u001b[A\n",
            "  0%|          | 0/8 [37:02<?, ?it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            " Epoch {epoch}\n",
            "Training loss: {loss_train_avg}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "  0%|          | 0/46 [00:00<?, ?it/s]\u001b[A\n",
            "  2%|▏         | 1/46 [00:03<02:52,  3.83s/it]\u001b[A\n",
            "  4%|▍         | 2/46 [00:07<02:43,  3.72s/it]\u001b[A\n",
            "  7%|▋         | 3/46 [00:13<03:21,  4.68s/it]\u001b[A\n",
            "  9%|▊         | 4/46 [00:17<03:08,  4.50s/it]\u001b[A\n",
            " 11%|█         | 5/46 [00:20<02:46,  4.05s/it]\u001b[A\n",
            " 13%|█▎        | 6/46 [00:24<02:30,  3.77s/it]\u001b[A\n",
            " 15%|█▌        | 7/46 [00:28<02:39,  4.10s/it]\u001b[A\n",
            " 17%|█▋        | 8/46 [00:32<02:33,  4.04s/it]\u001b[A\n",
            " 20%|█▉        | 9/46 [00:35<02:19,  3.78s/it]\u001b[A\n",
            " 22%|██▏       | 10/46 [00:39<02:10,  3.61s/it]\u001b[A\n",
            " 24%|██▍       | 11/46 [00:43<02:13,  3.82s/it]\u001b[A\n",
            " 26%|██▌       | 12/46 [00:47<02:16,  4.00s/it]\u001b[A\n",
            " 28%|██▊       | 13/46 [00:51<02:04,  3.76s/it]\u001b[A\n",
            " 30%|███       | 14/46 [00:54<01:54,  3.59s/it]\u001b[A\n",
            " 33%|███▎      | 15/46 [00:58<01:53,  3.65s/it]\u001b[A\n",
            " 35%|███▍      | 16/46 [01:03<02:06,  4.22s/it]\u001b[A\n",
            " 37%|███▋      | 17/46 [01:08<02:09,  4.48s/it]\u001b[A\n",
            " 39%|███▉      | 18/46 [01:11<01:54,  4.10s/it]\u001b[A\n",
            " 41%|████▏     | 19/46 [01:15<01:43,  3.84s/it]\u001b[A\n",
            " 43%|████▎     | 20/46 [01:18<01:39,  3.81s/it]\u001b[A\n",
            " 46%|████▌     | 21/46 [01:23<01:43,  4.15s/it]\u001b[A\n",
            " 48%|████▊     | 22/46 [01:27<01:32,  3.87s/it]\u001b[A\n",
            " 50%|█████     | 23/46 [01:30<01:24,  3.67s/it]\u001b[A\n",
            " 52%|█████▏    | 24/46 [01:33<01:17,  3.54s/it]\u001b[A\n",
            " 54%|█████▍    | 25/46 [01:38<01:25,  4.06s/it]\u001b[A\n",
            " 57%|█████▋    | 26/46 [01:42<01:17,  3.87s/it]\u001b[A\n",
            " 59%|█████▊    | 27/46 [01:45<01:09,  3.67s/it]\u001b[A\n",
            " 61%|██████    | 28/46 [01:48<01:03,  3.53s/it]\u001b[A\n",
            " 63%|██████▎   | 29/46 [01:53<01:06,  3.94s/it]\u001b[A\n",
            " 65%|██████▌   | 30/46 [01:57<01:02,  3.90s/it]\u001b[A\n",
            " 67%|██████▋   | 31/46 [02:00<00:55,  3.69s/it]\u001b[A\n",
            " 70%|██████▉   | 32/46 [02:03<00:49,  3.56s/it]\u001b[A\n",
            " 72%|███████▏  | 33/46 [02:08<00:49,  3.83s/it]\u001b[A\n",
            " 74%|███████▍  | 34/46 [02:12<00:47,  3.95s/it]\u001b[A\n",
            " 76%|███████▌  | 35/46 [02:15<00:41,  3.73s/it]\u001b[A\n",
            " 78%|███████▊  | 36/46 [02:18<00:35,  3.57s/it]\u001b[A\n",
            " 80%|████████  | 37/46 [02:22<00:33,  3.68s/it]\u001b[A\n",
            " 83%|████████▎ | 38/46 [02:27<00:32,  4.01s/it]\u001b[A\n",
            " 85%|████████▍ | 39/46 [02:30<00:26,  3.78s/it]\u001b[A\n",
            " 87%|████████▋ | 40/46 [02:34<00:21,  3.61s/it]\u001b[A\n",
            " 89%|████████▉ | 41/46 [02:37<00:17,  3.57s/it]\u001b[A\n",
            " 91%|█████████▏| 42/46 [02:42<00:16,  4.07s/it]\u001b[A\n",
            " 93%|█████████▎| 43/46 [02:45<00:11,  3.81s/it]\u001b[A\n",
            " 96%|█████████▌| 44/46 [02:49<00:07,  3.63s/it]\u001b[A\n",
            " 98%|█████████▊| 45/46 [02:52<00:03,  3.50s/it]\u001b[A\n",
            "100%|██████████| 46/46 [02:54<00:00,  3.79s/it]\n",
            " 12%|█▎        | 1/8 [39:57<4:39:39, 2397.02s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy:106/128\n",
            " -> 0.828125\n",
            "Accuracy:60/107\n",
            " -> 0.5607476635514018\n",
            "Accuracy:94/128\n",
            " -> 0.734375\n",
            "Validation loss: 0.682885155081749\n",
            "F1 Score (weighted): 0.7143828351789917\n",
            "Accuracy Score: 0.7162534435261708\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "Epoch 2:   0%|          | 0/182 [00:00<?, ?it/s]\u001b[A\n",
            "Epoch 2:   0%|          | 0/182 [00:11<?, ?it/s, training_loss=0.216]\u001b[A\n",
            "Epoch 2:   1%|          | 1/182 [00:11<35:52, 11.89s/it, training_loss=0.216]\u001b[A\n",
            "Epoch 2:   1%|          | 1/182 [00:24<35:52, 11.89s/it, training_loss=0.203]\u001b[A\n",
            "Epoch 2:   1%|          | 2/182 [00:24<37:20, 12.45s/it, training_loss=0.203]\u001b[A\n",
            "Epoch 2:   1%|          | 2/182 [00:37<37:20, 12.45s/it, training_loss=0.204]\u001b[A\n",
            "Epoch 2:   2%|▏         | 3/182 [00:37<37:20, 12.51s/it, training_loss=0.204]\u001b[A\n",
            "Epoch 2:   2%|▏         | 3/182 [00:48<37:20, 12.51s/it, training_loss=0.233]\u001b[A\n",
            "Epoch 2:   2%|▏         | 4/182 [00:48<35:14, 11.88s/it, training_loss=0.233]\u001b[A\n",
            "Epoch 2:   2%|▏         | 4/182 [00:59<35:14, 11.88s/it, training_loss=0.319]\u001b[A\n",
            "Epoch 2:   3%|▎         | 5/182 [00:59<34:49, 11.80s/it, training_loss=0.319]\u001b[A\n",
            "Epoch 2:   3%|▎         | 5/182 [01:12<34:49, 11.80s/it, training_loss=0.175]\u001b[A\n",
            "Epoch 2:   3%|▎         | 6/182 [01:12<35:22, 12.06s/it, training_loss=0.175]\u001b[A\n",
            "Epoch 2:   3%|▎         | 6/182 [01:25<35:22, 12.06s/it, training_loss=0.183]\u001b[A\n",
            "Epoch 2:   4%|▍         | 7/182 [01:25<35:41, 12.24s/it, training_loss=0.183]\u001b[A\n",
            "Epoch 2:   4%|▍         | 7/182 [01:36<35:41, 12.24s/it, training_loss=0.153]\u001b[A\n",
            "Epoch 2:   4%|▍         | 8/182 [01:36<34:29, 11.89s/it, training_loss=0.153]\u001b[A\n",
            "Epoch 2:   4%|▍         | 8/182 [01:47<34:29, 11.89s/it, training_loss=0.222]\u001b[A\n",
            "Epoch 2:   5%|▍         | 9/182 [01:47<33:49, 11.73s/it, training_loss=0.222]\u001b[A\n",
            "Epoch 2:   5%|▍         | 9/182 [02:00<33:49, 11.73s/it, training_loss=0.185]\u001b[A\n",
            "Epoch 2:   5%|▌         | 10/182 [02:00<34:19, 11.98s/it, training_loss=0.185]\u001b[A\n",
            "Epoch 2:   5%|▌         | 10/182 [02:13<34:19, 11.98s/it, training_loss=0.250]\u001b[A\n",
            "Epoch 2:   6%|▌         | 11/182 [02:13<35:05, 12.31s/it, training_loss=0.250]\u001b[A\n",
            "Epoch 2:   6%|▌         | 11/182 [02:24<35:05, 12.31s/it, training_loss=0.356]\u001b[A\n",
            "Epoch 2:   7%|▋         | 12/182 [02:24<34:25, 12.15s/it, training_loss=0.356]\u001b[A\n",
            "Epoch 2:   7%|▋         | 12/182 [02:38<34:25, 12.15s/it, training_loss=0.205]\u001b[A\n",
            "Epoch 2:   7%|▋         | 13/182 [02:38<35:09, 12.48s/it, training_loss=0.205]\u001b[A\n",
            "Epoch 2:   7%|▋         | 13/182 [02:50<35:09, 12.48s/it, training_loss=0.114]\u001b[A\n",
            "Epoch 2:   8%|▊         | 14/182 [02:50<34:56, 12.48s/it, training_loss=0.114]\u001b[A\n",
            "Epoch 2:   8%|▊         | 14/182 [03:03<34:56, 12.48s/it, training_loss=0.285]\u001b[A\n",
            "Epoch 2:   8%|▊         | 15/182 [03:03<34:45, 12.49s/it, training_loss=0.285]\u001b[A\n",
            "Epoch 2:   8%|▊         | 15/182 [03:14<34:45, 12.49s/it, training_loss=0.172]\u001b[A\n",
            "Epoch 2:   9%|▉         | 16/182 [03:14<33:17, 12.03s/it, training_loss=0.172]\u001b[A\n",
            "Epoch 2:   9%|▉         | 16/182 [03:25<33:17, 12.03s/it, training_loss=0.154]\u001b[A\n",
            "Epoch 2:   9%|▉         | 17/182 [03:25<32:38, 11.87s/it, training_loss=0.154]\u001b[A\n",
            "Epoch 2:   9%|▉         | 17/182 [03:38<32:38, 11.87s/it, training_loss=0.249]\u001b[A\n",
            "Epoch 2:  10%|▉         | 18/182 [03:38<33:02, 12.09s/it, training_loss=0.249]\u001b[A\n",
            "Epoch 2:  10%|▉         | 18/182 [03:50<33:02, 12.09s/it, training_loss=0.138]\u001b[A\n",
            "Epoch 2:  10%|█         | 19/182 [03:50<33:13, 12.23s/it, training_loss=0.138]\u001b[A\n",
            "Epoch 2:  10%|█         | 19/182 [04:02<33:13, 12.23s/it, training_loss=0.211]\u001b[A\n",
            "Epoch 2:  11%|█         | 20/182 [04:02<32:13, 11.94s/it, training_loss=0.211]\u001b[A\n",
            "Epoch 2:  11%|█         | 20/182 [04:13<32:13, 11.94s/it, training_loss=0.106]\u001b[A\n",
            "Epoch 2:  12%|█▏        | 21/182 [04:13<31:30, 11.74s/it, training_loss=0.106]\u001b[A\n",
            "Epoch 2:  12%|█▏        | 21/182 [04:25<31:30, 11.74s/it, training_loss=0.162]\u001b[A\n",
            "Epoch 2:  12%|█▏        | 22/182 [04:25<31:55, 11.97s/it, training_loss=0.162]\u001b[A\n",
            "Epoch 2:  12%|█▏        | 22/182 [04:38<31:55, 11.97s/it, training_loss=0.135]\u001b[A\n",
            "Epoch 2:  13%|█▎        | 23/182 [04:38<32:11, 12.15s/it, training_loss=0.135]\u001b[A\n",
            "Epoch 2:  13%|█▎        | 23/182 [04:49<32:11, 12.15s/it, training_loss=0.184]\u001b[A\n",
            "Epoch 2:  13%|█▎        | 24/182 [04:49<31:28, 11.95s/it, training_loss=0.184]\u001b[A\n",
            "Epoch 2:  13%|█▎        | 24/182 [05:00<31:28, 11.95s/it, training_loss=0.125]\u001b[A\n",
            "Epoch 2:  14%|█▎        | 25/182 [05:00<30:34, 11.68s/it, training_loss=0.125]\u001b[A\n",
            "Epoch 2:  14%|█▎        | 25/182 [05:13<30:34, 11.68s/it, training_loss=0.173]\u001b[A\n",
            "Epoch 2:  14%|█▍        | 26/182 [05:13<31:01, 11.93s/it, training_loss=0.173]\u001b[A\n",
            "Epoch 2:  14%|█▍        | 26/182 [05:26<31:01, 11.93s/it, training_loss=0.340]\u001b[A\n",
            "Epoch 2:  15%|█▍        | 27/182 [05:26<31:18, 12.12s/it, training_loss=0.340]\u001b[A\n",
            "Epoch 2:  15%|█▍        | 27/182 [05:37<31:18, 12.12s/it, training_loss=0.130]\u001b[A\n",
            "Epoch 2:  15%|█▌        | 28/182 [05:37<30:50, 12.01s/it, training_loss=0.130]\u001b[A\n",
            "Epoch 2:  15%|█▌        | 28/182 [05:48<30:50, 12.01s/it, training_loss=0.163]\u001b[A\n",
            "Epoch 2:  16%|█▌        | 29/182 [05:48<29:50, 11.70s/it, training_loss=0.163]\u001b[A\n",
            "Epoch 2:  16%|█▌        | 29/182 [06:01<29:50, 11.70s/it, training_loss=0.370]\u001b[A\n",
            "Epoch 2:  16%|█▋        | 30/182 [06:01<30:12, 11.93s/it, training_loss=0.370]\u001b[A\n",
            "Epoch 2:  16%|█▋        | 30/182 [06:13<30:12, 11.93s/it, training_loss=0.180]\u001b[A\n",
            "Epoch 2:  17%|█▋        | 31/182 [06:13<30:31, 12.13s/it, training_loss=0.180]\u001b[A\n",
            "Epoch 2:  17%|█▋        | 31/182 [06:25<30:31, 12.13s/it, training_loss=0.402]\u001b[A\n",
            "Epoch 2:  18%|█▊        | 32/182 [06:25<30:13, 12.09s/it, training_loss=0.402]\u001b[A\n",
            "Epoch 2:  18%|█▊        | 32/182 [06:36<30:13, 12.09s/it, training_loss=0.220]\u001b[A\n",
            "Epoch 2:  18%|█▊        | 33/182 [06:36<28:57, 11.66s/it, training_loss=0.220]\u001b[A\n",
            "Epoch 2:  18%|█▊        | 33/182 [06:51<28:57, 11.66s/it, training_loss=0.156]\u001b[A\n",
            "Epoch 2:  19%|█▊        | 34/182 [06:51<31:02, 12.58s/it, training_loss=0.156]\u001b[A\n",
            "Epoch 2:  19%|█▊        | 34/182 [07:03<31:02, 12.58s/it, training_loss=0.256]\u001b[A\n",
            "Epoch 2:  19%|█▉        | 35/182 [07:03<30:46, 12.56s/it, training_loss=0.256]\u001b[A\n",
            "Epoch 2:  19%|█▉        | 35/182 [07:16<30:46, 12.56s/it, training_loss=0.159]\u001b[A\n",
            "Epoch 2:  20%|█▉        | 36/182 [07:16<30:35, 12.57s/it, training_loss=0.159]\u001b[A\n",
            "Epoch 2:  20%|█▉        | 36/182 [07:27<30:35, 12.57s/it, training_loss=0.202]\u001b[A\n",
            "Epoch 2:  20%|██        | 37/182 [07:27<29:37, 12.26s/it, training_loss=0.202]\u001b[A\n",
            "Epoch 2:  20%|██        | 37/182 [07:39<29:37, 12.26s/it, training_loss=0.315]\u001b[A\n",
            "Epoch 2:  21%|██        | 38/182 [07:39<28:40, 11.95s/it, training_loss=0.315]\u001b[A\n",
            "Epoch 2:  21%|██        | 38/182 [07:51<28:40, 11.95s/it, training_loss=0.266]\u001b[A\n",
            "Epoch 2:  21%|██▏       | 39/182 [07:51<29:01, 12.18s/it, training_loss=0.266]\u001b[A\n",
            "Epoch 2:  21%|██▏       | 39/182 [08:04<29:01, 12.18s/it, training_loss=0.195]\u001b[A\n",
            "Epoch 2:  22%|██▏       | 40/182 [08:04<29:11, 12.34s/it, training_loss=0.195]\u001b[A\n",
            "Epoch 2:  22%|██▏       | 40/182 [08:16<29:11, 12.34s/it, training_loss=0.198]\u001b[A\n",
            "Epoch 2:  23%|██▎       | 41/182 [08:16<28:47, 12.25s/it, training_loss=0.198]\u001b[A\n",
            "Epoch 2:  23%|██▎       | 41/182 [08:27<28:47, 12.25s/it, training_loss=0.215]\u001b[A\n",
            "Epoch 2:  23%|██▎       | 42/182 [08:27<27:28, 11.78s/it, training_loss=0.215]\u001b[A\n",
            "Epoch 2:  23%|██▎       | 42/182 [08:39<27:28, 11.78s/it, training_loss=0.300]\u001b[A\n",
            "Epoch 2:  24%|██▎       | 43/182 [08:39<27:50, 12.02s/it, training_loss=0.300]\u001b[A\n",
            "Epoch 2:  24%|██▎       | 43/182 [08:52<27:50, 12.02s/it, training_loss=0.151]\u001b[A\n",
            "Epoch 2:  24%|██▍       | 44/182 [08:52<28:00, 12.18s/it, training_loss=0.151]\u001b[A\n",
            "Epoch 2:  24%|██▍       | 44/182 [09:04<28:00, 12.18s/it, training_loss=0.179]\u001b[A\n",
            "Epoch 2:  25%|██▍       | 45/182 [09:04<27:51, 12.20s/it, training_loss=0.179]\u001b[A\n",
            "Epoch 2:  25%|██▍       | 45/182 [09:15<27:51, 12.20s/it, training_loss=0.323]\u001b[A\n",
            "Epoch 2:  25%|██▌       | 46/182 [09:15<26:31, 11.70s/it, training_loss=0.323]\u001b[A\n",
            "Epoch 2:  25%|██▌       | 46/182 [09:27<26:31, 11.70s/it, training_loss=0.171]\u001b[A\n",
            "Epoch 2:  26%|██▌       | 47/182 [09:27<26:53, 11.95s/it, training_loss=0.171]\u001b[A\n",
            "Epoch 2:  26%|██▌       | 47/182 [09:40<26:53, 11.95s/it, training_loss=0.192]\u001b[A\n",
            "Epoch 2:  26%|██▋       | 48/182 [09:40<27:09, 12.16s/it, training_loss=0.192]\u001b[A\n",
            "Epoch 2:  26%|██▋       | 48/182 [09:52<27:09, 12.16s/it, training_loss=0.187]\u001b[A\n",
            "Epoch 2:  27%|██▋       | 49/182 [09:52<27:10, 12.26s/it, training_loss=0.187]\u001b[A\n",
            "Epoch 2:  27%|██▋       | 49/182 [10:03<27:10, 12.26s/it, training_loss=0.285]\u001b[A\n",
            "Epoch 2:  27%|██▋       | 50/182 [10:03<25:41, 11.68s/it, training_loss=0.285]\u001b[A\n",
            "Epoch 2:  27%|██▋       | 50/182 [10:15<25:41, 11.68s/it, training_loss=0.184]\u001b[A\n",
            "Epoch 2:  28%|██▊       | 51/182 [10:15<25:59, 11.91s/it, training_loss=0.184]\u001b[A\n",
            "Epoch 2:  28%|██▊       | 51/182 [10:28<25:59, 11.91s/it, training_loss=0.153]\u001b[A\n",
            "Epoch 2:  29%|██▊       | 52/182 [10:28<26:11, 12.09s/it, training_loss=0.153]\u001b[A\n",
            "Epoch 2:  29%|██▊       | 52/182 [10:40<26:11, 12.09s/it, training_loss=0.162]\u001b[A\n",
            "Epoch 2:  29%|██▉       | 53/182 [10:40<26:17, 12.23s/it, training_loss=0.162]\u001b[A\n",
            "Epoch 2:  29%|██▉       | 53/182 [10:51<26:17, 12.23s/it, training_loss=0.134]\u001b[A\n",
            "Epoch 2:  30%|██▉       | 54/182 [10:51<24:57, 11.70s/it, training_loss=0.134]\u001b[A\n",
            "Epoch 2:  30%|██▉       | 54/182 [11:03<24:57, 11.70s/it, training_loss=0.154]\u001b[A\n",
            "Epoch 2:  30%|███       | 55/182 [11:03<25:01, 11.83s/it, training_loss=0.154]\u001b[A\n",
            "Epoch 2:  30%|███       | 55/182 [11:18<25:01, 11.83s/it, training_loss=0.132]\u001b[A\n",
            "Epoch 2:  31%|███       | 56/182 [11:18<26:50, 12.78s/it, training_loss=0.132]\u001b[A\n",
            "Epoch 2:  31%|███       | 56/182 [11:29<26:50, 12.78s/it, training_loss=0.375]\u001b[A\n",
            "Epoch 2:  31%|███▏      | 57/182 [11:29<25:44, 12.36s/it, training_loss=0.375]\u001b[A\n",
            "Epoch 2:  31%|███▏      | 57/182 [11:40<25:44, 12.36s/it, training_loss=0.152]\u001b[A\n",
            "Epoch 2:  32%|███▏      | 58/182 [11:40<24:48, 12.00s/it, training_loss=0.152]\u001b[A\n",
            "Epoch 2:  32%|███▏      | 58/182 [11:53<24:48, 12.00s/it, training_loss=0.204]\u001b[A\n",
            "Epoch 2:  32%|███▏      | 59/182 [11:53<24:56, 12.17s/it, training_loss=0.204]\u001b[A\n",
            "Epoch 2:  32%|███▏      | 59/182 [12:05<24:56, 12.17s/it, training_loss=0.459]\u001b[A\n",
            "Epoch 2:  33%|███▎      | 60/182 [12:05<24:58, 12.28s/it, training_loss=0.459]\u001b[A\n",
            "Epoch 2:  33%|███▎      | 60/182 [12:17<24:58, 12.28s/it, training_loss=0.143]\u001b[A\n",
            "Epoch 2:  34%|███▎      | 61/182 [12:17<24:24, 12.10s/it, training_loss=0.143]\u001b[A\n",
            "Epoch 2:  34%|███▎      | 61/182 [12:28<24:24, 12.10s/it, training_loss=0.283]\u001b[A\n",
            "Epoch 2:  34%|███▍      | 62/182 [12:28<23:28, 11.73s/it, training_loss=0.283]\u001b[A\n",
            "Epoch 2:  34%|███▍      | 62/182 [12:40<23:28, 11.73s/it, training_loss=0.212]\u001b[A\n",
            "Epoch 2:  35%|███▍      | 63/182 [12:40<23:43, 11.97s/it, training_loss=0.212]\u001b[A\n",
            "Epoch 2:  35%|███▍      | 63/182 [12:53<23:43, 11.97s/it, training_loss=0.237]\u001b[A\n",
            "Epoch 2:  35%|███▌      | 64/182 [12:53<23:53, 12.15s/it, training_loss=0.237]\u001b[A\n",
            "Epoch 2:  35%|███▌      | 64/182 [13:05<23:53, 12.15s/it, training_loss=0.179]\u001b[A\n",
            "Epoch 2:  36%|███▌      | 65/182 [13:05<23:33, 12.08s/it, training_loss=0.179]\u001b[A\n",
            "Epoch 2:  36%|███▌      | 65/182 [13:16<23:33, 12.08s/it, training_loss=0.123]\u001b[A\n",
            "Epoch 2:  36%|███▋      | 66/182 [13:16<22:35, 11.69s/it, training_loss=0.123]\u001b[A\n",
            "Epoch 2:  36%|███▋      | 66/182 [13:28<22:35, 11.69s/it, training_loss=0.173]\u001b[A\n",
            "Epoch 2:  37%|███▋      | 67/182 [13:28<22:50, 11.92s/it, training_loss=0.173]\u001b[A\n",
            "Epoch 2:  37%|███▋      | 67/182 [13:41<22:50, 11.92s/it, training_loss=0.172]\u001b[A\n",
            "Epoch 2:  37%|███▋      | 68/182 [13:41<23:00, 12.11s/it, training_loss=0.172]\u001b[A\n",
            "Epoch 2:  37%|███▋      | 68/182 [13:53<23:00, 12.11s/it, training_loss=0.221]\u001b[A\n",
            "Epoch 2:  38%|███▊      | 69/182 [13:53<22:46, 12.09s/it, training_loss=0.221]\u001b[A\n",
            "Epoch 2:  38%|███▊      | 69/182 [14:03<22:46, 12.09s/it, training_loss=0.278]\u001b[A\n",
            "Epoch 2:  38%|███▊      | 70/182 [14:03<21:45, 11.65s/it, training_loss=0.278]\u001b[A\n",
            "Epoch 2:  38%|███▊      | 70/182 [14:16<21:45, 11.65s/it, training_loss=0.170]\u001b[A\n",
            "Epoch 2:  39%|███▉      | 71/182 [14:16<22:02, 11.91s/it, training_loss=0.170]\u001b[A\n",
            "Epoch 2:  39%|███▉      | 71/182 [14:28<22:02, 11.91s/it, training_loss=0.158]\u001b[A\n",
            "Epoch 2:  40%|███▉      | 72/182 [14:28<22:10, 12.10s/it, training_loss=0.158]\u001b[A\n",
            "Epoch 2:  40%|███▉      | 72/182 [14:40<22:10, 12.10s/it, training_loss=0.273]\u001b[A\n",
            "Epoch 2:  40%|████      | 73/182 [14:40<21:57, 12.09s/it, training_loss=0.273]\u001b[A\n",
            "Epoch 2:  40%|████      | 73/182 [14:51<21:57, 12.09s/it, training_loss=0.208]\u001b[A\n",
            "Epoch 2:  41%|████      | 74/182 [14:51<20:57, 11.64s/it, training_loss=0.208]\u001b[A\n",
            "Epoch 2:  41%|████      | 74/182 [15:04<20:57, 11.64s/it, training_loss=0.284]\u001b[A\n",
            "Epoch 2:  41%|████      | 75/182 [15:04<21:11, 11.88s/it, training_loss=0.284]\u001b[A\n",
            "Epoch 2:  41%|████      | 75/182 [15:16<21:11, 11.88s/it, training_loss=0.096]\u001b[A\n",
            "Epoch 2:  42%|████▏     | 76/182 [15:16<21:22, 12.10s/it, training_loss=0.096]\u001b[A\n",
            "Epoch 2:  42%|████▏     | 76/182 [15:28<21:22, 12.10s/it, training_loss=0.335]\u001b[A\n",
            "Epoch 2:  42%|████▏     | 77/182 [15:28<21:15, 12.15s/it, training_loss=0.335]\u001b[A\n",
            "Epoch 2:  42%|████▏     | 77/182 [15:41<21:15, 12.15s/it, training_loss=0.232]\u001b[A\n",
            "Epoch 2:  43%|████▎     | 78/182 [15:41<21:19, 12.31s/it, training_loss=0.232]\u001b[A\n",
            "Epoch 2:  43%|████▎     | 78/182 [15:54<21:19, 12.31s/it, training_loss=0.194]\u001b[A\n",
            "Epoch 2:  43%|████▎     | 79/182 [15:54<21:14, 12.37s/it, training_loss=0.194]\u001b[A\n",
            "Epoch 2:  43%|████▎     | 79/182 [16:06<21:14, 12.37s/it, training_loss=0.269]\u001b[A\n",
            "Epoch 2:  44%|████▍     | 80/182 [16:06<21:06, 12.41s/it, training_loss=0.269]\u001b[A\n",
            "Epoch 2:  44%|████▍     | 80/182 [16:17<21:06, 12.41s/it, training_loss=0.156]\u001b[A\n",
            "Epoch 2:  45%|████▍     | 81/182 [16:17<20:08, 11.96s/it, training_loss=0.156]\u001b[A\n",
            "Epoch 2:  45%|████▍     | 81/182 [16:29<20:08, 11.96s/it, training_loss=0.111]\u001b[A\n",
            "Epoch 2:  45%|████▌     | 82/182 [16:29<19:45, 11.86s/it, training_loss=0.111]\u001b[A\n",
            "Epoch 2:  45%|████▌     | 82/182 [16:41<19:45, 11.86s/it, training_loss=0.211]\u001b[A\n",
            "Epoch 2:  46%|████▌     | 83/182 [16:41<19:54, 12.06s/it, training_loss=0.211]\u001b[A\n",
            "Epoch 2:  46%|████▌     | 83/182 [16:54<19:54, 12.06s/it, training_loss=0.158]\u001b[A\n",
            "Epoch 2:  46%|████▌     | 84/182 [16:54<19:56, 12.21s/it, training_loss=0.158]\u001b[A\n",
            "Epoch 2:  46%|████▌     | 84/182 [17:05<19:56, 12.21s/it, training_loss=0.098]\u001b[A\n",
            "Epoch 2:  47%|████▋     | 85/182 [17:05<19:12, 11.88s/it, training_loss=0.098]\u001b[A\n",
            "Epoch 2:  47%|████▋     | 85/182 [17:16<19:12, 11.88s/it, training_loss=0.385]\u001b[A\n",
            "Epoch 2:  47%|████▋     | 86/182 [17:16<18:47, 11.75s/it, training_loss=0.385]\u001b[A\n",
            "Epoch 2:  47%|████▋     | 86/182 [17:29<18:47, 11.75s/it, training_loss=0.391]\u001b[A\n",
            "Epoch 2:  48%|████▊     | 87/182 [17:29<18:56, 11.97s/it, training_loss=0.391]\u001b[A\n",
            "Epoch 2:  48%|████▊     | 87/182 [17:41<18:56, 11.97s/it, training_loss=0.063]\u001b[A\n",
            "Epoch 2:  48%|████▊     | 88/182 [17:41<19:02, 12.16s/it, training_loss=0.063]\u001b[A\n",
            "Epoch 2:  48%|████▊     | 88/182 [17:53<19:02, 12.16s/it, training_loss=0.169]\u001b[A\n",
            "Epoch 2:  49%|████▉     | 89/182 [17:53<18:30, 11.94s/it, training_loss=0.169]\u001b[A\n",
            "Epoch 2:  49%|████▉     | 89/182 [18:04<18:30, 11.94s/it, training_loss=0.126]\u001b[A\n",
            "Epoch 2:  49%|████▉     | 90/182 [18:04<17:56, 11.70s/it, training_loss=0.126]\u001b[A\n",
            "Epoch 2:  49%|████▉     | 90/182 [18:16<17:56, 11.70s/it, training_loss=0.320]\u001b[A\n",
            "Epoch 2:  50%|█████     | 91/182 [18:16<18:07, 11.95s/it, training_loss=0.320]\u001b[A\n",
            "Epoch 2:  50%|█████     | 91/182 [18:29<18:07, 11.95s/it, training_loss=0.228]\u001b[A\n",
            "Epoch 2:  51%|█████     | 92/182 [18:29<18:10, 12.11s/it, training_loss=0.228]\u001b[A\n",
            "Epoch 2:  51%|█████     | 92/182 [18:40<18:10, 12.11s/it, training_loss=0.233]\u001b[A\n",
            "Epoch 2:  51%|█████     | 93/182 [18:40<17:40, 11.92s/it, training_loss=0.233]\u001b[A\n",
            "Epoch 2:  51%|█████     | 93/182 [18:51<17:40, 11.92s/it, training_loss=0.176]\u001b[A\n",
            "Epoch 2:  52%|█████▏    | 94/182 [18:51<17:05, 11.66s/it, training_loss=0.176]\u001b[A\n",
            "Epoch 2:  52%|█████▏    | 94/182 [19:04<17:05, 11.66s/it, training_loss=0.217]\u001b[A\n",
            "Epoch 2:  52%|█████▏    | 95/182 [19:04<17:14, 11.89s/it, training_loss=0.217]\u001b[A\n",
            "Epoch 2:  52%|█████▏    | 95/182 [19:16<17:14, 11.89s/it, training_loss=0.141]\u001b[A\n",
            "Epoch 2:  53%|█████▎    | 96/182 [19:17<17:20, 12.10s/it, training_loss=0.141]\u001b[A\n",
            "Epoch 2:  53%|█████▎    | 96/182 [19:28<17:20, 12.10s/it, training_loss=0.323]\u001b[A\n",
            "Epoch 2:  53%|█████▎    | 97/182 [19:28<16:57, 11.97s/it, training_loss=0.323]\u001b[A\n",
            "Epoch 2:  53%|█████▎    | 97/182 [19:39<16:57, 11.97s/it, training_loss=0.139]\u001b[A\n",
            "Epoch 2:  54%|█████▍    | 98/182 [19:39<16:18, 11.65s/it, training_loss=0.139]\u001b[A\n",
            "Epoch 2:  54%|█████▍    | 98/182 [19:54<16:18, 11.65s/it, training_loss=0.205]\u001b[A\n",
            "Epoch 2:  54%|█████▍    | 99/182 [19:54<17:25, 12.59s/it, training_loss=0.205]\u001b[A\n",
            "Epoch 2:  54%|█████▍    | 99/182 [20:06<17:25, 12.59s/it, training_loss=0.168]\u001b[A\n",
            "Epoch 2:  55%|█████▍    | 100/182 [20:06<17:10, 12.57s/it, training_loss=0.168]\u001b[A\n",
            "Epoch 2:  55%|█████▍    | 100/182 [20:19<17:10, 12.57s/it, training_loss=0.253]\u001b[A\n",
            "Epoch 2:  55%|█████▌    | 101/182 [20:19<17:03, 12.64s/it, training_loss=0.253]\u001b[A\n",
            "Epoch 2:  55%|█████▌    | 101/182 [20:30<17:03, 12.64s/it, training_loss=0.164]\u001b[A\n",
            "Epoch 2:  56%|█████▌    | 102/182 [20:30<16:19, 12.24s/it, training_loss=0.164]\u001b[A\n",
            "Epoch 2:  56%|█████▌    | 102/182 [20:42<16:19, 12.24s/it, training_loss=0.142]\u001b[A\n",
            "Epoch 2:  57%|█████▋    | 103/182 [20:42<15:44, 11.95s/it, training_loss=0.142]\u001b[A\n",
            "Epoch 2:  57%|█████▋    | 103/182 [20:54<15:44, 11.95s/it, training_loss=0.116]\u001b[A\n",
            "Epoch 2:  57%|█████▋    | 104/182 [20:54<15:47, 12.14s/it, training_loss=0.116]\u001b[A\n",
            "Epoch 2:  57%|█████▋    | 104/182 [21:07<15:47, 12.14s/it, training_loss=0.177]\u001b[A\n",
            "Epoch 2:  58%|█████▊    | 105/182 [21:07<15:42, 12.24s/it, training_loss=0.177]\u001b[A\n",
            "Epoch 2:  58%|█████▊    | 105/182 [21:18<15:42, 12.24s/it, training_loss=0.214]\u001b[A\n",
            "Epoch 2:  58%|█████▊    | 106/182 [21:18<15:07, 11.95s/it, training_loss=0.214]\u001b[A\n",
            "Epoch 2:  58%|█████▊    | 106/182 [21:29<15:07, 11.95s/it, training_loss=0.152]\u001b[A\n",
            "Epoch 2:  59%|█████▉    | 107/182 [21:29<14:39, 11.72s/it, training_loss=0.152]\u001b[A\n",
            "Epoch 2:  59%|█████▉    | 107/182 [21:42<14:39, 11.72s/it, training_loss=0.217]\u001b[A\n",
            "Epoch 2:  59%|█████▉    | 108/182 [21:42<14:44, 11.95s/it, training_loss=0.217]\u001b[A\n",
            "Epoch 2:  59%|█████▉    | 108/182 [21:54<14:44, 11.95s/it, training_loss=0.161]\u001b[A\n",
            "Epoch 2:  60%|█████▉    | 109/182 [21:54<14:45, 12.14s/it, training_loss=0.161]\u001b[A\n",
            "Epoch 2:  60%|█████▉    | 109/182 [22:06<14:45, 12.14s/it, training_loss=0.156]\u001b[A\n",
            "Epoch 2:  60%|██████    | 110/182 [22:06<14:21, 11.96s/it, training_loss=0.156]\u001b[A\n",
            "Epoch 2:  60%|██████    | 110/182 [22:17<14:21, 11.96s/it, training_loss=0.340]\u001b[A\n",
            "Epoch 2:  61%|██████    | 111/182 [22:17<13:46, 11.65s/it, training_loss=0.340]\u001b[A\n",
            "Epoch 2:  61%|██████    | 111/182 [22:29<13:46, 11.65s/it, training_loss=0.122]\u001b[A\n",
            "Epoch 2:  62%|██████▏   | 112/182 [22:29<13:52, 11.90s/it, training_loss=0.122]\u001b[A\n",
            "Epoch 2:  62%|██████▏   | 112/182 [22:42<13:52, 11.90s/it, training_loss=0.128]\u001b[A\n",
            "Epoch 2:  62%|██████▏   | 113/182 [22:42<13:53, 12.08s/it, training_loss=0.128]\u001b[A\n",
            "Epoch 2:  62%|██████▏   | 113/182 [22:54<13:53, 12.08s/it, training_loss=0.173]\u001b[A\n",
            "Epoch 2:  63%|██████▎   | 114/182 [22:54<13:34, 11.98s/it, training_loss=0.173]\u001b[A\n",
            "Epoch 2:  63%|██████▎   | 114/182 [23:04<13:34, 11.98s/it, training_loss=0.172]\u001b[A\n",
            "Epoch 2:  63%|██████▎   | 115/182 [23:04<13:00, 11.65s/it, training_loss=0.172]\u001b[A\n",
            "Epoch 2:  63%|██████▎   | 115/182 [23:17<13:00, 11.65s/it, training_loss=0.105]\u001b[A\n",
            "Epoch 2:  64%|██████▎   | 116/182 [23:17<13:06, 11.91s/it, training_loss=0.105]\u001b[A\n",
            "Epoch 2:  64%|██████▎   | 116/182 [23:30<13:06, 11.91s/it, training_loss=0.160]\u001b[A\n",
            "Epoch 2:  64%|██████▍   | 117/182 [23:30<13:08, 12.13s/it, training_loss=0.160]\u001b[A\n",
            "Epoch 2:  64%|██████▍   | 117/182 [23:42<13:08, 12.13s/it, training_loss=0.104]\u001b[A\n",
            "Epoch 2:  65%|██████▍   | 118/182 [23:42<12:58, 12.16s/it, training_loss=0.104]\u001b[A\n",
            "Epoch 2:  65%|██████▍   | 118/182 [23:52<12:58, 12.16s/it, training_loss=0.163]\u001b[A\n",
            "Epoch 2:  65%|██████▌   | 119/182 [23:52<12:17, 11.71s/it, training_loss=0.163]\u001b[A\n",
            "Epoch 2:  65%|██████▌   | 119/182 [24:05<12:17, 11.71s/it, training_loss=0.121]\u001b[A\n",
            "Epoch 2:  66%|██████▌   | 120/182 [24:05<12:20, 11.94s/it, training_loss=0.121]\u001b[A\n",
            "Epoch 2:  66%|██████▌   | 120/182 [24:20<12:20, 11.94s/it, training_loss=0.180]\u001b[A\n",
            "Epoch 2:  66%|██████▋   | 121/182 [24:20<13:01, 12.81s/it, training_loss=0.180]\u001b[A\n",
            "Epoch 2:  66%|██████▋   | 121/182 [24:30<13:01, 12.81s/it, training_loss=0.107]\u001b[A\n",
            "Epoch 2:  67%|██████▋   | 122/182 [24:30<12:05, 12.08s/it, training_loss=0.107]\u001b[A\n",
            "Epoch 2:  67%|██████▋   | 122/182 [24:43<12:05, 12.08s/it, training_loss=0.098]\u001b[A\n",
            "Epoch 2:  68%|██████▊   | 123/182 [24:43<11:59, 12.19s/it, training_loss=0.098]\u001b[A\n",
            "Epoch 2:  68%|██████▊   | 123/182 [24:55<11:59, 12.19s/it, training_loss=0.109]\u001b[A\n",
            "Epoch 2:  68%|██████▊   | 124/182 [24:55<11:53, 12.30s/it, training_loss=0.109]\u001b[A\n",
            "Epoch 2:  68%|██████▊   | 124/182 [25:08<11:53, 12.30s/it, training_loss=0.161]\u001b[A\n",
            "Epoch 2:  69%|██████▊   | 125/182 [25:08<11:44, 12.35s/it, training_loss=0.161]\u001b[A\n",
            "Epoch 2:  69%|██████▊   | 125/182 [25:18<11:44, 12.35s/it, training_loss=0.143]\u001b[A\n",
            "Epoch 2:  69%|██████▉   | 126/182 [25:18<10:59, 11.77s/it, training_loss=0.143]\u001b[A\n",
            "Epoch 2:  69%|██████▉   | 126/182 [25:30<10:59, 11.77s/it, training_loss=0.060]\u001b[A\n",
            "Epoch 2:  70%|██████▉   | 127/182 [25:30<10:55, 11.93s/it, training_loss=0.060]\u001b[A\n",
            "Epoch 2:  70%|██████▉   | 127/182 [25:43<10:55, 11.93s/it, training_loss=0.300]\u001b[A\n",
            "Epoch 2:  70%|███████   | 128/182 [25:43<10:55, 12.13s/it, training_loss=0.300]\u001b[A\n",
            "Epoch 2:  70%|███████   | 128/182 [25:56<10:55, 12.13s/it, training_loss=0.155]\u001b[A\n",
            "Epoch 2:  71%|███████   | 129/182 [25:56<10:50, 12.27s/it, training_loss=0.155]\u001b[A\n",
            "Epoch 2:  71%|███████   | 129/182 [26:06<10:50, 12.27s/it, training_loss=0.149]\u001b[A\n",
            "Epoch 2:  71%|███████▏  | 130/182 [26:06<10:10, 11.74s/it, training_loss=0.149]\u001b[A\n",
            "Epoch 2:  71%|███████▏  | 130/182 [26:18<10:10, 11.74s/it, training_loss=0.154]\u001b[A\n",
            "Epoch 2:  72%|███████▏  | 131/182 [26:18<10:02, 11.82s/it, training_loss=0.154]\u001b[A\n",
            "Epoch 2:  72%|███████▏  | 131/182 [26:31<10:02, 11.82s/it, training_loss=0.385]\u001b[A\n",
            "Epoch 2:  73%|███████▎  | 132/182 [26:31<10:01, 12.04s/it, training_loss=0.385]\u001b[A\n",
            "Epoch 2:  73%|███████▎  | 132/182 [26:43<10:01, 12.04s/it, training_loss=0.233]\u001b[A\n",
            "Epoch 2:  73%|███████▎  | 133/182 [26:43<09:56, 12.18s/it, training_loss=0.233]\u001b[A\n",
            "Epoch 2:  73%|███████▎  | 133/182 [26:54<09:56, 12.18s/it, training_loss=0.212]\u001b[A\n",
            "Epoch 2:  74%|███████▎  | 134/182 [26:54<09:22, 11.73s/it, training_loss=0.212]\u001b[A\n",
            "Epoch 2:  74%|███████▎  | 134/182 [27:06<09:22, 11.73s/it, training_loss=0.080]\u001b[A\n",
            "Epoch 2:  74%|███████▍  | 135/182 [27:06<09:13, 11.77s/it, training_loss=0.080]\u001b[A\n",
            "Epoch 2:  74%|███████▍  | 135/182 [27:18<09:13, 11.77s/it, training_loss=0.196]\u001b[A\n",
            "Epoch 2:  75%|███████▍  | 136/182 [27:18<09:12, 12.02s/it, training_loss=0.196]\u001b[A\n",
            "Epoch 2:  75%|███████▍  | 136/182 [27:31<09:12, 12.02s/it, training_loss=0.140]\u001b[A\n",
            "Epoch 2:  75%|███████▌  | 137/182 [27:31<09:08, 12.20s/it, training_loss=0.140]\u001b[A\n",
            "Epoch 2:  75%|███████▌  | 137/182 [27:42<09:08, 12.20s/it, training_loss=0.269]\u001b[A\n",
            "Epoch 2:  76%|███████▌  | 138/182 [27:42<08:41, 11.86s/it, training_loss=0.269]\u001b[A\n",
            "Epoch 2:  76%|███████▌  | 138/182 [27:53<08:41, 11.86s/it, training_loss=0.079]\u001b[A\n",
            "Epoch 2:  76%|███████▋  | 139/182 [27:53<08:25, 11.75s/it, training_loss=0.079]\u001b[A\n",
            "Epoch 2:  76%|███████▋  | 139/182 [28:06<08:25, 11.75s/it, training_loss=0.206]\u001b[A\n",
            "Epoch 2:  77%|███████▋  | 140/182 [28:06<08:23, 12.00s/it, training_loss=0.206]\u001b[A\n",
            "Epoch 2:  77%|███████▋  | 140/182 [28:19<08:23, 12.00s/it, training_loss=0.132]\u001b[A\n",
            "Epoch 2:  77%|███████▋  | 141/182 [28:19<08:19, 12.19s/it, training_loss=0.132]\u001b[A\n",
            "Epoch 2:  77%|███████▋  | 141/182 [28:30<08:19, 12.19s/it, training_loss=0.187]\u001b[A\n",
            "Epoch 2:  78%|███████▊  | 142/182 [28:30<07:58, 11.96s/it, training_loss=0.187]\u001b[A\n",
            "Epoch 2:  78%|███████▊  | 142/182 [28:44<07:58, 11.96s/it, training_loss=0.225]\u001b[A\n",
            "Epoch 2:  79%|███████▊  | 143/182 [28:44<08:06, 12.47s/it, training_loss=0.225]\u001b[A\n",
            "Epoch 2:  79%|███████▊  | 143/182 [28:56<08:06, 12.47s/it, training_loss=0.102]\u001b[A\n",
            "Epoch 2:  79%|███████▉  | 144/182 [28:56<07:54, 12.50s/it, training_loss=0.102]\u001b[A\n",
            "Epoch 2:  79%|███████▉  | 144/182 [29:09<07:54, 12.50s/it, training_loss=0.153]\u001b[A\n",
            "Epoch 2:  80%|███████▉  | 145/182 [29:09<07:42, 12.51s/it, training_loss=0.153]\u001b[A\n",
            "Epoch 2:  80%|███████▉  | 145/182 [29:19<07:42, 12.51s/it, training_loss=0.057]\u001b[A\n",
            "Epoch 2:  80%|████████  | 146/182 [29:19<07:09, 11.93s/it, training_loss=0.057]\u001b[A\n",
            "Epoch 2:  80%|████████  | 146/182 [29:31<07:09, 11.93s/it, training_loss=0.229]\u001b[A\n",
            "Epoch 2:  81%|████████  | 147/182 [29:31<06:58, 11.96s/it, training_loss=0.229]\u001b[A\n",
            "Epoch 2:  81%|████████  | 147/182 [29:44<06:58, 11.96s/it, training_loss=0.181]\u001b[A\n",
            "Epoch 2:  81%|████████▏ | 148/182 [29:44<06:53, 12.15s/it, training_loss=0.181]\u001b[A\n",
            "Epoch 2:  81%|████████▏ | 148/182 [29:57<06:53, 12.15s/it, training_loss=0.212]\u001b[A\n",
            "Epoch 2:  82%|████████▏ | 149/182 [29:57<06:45, 12.29s/it, training_loss=0.212]\u001b[A\n",
            "Epoch 2:  82%|████████▏ | 149/182 [30:08<06:45, 12.29s/it, training_loss=0.086]\u001b[A\n",
            "Epoch 2:  82%|████████▏ | 150/182 [30:08<06:20, 11.90s/it, training_loss=0.086]\u001b[A\n",
            "Epoch 2:  82%|████████▏ | 150/182 [30:19<06:20, 11.90s/it, training_loss=0.253]\u001b[A\n",
            "Epoch 2:  83%|████████▎ | 151/182 [30:19<06:06, 11.81s/it, training_loss=0.253]\u001b[A\n",
            "Epoch 2:  83%|████████▎ | 151/182 [30:32<06:06, 11.81s/it, training_loss=0.188]\u001b[A\n",
            "Epoch 2:  84%|████████▎ | 152/182 [30:32<06:01, 12.04s/it, training_loss=0.188]\u001b[A\n",
            "Epoch 2:  84%|████████▎ | 152/182 [30:44<06:01, 12.04s/it, training_loss=0.190]\u001b[A\n",
            "Epoch 2:  84%|████████▍ | 153/182 [30:44<05:53, 12.20s/it, training_loss=0.190]\u001b[A\n",
            "Epoch 2:  84%|████████▍ | 153/182 [30:56<05:53, 12.20s/it, training_loss=0.087]\u001b[A\n",
            "Epoch 2:  85%|████████▍ | 154/182 [30:56<05:32, 11.89s/it, training_loss=0.087]\u001b[A\n",
            "Epoch 2:  85%|████████▍ | 154/182 [31:07<05:32, 11.89s/it, training_loss=0.221]\u001b[A\n",
            "Epoch 2:  85%|████████▌ | 155/182 [31:07<05:16, 11.73s/it, training_loss=0.221]\u001b[A\n",
            "Epoch 2:  85%|████████▌ | 155/182 [31:19<05:16, 11.73s/it, training_loss=0.290]\u001b[A\n",
            "Epoch 2:  86%|████████▌ | 156/182 [31:19<05:11, 11.97s/it, training_loss=0.290]\u001b[A\n",
            "Epoch 2:  86%|████████▌ | 156/182 [31:32<05:11, 11.97s/it, training_loss=0.118]\u001b[A\n",
            "Epoch 2:  86%|████████▋ | 157/182 [31:32<05:04, 12.17s/it, training_loss=0.118]\u001b[A\n",
            "Epoch 2:  86%|████████▋ | 157/182 [31:44<05:04, 12.17s/it, training_loss=0.167]\u001b[A\n",
            "Epoch 2:  87%|████████▋ | 158/182 [31:44<04:48, 12.02s/it, training_loss=0.167]\u001b[A\n",
            "Epoch 2:  87%|████████▋ | 158/182 [31:55<04:48, 12.02s/it, training_loss=0.154]\u001b[A\n",
            "Epoch 2:  87%|████████▋ | 159/182 [31:55<04:29, 11.70s/it, training_loss=0.154]\u001b[A\n",
            "Epoch 2:  87%|████████▋ | 159/182 [32:07<04:29, 11.70s/it, training_loss=0.098]\u001b[A\n",
            "Epoch 2:  88%|████████▊ | 160/182 [32:07<04:22, 11.94s/it, training_loss=0.098]\u001b[A\n",
            "Epoch 2:  88%|████████▊ | 160/182 [32:20<04:22, 11.94s/it, training_loss=0.193]\u001b[A\n",
            "Epoch 2:  88%|████████▊ | 161/182 [32:20<04:14, 12.11s/it, training_loss=0.193]\u001b[A\n",
            "Epoch 2:  88%|████████▊ | 161/182 [32:32<04:14, 12.11s/it, training_loss=0.129]\u001b[A\n",
            "Epoch 2:  89%|████████▉ | 162/182 [32:32<04:01, 12.06s/it, training_loss=0.129]\u001b[A\n",
            "Epoch 2:  89%|████████▉ | 162/182 [32:42<04:01, 12.06s/it, training_loss=0.134]\u001b[A\n",
            "Epoch 2:  90%|████████▉ | 163/182 [32:42<03:41, 11.67s/it, training_loss=0.134]\u001b[A\n",
            "Epoch 2:  90%|████████▉ | 163/182 [32:55<03:41, 11.67s/it, training_loss=0.117]\u001b[A\n",
            "Epoch 2:  90%|█████████ | 164/182 [32:55<03:35, 11.95s/it, training_loss=0.117]\u001b[A\n",
            "Epoch 2:  90%|█████████ | 164/182 [33:10<03:35, 11.95s/it, training_loss=0.086]\u001b[A\n",
            "Epoch 2:  91%|█████████ | 165/182 [33:10<03:37, 12.78s/it, training_loss=0.086]\u001b[A\n",
            "Epoch 2:  91%|█████████ | 165/182 [33:22<03:37, 12.78s/it, training_loss=0.156]\u001b[A\n",
            "Epoch 2:  91%|█████████ | 166/182 [33:22<03:23, 12.71s/it, training_loss=0.156]\u001b[A\n",
            "Epoch 2:  91%|█████████ | 166/182 [33:33<03:23, 12.71s/it, training_loss=0.180]\u001b[A\n",
            "Epoch 2:  92%|█████████▏| 167/182 [33:33<03:00, 12.06s/it, training_loss=0.180]\u001b[A\n",
            "Epoch 2:  92%|█████████▏| 167/182 [33:45<03:00, 12.06s/it, training_loss=0.125]\u001b[A\n",
            "Epoch 2:  92%|█████████▏| 168/182 [33:45<02:48, 12.07s/it, training_loss=0.125]\u001b[A\n",
            "Epoch 2:  92%|█████████▏| 168/182 [33:57<02:48, 12.07s/it, training_loss=0.127]\u001b[A\n",
            "Epoch 2:  93%|█████████▎| 169/182 [33:57<02:38, 12.22s/it, training_loss=0.127]\u001b[A\n",
            "Epoch 2:  93%|█████████▎| 169/182 [34:10<02:38, 12.22s/it, training_loss=0.277]\u001b[A\n",
            "Epoch 2:  93%|█████████▎| 170/182 [34:10<02:28, 12.34s/it, training_loss=0.277]\u001b[A\n",
            "Epoch 2:  93%|█████████▎| 170/182 [34:21<02:28, 12.34s/it, training_loss=0.059]\u001b[A\n",
            "Epoch 2:  94%|█████████▍| 171/182 [34:21<02:10, 11.83s/it, training_loss=0.059]\u001b[A\n",
            "Epoch 2:  94%|█████████▍| 171/182 [34:33<02:10, 11.83s/it, training_loss=0.064]\u001b[A\n",
            "Epoch 2:  95%|█████████▍| 172/182 [34:33<01:58, 11.82s/it, training_loss=0.064]\u001b[A\n",
            "Epoch 2:  95%|█████████▍| 172/182 [34:45<01:58, 11.82s/it, training_loss=0.438]\u001b[A\n",
            "Epoch 2:  95%|█████████▌| 173/182 [34:45<01:48, 12.04s/it, training_loss=0.438]\u001b[A\n",
            "Epoch 2:  95%|█████████▌| 173/182 [34:58<01:48, 12.04s/it, training_loss=0.164]\u001b[A\n",
            "Epoch 2:  96%|█████████▌| 174/182 [34:58<01:37, 12.19s/it, training_loss=0.164]\u001b[A\n",
            "Epoch 2:  96%|█████████▌| 174/182 [35:09<01:37, 12.19s/it, training_loss=0.045]\u001b[A\n",
            "Epoch 2:  96%|█████████▌| 175/182 [35:09<01:22, 11.79s/it, training_loss=0.045]\u001b[A\n",
            "Epoch 2:  96%|█████████▌| 175/182 [35:20<01:22, 11.79s/it, training_loss=0.138]\u001b[A\n",
            "Epoch 2:  97%|█████████▋| 176/182 [35:20<01:10, 11.74s/it, training_loss=0.138]\u001b[A\n",
            "Epoch 2:  97%|█████████▋| 176/182 [35:33<01:10, 11.74s/it, training_loss=0.055]\u001b[A\n",
            "Epoch 2:  97%|█████████▋| 177/182 [35:33<01:00, 12.03s/it, training_loss=0.055]\u001b[A\n",
            "Epoch 2:  97%|█████████▋| 177/182 [35:46<01:00, 12.03s/it, training_loss=0.078]\u001b[A\n",
            "Epoch 2:  98%|█████████▊| 178/182 [35:46<00:48, 12.24s/it, training_loss=0.078]\u001b[A\n",
            "Epoch 2:  98%|█████████▊| 178/182 [35:57<00:48, 12.24s/it, training_loss=0.061]\u001b[A\n",
            "Epoch 2:  98%|█████████▊| 179/182 [35:57<00:35, 11.92s/it, training_loss=0.061]\u001b[A\n",
            "Epoch 2:  98%|█████████▊| 179/182 [36:08<00:35, 11.92s/it, training_loss=0.050]\u001b[A\n",
            "Epoch 2:  99%|█████████▉| 180/182 [36:08<00:23, 11.75s/it, training_loss=0.050]\u001b[A\n",
            "Epoch 2:  99%|█████████▉| 180/182 [36:21<00:23, 11.75s/it, training_loss=0.125]\u001b[A\n",
            "Epoch 2:  99%|█████████▉| 181/182 [36:21<00:11, 11.99s/it, training_loss=0.125]\u001b[A\n",
            "Epoch 2:  99%|█████████▉| 181/182 [36:23<00:11, 11.99s/it, training_loss=0.112]\u001b[A\n",
            "Epoch 2: 100%|██████████| 182/182 [36:23<00:00,  8.99s/it, training_loss=0.112]\u001b[A\n",
            " 12%|█▎        | 1/8 [1:16:25<4:39:39, 2397.02s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            " Epoch {epoch}\n",
            "Training loss: {loss_train_avg}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "  0%|          | 0/46 [00:00<?, ?it/s]\u001b[A\n",
            "  2%|▏         | 1/46 [00:03<02:56,  3.91s/it]\u001b[A\n",
            "  4%|▍         | 2/46 [00:07<02:34,  3.52s/it]\u001b[A\n",
            "  7%|▋         | 3/46 [00:11<02:48,  3.91s/it]\u001b[A\n",
            "  9%|▊         | 4/46 [00:16<03:04,  4.39s/it]\u001b[A\n",
            " 11%|█         | 5/46 [00:20<02:48,  4.12s/it]\u001b[A\n",
            " 13%|█▎        | 6/46 [00:23<02:32,  3.80s/it]\u001b[A\n",
            " 15%|█▌        | 7/46 [00:26<02:20,  3.61s/it]\u001b[A\n",
            " 17%|█▋        | 8/46 [00:31<02:29,  3.94s/it]\u001b[A\n",
            " 20%|█▉        | 9/46 [00:35<02:27,  3.98s/it]\u001b[A\n",
            " 22%|██▏       | 10/46 [00:38<02:14,  3.74s/it]\u001b[A\n",
            " 24%|██▍       | 11/46 [00:41<02:05,  3.59s/it]\u001b[A\n",
            " 26%|██▌       | 12/46 [00:46<02:08,  3.77s/it]\u001b[A\n",
            " 28%|██▊       | 13/46 [00:50<02:12,  4.01s/it]\u001b[A\n",
            " 30%|███       | 14/46 [00:54<02:04,  3.90s/it]\u001b[A\n",
            " 33%|███▎      | 15/46 [00:59<02:12,  4.26s/it]\u001b[A\n",
            " 35%|███▍      | 16/46 [01:04<02:16,  4.55s/it]\u001b[A\n",
            " 37%|███▋      | 17/46 [01:08<02:02,  4.24s/it]\u001b[A\n",
            " 39%|███▉      | 18/46 [01:11<01:50,  3.94s/it]\u001b[A\n",
            " 41%|████▏     | 19/46 [01:14<01:40,  3.72s/it]\u001b[A\n",
            " 43%|████▎     | 20/46 [01:19<01:44,  4.04s/it]\u001b[A\n",
            " 46%|████▌     | 21/46 [01:23<01:39,  3.99s/it]\u001b[A\n",
            " 48%|████▊     | 22/46 [01:26<01:30,  3.75s/it]\u001b[A\n",
            " 50%|█████     | 23/46 [01:29<01:22,  3.59s/it]\u001b[A\n",
            " 52%|█████▏    | 24/46 [01:33<01:23,  3.81s/it]\u001b[A\n",
            " 54%|█████▍    | 25/46 [01:38<01:24,  4.02s/it]\u001b[A\n",
            " 57%|█████▋    | 26/46 [01:41<01:15,  3.77s/it]\u001b[A\n",
            " 59%|█████▊    | 27/46 [01:44<01:08,  3.61s/it]\u001b[A\n",
            " 61%|██████    | 28/46 [01:48<01:06,  3.69s/it]\u001b[A\n",
            " 63%|██████▎   | 29/46 [01:53<01:08,  4.02s/it]\u001b[A\n",
            " 65%|██████▌   | 30/46 [01:56<01:00,  3.78s/it]\u001b[A\n",
            " 67%|██████▋   | 31/46 [01:59<00:54,  3.61s/it]\u001b[A\n",
            " 70%|██████▉   | 32/46 [02:03<00:49,  3.54s/it]\u001b[A\n",
            " 72%|███████▏  | 33/46 [02:08<00:52,  4.06s/it]\u001b[A\n",
            " 74%|███████▍  | 34/46 [02:11<00:45,  3.81s/it]\u001b[A\n",
            " 76%|███████▌  | 35/46 [02:15<00:40,  3.64s/it]\u001b[A\n",
            " 78%|███████▊  | 36/46 [02:18<00:35,  3.51s/it]\u001b[A\n",
            " 80%|████████  | 37/46 [02:23<00:35,  3.96s/it]\u001b[A\n",
            " 83%|████████▎ | 38/46 [02:26<00:31,  3.88s/it]\u001b[A\n",
            " 85%|████████▍ | 39/46 [02:30<00:25,  3.68s/it]\u001b[A\n",
            " 87%|████████▋ | 40/46 [02:33<00:21,  3.54s/it]\u001b[A\n",
            " 89%|████████▉ | 41/46 [02:37<00:19,  3.86s/it]\u001b[A\n",
            " 91%|█████████▏| 42/46 [02:42<00:15,  3.94s/it]\u001b[A\n",
            " 93%|█████████▎| 43/46 [02:45<00:11,  3.72s/it]\u001b[A\n",
            " 96%|█████████▌| 44/46 [02:48<00:07,  3.56s/it]\u001b[A\n",
            " 98%|█████████▊| 45/46 [02:52<00:03,  3.71s/it]\u001b[A\n",
            "100%|██████████| 46/46 [02:54<00:00,  3.80s/it]\n",
            " 25%|██▌       | 2/8 [1:19:20<3:57:43, 2377.27s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy:113/128\n",
            " -> 0.8828125\n",
            "Accuracy:84/107\n",
            " -> 0.7850467289719626\n",
            "Accuracy:78/128\n",
            " -> 0.609375\n",
            "Validation loss: 0.5827840845222059\n",
            "F1 Score (weighted): 0.7543843782971115\n",
            "Accuracy Score: 0.7575757575757576\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "Epoch 3:   0%|          | 0/182 [00:00<?, ?it/s]\u001b[A\n",
            "Epoch 3:   0%|          | 0/182 [00:10<?, ?it/s, training_loss=0.120]\u001b[A\n",
            "Epoch 3:   1%|          | 1/182 [00:10<32:28, 10.76s/it, training_loss=0.120]\u001b[A\n",
            "Epoch 3:   1%|          | 1/182 [00:23<32:28, 10.76s/it, training_loss=0.066]\u001b[A\n",
            "Epoch 3:   1%|          | 2/182 [00:23<35:46, 11.93s/it, training_loss=0.066]\u001b[A\n",
            "Epoch 3:   1%|          | 2/182 [00:36<35:46, 11.93s/it, training_loss=0.135]\u001b[A\n",
            "Epoch 3:   2%|▏         | 3/182 [00:36<36:24, 12.20s/it, training_loss=0.135]\u001b[A\n",
            "Epoch 3:   2%|▏         | 3/182 [00:48<36:24, 12.20s/it, training_loss=0.076]\u001b[A\n",
            "Epoch 3:   2%|▏         | 4/182 [00:48<36:00, 12.14s/it, training_loss=0.076]\u001b[A\n",
            "Epoch 3:   2%|▏         | 4/182 [00:58<36:00, 12.14s/it, training_loss=0.159]\u001b[A\n",
            "Epoch 3:   3%|▎         | 5/182 [00:58<34:11, 11.59s/it, training_loss=0.159]\u001b[A\n",
            "Epoch 3:   3%|▎         | 5/182 [01:11<34:11, 11.59s/it, training_loss=0.126]\u001b[A\n",
            "Epoch 3:   3%|▎         | 6/182 [01:11<34:51, 11.88s/it, training_loss=0.126]\u001b[A\n",
            "Epoch 3:   3%|▎         | 6/182 [01:23<34:51, 11.88s/it, training_loss=0.130]\u001b[A\n",
            "Epoch 3:   4%|▍         | 7/182 [01:23<35:14, 12.08s/it, training_loss=0.130]\u001b[A\n",
            "Epoch 3:   4%|▍         | 7/182 [01:35<35:14, 12.08s/it, training_loss=0.107]\u001b[A\n",
            "Epoch 3:   4%|▍         | 8/182 [01:35<34:59, 12.06s/it, training_loss=0.107]\u001b[A\n",
            "Epoch 3:   4%|▍         | 8/182 [01:46<34:59, 12.06s/it, training_loss=0.071]\u001b[A\n",
            "Epoch 3:   5%|▍         | 9/182 [01:46<33:30, 11.62s/it, training_loss=0.071]\u001b[A\n",
            "Epoch 3:   5%|▍         | 9/182 [01:58<33:30, 11.62s/it, training_loss=0.085]\u001b[A\n",
            "Epoch 3:   5%|▌         | 10/182 [01:58<34:07, 11.90s/it, training_loss=0.085]\u001b[A\n",
            "Epoch 3:   5%|▌         | 10/182 [02:11<34:07, 11.90s/it, training_loss=0.229]\u001b[A\n",
            "Epoch 3:   6%|▌         | 11/182 [02:11<34:30, 12.11s/it, training_loss=0.229]\u001b[A\n",
            "Epoch 3:   6%|▌         | 11/182 [02:23<34:30, 12.11s/it, training_loss=0.163]\u001b[A\n",
            "Epoch 3:   7%|▋         | 12/182 [02:23<34:28, 12.17s/it, training_loss=0.163]\u001b[A\n",
            "Epoch 3:   7%|▋         | 12/182 [02:37<34:28, 12.17s/it, training_loss=0.275]\u001b[A\n",
            "Epoch 3:   7%|▋         | 13/182 [02:37<35:42, 12.68s/it, training_loss=0.275]\u001b[A\n",
            "Epoch 3:   7%|▋         | 13/182 [02:49<35:42, 12.68s/it, training_loss=0.080]\u001b[A\n",
            "Epoch 3:   8%|▊         | 14/182 [02:49<34:28, 12.31s/it, training_loss=0.080]\u001b[A\n",
            "Epoch 3:   8%|▊         | 14/182 [03:01<34:28, 12.31s/it, training_loss=0.143]\u001b[A\n",
            "Epoch 3:   8%|▊         | 15/182 [03:01<34:24, 12.36s/it, training_loss=0.143]\u001b[A\n",
            "Epoch 3:   8%|▊         | 15/182 [03:14<34:24, 12.36s/it, training_loss=0.072]\u001b[A\n",
            "Epoch 3:   9%|▉         | 16/182 [03:14<34:25, 12.44s/it, training_loss=0.072]\u001b[A\n",
            "Epoch 3:   9%|▉         | 16/182 [03:26<34:25, 12.44s/it, training_loss=0.293]\u001b[A\n",
            "Epoch 3:   9%|▉         | 17/182 [03:26<33:48, 12.29s/it, training_loss=0.293]\u001b[A\n",
            "Epoch 3:   9%|▉         | 17/182 [03:36<33:48, 12.29s/it, training_loss=0.078]\u001b[A\n",
            "Epoch 3:  10%|▉         | 18/182 [03:36<32:18, 11.82s/it, training_loss=0.078]\u001b[A\n",
            "Epoch 3:  10%|▉         | 18/182 [03:49<32:18, 11.82s/it, training_loss=0.126]\u001b[A\n",
            "Epoch 3:  10%|█         | 19/182 [03:49<32:37, 12.01s/it, training_loss=0.126]\u001b[A\n",
            "Epoch 3:  10%|█         | 19/182 [04:01<32:37, 12.01s/it, training_loss=0.188]\u001b[A\n",
            "Epoch 3:  11%|█         | 20/182 [04:01<32:49, 12.16s/it, training_loss=0.188]\u001b[A\n",
            "Epoch 3:  11%|█         | 20/182 [04:13<32:49, 12.16s/it, training_loss=0.128]\u001b[A\n",
            "Epoch 3:  12%|█▏        | 21/182 [04:13<32:34, 12.14s/it, training_loss=0.128]\u001b[A\n",
            "Epoch 3:  12%|█▏        | 21/182 [04:24<32:34, 12.14s/it, training_loss=0.163]\u001b[A\n",
            "Epoch 3:  12%|█▏        | 22/182 [04:24<31:11, 11.69s/it, training_loss=0.163]\u001b[A\n",
            "Epoch 3:  12%|█▏        | 22/182 [04:36<31:11, 11.69s/it, training_loss=0.107]\u001b[A\n",
            "Epoch 3:  13%|█▎        | 23/182 [04:36<31:36, 11.93s/it, training_loss=0.107]\u001b[A\n",
            "Epoch 3:  13%|█▎        | 23/182 [04:49<31:36, 11.93s/it, training_loss=0.113]\u001b[A\n",
            "Epoch 3:  13%|█▎        | 24/182 [04:49<31:54, 12.11s/it, training_loss=0.113]\u001b[A\n",
            "Epoch 3:  13%|█▎        | 24/182 [05:01<31:54, 12.11s/it, training_loss=0.118]\u001b[A\n",
            "Epoch 3:  14%|█▎        | 25/182 [05:01<31:49, 12.16s/it, training_loss=0.118]\u001b[A\n",
            "Epoch 3:  14%|█▎        | 25/182 [05:12<31:49, 12.16s/it, training_loss=0.170]\u001b[A\n",
            "Epoch 3:  14%|█▍        | 26/182 [05:12<30:17, 11.65s/it, training_loss=0.170]\u001b[A\n",
            "Epoch 3:  14%|█▍        | 26/182 [05:24<30:17, 11.65s/it, training_loss=0.177]\u001b[A\n",
            "Epoch 3:  15%|█▍        | 27/182 [05:24<30:45, 11.91s/it, training_loss=0.177]\u001b[A\n",
            "Epoch 3:  15%|█▍        | 27/182 [05:37<30:45, 11.91s/it, training_loss=0.035]\u001b[A\n",
            "Epoch 3:  15%|█▌        | 28/182 [05:37<31:02, 12.09s/it, training_loss=0.035]\u001b[A\n",
            "Epoch 3:  15%|█▌        | 28/182 [05:49<31:02, 12.09s/it, training_loss=0.052]\u001b[A\n",
            "Epoch 3:  16%|█▌        | 29/182 [05:49<31:04, 12.19s/it, training_loss=0.052]\u001b[A\n",
            "Epoch 3:  16%|█▌        | 29/182 [06:00<31:04, 12.19s/it, training_loss=0.145]\u001b[A\n",
            "Epoch 3:  16%|█▋        | 30/182 [06:00<29:34, 11.67s/it, training_loss=0.145]\u001b[A\n",
            "Epoch 3:  16%|█▋        | 30/182 [06:12<29:34, 11.67s/it, training_loss=0.128]\u001b[A\n",
            "Epoch 3:  17%|█▋        | 31/182 [06:12<29:56, 11.90s/it, training_loss=0.128]\u001b[A\n",
            "Epoch 3:  17%|█▋        | 31/182 [06:25<29:56, 11.90s/it, training_loss=0.079]\u001b[A\n",
            "Epoch 3:  18%|█▊        | 32/182 [06:25<30:13, 12.09s/it, training_loss=0.079]\u001b[A\n",
            "Epoch 3:  18%|█▊        | 32/182 [06:37<30:13, 12.09s/it, training_loss=0.111]\u001b[A\n",
            "Epoch 3:  18%|█▊        | 33/182 [06:37<30:21, 12.22s/it, training_loss=0.111]\u001b[A\n",
            "Epoch 3:  18%|█▊        | 33/182 [06:49<30:21, 12.22s/it, training_loss=0.069]\u001b[A\n",
            "Epoch 3:  19%|█▊        | 34/182 [06:49<29:54, 12.13s/it, training_loss=0.069]\u001b[A\n",
            "Epoch 3:  19%|█▊        | 34/182 [07:03<29:54, 12.13s/it, training_loss=0.107]\u001b[A\n",
            "Epoch 3:  19%|█▉        | 35/182 [07:03<31:05, 12.69s/it, training_loss=0.107]\u001b[A\n",
            "Epoch 3:  19%|█▉        | 35/182 [07:15<31:05, 12.69s/it, training_loss=0.157]\u001b[A\n",
            "Epoch 3:  20%|█▉        | 36/182 [07:15<30:40, 12.61s/it, training_loss=0.157]\u001b[A\n",
            "Epoch 3:  20%|█▉        | 36/182 [07:28<30:40, 12.61s/it, training_loss=0.217]\u001b[A\n",
            "Epoch 3:  20%|██        | 37/182 [07:28<30:24, 12.58s/it, training_loss=0.217]\u001b[A\n",
            "Epoch 3:  20%|██        | 37/182 [07:41<30:24, 12.58s/it, training_loss=0.131]\u001b[A\n",
            "Epoch 3:  21%|██        | 38/182 [07:41<30:08, 12.56s/it, training_loss=0.131]\u001b[A\n",
            "Epoch 3:  21%|██        | 38/182 [07:51<30:08, 12.56s/it, training_loss=0.045]\u001b[A\n",
            "Epoch 3:  21%|██▏       | 39/182 [07:51<28:27, 11.94s/it, training_loss=0.045]\u001b[A\n",
            "Epoch 3:  21%|██▏       | 39/182 [08:03<28:27, 11.94s/it, training_loss=0.083]\u001b[A\n",
            "Epoch 3:  22%|██▏       | 40/182 [08:03<28:29, 12.04s/it, training_loss=0.083]\u001b[A\n",
            "Epoch 3:  22%|██▏       | 40/182 [08:16<28:29, 12.04s/it, training_loss=0.107]\u001b[A\n",
            "Epoch 3:  23%|██▎       | 41/182 [08:16<28:41, 12.21s/it, training_loss=0.107]\u001b[A\n",
            "Epoch 3:  23%|██▎       | 41/182 [08:28<28:41, 12.21s/it, training_loss=0.047]\u001b[A\n",
            "Epoch 3:  23%|██▎       | 42/182 [08:28<28:43, 12.31s/it, training_loss=0.047]\u001b[A\n",
            "Epoch 3:  23%|██▎       | 42/182 [08:39<28:43, 12.31s/it, training_loss=0.112]\u001b[A\n",
            "Epoch 3:  24%|██▎       | 43/182 [08:39<27:16, 11.77s/it, training_loss=0.112]\u001b[A\n",
            "Epoch 3:  24%|██▎       | 43/182 [08:51<27:16, 11.77s/it, training_loss=0.111]\u001b[A\n",
            "Epoch 3:  24%|██▍       | 44/182 [08:51<27:16, 11.86s/it, training_loss=0.111]\u001b[A\n",
            "Epoch 3:  24%|██▍       | 44/182 [09:04<27:16, 11.86s/it, training_loss=0.059]\u001b[A\n",
            "Epoch 3:  25%|██▍       | 45/182 [09:04<27:33, 12.07s/it, training_loss=0.059]\u001b[A\n",
            "Epoch 3:  25%|██▍       | 45/182 [09:16<27:33, 12.07s/it, training_loss=0.118]\u001b[A\n",
            "Epoch 3:  25%|██▌       | 46/182 [09:16<27:43, 12.23s/it, training_loss=0.118]\u001b[A\n",
            "Epoch 3:  25%|██▌       | 46/182 [09:27<27:43, 12.23s/it, training_loss=0.030]\u001b[A\n",
            "Epoch 3:  26%|██▌       | 47/182 [09:27<26:33, 11.81s/it, training_loss=0.030]\u001b[A\n",
            "Epoch 3:  26%|██▌       | 47/182 [09:41<26:33, 11.81s/it, training_loss=0.052]\u001b[A\n",
            "Epoch 3:  26%|██▋       | 48/182 [09:41<27:52, 12.48s/it, training_loss=0.052]\u001b[A\n",
            "Epoch 3:  26%|██▋       | 48/182 [09:53<27:52, 12.48s/it, training_loss=0.351]\u001b[A\n",
            "Epoch 3:  27%|██▋       | 49/182 [09:54<27:38, 12.47s/it, training_loss=0.351]\u001b[A\n",
            "Epoch 3:  27%|██▋       | 49/182 [10:06<27:38, 12.47s/it, training_loss=0.076]\u001b[A\n",
            "Epoch 3:  27%|██▋       | 50/182 [10:06<27:31, 12.51s/it, training_loss=0.076]\u001b[A\n",
            "Epoch 3:  27%|██▋       | 50/182 [10:19<27:31, 12.51s/it, training_loss=0.167]\u001b[A\n",
            "Epoch 3:  28%|██▊       | 51/182 [10:19<27:18, 12.51s/it, training_loss=0.167]\u001b[A\n",
            "Epoch 3:  28%|██▊       | 51/182 [10:29<27:18, 12.51s/it, training_loss=0.101]\u001b[A\n",
            "Epoch 3:  29%|██▊       | 52/182 [10:29<25:46, 11.89s/it, training_loss=0.101]\u001b[A\n",
            "Epoch 3:  29%|██▊       | 52/182 [10:41<25:46, 11.89s/it, training_loss=0.134]\u001b[A\n",
            "Epoch 3:  29%|██▉       | 53/182 [10:41<25:47, 12.00s/it, training_loss=0.134]\u001b[A\n",
            "Epoch 3:  29%|██▉       | 53/182 [10:54<25:47, 12.00s/it, training_loss=0.193]\u001b[A\n",
            "Epoch 3:  30%|██▉       | 54/182 [10:54<26:00, 12.19s/it, training_loss=0.193]\u001b[A\n",
            "Epoch 3:  30%|██▉       | 54/182 [11:07<26:00, 12.19s/it, training_loss=0.222]\u001b[A\n",
            "Epoch 3:  30%|███       | 55/182 [11:07<26:03, 12.31s/it, training_loss=0.222]\u001b[A\n",
            "Epoch 3:  30%|███       | 55/182 [11:17<26:03, 12.31s/it, training_loss=0.098]\u001b[A\n",
            "Epoch 3:  31%|███       | 56/182 [11:17<24:52, 11.84s/it, training_loss=0.098]\u001b[A\n",
            "Epoch 3:  31%|███       | 56/182 [11:31<24:52, 11.84s/it, training_loss=0.054]\u001b[A\n",
            "Epoch 3:  31%|███▏      | 57/182 [11:31<25:45, 12.36s/it, training_loss=0.054]\u001b[A\n",
            "Epoch 3:  31%|███▏      | 57/182 [11:44<25:45, 12.36s/it, training_loss=0.112]\u001b[A\n",
            "Epoch 3:  32%|███▏      | 58/182 [11:44<26:03, 12.61s/it, training_loss=0.112]\u001b[A\n",
            "Epoch 3:  32%|███▏      | 58/182 [11:57<26:03, 12.61s/it, training_loss=0.172]\u001b[A\n",
            "Epoch 3:  32%|███▏      | 59/182 [11:57<25:49, 12.60s/it, training_loss=0.172]\u001b[A\n",
            "Epoch 3:  32%|███▏      | 59/182 [12:09<25:49, 12.60s/it, training_loss=0.210]\u001b[A\n",
            "Epoch 3:  33%|███▎      | 60/182 [12:09<25:22, 12.48s/it, training_loss=0.210]\u001b[A\n",
            "Epoch 3:  33%|███▎      | 60/182 [12:19<25:22, 12.48s/it, training_loss=0.406]\u001b[A\n",
            "Epoch 3:  34%|███▎      | 61/182 [12:19<24:02, 11.92s/it, training_loss=0.406]\u001b[A\n",
            "Epoch 3:  34%|███▎      | 61/182 [12:32<24:02, 11.92s/it, training_loss=0.102]\u001b[A\n",
            "Epoch 3:  34%|███▍      | 62/182 [12:32<24:12, 12.10s/it, training_loss=0.102]\u001b[A\n",
            "Epoch 3:  34%|███▍      | 62/182 [12:45<24:12, 12.10s/it, training_loss=0.175]\u001b[A\n",
            "Epoch 3:  35%|███▍      | 63/182 [12:45<24:18, 12.25s/it, training_loss=0.175]\u001b[A\n",
            "Epoch 3:  35%|███▍      | 63/182 [12:57<24:18, 12.25s/it, training_loss=0.152]\u001b[A\n",
            "Epoch 3:  35%|███▌      | 64/182 [12:57<24:06, 12.26s/it, training_loss=0.152]\u001b[A\n",
            "Epoch 3:  35%|███▌      | 64/182 [13:07<24:06, 12.26s/it, training_loss=0.284]\u001b[A\n",
            "Epoch 3:  36%|███▌      | 65/182 [13:07<22:52, 11.73s/it, training_loss=0.284]\u001b[A\n",
            "Epoch 3:  36%|███▌      | 65/182 [13:20<22:52, 11.73s/it, training_loss=0.163]\u001b[A\n",
            "Epoch 3:  36%|███▋      | 66/182 [13:20<23:12, 12.00s/it, training_loss=0.163]\u001b[A\n",
            "Epoch 3:  36%|███▋      | 66/182 [13:33<23:12, 12.00s/it, training_loss=0.056]\u001b[A\n",
            "Epoch 3:  37%|███▋      | 67/182 [13:33<23:22, 12.20s/it, training_loss=0.056]\u001b[A\n",
            "Epoch 3:  37%|███▋      | 67/182 [13:45<23:22, 12.20s/it, training_loss=0.076]\u001b[A\n",
            "Epoch 3:  37%|███▋      | 68/182 [13:45<23:24, 12.32s/it, training_loss=0.076]\u001b[A\n",
            "Epoch 3:  37%|███▋      | 68/182 [13:56<23:24, 12.32s/it, training_loss=0.124]\u001b[A\n",
            "Epoch 3:  38%|███▊      | 69/182 [13:56<22:10, 11.77s/it, training_loss=0.124]\u001b[A\n",
            "Epoch 3:  38%|███▊      | 69/182 [14:08<22:10, 11.77s/it, training_loss=0.205]\u001b[A\n",
            "Epoch 3:  38%|███▊      | 70/182 [14:08<22:20, 11.97s/it, training_loss=0.205]\u001b[A\n",
            "Epoch 3:  38%|███▊      | 70/182 [14:21<22:20, 11.97s/it, training_loss=0.084]\u001b[A\n",
            "Epoch 3:  39%|███▉      | 71/182 [14:21<22:29, 12.16s/it, training_loss=0.084]\u001b[A\n",
            "Epoch 3:  39%|███▉      | 71/182 [14:33<22:29, 12.16s/it, training_loss=0.116]\u001b[A\n",
            "Epoch 3:  40%|███▉      | 72/182 [14:33<22:32, 12.30s/it, training_loss=0.116]\u001b[A\n",
            "Epoch 3:  40%|███▉      | 72/182 [14:44<22:32, 12.30s/it, training_loss=0.069]\u001b[A\n",
            "Epoch 3:  40%|████      | 73/182 [14:44<21:28, 11.82s/it, training_loss=0.069]\u001b[A\n",
            "Epoch 3:  40%|████      | 73/182 [14:56<21:28, 11.82s/it, training_loss=0.057]\u001b[A\n",
            "Epoch 3:  41%|████      | 74/182 [14:56<21:23, 11.88s/it, training_loss=0.057]\u001b[A\n",
            "Epoch 3:  41%|████      | 74/182 [15:09<21:23, 11.88s/it, training_loss=0.170]\u001b[A\n",
            "Epoch 3:  41%|████      | 75/182 [15:09<21:33, 12.09s/it, training_loss=0.170]\u001b[A\n",
            "Epoch 3:  41%|████      | 75/182 [15:21<21:33, 12.09s/it, training_loss=0.063]\u001b[A\n",
            "Epoch 3:  42%|████▏     | 76/182 [15:21<21:39, 12.26s/it, training_loss=0.063]\u001b[A\n",
            "Epoch 3:  42%|████▏     | 76/182 [15:32<21:39, 12.26s/it, training_loss=0.055]\u001b[A\n",
            "Epoch 3:  42%|████▏     | 77/182 [15:32<20:44, 11.86s/it, training_loss=0.055]\u001b[A\n",
            "Epoch 3:  42%|████▏     | 77/182 [15:44<20:44, 11.86s/it, training_loss=0.075]\u001b[A\n",
            "Epoch 3:  43%|████▎     | 78/182 [15:44<20:28, 11.81s/it, training_loss=0.075]\u001b[A\n",
            "Epoch 3:  43%|████▎     | 78/182 [15:57<20:28, 11.81s/it, training_loss=0.145]\u001b[A\n",
            "Epoch 3:  43%|████▎     | 79/182 [15:57<20:40, 12.04s/it, training_loss=0.145]\u001b[A\n",
            "Epoch 3:  43%|████▎     | 79/182 [16:11<20:40, 12.04s/it, training_loss=0.043]\u001b[A\n",
            "Epoch 3:  44%|████▍     | 80/182 [16:11<21:34, 12.70s/it, training_loss=0.043]\u001b[A\n",
            "Epoch 3:  44%|████▍     | 80/182 [16:22<21:34, 12.70s/it, training_loss=0.273]\u001b[A\n",
            "Epoch 3:  45%|████▍     | 81/182 [16:22<20:35, 12.23s/it, training_loss=0.273]\u001b[A\n",
            "Epoch 3:  45%|████▍     | 81/182 [16:34<20:35, 12.23s/it, training_loss=0.158]\u001b[A\n",
            "Epoch 3:  45%|████▌     | 82/182 [16:34<20:30, 12.31s/it, training_loss=0.158]\u001b[A\n",
            "Epoch 3:  45%|████▌     | 82/182 [16:47<20:30, 12.31s/it, training_loss=0.244]\u001b[A\n",
            "Epoch 3:  46%|████▌     | 83/182 [16:47<20:26, 12.39s/it, training_loss=0.244]\u001b[A\n",
            "Epoch 3:  46%|████▌     | 83/182 [16:59<20:26, 12.39s/it, training_loss=0.029]\u001b[A\n",
            "Epoch 3:  46%|████▌     | 84/182 [16:59<20:07, 12.32s/it, training_loss=0.029]\u001b[A\n",
            "Epoch 3:  46%|████▌     | 84/182 [17:10<20:07, 12.32s/it, training_loss=0.047]\u001b[A\n",
            "Epoch 3:  47%|████▋     | 85/182 [17:10<19:09, 11.85s/it, training_loss=0.047]\u001b[A\n",
            "Epoch 3:  47%|████▋     | 85/182 [17:22<19:09, 11.85s/it, training_loss=0.059]\u001b[A\n",
            "Epoch 3:  47%|████▋     | 86/182 [17:22<19:18, 12.07s/it, training_loss=0.059]\u001b[A\n",
            "Epoch 3:  47%|████▋     | 86/182 [17:35<19:18, 12.07s/it, training_loss=0.175]\u001b[A\n",
            "Epoch 3:  48%|████▊     | 87/182 [17:35<19:19, 12.21s/it, training_loss=0.175]\u001b[A\n",
            "Epoch 3:  48%|████▊     | 87/182 [17:47<19:19, 12.21s/it, training_loss=0.095]\u001b[A\n",
            "Epoch 3:  48%|████▊     | 88/182 [17:47<19:11, 12.25s/it, training_loss=0.095]\u001b[A\n",
            "Epoch 3:  48%|████▊     | 88/182 [17:58<19:11, 12.25s/it, training_loss=0.104]\u001b[A\n",
            "Epoch 3:  49%|████▉     | 89/182 [17:58<18:08, 11.71s/it, training_loss=0.104]\u001b[A\n",
            "Epoch 3:  49%|████▉     | 89/182 [18:10<18:08, 11.71s/it, training_loss=0.154]\u001b[A\n",
            "Epoch 3:  49%|████▉     | 90/182 [18:10<18:19, 11.95s/it, training_loss=0.154]\u001b[A\n",
            "Epoch 3:  49%|████▉     | 90/182 [18:23<18:19, 11.95s/it, training_loss=0.136]\u001b[A\n",
            "Epoch 3:  50%|█████     | 91/182 [18:23<18:27, 12.17s/it, training_loss=0.136]\u001b[A\n",
            "Epoch 3:  50%|█████     | 91/182 [18:36<18:27, 12.17s/it, training_loss=0.033]\u001b[A\n",
            "Epoch 3:  51%|█████     | 92/182 [18:36<18:24, 12.27s/it, training_loss=0.033]\u001b[A\n",
            "Epoch 3:  51%|█████     | 92/182 [18:46<18:24, 12.27s/it, training_loss=0.095]\u001b[A\n",
            "Epoch 3:  51%|█████     | 93/182 [18:46<17:22, 11.71s/it, training_loss=0.095]\u001b[A\n",
            "Epoch 3:  51%|█████     | 93/182 [18:58<17:22, 11.71s/it, training_loss=0.133]\u001b[A\n",
            "Epoch 3:  52%|█████▏    | 94/182 [18:58<17:25, 11.88s/it, training_loss=0.133]\u001b[A\n",
            "Epoch 3:  52%|█████▏    | 94/182 [19:11<17:25, 11.88s/it, training_loss=0.247]\u001b[A\n",
            "Epoch 3:  52%|█████▏    | 95/182 [19:11<17:32, 12.10s/it, training_loss=0.247]\u001b[A\n",
            "Epoch 3:  52%|█████▏    | 95/182 [19:23<17:32, 12.10s/it, training_loss=0.043]\u001b[A\n",
            "Epoch 3:  53%|█████▎    | 96/182 [19:23<17:30, 12.22s/it, training_loss=0.043]\u001b[A\n",
            "Epoch 3:  53%|█████▎    | 96/182 [19:34<17:30, 12.22s/it, training_loss=0.114]\u001b[A\n",
            "Epoch 3:  53%|█████▎    | 97/182 [19:34<16:31, 11.67s/it, training_loss=0.114]\u001b[A\n",
            "Epoch 3:  53%|█████▎    | 97/182 [19:46<16:31, 11.67s/it, training_loss=0.062]\u001b[A\n",
            "Epoch 3:  54%|█████▍    | 98/182 [19:46<16:33, 11.83s/it, training_loss=0.062]\u001b[A\n",
            "Epoch 3:  54%|█████▍    | 98/182 [19:58<16:33, 11.83s/it, training_loss=0.164]\u001b[A\n",
            "Epoch 3:  54%|█████▍    | 99/182 [19:58<16:40, 12.06s/it, training_loss=0.164]\u001b[A\n",
            "Epoch 3:  54%|█████▍    | 99/182 [20:11<16:40, 12.06s/it, training_loss=0.205]\u001b[A\n",
            "Epoch 3:  55%|█████▍    | 100/182 [20:11<16:41, 12.21s/it, training_loss=0.205]\u001b[A\n",
            "Epoch 3:  55%|█████▍    | 100/182 [20:22<16:41, 12.21s/it, training_loss=0.123]\u001b[A\n",
            "Epoch 3:  55%|█████▌    | 101/182 [20:22<15:49, 11.72s/it, training_loss=0.123]\u001b[A\n",
            "Epoch 3:  55%|█████▌    | 101/182 [20:34<15:49, 11.72s/it, training_loss=0.129]\u001b[A\n",
            "Epoch 3:  56%|█████▌    | 102/182 [20:34<15:45, 11.82s/it, training_loss=0.129]\u001b[A\n",
            "Epoch 3:  56%|█████▌    | 102/182 [20:49<15:45, 11.82s/it, training_loss=0.260]\u001b[A\n",
            "Epoch 3:  57%|█████▋    | 103/182 [20:49<16:48, 12.77s/it, training_loss=0.260]\u001b[A\n",
            "Epoch 3:  57%|█████▋    | 103/182 [21:00<16:48, 12.77s/it, training_loss=0.095]\u001b[A\n",
            "Epoch 3:  57%|█████▋    | 104/182 [21:00<16:06, 12.40s/it, training_loss=0.095]\u001b[A\n",
            "Epoch 3:  57%|█████▋    | 104/182 [21:11<16:06, 12.40s/it, training_loss=0.127]\u001b[A\n",
            "Epoch 3:  58%|█████▊    | 105/182 [21:11<15:23, 11.99s/it, training_loss=0.127]\u001b[A\n",
            "Epoch 3:  58%|█████▊    | 105/182 [21:24<15:23, 11.99s/it, training_loss=0.039]\u001b[A\n",
            "Epoch 3:  58%|█████▊    | 106/182 [21:24<15:23, 12.15s/it, training_loss=0.039]\u001b[A\n",
            "Epoch 3:  58%|█████▊    | 106/182 [21:36<15:23, 12.15s/it, training_loss=0.047]\u001b[A\n",
            "Epoch 3:  59%|█████▉    | 107/182 [21:36<15:19, 12.26s/it, training_loss=0.047]\u001b[A\n",
            "Epoch 3:  59%|█████▉    | 107/182 [21:48<15:19, 12.26s/it, training_loss=0.107]\u001b[A\n",
            "Epoch 3:  59%|█████▉    | 108/182 [21:48<14:57, 12.12s/it, training_loss=0.107]\u001b[A\n",
            "Epoch 3:  59%|█████▉    | 108/182 [21:59<14:57, 12.12s/it, training_loss=0.156]\u001b[A\n",
            "Epoch 3:  60%|█████▉    | 109/182 [21:59<14:18, 11.75s/it, training_loss=0.156]\u001b[A\n",
            "Epoch 3:  60%|█████▉    | 109/182 [22:12<14:18, 11.75s/it, training_loss=0.035]\u001b[A\n",
            "Epoch 3:  60%|██████    | 110/182 [22:12<14:23, 12.00s/it, training_loss=0.035]\u001b[A\n",
            "Epoch 3:  60%|██████    | 110/182 [22:24<14:23, 12.00s/it, training_loss=0.211]\u001b[A\n",
            "Epoch 3:  61%|██████    | 111/182 [22:24<14:25, 12.19s/it, training_loss=0.211]\u001b[A\n",
            "Epoch 3:  61%|██████    | 111/182 [22:36<14:25, 12.19s/it, training_loss=0.169]\u001b[A\n",
            "Epoch 3:  62%|██████▏   | 112/182 [22:36<14:11, 12.17s/it, training_loss=0.169]\u001b[A\n",
            "Epoch 3:  62%|██████▏   | 112/182 [22:47<14:11, 12.17s/it, training_loss=0.028]\u001b[A\n",
            "Epoch 3:  62%|██████▏   | 113/182 [22:47<13:28, 11.72s/it, training_loss=0.028]\u001b[A\n",
            "Epoch 3:  62%|██████▏   | 113/182 [22:59<13:28, 11.72s/it, training_loss=0.145]\u001b[A\n",
            "Epoch 3:  63%|██████▎   | 114/182 [22:59<13:33, 11.96s/it, training_loss=0.145]\u001b[A\n",
            "Epoch 3:  63%|██████▎   | 114/182 [23:12<13:33, 11.96s/it, training_loss=0.265]\u001b[A\n",
            "Epoch 3:  63%|██████▎   | 115/182 [23:12<13:32, 12.13s/it, training_loss=0.265]\u001b[A\n",
            "Epoch 3:  63%|██████▎   | 115/182 [23:24<13:32, 12.13s/it, training_loss=0.089]\u001b[A\n",
            "Epoch 3:  64%|██████▎   | 116/182 [23:24<13:20, 12.13s/it, training_loss=0.089]\u001b[A\n",
            "Epoch 3:  64%|██████▎   | 116/182 [23:35<13:20, 12.13s/it, training_loss=0.031]\u001b[A\n",
            "Epoch 3:  64%|██████▍   | 117/182 [23:35<12:37, 11.66s/it, training_loss=0.031]\u001b[A\n",
            "Epoch 3:  64%|██████▍   | 117/182 [23:47<12:37, 11.66s/it, training_loss=0.083]\u001b[A\n",
            "Epoch 3:  65%|██████▍   | 118/182 [23:47<12:42, 11.91s/it, training_loss=0.083]\u001b[A\n",
            "Epoch 3:  65%|██████▍   | 118/182 [24:00<12:42, 11.91s/it, training_loss=0.121]\u001b[A\n",
            "Epoch 3:  65%|██████▌   | 119/182 [24:00<12:43, 12.12s/it, training_loss=0.121]\u001b[A\n",
            "Epoch 3:  65%|██████▌   | 119/182 [24:12<12:43, 12.12s/it, training_loss=0.230]\u001b[A\n",
            "Epoch 3:  66%|██████▌   | 120/182 [24:12<12:34, 12.17s/it, training_loss=0.230]\u001b[A\n",
            "Epoch 3:  66%|██████▌   | 120/182 [24:23<12:34, 12.17s/it, training_loss=0.199]\u001b[A\n",
            "Epoch 3:  66%|██████▋   | 121/182 [24:23<11:51, 11.66s/it, training_loss=0.199]\u001b[A\n",
            "Epoch 3:  66%|██████▋   | 121/182 [24:35<11:51, 11.66s/it, training_loss=0.045]\u001b[A\n",
            "Epoch 3:  67%|██████▋   | 122/182 [24:35<11:55, 11.93s/it, training_loss=0.045]\u001b[A\n",
            "Epoch 3:  67%|██████▋   | 122/182 [24:48<11:55, 11.93s/it, training_loss=0.028]\u001b[A\n",
            "Epoch 3:  68%|██████▊   | 123/182 [24:48<11:55, 12.13s/it, training_loss=0.028]\u001b[A\n",
            "Epoch 3:  68%|██████▊   | 123/182 [25:00<11:55, 12.13s/it, training_loss=0.052]\u001b[A\n",
            "Epoch 3:  68%|██████▊   | 124/182 [25:00<11:48, 12.22s/it, training_loss=0.052]\u001b[A\n",
            "Epoch 3:  68%|██████▊   | 124/182 [25:11<11:48, 12.22s/it, training_loss=0.130]\u001b[A\n",
            "Epoch 3:  69%|██████▊   | 125/182 [25:11<11:09, 11.74s/it, training_loss=0.130]\u001b[A\n",
            "Epoch 3:  69%|██████▊   | 125/182 [25:25<11:09, 11.74s/it, training_loss=0.149]\u001b[A\n",
            "Epoch 3:  69%|██████▉   | 126/182 [25:25<11:45, 12.60s/it, training_loss=0.149]\u001b[A\n",
            "Epoch 3:  69%|██████▉   | 126/182 [25:38<11:45, 12.60s/it, training_loss=0.145]\u001b[A\n",
            "Epoch 3:  70%|██████▉   | 127/182 [25:38<11:32, 12.60s/it, training_loss=0.145]\u001b[A\n",
            "Epoch 3:  70%|██████▉   | 127/182 [25:49<11:32, 12.60s/it, training_loss=0.088]\u001b[A\n",
            "Epoch 3:  70%|███████   | 128/182 [25:49<10:51, 12.06s/it, training_loss=0.088]\u001b[A\n",
            "Epoch 3:  70%|███████   | 128/182 [26:00<10:51, 12.06s/it, training_loss=0.041]\u001b[A\n",
            "Epoch 3:  71%|███████   | 129/182 [26:00<10:33, 11.95s/it, training_loss=0.041]\u001b[A\n",
            "Epoch 3:  71%|███████   | 129/182 [26:13<10:33, 11.95s/it, training_loss=0.036]\u001b[A\n",
            "Epoch 3:  71%|███████▏  | 130/182 [26:13<10:31, 12.15s/it, training_loss=0.036]\u001b[A\n",
            "Epoch 3:  71%|███████▏  | 130/182 [26:26<10:31, 12.15s/it, training_loss=0.115]\u001b[A\n",
            "Epoch 3:  72%|███████▏  | 131/182 [26:26<10:27, 12.31s/it, training_loss=0.115]\u001b[A\n",
            "Epoch 3:  72%|███████▏  | 131/182 [26:37<10:27, 12.31s/it, training_loss=0.037]\u001b[A\n",
            "Epoch 3:  73%|███████▎  | 132/182 [26:37<09:59, 11.98s/it, training_loss=0.037]\u001b[A\n",
            "Epoch 3:  73%|███████▎  | 132/182 [26:48<09:59, 11.98s/it, training_loss=0.069]\u001b[A\n",
            "Epoch 3:  73%|███████▎  | 133/182 [26:48<09:39, 11.84s/it, training_loss=0.069]\u001b[A\n",
            "Epoch 3:  73%|███████▎  | 133/182 [27:01<09:39, 11.84s/it, training_loss=0.024]\u001b[A\n",
            "Epoch 3:  74%|███████▎  | 134/182 [27:01<09:39, 12.07s/it, training_loss=0.024]\u001b[A\n",
            "Epoch 3:  74%|███████▎  | 134/182 [27:14<09:39, 12.07s/it, training_loss=0.096]\u001b[A\n",
            "Epoch 3:  74%|███████▍  | 135/182 [27:14<09:35, 12.25s/it, training_loss=0.096]\u001b[A\n",
            "Epoch 3:  74%|███████▍  | 135/182 [27:25<09:35, 12.25s/it, training_loss=0.108]\u001b[A\n",
            "Epoch 3:  75%|███████▍  | 136/182 [27:25<09:15, 12.08s/it, training_loss=0.108]\u001b[A\n",
            "Epoch 3:  75%|███████▍  | 136/182 [27:37<09:15, 12.08s/it, training_loss=0.102]\u001b[A\n",
            "Epoch 3:  75%|███████▌  | 137/182 [27:37<08:50, 11.78s/it, training_loss=0.102]\u001b[A\n",
            "Epoch 3:  75%|███████▌  | 137/182 [27:49<08:50, 11.78s/it, training_loss=0.197]\u001b[A\n",
            "Epoch 3:  76%|███████▌  | 138/182 [27:49<08:51, 12.07s/it, training_loss=0.197]\u001b[A\n",
            "Epoch 3:  76%|███████▌  | 138/182 [28:02<08:51, 12.07s/it, training_loss=0.022]\u001b[A\n",
            "Epoch 3:  76%|███████▋  | 139/182 [28:02<08:47, 12.28s/it, training_loss=0.022]\u001b[A\n",
            "Epoch 3:  76%|███████▋  | 139/182 [28:14<08:47, 12.28s/it, training_loss=0.083]\u001b[A\n",
            "Epoch 3:  77%|███████▋  | 140/182 [28:14<08:34, 12.26s/it, training_loss=0.083]\u001b[A\n",
            "Epoch 3:  77%|███████▋  | 140/182 [28:25<08:34, 12.26s/it, training_loss=0.027]\u001b[A\n",
            "Epoch 3:  77%|███████▋  | 141/182 [28:25<08:07, 11.90s/it, training_loss=0.027]\u001b[A\n",
            "Epoch 3:  77%|███████▋  | 141/182 [28:38<08:07, 11.90s/it, training_loss=0.084]\u001b[A\n",
            "Epoch 3:  78%|███████▊  | 142/182 [28:38<08:06, 12.16s/it, training_loss=0.084]\u001b[A\n",
            "Epoch 3:  78%|███████▊  | 142/182 [28:51<08:06, 12.16s/it, training_loss=0.029]\u001b[A\n",
            "Epoch 3:  79%|███████▊  | 143/182 [28:51<07:58, 12.28s/it, training_loss=0.029]\u001b[A\n",
            "Epoch 3:  79%|███████▊  | 143/182 [29:03<07:58, 12.28s/it, training_loss=0.101]\u001b[A\n",
            "Epoch 3:  79%|███████▉  | 144/182 [29:03<07:46, 12.28s/it, training_loss=0.101]\u001b[A\n",
            "Epoch 3:  79%|███████▉  | 144/182 [29:13<07:46, 12.28s/it, training_loss=0.070]\u001b[A\n",
            "Epoch 3:  80%|███████▉  | 145/182 [29:13<07:15, 11.77s/it, training_loss=0.070]\u001b[A\n",
            "Epoch 3:  80%|███████▉  | 145/182 [29:26<07:15, 11.77s/it, training_loss=0.229]\u001b[A\n",
            "Epoch 3:  80%|████████  | 146/182 [29:26<07:11, 11.99s/it, training_loss=0.229]\u001b[A\n",
            "Epoch 3:  80%|████████  | 146/182 [29:39<07:11, 11.99s/it, training_loss=0.064]\u001b[A\n",
            "Epoch 3:  81%|████████  | 147/182 [29:39<07:05, 12.17s/it, training_loss=0.064]\u001b[A\n",
            "Epoch 3:  81%|████████  | 147/182 [29:51<07:05, 12.17s/it, training_loss=0.057]\u001b[A\n",
            "Epoch 3:  81%|████████▏ | 148/182 [29:51<06:59, 12.35s/it, training_loss=0.057]\u001b[A\n",
            "Epoch 3:  81%|████████▏ | 148/182 [30:04<06:59, 12.35s/it, training_loss=0.121]\u001b[A\n",
            "Epoch 3:  82%|████████▏ | 149/182 [30:04<06:48, 12.36s/it, training_loss=0.121]\u001b[A\n",
            "Epoch 3:  82%|████████▏ | 149/182 [30:16<06:48, 12.36s/it, training_loss=0.311]\u001b[A\n",
            "Epoch 3:  82%|████████▏ | 150/182 [30:16<06:37, 12.43s/it, training_loss=0.311]\u001b[A\n",
            "Epoch 3:  82%|████████▏ | 150/182 [30:29<06:37, 12.43s/it, training_loss=0.111]\u001b[A\n",
            "Epoch 3:  83%|████████▎ | 151/182 [30:29<06:27, 12.52s/it, training_loss=0.111]\u001b[A\n",
            "Epoch 3:  83%|████████▎ | 151/182 [30:42<06:27, 12.52s/it, training_loss=0.056]\u001b[A\n",
            "Epoch 3:  84%|████████▎ | 152/182 [30:42<06:15, 12.52s/it, training_loss=0.056]\u001b[A\n",
            "Epoch 3:  84%|████████▎ | 152/182 [30:52<06:15, 12.52s/it, training_loss=0.055]\u001b[A\n",
            "Epoch 3:  84%|████████▍ | 153/182 [30:52<05:45, 11.90s/it, training_loss=0.055]\u001b[A\n",
            "Epoch 3:  84%|████████▍ | 153/182 [31:04<05:45, 11.90s/it, training_loss=0.217]\u001b[A\n",
            "Epoch 3:  85%|████████▍ | 154/182 [31:04<05:36, 12.01s/it, training_loss=0.217]\u001b[A\n",
            "Epoch 3:  85%|████████▍ | 154/182 [31:17<05:36, 12.01s/it, training_loss=0.228]\u001b[A\n",
            "Epoch 3:  85%|████████▌ | 155/182 [31:17<05:28, 12.18s/it, training_loss=0.228]\u001b[A\n",
            "Epoch 3:  85%|████████▌ | 155/182 [31:29<05:28, 12.18s/it, training_loss=0.082]\u001b[A\n",
            "Epoch 3:  86%|████████▌ | 156/182 [31:29<05:19, 12.29s/it, training_loss=0.082]\u001b[A\n",
            "Epoch 3:  86%|████████▌ | 156/182 [31:40<05:19, 12.29s/it, training_loss=0.061]\u001b[A\n",
            "Epoch 3:  86%|████████▋ | 157/182 [31:40<04:54, 11.76s/it, training_loss=0.061]\u001b[A\n",
            "Epoch 3:  86%|████████▋ | 157/182 [31:52<04:54, 11.76s/it, training_loss=0.278]\u001b[A\n",
            "Epoch 3:  87%|████████▋ | 158/182 [31:52<04:44, 11.84s/it, training_loss=0.278]\u001b[A\n",
            "Epoch 3:  87%|████████▋ | 158/182 [32:05<04:44, 11.84s/it, training_loss=0.018]\u001b[A\n",
            "Epoch 3:  87%|████████▋ | 159/182 [32:05<04:37, 12.08s/it, training_loss=0.018]\u001b[A\n",
            "Epoch 3:  87%|████████▋ | 159/182 [32:17<04:37, 12.08s/it, training_loss=0.146]\u001b[A\n",
            "Epoch 3:  88%|████████▊ | 160/182 [32:17<04:30, 12.29s/it, training_loss=0.146]\u001b[A\n",
            "Epoch 3:  88%|████████▊ | 160/182 [32:28<04:30, 12.29s/it, training_loss=0.081]\u001b[A\n",
            "Epoch 3:  88%|████████▊ | 161/182 [32:28<04:10, 11.93s/it, training_loss=0.081]\u001b[A\n",
            "Epoch 3:  88%|████████▊ | 161/182 [32:40<04:10, 11.93s/it, training_loss=0.114]\u001b[A\n",
            "Epoch 3:  89%|████████▉ | 162/182 [32:40<03:57, 11.86s/it, training_loss=0.114]\u001b[A\n",
            "Epoch 3:  89%|████████▉ | 162/182 [32:53<03:57, 11.86s/it, training_loss=0.022]\u001b[A\n",
            "Epoch 3:  90%|████████▉ | 163/182 [32:53<03:49, 12.08s/it, training_loss=0.022]\u001b[A\n",
            "Epoch 3:  90%|████████▉ | 163/182 [33:05<03:49, 12.08s/it, training_loss=0.075]\u001b[A\n",
            "Epoch 3:  90%|█████████ | 164/182 [33:05<03:40, 12.24s/it, training_loss=0.075]\u001b[A\n",
            "Epoch 3:  90%|█████████ | 164/182 [33:17<03:40, 12.24s/it, training_loss=0.056]\u001b[A\n",
            "Epoch 3:  91%|█████████ | 165/182 [33:17<03:24, 12.02s/it, training_loss=0.056]\u001b[A\n",
            "Epoch 3:  91%|█████████ | 165/182 [33:28<03:24, 12.02s/it, training_loss=0.225]\u001b[A\n",
            "Epoch 3:  91%|█████████ | 166/182 [33:28<03:09, 11.82s/it, training_loss=0.225]\u001b[A\n",
            "Epoch 3:  91%|█████████ | 166/182 [33:41<03:09, 11.82s/it, training_loss=0.134]\u001b[A\n",
            "Epoch 3:  92%|█████████▏| 167/182 [33:41<03:00, 12.05s/it, training_loss=0.134]\u001b[A\n",
            "Epoch 3:  92%|█████████▏| 167/182 [33:53<03:00, 12.05s/it, training_loss=0.036]\u001b[A\n",
            "Epoch 3:  92%|█████████▏| 168/182 [33:54<02:51, 12.23s/it, training_loss=0.036]\u001b[A\n",
            "Epoch 3:  92%|█████████▏| 168/182 [34:05<02:51, 12.23s/it, training_loss=0.034]\u001b[A\n",
            "Epoch 3:  93%|█████████▎| 169/182 [34:05<02:37, 12.09s/it, training_loss=0.034]\u001b[A\n",
            "Epoch 3:  93%|█████████▎| 169/182 [34:16<02:37, 12.09s/it, training_loss=0.095]\u001b[A\n",
            "Epoch 3:  93%|█████████▎| 170/182 [34:16<02:21, 11.79s/it, training_loss=0.095]\u001b[A\n",
            "Epoch 3:  93%|█████████▎| 170/182 [34:29<02:21, 11.79s/it, training_loss=0.103]\u001b[A\n",
            "Epoch 3:  94%|█████████▍| 171/182 [34:29<02:12, 12.07s/it, training_loss=0.103]\u001b[A\n",
            "Epoch 3:  94%|█████████▍| 171/182 [34:44<02:12, 12.07s/it, training_loss=0.156]\u001b[A\n",
            "Epoch 3:  95%|█████████▍| 172/182 [34:44<02:09, 13.00s/it, training_loss=0.156]\u001b[A\n",
            "Epoch 3:  95%|█████████▍| 172/182 [34:55<02:09, 13.00s/it, training_loss=0.279]\u001b[A\n",
            "Epoch 3:  95%|█████████▌| 173/182 [34:55<01:50, 12.26s/it, training_loss=0.279]\u001b[A\n",
            "Epoch 3:  95%|█████████▌| 173/182 [35:07<01:50, 12.26s/it, training_loss=0.175]\u001b[A\n",
            "Epoch 3:  96%|█████████▌| 174/182 [35:07<01:38, 12.25s/it, training_loss=0.175]\u001b[A\n",
            "Epoch 3:  96%|█████████▌| 174/182 [35:20<01:38, 12.25s/it, training_loss=0.205]\u001b[A\n",
            "Epoch 3:  96%|█████████▌| 175/182 [35:20<01:26, 12.36s/it, training_loss=0.205]\u001b[A\n",
            "Epoch 3:  96%|█████████▌| 175/182 [35:32<01:26, 12.36s/it, training_loss=0.100]\u001b[A\n",
            "Epoch 3:  97%|█████████▋| 176/182 [35:32<01:14, 12.44s/it, training_loss=0.100]\u001b[A\n",
            "Epoch 3:  97%|█████████▋| 176/182 [35:43<01:14, 12.44s/it, training_loss=0.180]\u001b[A\n",
            "Epoch 3:  97%|█████████▋| 177/182 [35:43<00:59, 11.95s/it, training_loss=0.180]\u001b[A\n",
            "Epoch 3:  97%|█████████▋| 177/182 [35:55<00:59, 11.95s/it, training_loss=0.024]\u001b[A\n",
            "Epoch 3:  98%|█████████▊| 178/182 [35:55<00:47, 11.92s/it, training_loss=0.024]\u001b[A\n",
            "Epoch 3:  98%|█████████▊| 178/182 [36:07<00:47, 11.92s/it, training_loss=0.096]\u001b[A\n",
            "Epoch 3:  98%|█████████▊| 179/182 [36:07<00:36, 12.12s/it, training_loss=0.096]\u001b[A\n",
            "Epoch 3:  98%|█████████▊| 179/182 [36:20<00:36, 12.12s/it, training_loss=0.224]\u001b[A\n",
            "Epoch 3:  99%|█████████▉| 180/182 [36:20<00:24, 12.29s/it, training_loss=0.224]\u001b[A\n",
            "Epoch 3:  99%|█████████▉| 180/182 [36:31<00:24, 12.29s/it, training_loss=0.019]\u001b[A\n",
            "Epoch 3:  99%|█████████▉| 181/182 [36:31<00:11, 11.95s/it, training_loss=0.019]\u001b[A\n",
            "Epoch 3:  99%|█████████▉| 181/182 [36:34<00:11, 11.95s/it, training_loss=0.239]\u001b[A\n",
            "Epoch 3: 100%|██████████| 182/182 [36:34<00:00,  9.27s/it, training_loss=0.239]\u001b[A\n",
            " 25%|██▌       | 2/8 [1:55:59<3:57:43, 2377.27s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            " Epoch {epoch}\n",
            "Training loss: {loss_train_avg}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "  0%|          | 0/46 [00:00<?, ?it/s]\u001b[A\n",
            "  2%|▏         | 1/46 [00:03<02:26,  3.26s/it]\u001b[A\n",
            "  4%|▍         | 2/46 [00:06<02:22,  3.24s/it]\u001b[A\n",
            "  7%|▋         | 3/46 [00:12<03:19,  4.63s/it]\u001b[A\n",
            "  9%|▊         | 4/46 [00:16<02:56,  4.21s/it]\u001b[A\n",
            " 11%|█         | 5/46 [00:19<02:37,  3.85s/it]\u001b[A\n",
            " 13%|█▎        | 6/46 [00:22<02:25,  3.63s/it]\u001b[A\n",
            " 15%|█▌        | 7/46 [00:27<02:36,  4.01s/it]\u001b[A\n",
            " 17%|█▋        | 8/46 [00:31<02:31,  3.98s/it]\u001b[A\n",
            " 20%|█▉        | 9/46 [00:34<02:18,  3.74s/it]\u001b[A\n",
            " 22%|██▏       | 10/46 [00:37<02:08,  3.58s/it]\u001b[A\n",
            " 24%|██▍       | 11/46 [00:42<02:12,  3.78s/it]\u001b[A\n",
            " 26%|██▌       | 12/46 [00:46<02:15,  4.00s/it]\u001b[A\n",
            " 28%|██▊       | 13/46 [00:49<02:04,  3.77s/it]\u001b[A\n",
            " 30%|███       | 14/46 [00:53<01:55,  3.61s/it]\u001b[A\n",
            " 33%|███▎      | 15/46 [00:56<01:53,  3.65s/it]\u001b[A\n",
            " 35%|███▍      | 16/46 [01:01<02:01,  4.06s/it]\u001b[A\n",
            " 37%|███▋      | 17/46 [01:05<01:50,  3.81s/it]\u001b[A\n",
            " 39%|███▉      | 18/46 [01:08<01:41,  3.63s/it]\u001b[A\n",
            " 41%|████▏     | 19/46 [01:11<01:34,  3.51s/it]\u001b[A\n",
            " 43%|████▎     | 20/46 [01:16<01:45,  4.04s/it]\u001b[A\n",
            " 46%|████▌     | 21/46 [01:20<01:36,  3.86s/it]\u001b[A\n",
            " 48%|████▊     | 22/46 [01:23<01:28,  3.67s/it]\u001b[A\n",
            " 50%|█████     | 23/46 [01:26<01:21,  3.54s/it]\u001b[A\n",
            " 52%|█████▏    | 24/46 [01:31<01:26,  3.95s/it]\u001b[A\n",
            " 54%|█████▍    | 25/46 [01:35<01:21,  3.90s/it]\u001b[A\n",
            " 57%|█████▋    | 26/46 [01:38<01:13,  3.69s/it]\u001b[A\n",
            " 59%|█████▊    | 27/46 [01:41<01:07,  3.55s/it]\u001b[A\n",
            " 61%|██████    | 28/46 [01:46<01:08,  3.80s/it]\u001b[A\n",
            " 63%|██████▎   | 29/46 [01:50<01:07,  3.95s/it]\u001b[A\n",
            " 65%|██████▌   | 30/46 [01:53<00:59,  3.74s/it]\u001b[A\n",
            " 67%|██████▋   | 31/46 [01:57<00:53,  3.59s/it]\u001b[A\n",
            " 70%|██████▉   | 32/46 [02:00<00:51,  3.66s/it]\u001b[A\n",
            " 72%|███████▏  | 33/46 [02:05<00:52,  4.02s/it]\u001b[A\n",
            " 74%|███████▍  | 34/46 [02:08<00:45,  3.77s/it]\u001b[A\n",
            " 76%|███████▌  | 35/46 [02:12<00:39,  3.61s/it]\u001b[A\n",
            " 78%|███████▊  | 36/46 [02:15<00:35,  3.52s/it]\u001b[A\n",
            " 80%|████████  | 37/46 [02:20<00:36,  4.05s/it]\u001b[A\n",
            " 83%|████████▎ | 38/46 [02:23<00:30,  3.82s/it]\u001b[A\n",
            " 85%|████████▍ | 39/46 [02:27<00:25,  3.65s/it]\u001b[A\n",
            " 87%|████████▋ | 40/46 [02:30<00:21,  3.51s/it]\u001b[A\n",
            " 89%|████████▉ | 41/46 [02:35<00:19,  3.95s/it]\u001b[A\n",
            " 91%|█████████▏| 42/46 [02:39<00:15,  3.87s/it]\u001b[A\n",
            " 93%|█████████▎| 43/46 [02:42<00:11,  3.73s/it]\u001b[A\n",
            " 96%|█████████▌| 44/46 [02:47<00:08,  4.25s/it]\u001b[A\n",
            " 98%|█████████▊| 45/46 [02:53<00:04,  4.64s/it]\u001b[A\n",
            "100%|██████████| 46/46 [02:54<00:00,  3.80s/it]\n",
            " 38%|███▊      | 3/8 [1:58:53<3:17:57, 2375.50s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy:113/128\n",
            " -> 0.8828125\n",
            "Accuracy:77/107\n",
            " -> 0.719626168224299\n",
            "Accuracy:96/128\n",
            " -> 0.75\n",
            "Validation loss: 0.5526419838323541\n",
            "F1 Score (weighted): 0.7867292135664036\n",
            "Accuracy Score: 0.7878787878787878\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "Epoch 4:   0%|          | 0/182 [00:00<?, ?it/s]\u001b[A\n",
            "Epoch 4:   0%|          | 0/182 [00:10<?, ?it/s, training_loss=0.184]\u001b[A\n",
            "Epoch 4:   1%|          | 1/182 [00:10<33:00, 10.94s/it, training_loss=0.184]\u001b[A\n",
            "Epoch 4:   1%|          | 1/182 [00:22<33:00, 10.94s/it, training_loss=0.028]\u001b[A\n",
            "Epoch 4:   1%|          | 2/182 [00:22<34:17, 11.43s/it, training_loss=0.028]\u001b[A\n",
            "Epoch 4:   1%|          | 2/182 [00:35<34:17, 11.43s/it, training_loss=0.074]\u001b[A\n",
            "Epoch 4:   2%|▏         | 3/182 [00:35<35:39, 11.95s/it, training_loss=0.074]\u001b[A\n",
            "Epoch 4:   2%|▏         | 3/182 [00:47<35:39, 11.95s/it, training_loss=0.038]\u001b[A\n",
            "Epoch 4:   2%|▏         | 4/182 [00:47<36:09, 12.19s/it, training_loss=0.038]\u001b[A\n",
            "Epoch 4:   2%|▏         | 4/182 [00:59<36:09, 12.19s/it, training_loss=0.063]\u001b[A\n",
            "Epoch 4:   3%|▎         | 5/182 [00:59<35:03, 11.89s/it, training_loss=0.063]\u001b[A\n",
            "Epoch 4:   3%|▎         | 5/182 [01:10<35:03, 11.89s/it, training_loss=0.057]\u001b[A\n",
            "Epoch 4:   3%|▎         | 6/182 [01:10<34:08, 11.64s/it, training_loss=0.057]\u001b[A\n",
            "Epoch 4:   3%|▎         | 6/182 [01:22<34:08, 11.64s/it, training_loss=0.025]\u001b[A\n",
            "Epoch 4:   4%|▍         | 7/182 [01:22<34:47, 11.93s/it, training_loss=0.025]\u001b[A\n",
            "Epoch 4:   4%|▍         | 7/182 [01:35<34:47, 11.93s/it, training_loss=0.093]\u001b[A\n",
            "Epoch 4:   4%|▍         | 8/182 [01:35<35:06, 12.11s/it, training_loss=0.093]\u001b[A\n",
            "Epoch 4:   4%|▍         | 8/182 [01:46<35:06, 12.11s/it, training_loss=0.042]\u001b[A\n",
            "Epoch 4:   5%|▍         | 9/182 [01:46<34:23, 11.93s/it, training_loss=0.042]\u001b[A\n",
            "Epoch 4:   5%|▍         | 9/182 [01:57<34:23, 11.93s/it, training_loss=0.042]\u001b[A\n",
            "Epoch 4:   5%|▌         | 10/182 [01:57<33:21, 11.64s/it, training_loss=0.042]\u001b[A\n",
            "Epoch 4:   5%|▌         | 10/182 [02:10<33:21, 11.64s/it, training_loss=0.031]\u001b[A\n",
            "Epoch 4:   6%|▌         | 11/182 [02:10<33:55, 11.90s/it, training_loss=0.031]\u001b[A\n",
            "Epoch 4:   6%|▌         | 11/182 [02:22<33:55, 11.90s/it, training_loss=0.038]\u001b[A\n",
            "Epoch 4:   7%|▋         | 12/182 [02:22<34:19, 12.11s/it, training_loss=0.038]\u001b[A\n",
            "Epoch 4:   7%|▋         | 12/182 [02:34<34:19, 12.11s/it, training_loss=0.039]\u001b[A\n",
            "Epoch 4:   7%|▋         | 13/182 [02:34<33:51, 12.02s/it, training_loss=0.039]\u001b[A\n",
            "Epoch 4:   7%|▋         | 13/182 [02:45<33:51, 12.02s/it, training_loss=0.158]\u001b[A\n",
            "Epoch 4:   8%|▊         | 14/182 [02:45<32:42, 11.68s/it, training_loss=0.158]\u001b[A\n",
            "Epoch 4:   8%|▊         | 14/182 [02:58<32:42, 11.68s/it, training_loss=0.022]\u001b[A\n",
            "Epoch 4:   8%|▊         | 15/182 [02:58<33:11, 11.93s/it, training_loss=0.022]\u001b[A\n",
            "Epoch 4:   8%|▊         | 15/182 [03:10<33:11, 11.93s/it, training_loss=0.019]\u001b[A\n",
            "Epoch 4:   9%|▉         | 16/182 [03:10<33:33, 12.13s/it, training_loss=0.019]\u001b[A\n",
            "Epoch 4:   9%|▉         | 16/182 [03:24<33:33, 12.13s/it, training_loss=0.185]\u001b[A\n",
            "Epoch 4:   9%|▉         | 17/182 [03:24<34:21, 12.49s/it, training_loss=0.185]\u001b[A\n",
            "Epoch 4:   9%|▉         | 17/182 [03:34<34:21, 12.49s/it, training_loss=0.170]\u001b[A\n",
            "Epoch 4:  10%|▉         | 18/182 [03:34<32:23, 11.85s/it, training_loss=0.170]\u001b[A\n",
            "Epoch 4:  10%|▉         | 18/182 [03:46<32:23, 11.85s/it, training_loss=0.036]\u001b[A\n",
            "Epoch 4:  10%|█         | 19/182 [03:46<32:33, 11.98s/it, training_loss=0.036]\u001b[A\n",
            "Epoch 4:  10%|█         | 19/182 [03:59<32:33, 11.98s/it, training_loss=0.102]\u001b[A\n",
            "Epoch 4:  11%|█         | 20/182 [03:59<32:47, 12.14s/it, training_loss=0.102]\u001b[A\n",
            "Epoch 4:  11%|█         | 20/182 [04:11<32:47, 12.14s/it, training_loss=0.090]\u001b[A\n",
            "Epoch 4:  12%|█▏        | 21/182 [04:11<32:51, 12.25s/it, training_loss=0.090]\u001b[A\n",
            "Epoch 4:  12%|█▏        | 21/182 [04:22<32:51, 12.25s/it, training_loss=0.027]\u001b[A\n",
            "Epoch 4:  12%|█▏        | 22/182 [04:22<31:08, 11.68s/it, training_loss=0.027]\u001b[A\n",
            "Epoch 4:  12%|█▏        | 22/182 [04:34<31:08, 11.68s/it, training_loss=0.288]\u001b[A\n",
            "Epoch 4:  13%|█▎        | 23/182 [04:34<31:27, 11.87s/it, training_loss=0.288]\u001b[A\n",
            "Epoch 4:  13%|█▎        | 23/182 [04:49<31:27, 11.87s/it, training_loss=0.081]\u001b[A\n",
            "Epoch 4:  13%|█▎        | 24/182 [04:49<34:06, 12.95s/it, training_loss=0.081]\u001b[A\n",
            "Epoch 4:  13%|█▎        | 24/182 [05:02<34:06, 12.95s/it, training_loss=0.259]\u001b[A\n",
            "Epoch 4:  14%|█▎        | 25/182 [05:02<33:20, 12.74s/it, training_loss=0.259]\u001b[A\n",
            "Epoch 4:  14%|█▎        | 25/182 [05:12<33:20, 12.74s/it, training_loss=0.022]\u001b[A\n",
            "Epoch 4:  14%|█▍        | 26/182 [05:12<31:31, 12.12s/it, training_loss=0.022]\u001b[A\n",
            "Epoch 4:  14%|█▍        | 26/182 [05:25<31:31, 12.12s/it, training_loss=0.184]\u001b[A\n",
            "Epoch 4:  15%|█▍        | 27/182 [05:25<31:36, 12.23s/it, training_loss=0.184]\u001b[A\n",
            "Epoch 4:  15%|█▍        | 27/182 [05:37<31:36, 12.23s/it, training_loss=0.068]\u001b[A\n",
            "Epoch 4:  15%|█▌        | 28/182 [05:37<31:38, 12.33s/it, training_loss=0.068]\u001b[A\n",
            "Epoch 4:  15%|█▌        | 28/182 [05:50<31:38, 12.33s/it, training_loss=0.016]\u001b[A\n",
            "Epoch 4:  16%|█▌        | 29/182 [05:50<31:21, 12.29s/it, training_loss=0.016]\u001b[A\n",
            "Epoch 4:  16%|█▌        | 29/182 [06:00<31:21, 12.29s/it, training_loss=0.120]\u001b[A\n",
            "Epoch 4:  16%|█▋        | 30/182 [06:00<29:51, 11.78s/it, training_loss=0.120]\u001b[A\n",
            "Epoch 4:  16%|█▋        | 30/182 [06:13<29:51, 11.78s/it, training_loss=0.045]\u001b[A\n",
            "Epoch 4:  17%|█▋        | 31/182 [06:13<30:11, 12.00s/it, training_loss=0.045]\u001b[A\n",
            "Epoch 4:  17%|█▋        | 31/182 [06:25<30:11, 12.00s/it, training_loss=0.015]\u001b[A\n",
            "Epoch 4:  18%|█▊        | 32/182 [06:25<30:23, 12.16s/it, training_loss=0.015]\u001b[A\n",
            "Epoch 4:  18%|█▊        | 32/182 [06:37<30:23, 12.16s/it, training_loss=0.018]\u001b[A\n",
            "Epoch 4:  18%|█▊        | 33/182 [06:37<30:14, 12.18s/it, training_loss=0.018]\u001b[A\n",
            "Epoch 4:  18%|█▊        | 33/182 [06:48<30:14, 12.18s/it, training_loss=0.049]\u001b[A\n",
            "Epoch 4:  19%|█▊        | 34/182 [06:48<28:49, 11.69s/it, training_loss=0.049]\u001b[A\n",
            "Epoch 4:  19%|█▊        | 34/182 [07:02<28:49, 11.69s/it, training_loss=0.017]\u001b[A\n",
            "Epoch 4:  19%|█▉        | 35/182 [07:02<30:33, 12.47s/it, training_loss=0.017]\u001b[A\n",
            "Epoch 4:  19%|█▉        | 35/182 [07:17<30:33, 12.47s/it, training_loss=0.160]\u001b[A\n",
            "Epoch 4:  20%|█▉        | 36/182 [07:17<31:49, 13.08s/it, training_loss=0.160]\u001b[A\n",
            "Epoch 4:  20%|█▉        | 36/182 [07:29<31:49, 13.08s/it, training_loss=0.046]\u001b[A\n",
            "Epoch 4:  20%|██        | 37/182 [07:29<31:16, 12.94s/it, training_loss=0.046]\u001b[A\n",
            "Epoch 4:  20%|██        | 37/182 [07:41<31:16, 12.94s/it, training_loss=0.085]\u001b[A\n",
            "Epoch 4:  21%|██        | 38/182 [07:41<30:12, 12.59s/it, training_loss=0.085]\u001b[A\n",
            "Epoch 4:  21%|██        | 38/182 [07:52<30:12, 12.59s/it, training_loss=0.166]\u001b[A\n",
            "Epoch 4:  21%|██▏       | 39/182 [07:52<28:47, 12.08s/it, training_loss=0.166]\u001b[A\n",
            "Epoch 4:  21%|██▏       | 39/182 [08:05<28:47, 12.08s/it, training_loss=0.065]\u001b[A\n",
            "Epoch 4:  22%|██▏       | 40/182 [08:05<28:52, 12.20s/it, training_loss=0.065]\u001b[A\n",
            "Epoch 4:  22%|██▏       | 40/182 [08:17<28:52, 12.20s/it, training_loss=0.034]\u001b[A\n",
            "Epoch 4:  23%|██▎       | 41/182 [08:17<28:54, 12.30s/it, training_loss=0.034]\u001b[A\n",
            "Epoch 4:  23%|██▎       | 41/182 [08:29<28:54, 12.30s/it, training_loss=0.028]\u001b[A\n",
            "Epoch 4:  23%|██▎       | 42/182 [08:29<28:29, 12.21s/it, training_loss=0.028]\u001b[A\n",
            "Epoch 4:  23%|██▎       | 42/182 [08:40<28:29, 12.21s/it, training_loss=0.083]\u001b[A\n",
            "Epoch 4:  24%|██▎       | 43/182 [08:40<27:17, 11.78s/it, training_loss=0.083]\u001b[A\n",
            "Epoch 4:  24%|██▎       | 43/182 [08:52<27:17, 11.78s/it, training_loss=0.017]\u001b[A\n",
            "Epoch 4:  24%|██▍       | 44/182 [08:52<27:35, 12.00s/it, training_loss=0.017]\u001b[A\n",
            "Epoch 4:  24%|██▍       | 44/182 [09:05<27:35, 12.00s/it, training_loss=0.014]\u001b[A\n",
            "Epoch 4:  25%|██▍       | 45/182 [09:05<27:48, 12.18s/it, training_loss=0.014]\u001b[A\n",
            "Epoch 4:  25%|██▍       | 45/182 [09:17<27:48, 12.18s/it, training_loss=0.017]\u001b[A\n",
            "Epoch 4:  25%|██▌       | 46/182 [09:17<27:43, 12.23s/it, training_loss=0.017]\u001b[A\n",
            "Epoch 4:  25%|██▌       | 46/182 [09:28<27:43, 12.23s/it, training_loss=0.033]\u001b[A\n",
            "Epoch 4:  26%|██▌       | 47/182 [09:28<26:23, 11.73s/it, training_loss=0.033]\u001b[A\n",
            "Epoch 4:  26%|██▌       | 47/182 [09:43<26:23, 11.73s/it, training_loss=0.014]\u001b[A\n",
            "Epoch 4:  26%|██▋       | 48/182 [09:43<28:17, 12.67s/it, training_loss=0.014]\u001b[A\n",
            "Epoch 4:  26%|██▋       | 48/182 [09:55<28:17, 12.67s/it, training_loss=0.187]\u001b[A\n",
            "Epoch 4:  27%|██▋       | 49/182 [09:55<27:58, 12.62s/it, training_loss=0.187]\u001b[A\n",
            "Epoch 4:  27%|██▋       | 49/182 [10:06<27:58, 12.62s/it, training_loss=0.018]\u001b[A\n",
            "Epoch 4:  27%|██▋       | 50/182 [10:06<26:25, 12.01s/it, training_loss=0.018]\u001b[A\n",
            "Epoch 4:  27%|██▋       | 50/182 [10:18<26:25, 12.01s/it, training_loss=0.015]\u001b[A\n",
            "Epoch 4:  28%|██▊       | 51/182 [10:18<26:11, 12.00s/it, training_loss=0.015]\u001b[A\n",
            "Epoch 4:  28%|██▊       | 51/182 [10:30<26:11, 12.00s/it, training_loss=0.231]\u001b[A\n",
            "Epoch 4:  29%|██▊       | 52/182 [10:30<26:19, 12.15s/it, training_loss=0.231]\u001b[A\n",
            "Epoch 4:  29%|██▊       | 52/182 [10:43<26:19, 12.15s/it, training_loss=0.011]\u001b[A\n",
            "Epoch 4:  29%|██▉       | 53/182 [10:43<26:27, 12.31s/it, training_loss=0.011]\u001b[A\n",
            "Epoch 4:  29%|██▉       | 53/182 [10:54<26:27, 12.31s/it, training_loss=0.017]\u001b[A\n",
            "Epoch 4:  30%|██▉       | 54/182 [10:54<25:25, 11.92s/it, training_loss=0.017]\u001b[A\n",
            "Epoch 4:  30%|██▉       | 54/182 [11:06<25:25, 11.92s/it, training_loss=0.012]\u001b[A\n",
            "Epoch 4:  30%|███       | 55/182 [11:06<25:07, 11.87s/it, training_loss=0.012]\u001b[A\n",
            "Epoch 4:  30%|███       | 55/182 [11:18<25:07, 11.87s/it, training_loss=0.183]\u001b[A\n",
            "Epoch 4:  31%|███       | 56/182 [11:18<25:25, 12.11s/it, training_loss=0.183]\u001b[A\n",
            "Epoch 4:  31%|███       | 56/182 [11:31<25:25, 12.11s/it, training_loss=0.012]\u001b[A\n",
            "Epoch 4:  31%|███▏      | 57/182 [11:31<25:32, 12.26s/it, training_loss=0.012]\u001b[A\n",
            "Epoch 4:  31%|███▏      | 57/182 [11:42<25:32, 12.26s/it, training_loss=0.008]\u001b[A\n",
            "Epoch 4:  32%|███▏      | 58/182 [11:42<24:43, 11.96s/it, training_loss=0.008]\u001b[A\n",
            "Epoch 4:  32%|███▏      | 58/182 [11:54<24:43, 11.96s/it, training_loss=0.357]\u001b[A\n",
            "Epoch 4:  32%|███▏      | 59/182 [11:54<24:06, 11.76s/it, training_loss=0.357]\u001b[A\n",
            "Epoch 4:  32%|███▏      | 59/182 [12:06<24:06, 11.76s/it, training_loss=0.051]\u001b[A\n",
            "Epoch 4:  33%|███▎      | 60/182 [12:06<24:23, 12.00s/it, training_loss=0.051]\u001b[A\n",
            "Epoch 4:  33%|███▎      | 60/182 [12:19<24:23, 12.00s/it, training_loss=0.218]\u001b[A\n",
            "Epoch 4:  34%|███▎      | 61/182 [12:19<24:33, 12.18s/it, training_loss=0.218]\u001b[A\n",
            "Epoch 4:  34%|███▎      | 61/182 [12:30<24:33, 12.18s/it, training_loss=0.184]\u001b[A\n",
            "Epoch 4:  34%|███▍      | 62/182 [12:30<23:57, 11.98s/it, training_loss=0.184]\u001b[A\n",
            "Epoch 4:  34%|███▍      | 62/182 [12:41<23:57, 11.98s/it, training_loss=0.018]\u001b[A\n",
            "Epoch 4:  35%|███▍      | 63/182 [12:41<23:15, 11.72s/it, training_loss=0.018]\u001b[A\n",
            "Epoch 4:  35%|███▍      | 63/182 [12:54<23:15, 11.72s/it, training_loss=0.332]\u001b[A\n",
            "Epoch 4:  35%|███▌      | 64/182 [12:54<23:34, 11.99s/it, training_loss=0.332]\u001b[A\n",
            "Epoch 4:  35%|███▌      | 64/182 [13:07<23:34, 11.99s/it, training_loss=0.038]\u001b[A\n",
            "Epoch 4:  36%|███▌      | 65/182 [13:07<23:44, 12.17s/it, training_loss=0.038]\u001b[A\n",
            "Epoch 4:  36%|███▌      | 65/182 [13:18<23:44, 12.17s/it, training_loss=0.031]\u001b[A\n",
            "Epoch 4:  36%|███▋      | 66/182 [13:19<23:23, 12.10s/it, training_loss=0.031]\u001b[A\n",
            "Epoch 4:  36%|███▋      | 66/182 [13:29<23:23, 12.10s/it, training_loss=0.245]\u001b[A\n",
            "Epoch 4:  37%|███▋      | 67/182 [13:29<22:25, 11.70s/it, training_loss=0.245]\u001b[A\n",
            "Epoch 4:  37%|███▋      | 67/182 [13:42<22:25, 11.70s/it, training_loss=0.125]\u001b[A\n",
            "Epoch 4:  37%|███▋      | 68/182 [13:42<22:40, 11.93s/it, training_loss=0.125]\u001b[A\n",
            "Epoch 4:  37%|███▋      | 68/182 [13:54<22:40, 11.93s/it, training_loss=0.019]\u001b[A\n",
            "Epoch 4:  38%|███▊      | 69/182 [13:54<22:50, 12.13s/it, training_loss=0.019]\u001b[A\n",
            "Epoch 4:  38%|███▊      | 69/182 [14:06<22:50, 12.13s/it, training_loss=0.024]\u001b[A\n",
            "Epoch 4:  38%|███▊      | 70/182 [14:06<22:32, 12.07s/it, training_loss=0.024]\u001b[A\n",
            "Epoch 4:  38%|███▊      | 70/182 [14:17<22:32, 12.07s/it, training_loss=0.038]\u001b[A\n",
            "Epoch 4:  39%|███▉      | 71/182 [14:17<21:37, 11.69s/it, training_loss=0.038]\u001b[A\n",
            "Epoch 4:  39%|███▉      | 71/182 [14:32<21:37, 11.69s/it, training_loss=0.057]\u001b[A\n",
            "Epoch 4:  40%|███▉      | 72/182 [14:32<23:07, 12.62s/it, training_loss=0.057]\u001b[A\n",
            "Epoch 4:  40%|███▉      | 72/182 [14:44<23:07, 12.62s/it, training_loss=0.052]\u001b[A\n",
            "Epoch 4:  40%|████      | 73/182 [14:45<22:56, 12.63s/it, training_loss=0.052]\u001b[A\n",
            "Epoch 4:  40%|████      | 73/182 [14:57<22:56, 12.63s/it, training_loss=0.065]\u001b[A\n",
            "Epoch 4:  41%|████      | 74/182 [14:57<22:44, 12.63s/it, training_loss=0.065]\u001b[A\n",
            "Epoch 4:  41%|████      | 74/182 [15:09<22:44, 12.63s/it, training_loss=0.016]\u001b[A\n",
            "Epoch 4:  41%|████      | 75/182 [15:09<22:04, 12.38s/it, training_loss=0.016]\u001b[A\n",
            "Epoch 4:  41%|████      | 75/182 [15:20<22:04, 12.38s/it, training_loss=0.409]\u001b[A\n",
            "Epoch 4:  42%|████▏     | 76/182 [15:20<21:07, 11.96s/it, training_loss=0.409]\u001b[A\n",
            "Epoch 4:  42%|████▏     | 76/182 [15:32<21:07, 11.96s/it, training_loss=0.019]\u001b[A\n",
            "Epoch 4:  42%|████▏     | 77/182 [15:32<21:12, 12.12s/it, training_loss=0.019]\u001b[A\n",
            "Epoch 4:  42%|████▏     | 77/182 [15:45<21:12, 12.12s/it, training_loss=0.078]\u001b[A\n",
            "Epoch 4:  43%|████▎     | 78/182 [15:45<21:15, 12.26s/it, training_loss=0.078]\u001b[A\n",
            "Epoch 4:  43%|████▎     | 78/182 [15:57<21:15, 12.26s/it, training_loss=0.110]\u001b[A\n",
            "Epoch 4:  43%|████▎     | 79/182 [15:57<20:52, 12.16s/it, training_loss=0.110]\u001b[A\n",
            "Epoch 4:  43%|████▎     | 79/182 [16:08<20:52, 12.16s/it, training_loss=0.133]\u001b[A\n",
            "Epoch 4:  44%|████▍     | 80/182 [16:08<19:59, 11.76s/it, training_loss=0.133]\u001b[A\n",
            "Epoch 4:  44%|████▍     | 80/182 [16:20<19:59, 11.76s/it, training_loss=0.198]\u001b[A\n",
            "Epoch 4:  45%|████▍     | 81/182 [16:20<20:14, 12.02s/it, training_loss=0.198]\u001b[A\n",
            "Epoch 4:  45%|████▍     | 81/182 [16:33<20:14, 12.02s/it, training_loss=0.011]\u001b[A\n",
            "Epoch 4:  45%|████▌     | 82/182 [16:33<20:22, 12.23s/it, training_loss=0.011]\u001b[A\n",
            "Epoch 4:  45%|████▌     | 82/182 [16:46<20:22, 12.23s/it, training_loss=0.242]\u001b[A\n",
            "Epoch 4:  46%|████▌     | 83/182 [16:46<20:17, 12.30s/it, training_loss=0.242]\u001b[A\n",
            "Epoch 4:  46%|████▌     | 83/182 [16:56<20:17, 12.30s/it, training_loss=0.118]\u001b[A\n",
            "Epoch 4:  46%|████▌     | 84/182 [16:56<19:11, 11.75s/it, training_loss=0.118]\u001b[A\n",
            "Epoch 4:  46%|████▌     | 84/182 [17:08<19:11, 11.75s/it, training_loss=0.206]\u001b[A\n",
            "Epoch 4:  47%|████▋     | 85/182 [17:09<19:20, 11.97s/it, training_loss=0.206]\u001b[A\n",
            "Epoch 4:  47%|████▋     | 85/182 [17:21<19:20, 11.97s/it, training_loss=0.024]\u001b[A\n",
            "Epoch 4:  47%|████▋     | 86/182 [17:21<19:26, 12.15s/it, training_loss=0.024]\u001b[A\n",
            "Epoch 4:  47%|████▋     | 86/182 [17:34<19:26, 12.15s/it, training_loss=0.015]\u001b[A\n",
            "Epoch 4:  48%|████▊     | 87/182 [17:34<19:22, 12.24s/it, training_loss=0.015]\u001b[A\n",
            "Epoch 4:  48%|████▊     | 87/182 [17:44<19:22, 12.24s/it, training_loss=0.096]\u001b[A\n",
            "Epoch 4:  48%|████▊     | 88/182 [17:44<18:19, 11.70s/it, training_loss=0.096]\u001b[A\n",
            "Epoch 4:  48%|████▊     | 88/182 [17:56<18:19, 11.70s/it, training_loss=0.208]\u001b[A\n",
            "Epoch 4:  49%|████▉     | 89/182 [17:56<18:30, 11.94s/it, training_loss=0.208]\u001b[A\n",
            "Epoch 4:  49%|████▉     | 89/182 [18:09<18:30, 11.94s/it, training_loss=0.009]\u001b[A\n",
            "Epoch 4:  49%|████▉     | 90/182 [18:09<18:36, 12.14s/it, training_loss=0.009]\u001b[A\n",
            "Epoch 4:  49%|████▉     | 90/182 [18:22<18:36, 12.14s/it, training_loss=0.030]\u001b[A\n",
            "Epoch 4:  50%|█████     | 91/182 [18:22<18:35, 12.25s/it, training_loss=0.030]\u001b[A\n",
            "Epoch 4:  50%|█████     | 91/182 [18:32<18:35, 12.25s/it, training_loss=0.126]\u001b[A\n",
            "Epoch 4:  51%|█████     | 92/182 [18:32<17:35, 11.73s/it, training_loss=0.126]\u001b[A\n",
            "Epoch 4:  51%|█████     | 92/182 [18:44<17:35, 11.73s/it, training_loss=0.159]\u001b[A\n",
            "Epoch 4:  51%|█████     | 93/182 [18:44<17:39, 11.90s/it, training_loss=0.159]\u001b[A\n",
            "Epoch 4:  51%|█████     | 93/182 [18:57<17:39, 11.90s/it, training_loss=0.313]\u001b[A\n",
            "Epoch 4:  52%|█████▏    | 94/182 [18:57<17:45, 12.10s/it, training_loss=0.313]\u001b[A\n",
            "Epoch 4:  52%|█████▏    | 94/182 [19:10<17:45, 12.10s/it, training_loss=0.019]\u001b[A\n",
            "Epoch 4:  52%|█████▏    | 95/182 [19:10<17:44, 12.24s/it, training_loss=0.019]\u001b[A\n",
            "Epoch 4:  52%|█████▏    | 95/182 [19:24<17:44, 12.24s/it, training_loss=0.190]\u001b[A\n",
            "Epoch 4:  53%|█████▎    | 96/182 [19:24<18:30, 12.91s/it, training_loss=0.190]\u001b[A\n",
            "Epoch 4:  53%|█████▎    | 96/182 [19:35<18:30, 12.91s/it, training_loss=0.013]\u001b[A\n",
            "Epoch 4:  53%|█████▎    | 97/182 [19:35<17:17, 12.21s/it, training_loss=0.013]\u001b[A\n",
            "Epoch 4:  53%|█████▎    | 97/182 [19:47<17:17, 12.21s/it, training_loss=0.009]\u001b[A\n",
            "Epoch 4:  54%|█████▍    | 98/182 [19:47<17:13, 12.30s/it, training_loss=0.009]\u001b[A\n",
            "Epoch 4:  54%|█████▍    | 98/182 [20:00<17:13, 12.30s/it, training_loss=0.275]\u001b[A\n",
            "Epoch 4:  54%|█████▍    | 99/182 [20:00<17:09, 12.40s/it, training_loss=0.275]\u001b[A\n",
            "Epoch 4:  54%|█████▍    | 99/182 [20:12<17:09, 12.40s/it, training_loss=0.008]\u001b[A\n",
            "Epoch 4:  55%|█████▍    | 100/182 [20:12<16:56, 12.40s/it, training_loss=0.008]\u001b[A\n",
            "Epoch 4:  55%|█████▍    | 100/182 [20:23<16:56, 12.40s/it, training_loss=0.188]\u001b[A\n",
            "Epoch 4:  55%|█████▌    | 101/182 [20:23<16:00, 11.85s/it, training_loss=0.188]\u001b[A\n",
            "Epoch 4:  55%|█████▌    | 101/182 [20:35<16:00, 11.85s/it, training_loss=0.133]\u001b[A\n",
            "Epoch 4:  56%|█████▌    | 102/182 [20:35<16:05, 12.06s/it, training_loss=0.133]\u001b[A\n",
            "Epoch 4:  56%|█████▌    | 102/182 [20:48<16:05, 12.06s/it, training_loss=0.032]\u001b[A\n",
            "Epoch 4:  57%|█████▋    | 103/182 [20:48<16:06, 12.24s/it, training_loss=0.032]\u001b[A\n",
            "Epoch 4:  57%|█████▋    | 103/182 [21:00<16:06, 12.24s/it, training_loss=0.019]\u001b[A\n",
            "Epoch 4:  57%|█████▋    | 104/182 [21:00<16:00, 12.32s/it, training_loss=0.019]\u001b[A\n",
            "Epoch 4:  57%|█████▋    | 104/182 [21:11<16:00, 12.32s/it, training_loss=0.193]\u001b[A\n",
            "Epoch 4:  58%|█████▊    | 105/182 [21:11<15:05, 11.76s/it, training_loss=0.193]\u001b[A\n",
            "Epoch 4:  58%|█████▊    | 105/182 [21:23<15:05, 11.76s/it, training_loss=0.066]\u001b[A\n",
            "Epoch 4:  58%|█████▊    | 106/182 [21:23<15:02, 11.87s/it, training_loss=0.066]\u001b[A\n",
            "Epoch 4:  58%|█████▊    | 106/182 [21:36<15:02, 11.87s/it, training_loss=0.092]\u001b[A\n",
            "Epoch 4:  59%|█████▉    | 107/182 [21:36<15:04, 12.07s/it, training_loss=0.092]\u001b[A\n",
            "Epoch 4:  59%|█████▉    | 107/182 [21:48<15:04, 12.07s/it, training_loss=0.393]\u001b[A\n",
            "Epoch 4:  59%|█████▉    | 108/182 [21:48<15:04, 12.22s/it, training_loss=0.393]\u001b[A\n",
            "Epoch 4:  59%|█████▉    | 108/182 [21:59<15:04, 12.22s/it, training_loss=0.103]\u001b[A\n",
            "Epoch 4:  60%|█████▉    | 109/182 [21:59<14:15, 11.72s/it, training_loss=0.103]\u001b[A\n",
            "Epoch 4:  60%|█████▉    | 109/182 [22:11<14:15, 11.72s/it, training_loss=0.014]\u001b[A\n",
            "Epoch 4:  60%|██████    | 110/182 [22:11<14:08, 11.78s/it, training_loss=0.014]\u001b[A\n",
            "Epoch 4:  60%|██████    | 110/182 [22:23<14:08, 11.78s/it, training_loss=0.015]\u001b[A\n",
            "Epoch 4:  61%|██████    | 111/182 [22:23<14:12, 12.00s/it, training_loss=0.015]\u001b[A\n",
            "Epoch 4:  61%|██████    | 111/182 [22:36<14:12, 12.00s/it, training_loss=0.010]\u001b[A\n",
            "Epoch 4:  62%|██████▏   | 112/182 [22:36<14:12, 12.18s/it, training_loss=0.010]\u001b[A\n",
            "Epoch 4:  62%|██████▏   | 112/182 [22:47<14:12, 12.18s/it, training_loss=0.101]\u001b[A\n",
            "Epoch 4:  62%|██████▏   | 113/182 [22:47<13:32, 11.77s/it, training_loss=0.101]\u001b[A\n",
            "Epoch 4:  62%|██████▏   | 113/182 [22:58<13:32, 11.77s/it, training_loss=0.080]\u001b[A\n",
            "Epoch 4:  63%|██████▎   | 114/182 [22:58<13:22, 11.80s/it, training_loss=0.080]\u001b[A\n",
            "Epoch 4:  63%|██████▎   | 114/182 [23:11<13:22, 11.80s/it, training_loss=0.046]\u001b[A\n",
            "Epoch 4:  63%|██████▎   | 115/182 [23:11<13:25, 12.02s/it, training_loss=0.046]\u001b[A\n",
            "Epoch 4:  63%|██████▎   | 115/182 [23:24<13:25, 12.02s/it, training_loss=0.034]\u001b[A\n",
            "Epoch 4:  64%|██████▎   | 116/182 [23:24<13:24, 12.20s/it, training_loss=0.034]\u001b[A\n",
            "Epoch 4:  64%|██████▎   | 116/182 [23:35<13:24, 12.20s/it, training_loss=0.454]\u001b[A\n",
            "Epoch 4:  64%|██████▍   | 117/182 [23:35<12:51, 11.86s/it, training_loss=0.454]\u001b[A\n",
            "Epoch 4:  64%|██████▍   | 117/182 [23:46<12:51, 11.86s/it, training_loss=0.096]\u001b[A\n",
            "Epoch 4:  65%|██████▍   | 118/182 [23:46<12:30, 11.73s/it, training_loss=0.096]\u001b[A\n",
            "Epoch 4:  65%|██████▍   | 118/182 [24:01<12:30, 11.73s/it, training_loss=0.053]\u001b[A\n",
            "Epoch 4:  65%|██████▌   | 119/182 [24:01<13:17, 12.67s/it, training_loss=0.053]\u001b[A\n",
            "Epoch 4:  65%|██████▌   | 119/182 [24:13<13:17, 12.67s/it, training_loss=0.041]\u001b[A\n",
            "Epoch 4:  66%|██████▌   | 120/182 [24:13<13:02, 12.62s/it, training_loss=0.041]\u001b[A\n",
            "Epoch 4:  66%|██████▌   | 120/182 [24:26<13:02, 12.62s/it, training_loss=0.152]\u001b[A\n",
            "Epoch 4:  66%|██████▋   | 121/182 [24:26<12:48, 12.59s/it, training_loss=0.152]\u001b[A\n",
            "Epoch 4:  66%|██████▋   | 121/182 [24:36<12:48, 12.59s/it, training_loss=0.019]\u001b[A\n",
            "Epoch 4:  67%|██████▋   | 122/182 [24:36<11:56, 11.94s/it, training_loss=0.019]\u001b[A\n",
            "Epoch 4:  67%|██████▋   | 122/182 [24:49<11:56, 11.94s/it, training_loss=0.010]\u001b[A\n",
            "Epoch 4:  68%|██████▊   | 123/182 [24:49<11:49, 12.03s/it, training_loss=0.010]\u001b[A\n",
            "Epoch 4:  68%|██████▊   | 123/182 [25:01<11:49, 12.03s/it, training_loss=0.023]\u001b[A\n",
            "Epoch 4:  68%|██████▊   | 124/182 [25:01<11:47, 12.19s/it, training_loss=0.023]\u001b[A\n",
            "Epoch 4:  68%|██████▊   | 124/182 [25:14<11:47, 12.19s/it, training_loss=0.009]\u001b[A\n",
            "Epoch 4:  69%|██████▊   | 125/182 [25:14<11:41, 12.30s/it, training_loss=0.009]\u001b[A\n",
            "Epoch 4:  69%|██████▊   | 125/182 [25:24<11:41, 12.30s/it, training_loss=0.156]\u001b[A\n",
            "Epoch 4:  69%|██████▉   | 126/182 [25:24<11:01, 11.82s/it, training_loss=0.156]\u001b[A\n",
            "Epoch 4:  69%|██████▉   | 126/182 [25:36<11:01, 11.82s/it, training_loss=0.209]\u001b[A\n",
            "Epoch 4:  70%|██████▉   | 127/182 [25:36<10:51, 11.84s/it, training_loss=0.209]\u001b[A\n",
            "Epoch 4:  70%|██████▉   | 127/182 [25:49<10:51, 11.84s/it, training_loss=0.127]\u001b[A\n",
            "Epoch 4:  70%|███████   | 128/182 [25:49<10:51, 12.06s/it, training_loss=0.127]\u001b[A\n",
            "Epoch 4:  70%|███████   | 128/182 [26:01<10:51, 12.06s/it, training_loss=0.056]\u001b[A\n",
            "Epoch 4:  71%|███████   | 129/182 [26:01<10:47, 12.22s/it, training_loss=0.056]\u001b[A\n",
            "Epoch 4:  71%|███████   | 129/182 [26:12<10:47, 12.22s/it, training_loss=0.014]\u001b[A\n",
            "Epoch 4:  71%|███████▏  | 130/182 [26:12<10:14, 11.82s/it, training_loss=0.014]\u001b[A\n",
            "Epoch 4:  71%|███████▏  | 130/182 [26:24<10:14, 11.82s/it, training_loss=0.050]\u001b[A\n",
            "Epoch 4:  72%|███████▏  | 131/182 [26:24<10:00, 11.77s/it, training_loss=0.050]\u001b[A\n",
            "Epoch 4:  72%|███████▏  | 131/182 [26:36<10:00, 11.77s/it, training_loss=0.008]\u001b[A\n",
            "Epoch 4:  73%|███████▎  | 132/182 [26:37<09:59, 12.00s/it, training_loss=0.008]\u001b[A\n",
            "Epoch 4:  73%|███████▎  | 132/182 [26:49<09:59, 12.00s/it, training_loss=0.032]\u001b[A\n",
            "Epoch 4:  73%|███████▎  | 133/182 [26:49<09:57, 12.18s/it, training_loss=0.032]\u001b[A\n",
            "Epoch 4:  73%|███████▎  | 133/182 [27:00<09:57, 12.18s/it, training_loss=0.015]\u001b[A\n",
            "Epoch 4:  74%|███████▎  | 134/182 [27:00<09:31, 11.91s/it, training_loss=0.015]\u001b[A\n",
            "Epoch 4:  74%|███████▎  | 134/182 [27:12<09:31, 11.91s/it, training_loss=0.050]\u001b[A\n",
            "Epoch 4:  74%|███████▍  | 135/182 [27:12<09:11, 11.73s/it, training_loss=0.050]\u001b[A\n",
            "Epoch 4:  74%|███████▍  | 135/182 [27:25<09:11, 11.73s/it, training_loss=0.066]\u001b[A\n",
            "Epoch 4:  75%|███████▍  | 136/182 [27:25<09:19, 12.17s/it, training_loss=0.066]\u001b[A\n",
            "Epoch 4:  75%|███████▍  | 136/182 [27:37<09:19, 12.17s/it, training_loss=0.010]\u001b[A\n",
            "Epoch 4:  75%|███████▌  | 137/182 [27:37<09:13, 12.30s/it, training_loss=0.010]\u001b[A\n",
            "Epoch 4:  75%|███████▌  | 137/182 [27:49<09:13, 12.30s/it, training_loss=0.011]\u001b[A\n",
            "Epoch 4:  76%|███████▌  | 138/182 [27:49<08:50, 12.07s/it, training_loss=0.011]\u001b[A\n",
            "Epoch 4:  76%|███████▌  | 138/182 [28:00<08:50, 12.07s/it, training_loss=0.015]\u001b[A\n",
            "Epoch 4:  76%|███████▋  | 139/182 [28:00<08:26, 11.77s/it, training_loss=0.015]\u001b[A\n",
            "Epoch 4:  76%|███████▋  | 139/182 [28:13<08:26, 11.77s/it, training_loss=0.018]\u001b[A\n",
            "Epoch 4:  77%|███████▋  | 140/182 [28:13<08:23, 11.99s/it, training_loss=0.018]\u001b[A\n",
            "Epoch 4:  77%|███████▋  | 140/182 [28:25<08:23, 11.99s/it, training_loss=0.007]\u001b[A\n",
            "Epoch 4:  77%|███████▋  | 141/182 [28:25<08:18, 12.17s/it, training_loss=0.007]\u001b[A\n",
            "Epoch 4:  77%|███████▋  | 141/182 [28:37<08:18, 12.17s/it, training_loss=0.172]\u001b[A\n",
            "Epoch 4:  78%|███████▊  | 142/182 [28:37<08:01, 12.05s/it, training_loss=0.172]\u001b[A\n",
            "Epoch 4:  78%|███████▊  | 142/182 [28:50<08:01, 12.05s/it, training_loss=0.040]\u001b[A\n",
            "Epoch 4:  79%|███████▊  | 143/182 [28:50<08:04, 12.43s/it, training_loss=0.040]\u001b[A\n",
            "Epoch 4:  79%|███████▊  | 143/182 [29:03<08:04, 12.43s/it, training_loss=0.227]\u001b[A\n",
            "Epoch 4:  79%|███████▉  | 144/182 [29:03<07:51, 12.41s/it, training_loss=0.227]\u001b[A\n",
            "Epoch 4:  79%|███████▉  | 144/182 [29:15<07:51, 12.41s/it, training_loss=0.117]\u001b[A\n",
            "Epoch 4:  80%|███████▉  | 145/182 [29:15<07:40, 12.45s/it, training_loss=0.117]\u001b[A\n",
            "Epoch 4:  80%|███████▉  | 145/182 [29:28<07:40, 12.45s/it, training_loss=0.134]\u001b[A\n",
            "Epoch 4:  80%|████████  | 146/182 [29:28<07:29, 12.48s/it, training_loss=0.134]\u001b[A\n",
            "Epoch 4:  80%|████████  | 146/182 [29:38<07:29, 12.48s/it, training_loss=0.017]\u001b[A\n",
            "Epoch 4:  81%|████████  | 147/182 [29:38<06:55, 11.86s/it, training_loss=0.017]\u001b[A\n",
            "Epoch 4:  81%|████████  | 147/182 [29:50<06:55, 11.86s/it, training_loss=0.125]\u001b[A\n",
            "Epoch 4:  81%|████████▏ | 148/182 [29:50<06:45, 11.94s/it, training_loss=0.125]\u001b[A\n",
            "Epoch 4:  81%|████████▏ | 148/182 [30:03<06:45, 11.94s/it, training_loss=0.037]\u001b[A\n",
            "Epoch 4:  82%|████████▏ | 149/182 [30:03<06:40, 12.12s/it, training_loss=0.037]\u001b[A\n",
            "Epoch 4:  82%|████████▏ | 149/182 [30:15<06:40, 12.12s/it, training_loss=0.164]\u001b[A\n",
            "Epoch 4:  82%|████████▏ | 150/182 [30:15<06:32, 12.25s/it, training_loss=0.164]\u001b[A\n",
            "Epoch 4:  82%|████████▏ | 150/182 [30:26<06:32, 12.25s/it, training_loss=0.208]\u001b[A\n",
            "Epoch 4:  83%|████████▎ | 151/182 [30:26<06:05, 11.79s/it, training_loss=0.208]\u001b[A\n",
            "Epoch 4:  83%|████████▎ | 151/182 [30:38<06:05, 11.79s/it, training_loss=0.008]\u001b[A\n",
            "Epoch 4:  84%|████████▎ | 152/182 [30:38<05:54, 11.81s/it, training_loss=0.008]\u001b[A\n",
            "Epoch 4:  84%|████████▎ | 152/182 [30:50<05:54, 11.81s/it, training_loss=0.138]\u001b[A\n",
            "Epoch 4:  84%|████████▍ | 153/182 [30:50<05:48, 12.03s/it, training_loss=0.138]\u001b[A\n",
            "Epoch 4:  84%|████████▍ | 153/182 [31:03<05:48, 12.03s/it, training_loss=0.143]\u001b[A\n",
            "Epoch 4:  85%|████████▍ | 154/182 [31:03<05:41, 12.18s/it, training_loss=0.143]\u001b[A\n",
            "Epoch 4:  85%|████████▍ | 154/182 [31:14<05:41, 12.18s/it, training_loss=0.007]\u001b[A\n",
            "Epoch 4:  85%|████████▌ | 155/182 [31:14<05:18, 11.81s/it, training_loss=0.007]\u001b[A\n",
            "Epoch 4:  85%|████████▌ | 155/182 [31:26<05:18, 11.81s/it, training_loss=0.228]\u001b[A\n",
            "Epoch 4:  86%|████████▌ | 156/182 [31:26<05:05, 11.76s/it, training_loss=0.228]\u001b[A\n",
            "Epoch 4:  86%|████████▌ | 156/182 [31:38<05:05, 11.76s/it, training_loss=0.166]\u001b[A\n",
            "Epoch 4:  86%|████████▋ | 157/182 [31:38<04:59, 12.00s/it, training_loss=0.166]\u001b[A\n",
            "Epoch 4:  86%|████████▋ | 157/182 [31:51<04:59, 12.00s/it, training_loss=0.112]\u001b[A\n",
            "Epoch 4:  87%|████████▋ | 158/182 [31:51<04:52, 12.17s/it, training_loss=0.112]\u001b[A\n",
            "Epoch 4:  87%|████████▋ | 158/182 [32:02<04:52, 12.17s/it, training_loss=0.064]\u001b[A\n",
            "Epoch 4:  87%|████████▋ | 159/182 [32:02<04:32, 11.86s/it, training_loss=0.064]\u001b[A\n",
            "Epoch 4:  87%|████████▋ | 159/182 [32:13<04:32, 11.86s/it, training_loss=0.013]\u001b[A\n",
            "Epoch 4:  88%|████████▊ | 160/182 [32:13<04:17, 11.71s/it, training_loss=0.013]\u001b[A\n",
            "Epoch 4:  88%|████████▊ | 160/182 [32:26<04:17, 11.71s/it, training_loss=0.073]\u001b[A\n",
            "Epoch 4:  88%|████████▊ | 161/182 [32:26<04:11, 11.96s/it, training_loss=0.073]\u001b[A\n",
            "Epoch 4:  88%|████████▊ | 161/182 [32:38<04:11, 11.96s/it, training_loss=0.166]\u001b[A\n",
            "Epoch 4:  89%|████████▉ | 162/182 [32:38<04:03, 12.17s/it, training_loss=0.166]\u001b[A\n",
            "Epoch 4:  89%|████████▉ | 162/182 [32:50<04:03, 12.17s/it, training_loss=0.007]\u001b[A\n",
            "Epoch 4:  90%|████████▉ | 163/182 [32:50<03:46, 11.95s/it, training_loss=0.007]\u001b[A\n",
            "Epoch 4:  90%|████████▉ | 163/182 [33:01<03:46, 11.95s/it, training_loss=0.011]\u001b[A\n",
            "Epoch 4:  90%|█████████ | 164/182 [33:01<03:31, 11.72s/it, training_loss=0.011]\u001b[A\n",
            "Epoch 4:  90%|█████████ | 164/182 [33:14<03:31, 11.72s/it, training_loss=0.020]\u001b[A\n",
            "Epoch 4:  91%|█████████ | 165/182 [33:14<03:23, 11.97s/it, training_loss=0.020]\u001b[A\n",
            "Epoch 4:  91%|█████████ | 165/182 [33:26<03:23, 11.97s/it, training_loss=0.362]\u001b[A\n",
            "Epoch 4:  91%|█████████ | 166/182 [33:26<03:14, 12.14s/it, training_loss=0.362]\u001b[A\n",
            "Epoch 4:  91%|█████████ | 166/182 [33:38<03:14, 12.14s/it, training_loss=0.043]\u001b[A\n",
            "Epoch 4:  92%|█████████▏| 167/182 [33:38<03:00, 12.01s/it, training_loss=0.043]\u001b[A\n",
            "Epoch 4:  92%|█████████▏| 167/182 [33:51<03:00, 12.01s/it, training_loss=0.117]\u001b[A\n",
            "Epoch 4:  92%|█████████▏| 168/182 [33:51<02:53, 12.40s/it, training_loss=0.117]\u001b[A\n",
            "Epoch 4:  92%|█████████▏| 168/182 [34:04<02:53, 12.40s/it, training_loss=0.031]\u001b[A\n",
            "Epoch 4:  93%|█████████▎| 169/182 [34:04<02:41, 12.43s/it, training_loss=0.031]\u001b[A\n",
            "Epoch 4:  93%|█████████▎| 169/182 [34:16<02:41, 12.43s/it, training_loss=0.035]\u001b[A\n",
            "Epoch 4:  93%|█████████▎| 170/182 [34:16<02:28, 12.38s/it, training_loss=0.035]\u001b[A\n",
            "Epoch 4:  93%|█████████▎| 170/182 [34:26<02:28, 12.38s/it, training_loss=0.012]\u001b[A\n",
            "Epoch 4:  94%|█████████▍| 171/182 [34:26<02:09, 11.79s/it, training_loss=0.012]\u001b[A\n",
            "Epoch 4:  94%|█████████▍| 171/182 [34:39<02:09, 11.79s/it, training_loss=0.085]\u001b[A\n",
            "Epoch 4:  95%|█████████▍| 172/182 [34:39<02:00, 12.01s/it, training_loss=0.085]\u001b[A\n",
            "Epoch 4:  95%|█████████▍| 172/182 [34:51<02:00, 12.01s/it, training_loss=0.063]\u001b[A\n",
            "Epoch 4:  95%|█████████▌| 173/182 [34:51<01:49, 12.19s/it, training_loss=0.063]\u001b[A\n",
            "Epoch 4:  95%|█████████▌| 173/182 [35:04<01:49, 12.19s/it, training_loss=0.086]\u001b[A\n",
            "Epoch 4:  96%|█████████▌| 174/182 [35:04<01:38, 12.30s/it, training_loss=0.086]\u001b[A\n",
            "Epoch 4:  96%|█████████▌| 174/182 [35:14<01:38, 12.30s/it, training_loss=0.034]\u001b[A\n",
            "Epoch 4:  96%|█████████▌| 175/182 [35:14<01:21, 11.70s/it, training_loss=0.034]\u001b[A\n",
            "Epoch 4:  96%|█████████▌| 175/182 [35:27<01:21, 11.70s/it, training_loss=0.020]\u001b[A\n",
            "Epoch 4:  97%|█████████▋| 176/182 [35:27<01:12, 12.14s/it, training_loss=0.020]\u001b[A\n",
            "Epoch 4:  97%|█████████▋| 176/182 [35:40<01:12, 12.14s/it, training_loss=0.012]\u001b[A\n",
            "Epoch 4:  97%|█████████▋| 177/182 [35:40<01:01, 12.27s/it, training_loss=0.012]\u001b[A\n",
            "Epoch 4:  97%|█████████▋| 177/182 [35:53<01:01, 12.27s/it, training_loss=0.006]\u001b[A\n",
            "Epoch 4:  98%|█████████▊| 178/182 [35:53<00:49, 12.37s/it, training_loss=0.006]\u001b[A\n",
            "Epoch 4:  98%|█████████▊| 178/182 [36:03<00:49, 12.37s/it, training_loss=0.073]\u001b[A\n",
            "Epoch 4:  98%|█████████▊| 179/182 [36:03<00:35, 11.79s/it, training_loss=0.073]\u001b[A\n",
            "Epoch 4:  98%|█████████▊| 179/182 [36:15<00:35, 11.79s/it, training_loss=0.017]\u001b[A\n",
            "Epoch 4:  99%|█████████▉| 180/182 [36:15<00:23, 11.89s/it, training_loss=0.017]\u001b[A\n",
            "Epoch 4:  99%|█████████▉| 180/182 [36:28<00:23, 11.89s/it, training_loss=0.172]\u001b[A\n",
            "Epoch 4:  99%|█████████▉| 181/182 [36:28<00:12, 12.09s/it, training_loss=0.172]\u001b[A\n",
            "Epoch 4:  99%|█████████▉| 181/182 [36:30<00:12, 12.09s/it, training_loss=0.252]\u001b[A\n",
            "Epoch 4: 100%|██████████| 182/182 [36:30<00:00,  9.08s/it, training_loss=0.252]\u001b[A\n",
            " 38%|███▊      | 3/8 [2:35:28<3:17:57, 2375.50s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            " Epoch {epoch}\n",
            "Training loss: {loss_train_avg}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "  0%|          | 0/46 [00:00<?, ?it/s]\u001b[A\n",
            "  2%|▏         | 1/46 [00:05<04:04,  5.43s/it]\u001b[A\n",
            "  4%|▍         | 2/46 [00:09<03:26,  4.68s/it]\u001b[A\n",
            "  7%|▋         | 3/46 [00:13<03:02,  4.24s/it]\u001b[A\n",
            "  9%|▊         | 4/46 [00:17<02:49,  4.04s/it]\u001b[A\n",
            " 11%|█         | 5/46 [00:22<03:00,  4.40s/it]\u001b[A\n",
            " 13%|█▎        | 6/46 [00:25<02:40,  4.01s/it]\u001b[A\n",
            " 15%|█▌        | 7/46 [00:28<02:26,  3.76s/it]\u001b[A\n",
            " 17%|█▋        | 8/46 [00:31<02:16,  3.59s/it]\u001b[A\n",
            " 20%|█▉        | 9/46 [00:37<02:32,  4.12s/it]\u001b[A\n",
            " 22%|██▏       | 10/46 [00:40<02:20,  3.91s/it]\u001b[A\n",
            " 24%|██▍       | 11/46 [00:43<02:09,  3.70s/it]\u001b[A\n",
            " 26%|██▌       | 12/46 [00:46<02:00,  3.56s/it]\u001b[A\n",
            " 28%|██▊       | 13/46 [00:51<02:10,  3.96s/it]\u001b[A\n",
            " 30%|███       | 14/46 [00:55<02:05,  3.92s/it]\u001b[A\n",
            " 33%|███▎      | 15/46 [00:58<01:54,  3.71s/it]\u001b[A\n",
            " 35%|███▍      | 16/46 [01:02<01:47,  3.57s/it]\u001b[A\n",
            " 37%|███▋      | 17/46 [01:06<01:50,  3.82s/it]\u001b[A\n",
            " 39%|███▉      | 18/46 [01:10<01:51,  3.97s/it]\u001b[A\n",
            " 41%|████▏     | 19/46 [01:14<01:41,  3.75s/it]\u001b[A\n",
            " 43%|████▎     | 20/46 [01:17<01:33,  3.59s/it]\u001b[A\n",
            " 46%|████▌     | 21/46 [01:21<01:32,  3.70s/it]\u001b[A\n",
            " 48%|████▊     | 22/46 [01:26<01:36,  4.03s/it]\u001b[A\n",
            " 50%|█████     | 23/46 [01:29<01:27,  3.80s/it]\u001b[A\n",
            " 52%|█████▏    | 24/46 [01:32<01:19,  3.63s/it]\u001b[A\n",
            " 54%|█████▍    | 25/46 [01:36<01:15,  3.60s/it]\u001b[A\n",
            " 57%|█████▋    | 26/46 [01:41<01:21,  4.08s/it]\u001b[A\n",
            " 59%|█████▊    | 27/46 [01:44<01:12,  3.83s/it]\u001b[A\n",
            " 61%|██████    | 28/46 [01:47<01:05,  3.65s/it]\u001b[A\n",
            " 63%|██████▎   | 29/46 [01:51<00:59,  3.52s/it]\u001b[A\n",
            " 65%|██████▌   | 30/46 [01:56<01:04,  4.02s/it]\u001b[A\n",
            " 67%|██████▋   | 31/46 [02:00<01:02,  4.20s/it]\u001b[A\n",
            " 70%|██████▉   | 32/46 [02:05<01:00,  4.29s/it]\u001b[A\n",
            " 72%|███████▏  | 33/46 [02:09<00:55,  4.26s/it]\u001b[A\n",
            " 74%|███████▍  | 34/46 [02:14<00:52,  4.37s/it]\u001b[A\n",
            " 76%|███████▌  | 35/46 [02:17<00:44,  4.03s/it]\u001b[A\n",
            " 78%|███████▊  | 36/46 [02:20<00:37,  3.79s/it]\u001b[A\n",
            " 80%|████████  | 37/46 [02:24<00:33,  3.76s/it]\u001b[A\n",
            " 83%|████████▎ | 38/46 [02:29<00:33,  4.14s/it]\u001b[A\n",
            " 85%|████████▍ | 39/46 [02:32<00:27,  3.86s/it]\u001b[A\n",
            " 87%|████████▋ | 40/46 [02:35<00:22,  3.68s/it]\u001b[A\n",
            " 89%|████████▉ | 41/46 [02:38<00:17,  3.54s/it]\u001b[A\n",
            " 91%|█████████▏| 42/46 [02:44<00:16,  4.06s/it]\u001b[A\n",
            " 93%|█████████▎| 43/46 [02:47<00:11,  3.88s/it]\u001b[A\n",
            " 96%|█████████▌| 44/46 [02:50<00:07,  3.69s/it]\u001b[A\n",
            " 98%|█████████▊| 45/46 [02:54<00:03,  3.55s/it]\u001b[A\n",
            "100%|██████████| 46/46 [02:55<00:00,  3.82s/it]\n",
            " 50%|█████     | 4/8 [2:38:24<2:38:13, 2373.49s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy:113/128\n",
            " -> 0.8828125\n",
            "Accuracy:84/107\n",
            " -> 0.7850467289719626\n",
            "Accuracy:89/128\n",
            " -> 0.6953125\n",
            "Validation loss: 0.6177199196232401\n",
            "F1 Score (weighted): 0.7867599857949756\n",
            "Accuracy Score: 0.7878787878787878\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "Epoch 5:   0%|          | 0/182 [00:00<?, ?it/s]\u001b[A\n",
            "Epoch 5:   0%|          | 0/182 [00:12<?, ?it/s, training_loss=0.110]\u001b[A\n",
            "Epoch 5:   1%|          | 1/182 [00:12<36:33, 12.12s/it, training_loss=0.110]\u001b[A\n",
            "Epoch 5:   1%|          | 1/182 [00:24<36:33, 12.12s/it, training_loss=0.382]\u001b[A\n",
            "Epoch 5:   1%|          | 2/182 [00:24<37:09, 12.39s/it, training_loss=0.382]\u001b[A\n",
            "Epoch 5:   1%|          | 2/182 [00:37<37:09, 12.39s/it, training_loss=0.103]\u001b[A\n",
            "Epoch 5:   2%|▏         | 3/182 [00:37<37:16, 12.49s/it, training_loss=0.103]\u001b[A\n",
            "Epoch 5:   2%|▏         | 3/182 [00:47<37:16, 12.49s/it, training_loss=0.018]\u001b[A\n",
            "Epoch 5:   2%|▏         | 4/182 [00:47<34:50, 11.74s/it, training_loss=0.018]\u001b[A\n",
            "Epoch 5:   2%|▏         | 4/182 [00:59<34:50, 11.74s/it, training_loss=0.267]\u001b[A\n",
            "Epoch 5:   3%|▎         | 5/182 [00:59<34:58, 11.85s/it, training_loss=0.267]\u001b[A\n",
            "Epoch 5:   3%|▎         | 5/182 [01:12<34:58, 11.85s/it, training_loss=0.004]\u001b[A\n",
            "Epoch 5:   3%|▎         | 6/182 [01:12<35:28, 12.09s/it, training_loss=0.004]\u001b[A\n",
            "Epoch 5:   3%|▎         | 6/182 [01:25<35:28, 12.09s/it, training_loss=0.159]\u001b[A\n",
            "Epoch 5:   4%|▍         | 7/182 [01:25<35:46, 12.27s/it, training_loss=0.159]\u001b[A\n",
            "Epoch 5:   4%|▍         | 7/182 [01:35<35:46, 12.27s/it, training_loss=0.066]\u001b[A\n",
            "Epoch 5:   4%|▍         | 8/182 [01:35<34:12, 11.80s/it, training_loss=0.066]\u001b[A\n",
            "Epoch 5:   4%|▍         | 8/182 [01:47<34:12, 11.80s/it, training_loss=0.007]\u001b[A\n",
            "Epoch 5:   5%|▍         | 9/182 [01:47<33:54, 11.76s/it, training_loss=0.007]\u001b[A\n",
            "Epoch 5:   5%|▍         | 9/182 [02:00<33:54, 11.76s/it, training_loss=0.036]\u001b[A\n",
            "Epoch 5:   5%|▌         | 10/182 [02:00<34:24, 12.00s/it, training_loss=0.036]\u001b[A\n",
            "Epoch 5:   5%|▌         | 10/182 [02:12<34:24, 12.00s/it, training_loss=0.015]\u001b[A\n",
            "Epoch 5:   6%|▌         | 11/182 [02:12<34:44, 12.19s/it, training_loss=0.015]\u001b[A\n",
            "Epoch 5:   6%|▌         | 11/182 [02:23<34:44, 12.19s/it, training_loss=0.017]\u001b[A\n",
            "Epoch 5:   7%|▋         | 12/182 [02:23<33:37, 11.87s/it, training_loss=0.017]\u001b[A\n",
            "Epoch 5:   7%|▋         | 12/182 [02:35<33:37, 11.87s/it, training_loss=0.187]\u001b[A\n",
            "Epoch 5:   7%|▋         | 13/182 [02:35<33:06, 11.76s/it, training_loss=0.187]\u001b[A\n",
            "Epoch 5:   7%|▋         | 13/182 [02:47<33:06, 11.76s/it, training_loss=0.006]\u001b[A\n",
            "Epoch 5:   8%|▊         | 14/182 [02:47<33:35, 11.99s/it, training_loss=0.006]\u001b[A\n",
            "Epoch 5:   8%|▊         | 14/182 [03:00<33:35, 11.99s/it, training_loss=0.299]\u001b[A\n",
            "Epoch 5:   8%|▊         | 15/182 [03:00<33:55, 12.19s/it, training_loss=0.299]\u001b[A\n",
            "Epoch 5:   8%|▊         | 15/182 [03:12<33:55, 12.19s/it, training_loss=0.038]\u001b[A\n",
            "Epoch 5:   9%|▉         | 16/182 [03:12<33:13, 12.01s/it, training_loss=0.038]\u001b[A\n",
            "Epoch 5:   9%|▉         | 16/182 [03:23<33:13, 12.01s/it, training_loss=0.045]\u001b[A\n",
            "Epoch 5:   9%|▉         | 17/182 [03:23<32:22, 11.77s/it, training_loss=0.045]\u001b[A\n",
            "Epoch 5:   9%|▉         | 17/182 [03:35<32:22, 11.77s/it, training_loss=0.018]\u001b[A\n",
            "Epoch 5:  10%|▉         | 18/182 [03:35<32:48, 12.00s/it, training_loss=0.018]\u001b[A\n",
            "Epoch 5:  10%|▉         | 18/182 [03:48<32:48, 12.00s/it, training_loss=0.019]\u001b[A\n",
            "Epoch 5:  10%|█         | 19/182 [03:48<33:09, 12.20s/it, training_loss=0.019]\u001b[A\n",
            "Epoch 5:  10%|█         | 19/182 [04:00<33:09, 12.20s/it, training_loss=0.133]\u001b[A\n",
            "Epoch 5:  11%|█         | 20/182 [04:00<32:47, 12.15s/it, training_loss=0.133]\u001b[A\n",
            "Epoch 5:  11%|█         | 20/182 [04:13<32:47, 12.15s/it, training_loss=0.042]\u001b[A\n",
            "Epoch 5:  12%|█▏        | 21/182 [04:13<33:31, 12.50s/it, training_loss=0.042]\u001b[A\n",
            "Epoch 5:  12%|█▏        | 21/182 [04:26<33:31, 12.50s/it, training_loss=0.169]\u001b[A\n",
            "Epoch 5:  12%|█▏        | 22/182 [04:26<33:18, 12.49s/it, training_loss=0.169]\u001b[A\n",
            "Epoch 5:  12%|█▏        | 22/182 [04:39<33:18, 12.49s/it, training_loss=0.105]\u001b[A\n",
            "Epoch 5:  13%|█▎        | 23/182 [04:39<33:14, 12.54s/it, training_loss=0.105]\u001b[A\n",
            "Epoch 5:  13%|█▎        | 23/182 [04:51<33:14, 12.54s/it, training_loss=0.109]\u001b[A\n",
            "Epoch 5:  13%|█▎        | 24/182 [04:51<33:01, 12.54s/it, training_loss=0.109]\u001b[A\n",
            "Epoch 5:  13%|█▎        | 24/182 [05:02<33:01, 12.54s/it, training_loss=0.007]\u001b[A\n",
            "Epoch 5:  14%|█▎        | 25/182 [05:02<31:08, 11.90s/it, training_loss=0.007]\u001b[A\n",
            "Epoch 5:  14%|█▎        | 25/182 [05:14<31:08, 11.90s/it, training_loss=0.019]\u001b[A\n",
            "Epoch 5:  14%|█▍        | 26/182 [05:14<31:16, 12.03s/it, training_loss=0.019]\u001b[A\n",
            "Epoch 5:  14%|█▍        | 26/182 [05:27<31:16, 12.03s/it, training_loss=0.006]\u001b[A\n",
            "Epoch 5:  15%|█▍        | 27/182 [05:27<31:37, 12.24s/it, training_loss=0.006]\u001b[A\n",
            "Epoch 5:  15%|█▍        | 27/182 [05:39<31:37, 12.24s/it, training_loss=0.011]\u001b[A\n",
            "Epoch 5:  15%|█▌        | 28/182 [05:39<31:45, 12.37s/it, training_loss=0.011]\u001b[A\n",
            "Epoch 5:  15%|█▌        | 28/182 [05:50<31:45, 12.37s/it, training_loss=0.041]\u001b[A\n",
            "Epoch 5:  16%|█▌        | 29/182 [05:50<30:16, 11.87s/it, training_loss=0.041]\u001b[A\n",
            "Epoch 5:  16%|█▌        | 29/182 [06:02<30:16, 11.87s/it, training_loss=0.026]\u001b[A\n",
            "Epoch 5:  16%|█▋        | 30/182 [06:02<30:06, 11.89s/it, training_loss=0.026]\u001b[A\n",
            "Epoch 5:  16%|█▋        | 30/182 [06:14<30:06, 11.89s/it, training_loss=0.281]\u001b[A\n",
            "Epoch 5:  17%|█▋        | 31/182 [06:14<30:25, 12.09s/it, training_loss=0.281]\u001b[A\n",
            "Epoch 5:  17%|█▋        | 31/182 [06:27<30:25, 12.09s/it, training_loss=0.019]\u001b[A\n",
            "Epoch 5:  18%|█▊        | 32/182 [06:27<30:37, 12.25s/it, training_loss=0.019]\u001b[A\n",
            "Epoch 5:  18%|█▊        | 32/182 [06:38<30:37, 12.25s/it, training_loss=0.012]\u001b[A\n",
            "Epoch 5:  18%|█▊        | 33/182 [06:38<29:22, 11.83s/it, training_loss=0.012]\u001b[A\n",
            "Epoch 5:  18%|█▊        | 33/182 [06:50<29:22, 11.83s/it, training_loss=0.017]\u001b[A\n",
            "Epoch 5:  19%|█▊        | 34/182 [06:50<29:06, 11.80s/it, training_loss=0.017]\u001b[A\n",
            "Epoch 5:  19%|█▊        | 34/182 [07:02<29:06, 11.80s/it, training_loss=0.012]\u001b[A\n",
            "Epoch 5:  19%|█▉        | 35/182 [07:02<29:27, 12.02s/it, training_loss=0.012]\u001b[A\n",
            "Epoch 5:  19%|█▉        | 35/182 [07:15<29:27, 12.02s/it, training_loss=0.006]\u001b[A\n",
            "Epoch 5:  20%|█▉        | 36/182 [07:15<29:41, 12.20s/it, training_loss=0.006]\u001b[A\n",
            "Epoch 5:  20%|█▉        | 36/182 [07:26<29:41, 12.20s/it, training_loss=0.005]\u001b[A\n",
            "Epoch 5:  20%|██        | 37/182 [07:26<28:44, 11.89s/it, training_loss=0.005]\u001b[A\n",
            "Epoch 5:  20%|██        | 37/182 [07:37<28:44, 11.89s/it, training_loss=0.192]\u001b[A\n",
            "Epoch 5:  21%|██        | 38/182 [07:38<28:16, 11.78s/it, training_loss=0.192]\u001b[A\n",
            "Epoch 5:  21%|██        | 38/182 [07:50<28:16, 11.78s/it, training_loss=0.173]\u001b[A\n",
            "Epoch 5:  21%|██▏       | 39/182 [07:50<28:36, 12.00s/it, training_loss=0.173]\u001b[A\n",
            "Epoch 5:  21%|██▏       | 39/182 [08:03<28:36, 12.00s/it, training_loss=0.089]\u001b[A\n",
            "Epoch 5:  22%|██▏       | 40/182 [08:03<28:48, 12.18s/it, training_loss=0.089]\u001b[A\n",
            "Epoch 5:  22%|██▏       | 40/182 [08:14<28:48, 12.18s/it, training_loss=0.009]\u001b[A\n",
            "Epoch 5:  23%|██▎       | 41/182 [08:14<28:00, 11.92s/it, training_loss=0.009]\u001b[A\n",
            "Epoch 5:  23%|██▎       | 41/182 [08:25<28:00, 11.92s/it, training_loss=0.012]\u001b[A\n",
            "Epoch 5:  23%|██▎       | 42/182 [08:25<27:19, 11.71s/it, training_loss=0.012]\u001b[A\n",
            "Epoch 5:  23%|██▎       | 42/182 [08:38<27:19, 11.71s/it, training_loss=0.017]\u001b[A\n",
            "Epoch 5:  24%|██▎       | 43/182 [08:38<27:41, 11.95s/it, training_loss=0.017]\u001b[A\n",
            "Epoch 5:  24%|██▎       | 43/182 [08:50<27:41, 11.95s/it, training_loss=0.006]\u001b[A\n",
            "Epoch 5:  24%|██▍       | 44/182 [08:50<27:55, 12.14s/it, training_loss=0.006]\u001b[A\n",
            "Epoch 5:  24%|██▍       | 44/182 [09:02<27:55, 12.14s/it, training_loss=0.011]\u001b[A\n",
            "Epoch 5:  25%|██▍       | 45/182 [09:02<27:22, 11.99s/it, training_loss=0.011]\u001b[A\n",
            "Epoch 5:  25%|██▍       | 45/182 [09:15<27:22, 11.99s/it, training_loss=0.005]\u001b[A\n",
            "Epoch 5:  25%|██▌       | 46/182 [09:15<28:11, 12.44s/it, training_loss=0.005]\u001b[A\n",
            "Epoch 5:  25%|██▌       | 46/182 [09:28<28:11, 12.44s/it, training_loss=0.006]\u001b[A\n",
            "Epoch 5:  26%|██▌       | 47/182 [09:28<28:04, 12.48s/it, training_loss=0.006]\u001b[A\n",
            "Epoch 5:  26%|██▌       | 47/182 [09:40<28:04, 12.48s/it, training_loss=0.048]\u001b[A\n",
            "Epoch 5:  26%|██▋       | 48/182 [09:40<27:54, 12.50s/it, training_loss=0.048]\u001b[A\n",
            "Epoch 5:  26%|██▋       | 48/182 [09:51<27:54, 12.50s/it, training_loss=0.013]\u001b[A\n",
            "Epoch 5:  27%|██▋       | 49/182 [09:51<26:24, 11.91s/it, training_loss=0.013]\u001b[A\n",
            "Epoch 5:  27%|██▋       | 49/182 [10:03<26:24, 11.91s/it, training_loss=0.048]\u001b[A\n",
            "Epoch 5:  27%|██▋       | 50/182 [10:03<26:16, 11.95s/it, training_loss=0.048]\u001b[A\n",
            "Epoch 5:  27%|██▋       | 50/182 [10:19<26:16, 11.95s/it, training_loss=0.345]\u001b[A\n",
            "Epoch 5:  28%|██▊       | 51/182 [10:19<28:29, 13.05s/it, training_loss=0.345]\u001b[A\n",
            "Epoch 5:  28%|██▊       | 51/182 [10:31<28:29, 13.05s/it, training_loss=0.071]\u001b[A\n",
            "Epoch 5:  29%|██▊       | 52/182 [10:31<28:01, 12.93s/it, training_loss=0.071]\u001b[A\n",
            "Epoch 5:  29%|██▊       | 52/182 [10:42<28:01, 12.93s/it, training_loss=0.067]\u001b[A\n",
            "Epoch 5:  29%|██▉       | 53/182 [10:42<26:34, 12.36s/it, training_loss=0.067]\u001b[A\n",
            "Epoch 5:  29%|██▉       | 53/182 [10:54<26:34, 12.36s/it, training_loss=0.007]\u001b[A\n",
            "Epoch 5:  30%|██▉       | 54/182 [10:54<25:57, 12.17s/it, training_loss=0.007]\u001b[A\n",
            "Epoch 5:  30%|██▉       | 54/182 [11:07<25:57, 12.17s/it, training_loss=0.018]\u001b[A\n",
            "Epoch 5:  30%|███       | 55/182 [11:07<26:03, 12.31s/it, training_loss=0.018]\u001b[A\n",
            "Epoch 5:  30%|███       | 55/182 [11:19<26:03, 12.31s/it, training_loss=0.007]\u001b[A\n",
            "Epoch 5:  31%|███       | 56/182 [11:19<26:07, 12.44s/it, training_loss=0.007]\u001b[A\n",
            "Epoch 5:  31%|███       | 56/182 [11:31<26:07, 12.44s/it, training_loss=0.008]\u001b[A\n",
            "Epoch 5:  31%|███▏      | 57/182 [11:31<25:15, 12.12s/it, training_loss=0.008]\u001b[A\n",
            "Epoch 5:  31%|███▏      | 57/182 [11:42<25:15, 12.12s/it, training_loss=0.007]\u001b[A\n",
            "Epoch 5:  32%|███▏      | 58/182 [11:42<24:37, 11.92s/it, training_loss=0.007]\u001b[A\n",
            "Epoch 5:  32%|███▏      | 58/182 [11:55<24:37, 11.92s/it, training_loss=0.030]\u001b[A\n",
            "Epoch 5:  32%|███▏      | 59/182 [11:55<24:53, 12.14s/it, training_loss=0.030]\u001b[A\n",
            "Epoch 5:  32%|███▏      | 59/182 [12:08<24:53, 12.14s/it, training_loss=0.056]\u001b[A\n",
            "Epoch 5:  33%|███▎      | 60/182 [12:08<24:57, 12.27s/it, training_loss=0.056]\u001b[A\n",
            "Epoch 5:  33%|███▎      | 60/182 [12:19<24:57, 12.27s/it, training_loss=0.031]\u001b[A\n",
            "Epoch 5:  34%|███▎      | 61/182 [12:19<24:29, 12.14s/it, training_loss=0.031]\u001b[A\n",
            "Epoch 5:  34%|███▎      | 61/182 [12:30<24:29, 12.14s/it, training_loss=0.011]\u001b[A\n",
            "Epoch 5:  34%|███▍      | 62/182 [12:30<23:34, 11.79s/it, training_loss=0.011]\u001b[A\n",
            "Epoch 5:  34%|███▍      | 62/182 [12:43<23:34, 11.79s/it, training_loss=0.212]\u001b[A\n",
            "Epoch 5:  35%|███▍      | 63/182 [12:43<23:52, 12.03s/it, training_loss=0.212]\u001b[A\n",
            "Epoch 5:  35%|███▍      | 63/182 [12:56<23:52, 12.03s/it, training_loss=0.006]\u001b[A\n",
            "Epoch 5:  35%|███▌      | 64/182 [12:56<24:00, 12.21s/it, training_loss=0.006]\u001b[A\n",
            "Epoch 5:  35%|███▌      | 64/182 [13:08<24:00, 12.21s/it, training_loss=0.016]\u001b[A\n",
            "Epoch 5:  36%|███▌      | 65/182 [13:08<23:42, 12.16s/it, training_loss=0.016]\u001b[A\n",
            "Epoch 5:  36%|███▌      | 65/182 [13:18<23:42, 12.16s/it, training_loss=0.005]\u001b[A\n",
            "Epoch 5:  36%|███▋      | 66/182 [13:18<22:44, 11.77s/it, training_loss=0.005]\u001b[A\n",
            "Epoch 5:  36%|███▋      | 66/182 [13:31<22:44, 11.77s/it, training_loss=0.004]\u001b[A\n",
            "Epoch 5:  37%|███▋      | 67/182 [13:31<23:02, 12.02s/it, training_loss=0.004]\u001b[A\n",
            "Epoch 5:  37%|███▋      | 67/182 [13:44<23:02, 12.02s/it, training_loss=0.009]\u001b[A\n",
            "Epoch 5:  37%|███▋      | 68/182 [13:44<23:11, 12.21s/it, training_loss=0.009]\u001b[A\n",
            "Epoch 5:  37%|███▋      | 68/182 [13:56<23:11, 12.21s/it, training_loss=0.006]\u001b[A\n",
            "Epoch 5:  38%|███▊      | 69/182 [13:56<23:03, 12.25s/it, training_loss=0.006]\u001b[A\n",
            "Epoch 5:  38%|███▊      | 69/182 [14:10<23:03, 12.25s/it, training_loss=0.006]\u001b[A\n",
            "Epoch 5:  38%|███▊      | 70/182 [14:10<23:45, 12.73s/it, training_loss=0.006]\u001b[A\n",
            "Epoch 5:  38%|███▊      | 70/182 [14:21<23:45, 12.73s/it, training_loss=0.037]\u001b[A\n",
            "Epoch 5:  39%|███▉      | 71/182 [14:21<22:52, 12.37s/it, training_loss=0.037]\u001b[A\n",
            "Epoch 5:  39%|███▉      | 71/182 [14:34<22:52, 12.37s/it, training_loss=0.157]\u001b[A\n",
            "Epoch 5:  40%|███▉      | 72/182 [14:34<22:50, 12.46s/it, training_loss=0.157]\u001b[A\n",
            "Epoch 5:  40%|███▉      | 72/182 [14:47<22:50, 12.46s/it, training_loss=0.042]\u001b[A\n",
            "Epoch 5:  40%|████      | 73/182 [14:47<22:48, 12.55s/it, training_loss=0.042]\u001b[A\n",
            "Epoch 5:  40%|████      | 73/182 [14:59<22:48, 12.55s/it, training_loss=0.008]\u001b[A\n",
            "Epoch 5:  41%|████      | 74/182 [14:59<22:20, 12.41s/it, training_loss=0.008]\u001b[A\n",
            "Epoch 5:  41%|████      | 74/182 [15:10<22:20, 12.41s/it, training_loss=0.104]\u001b[A\n",
            "Epoch 5:  41%|████      | 75/182 [15:10<21:19, 11.96s/it, training_loss=0.104]\u001b[A\n",
            "Epoch 5:  41%|████      | 75/182 [15:23<21:19, 11.96s/it, training_loss=0.043]\u001b[A\n",
            "Epoch 5:  42%|████▏     | 76/182 [15:23<21:29, 12.17s/it, training_loss=0.043]\u001b[A\n",
            "Epoch 5:  42%|████▏     | 76/182 [15:35<21:29, 12.17s/it, training_loss=0.005]\u001b[A\n",
            "Epoch 5:  42%|████▏     | 77/182 [15:35<21:33, 12.32s/it, training_loss=0.005]\u001b[A\n",
            "Epoch 5:  42%|████▏     | 77/182 [15:47<21:33, 12.32s/it, training_loss=0.031]\u001b[A\n",
            "Epoch 5:  43%|████▎     | 78/182 [15:47<21:17, 12.28s/it, training_loss=0.031]\u001b[A\n",
            "Epoch 5:  43%|████▎     | 78/182 [15:58<21:17, 12.28s/it, training_loss=0.181]\u001b[A\n",
            "Epoch 5:  43%|████▎     | 79/182 [15:58<20:15, 11.80s/it, training_loss=0.181]\u001b[A\n",
            "Epoch 5:  43%|████▎     | 79/182 [16:11<20:15, 11.80s/it, training_loss=0.161]\u001b[A\n",
            "Epoch 5:  44%|████▍     | 80/182 [16:11<20:26, 12.02s/it, training_loss=0.161]\u001b[A\n",
            "Epoch 5:  44%|████▍     | 80/182 [16:23<20:26, 12.02s/it, training_loss=0.004]\u001b[A\n",
            "Epoch 5:  45%|████▍     | 81/182 [16:23<20:34, 12.22s/it, training_loss=0.004]\u001b[A\n",
            "Epoch 5:  45%|████▍     | 81/182 [16:36<20:34, 12.22s/it, training_loss=0.013]\u001b[A\n",
            "Epoch 5:  45%|████▌     | 82/182 [16:36<20:31, 12.32s/it, training_loss=0.013]\u001b[A\n",
            "Epoch 5:  45%|████▌     | 82/182 [16:46<20:31, 12.32s/it, training_loss=0.014]\u001b[A\n",
            "Epoch 5:  46%|████▌     | 83/182 [16:46<19:26, 11.79s/it, training_loss=0.014]\u001b[A\n",
            "Epoch 5:  46%|████▌     | 83/182 [16:59<19:26, 11.79s/it, training_loss=0.079]\u001b[A\n",
            "Epoch 5:  46%|████▌     | 84/182 [16:59<19:37, 12.01s/it, training_loss=0.079]\u001b[A\n",
            "Epoch 5:  46%|████▌     | 84/182 [17:12<19:37, 12.01s/it, training_loss=0.004]\u001b[A\n",
            "Epoch 5:  47%|████▋     | 85/182 [17:12<19:43, 12.21s/it, training_loss=0.004]\u001b[A\n",
            "Epoch 5:  47%|████▋     | 85/182 [17:24<19:43, 12.21s/it, training_loss=0.080]\u001b[A\n",
            "Epoch 5:  47%|████▋     | 86/182 [17:24<19:42, 12.32s/it, training_loss=0.080]\u001b[A\n",
            "Epoch 5:  47%|████▋     | 86/182 [17:35<19:42, 12.32s/it, training_loss=0.008]\u001b[A\n",
            "Epoch 5:  48%|████▊     | 87/182 [17:35<18:37, 11.77s/it, training_loss=0.008]\u001b[A\n",
            "Epoch 5:  48%|████▊     | 87/182 [17:47<18:37, 11.77s/it, training_loss=0.020]\u001b[A\n",
            "Epoch 5:  48%|████▊     | 88/182 [17:47<18:41, 11.93s/it, training_loss=0.020]\u001b[A\n",
            "Epoch 5:  48%|████▊     | 88/182 [18:00<18:41, 11.93s/it, training_loss=0.004]\u001b[A\n",
            "Epoch 5:  49%|████▉     | 89/182 [18:00<18:50, 12.15s/it, training_loss=0.004]\u001b[A\n",
            "Epoch 5:  49%|████▉     | 89/182 [18:12<18:50, 12.15s/it, training_loss=0.010]\u001b[A\n",
            "Epoch 5:  49%|████▉     | 90/182 [18:12<18:50, 12.29s/it, training_loss=0.010]\u001b[A\n",
            "Epoch 5:  49%|████▉     | 90/182 [18:23<18:50, 12.29s/it, training_loss=0.009]\u001b[A\n",
            "Epoch 5:  50%|█████     | 91/182 [18:23<17:56, 11.83s/it, training_loss=0.009]\u001b[A\n",
            "Epoch 5:  50%|█████     | 91/182 [18:35<17:56, 11.83s/it, training_loss=0.043]\u001b[A\n",
            "Epoch 5:  51%|█████     | 92/182 [18:35<17:46, 11.85s/it, training_loss=0.043]\u001b[A\n",
            "Epoch 5:  51%|█████     | 92/182 [18:47<17:46, 11.85s/it, training_loss=0.004]\u001b[A\n",
            "Epoch 5:  51%|█████     | 93/182 [18:47<17:53, 12.07s/it, training_loss=0.004]\u001b[A\n",
            "Epoch 5:  51%|█████     | 93/182 [19:00<17:53, 12.07s/it, training_loss=0.003]\u001b[A\n",
            "Epoch 5:  52%|█████▏    | 94/182 [19:00<17:58, 12.25s/it, training_loss=0.003]\u001b[A\n",
            "Epoch 5:  52%|█████▏    | 94/182 [19:13<17:58, 12.25s/it, training_loss=0.006]\u001b[A\n",
            "Epoch 5:  52%|█████▏    | 95/182 [19:13<17:51, 12.32s/it, training_loss=0.006]\u001b[A\n",
            "Epoch 5:  52%|█████▏    | 95/182 [19:25<17:51, 12.32s/it, training_loss=0.110]\u001b[A\n",
            "Epoch 5:  53%|█████▎    | 96/182 [19:25<17:53, 12.48s/it, training_loss=0.110]\u001b[A\n",
            "Epoch 5:  53%|█████▎    | 96/182 [19:38<17:53, 12.48s/it, training_loss=0.056]\u001b[A\n",
            "Epoch 5:  53%|█████▎    | 97/182 [19:38<17:44, 12.52s/it, training_loss=0.056]\u001b[A\n",
            "Epoch 5:  53%|█████▎    | 97/182 [19:51<17:44, 12.52s/it, training_loss=0.221]\u001b[A\n",
            "Epoch 5:  54%|█████▍    | 98/182 [19:51<17:34, 12.56s/it, training_loss=0.221]\u001b[A\n",
            "Epoch 5:  54%|█████▍    | 98/182 [20:01<17:34, 12.56s/it, training_loss=0.031]\u001b[A\n",
            "Epoch 5:  54%|█████▍    | 99/182 [20:02<16:37, 12.02s/it, training_loss=0.031]\u001b[A\n",
            "Epoch 5:  54%|█████▍    | 99/182 [20:13<16:37, 12.02s/it, training_loss=0.019]\u001b[A\n",
            "Epoch 5:  55%|█████▍    | 100/182 [20:13<16:24, 12.01s/it, training_loss=0.019]\u001b[A\n",
            "Epoch 5:  55%|█████▍    | 100/182 [20:26<16:24, 12.01s/it, training_loss=0.006]\u001b[A\n",
            "Epoch 5:  55%|█████▌    | 101/182 [20:26<16:27, 12.19s/it, training_loss=0.006]\u001b[A\n",
            "Epoch 5:  55%|█████▌    | 101/182 [20:39<16:27, 12.19s/it, training_loss=0.011]\u001b[A\n",
            "Epoch 5:  56%|█████▌    | 102/182 [20:39<16:26, 12.33s/it, training_loss=0.011]\u001b[A\n",
            "Epoch 5:  56%|█████▌    | 102/182 [20:50<16:26, 12.33s/it, training_loss=0.182]\u001b[A\n",
            "Epoch 5:  57%|█████▋    | 103/182 [20:50<15:41, 11.91s/it, training_loss=0.182]\u001b[A\n",
            "Epoch 5:  57%|█████▋    | 103/182 [21:01<15:41, 11.91s/it, training_loss=0.018]\u001b[A\n",
            "Epoch 5:  57%|█████▋    | 104/182 [21:01<15:25, 11.86s/it, training_loss=0.018]\u001b[A\n",
            "Epoch 5:  57%|█████▋    | 104/182 [21:14<15:25, 11.86s/it, training_loss=0.188]\u001b[A\n",
            "Epoch 5:  58%|█████▊    | 105/182 [21:14<15:31, 12.10s/it, training_loss=0.188]\u001b[A\n",
            "Epoch 5:  58%|█████▊    | 105/182 [21:27<15:31, 12.10s/it, training_loss=0.006]\u001b[A\n",
            "Epoch 5:  58%|█████▊    | 106/182 [21:27<15:33, 12.28s/it, training_loss=0.006]\u001b[A\n",
            "Epoch 5:  58%|█████▊    | 106/182 [21:38<15:33, 12.28s/it, training_loss=0.010]\u001b[A\n",
            "Epoch 5:  59%|█████▉    | 107/182 [21:38<15:01, 12.02s/it, training_loss=0.010]\u001b[A\n",
            "Epoch 5:  59%|█████▉    | 107/182 [21:49<15:01, 12.02s/it, training_loss=0.004]\u001b[A\n",
            "Epoch 5:  59%|█████▉    | 108/182 [21:49<14:32, 11.78s/it, training_loss=0.004]\u001b[A\n",
            "Epoch 5:  59%|█████▉    | 108/182 [22:02<14:32, 11.78s/it, training_loss=0.003]\u001b[A\n",
            "Epoch 5:  60%|█████▉    | 109/182 [22:02<14:36, 12.01s/it, training_loss=0.003]\u001b[A\n",
            "Epoch 5:  60%|█████▉    | 109/182 [22:15<14:36, 12.01s/it, training_loss=0.026]\u001b[A\n",
            "Epoch 5:  60%|██████    | 110/182 [22:15<14:38, 12.20s/it, training_loss=0.026]\u001b[A\n",
            "Epoch 5:  60%|██████    | 110/182 [22:26<14:38, 12.20s/it, training_loss=0.198]\u001b[A\n",
            "Epoch 5:  61%|██████    | 111/182 [22:26<14:14, 12.03s/it, training_loss=0.198]\u001b[A\n",
            "Epoch 5:  61%|██████    | 111/182 [22:37<14:14, 12.03s/it, training_loss=0.004]\u001b[A\n",
            "Epoch 5:  62%|██████▏   | 112/182 [22:37<13:39, 11.71s/it, training_loss=0.004]\u001b[A\n",
            "Epoch 5:  62%|██████▏   | 112/182 [22:50<13:39, 11.71s/it, training_loss=0.006]\u001b[A\n",
            "Epoch 5:  62%|██████▏   | 113/182 [22:50<13:46, 11.98s/it, training_loss=0.006]\u001b[A\n",
            "Epoch 5:  62%|██████▏   | 113/182 [23:03<13:46, 11.98s/it, training_loss=0.048]\u001b[A\n",
            "Epoch 5:  63%|██████▎   | 114/182 [23:03<13:49, 12.20s/it, training_loss=0.048]\u001b[A\n",
            "Epoch 5:  63%|██████▎   | 114/182 [23:15<13:49, 12.20s/it, training_loss=0.079]\u001b[A\n",
            "Epoch 5:  63%|██████▎   | 115/182 [23:15<13:35, 12.17s/it, training_loss=0.079]\u001b[A\n",
            "Epoch 5:  63%|██████▎   | 115/182 [23:26<13:35, 12.17s/it, training_loss=0.010]\u001b[A\n",
            "Epoch 5:  64%|██████▎   | 116/182 [23:26<12:58, 11.80s/it, training_loss=0.010]\u001b[A\n",
            "Epoch 5:  64%|██████▎   | 116/182 [23:38<12:58, 11.80s/it, training_loss=0.025]\u001b[A\n",
            "Epoch 5:  64%|██████▍   | 117/182 [23:38<13:01, 12.02s/it, training_loss=0.025]\u001b[A\n",
            "Epoch 5:  64%|██████▍   | 117/182 [23:51<13:01, 12.02s/it, training_loss=0.008]\u001b[A\n",
            "Epoch 5:  65%|██████▍   | 118/182 [23:51<13:00, 12.20s/it, training_loss=0.008]\u001b[A\n",
            "Epoch 5:  65%|██████▍   | 118/182 [24:03<13:00, 12.20s/it, training_loss=0.007]\u001b[A\n",
            "Epoch 5:  65%|██████▌   | 119/182 [24:03<12:49, 12.21s/it, training_loss=0.007]\u001b[A\n",
            "Epoch 5:  65%|██████▌   | 119/182 [24:15<12:49, 12.21s/it, training_loss=0.007]\u001b[A\n",
            "Epoch 5:  66%|██████▌   | 120/182 [24:15<12:25, 12.02s/it, training_loss=0.007]\u001b[A\n",
            "Epoch 5:  66%|██████▌   | 120/182 [24:28<12:25, 12.02s/it, training_loss=0.007]\u001b[A\n",
            "Epoch 5:  66%|██████▋   | 121/182 [24:28<12:47, 12.59s/it, training_loss=0.007]\u001b[A\n",
            "Epoch 5:  66%|██████▋   | 121/182 [24:41<12:47, 12.59s/it, training_loss=0.182]\u001b[A\n",
            "Epoch 5:  67%|██████▋   | 122/182 [24:41<12:35, 12.60s/it, training_loss=0.182]\u001b[A\n",
            "Epoch 5:  67%|██████▋   | 122/182 [24:53<12:35, 12.60s/it, training_loss=0.192]\u001b[A\n",
            "Epoch 5:  68%|██████▊   | 123/182 [24:53<12:02, 12.24s/it, training_loss=0.192]\u001b[A\n",
            "Epoch 5:  68%|██████▊   | 123/182 [25:04<12:02, 12.24s/it, training_loss=0.095]\u001b[A\n",
            "Epoch 5:  68%|██████▊   | 124/182 [25:04<11:33, 11.95s/it, training_loss=0.095]\u001b[A\n",
            "Epoch 5:  68%|██████▊   | 124/182 [25:16<11:33, 11.95s/it, training_loss=0.005]\u001b[A\n",
            "Epoch 5:  69%|██████▊   | 125/182 [25:16<11:33, 12.17s/it, training_loss=0.005]\u001b[A\n",
            "Epoch 5:  69%|██████▊   | 125/182 [25:29<11:33, 12.17s/it, training_loss=0.219]\u001b[A\n",
            "Epoch 5:  69%|██████▉   | 126/182 [25:29<11:30, 12.33s/it, training_loss=0.219]\u001b[A\n",
            "Epoch 5:  69%|██████▉   | 126/182 [25:41<11:30, 12.33s/it, training_loss=0.005]\u001b[A\n",
            "Epoch 5:  70%|██████▉   | 127/182 [25:41<11:10, 12.19s/it, training_loss=0.005]\u001b[A\n",
            "Epoch 5:  70%|██████▉   | 127/182 [25:52<11:10, 12.19s/it, training_loss=0.006]\u001b[A\n",
            "Epoch 5:  70%|███████   | 128/182 [25:52<10:36, 11.78s/it, training_loss=0.006]\u001b[A\n",
            "Epoch 5:  70%|███████   | 128/182 [26:04<10:36, 11.78s/it, training_loss=0.015]\u001b[A\n",
            "Epoch 5:  71%|███████   | 129/182 [26:04<10:37, 12.02s/it, training_loss=0.015]\u001b[A\n",
            "Epoch 5:  71%|███████   | 129/182 [26:17<10:37, 12.02s/it, training_loss=0.005]\u001b[A\n",
            "Epoch 5:  71%|███████▏  | 130/182 [26:17<10:34, 12.19s/it, training_loss=0.005]\u001b[A\n",
            "Epoch 5:  71%|███████▏  | 130/182 [26:29<10:34, 12.19s/it, training_loss=0.100]\u001b[A\n",
            "Epoch 5:  72%|███████▏  | 131/182 [26:29<10:21, 12.19s/it, training_loss=0.100]\u001b[A\n",
            "Epoch 5:  72%|███████▏  | 131/182 [26:40<10:21, 12.19s/it, training_loss=0.005]\u001b[A\n",
            "Epoch 5:  73%|███████▎  | 132/182 [26:40<09:46, 11.73s/it, training_loss=0.005]\u001b[A\n",
            "Epoch 5:  73%|███████▎  | 132/182 [26:52<09:46, 11.73s/it, training_loss=0.288]\u001b[A\n",
            "Epoch 5:  73%|███████▎  | 133/182 [26:52<09:47, 11.99s/it, training_loss=0.288]\u001b[A\n",
            "Epoch 5:  73%|███████▎  | 133/182 [27:05<09:47, 11.99s/it, training_loss=0.008]\u001b[A\n",
            "Epoch 5:  74%|███████▎  | 134/182 [27:05<09:44, 12.19s/it, training_loss=0.008]\u001b[A\n",
            "Epoch 5:  74%|███████▎  | 134/182 [27:18<09:44, 12.19s/it, training_loss=0.005]\u001b[A\n",
            "Epoch 5:  74%|███████▍  | 135/182 [27:18<09:37, 12.29s/it, training_loss=0.005]\u001b[A\n",
            "Epoch 5:  74%|███████▍  | 135/182 [27:28<09:37, 12.29s/it, training_loss=0.016]\u001b[A\n",
            "Epoch 5:  75%|███████▍  | 136/182 [27:28<09:04, 11.83s/it, training_loss=0.016]\u001b[A\n",
            "Epoch 5:  75%|███████▍  | 136/182 [27:41<09:04, 11.83s/it, training_loss=0.110]\u001b[A\n",
            "Epoch 5:  75%|███████▌  | 137/182 [27:41<09:01, 12.03s/it, training_loss=0.110]\u001b[A\n",
            "Epoch 5:  75%|███████▌  | 137/182 [27:55<09:01, 12.03s/it, training_loss=0.024]\u001b[A\n",
            "Epoch 5:  76%|███████▌  | 138/182 [27:55<09:11, 12.54s/it, training_loss=0.024]\u001b[A\n",
            "Epoch 5:  76%|███████▌  | 138/182 [28:07<09:11, 12.54s/it, training_loss=0.011]\u001b[A\n",
            "Epoch 5:  76%|███████▋  | 139/182 [28:07<08:59, 12.55s/it, training_loss=0.011]\u001b[A\n",
            "Epoch 5:  76%|███████▋  | 139/182 [28:18<08:59, 12.55s/it, training_loss=0.048]\u001b[A\n",
            "Epoch 5:  77%|███████▋  | 140/182 [28:18<08:20, 11.92s/it, training_loss=0.048]\u001b[A\n",
            "Epoch 5:  77%|███████▋  | 140/182 [28:30<08:20, 11.92s/it, training_loss=0.097]\u001b[A\n",
            "Epoch 5:  77%|███████▋  | 141/182 [28:30<08:12, 12.01s/it, training_loss=0.097]\u001b[A\n",
            "Epoch 5:  77%|███████▋  | 141/182 [28:42<08:12, 12.01s/it, training_loss=0.251]\u001b[A\n",
            "Epoch 5:  78%|███████▊  | 142/182 [28:42<08:06, 12.17s/it, training_loss=0.251]\u001b[A\n",
            "Epoch 5:  78%|███████▊  | 142/182 [28:55<08:06, 12.17s/it, training_loss=0.122]\u001b[A\n",
            "Epoch 5:  79%|███████▊  | 143/182 [28:55<07:59, 12.29s/it, training_loss=0.122]\u001b[A\n",
            "Epoch 5:  79%|███████▊  | 143/182 [29:06<07:59, 12.29s/it, training_loss=0.238]\u001b[A\n",
            "Epoch 5:  79%|███████▉  | 144/182 [29:06<07:28, 11.80s/it, training_loss=0.238]\u001b[A\n",
            "Epoch 5:  79%|███████▉  | 144/182 [29:18<07:28, 11.80s/it, training_loss=0.196]\u001b[A\n",
            "Epoch 5:  80%|███████▉  | 145/182 [29:18<07:19, 11.88s/it, training_loss=0.196]\u001b[A\n",
            "Epoch 5:  80%|███████▉  | 145/182 [29:33<07:19, 11.88s/it, training_loss=0.059]\u001b[A\n",
            "Epoch 5:  80%|████████  | 146/182 [29:33<07:42, 12.85s/it, training_loss=0.059]\u001b[A\n",
            "Epoch 5:  80%|████████  | 146/182 [29:45<07:42, 12.85s/it, training_loss=0.066]\u001b[A\n",
            "Epoch 5:  81%|████████  | 147/182 [29:45<07:26, 12.75s/it, training_loss=0.066]\u001b[A\n",
            "Epoch 5:  81%|████████  | 147/182 [29:56<07:26, 12.75s/it, training_loss=0.124]\u001b[A\n",
            "Epoch 5:  81%|████████▏ | 148/182 [29:56<06:49, 12.06s/it, training_loss=0.124]\u001b[A\n",
            "Epoch 5:  81%|████████▏ | 148/182 [30:08<06:49, 12.06s/it, training_loss=0.007]\u001b[A\n",
            "Epoch 5:  82%|████████▏ | 149/182 [30:08<06:39, 12.11s/it, training_loss=0.007]\u001b[A\n",
            "Epoch 5:  82%|████████▏ | 149/182 [30:21<06:39, 12.11s/it, training_loss=0.015]\u001b[A\n",
            "Epoch 5:  82%|████████▏ | 150/182 [30:21<06:32, 12.26s/it, training_loss=0.015]\u001b[A\n",
            "Epoch 5:  82%|████████▏ | 150/182 [30:33<06:32, 12.26s/it, training_loss=0.010]\u001b[A\n",
            "Epoch 5:  83%|████████▎ | 151/182 [30:33<06:23, 12.37s/it, training_loss=0.010]\u001b[A\n",
            "Epoch 5:  83%|████████▎ | 151/182 [30:44<06:23, 12.37s/it, training_loss=0.008]\u001b[A\n",
            "Epoch 5:  84%|████████▎ | 152/182 [30:44<05:54, 11.82s/it, training_loss=0.008]\u001b[A\n",
            "Epoch 5:  84%|████████▎ | 152/182 [30:56<05:54, 11.82s/it, training_loss=0.148]\u001b[A\n",
            "Epoch 5:  84%|████████▍ | 153/182 [30:56<05:45, 11.90s/it, training_loss=0.148]\u001b[A\n",
            "Epoch 5:  84%|████████▍ | 153/182 [31:09<05:45, 11.90s/it, training_loss=0.007]\u001b[A\n",
            "Epoch 5:  85%|████████▍ | 154/182 [31:09<05:39, 12.13s/it, training_loss=0.007]\u001b[A\n",
            "Epoch 5:  85%|████████▍ | 154/182 [31:21<05:39, 12.13s/it, training_loss=0.023]\u001b[A\n",
            "Epoch 5:  85%|████████▌ | 155/182 [31:21<05:31, 12.28s/it, training_loss=0.023]\u001b[A\n",
            "Epoch 5:  85%|████████▌ | 155/182 [31:32<05:31, 12.28s/it, training_loss=0.151]\u001b[A\n",
            "Epoch 5:  86%|████████▌ | 156/182 [31:32<05:08, 11.85s/it, training_loss=0.151]\u001b[A\n",
            "Epoch 5:  86%|████████▌ | 156/182 [31:44<05:08, 11.85s/it, training_loss=0.010]\u001b[A\n",
            "Epoch 5:  86%|████████▋ | 157/182 [31:44<04:55, 11.81s/it, training_loss=0.010]\u001b[A\n",
            "Epoch 5:  86%|████████▋ | 157/182 [31:56<04:55, 11.81s/it, training_loss=0.050]\u001b[A\n",
            "Epoch 5:  87%|████████▋ | 158/182 [31:56<04:49, 12.06s/it, training_loss=0.050]\u001b[A\n",
            "Epoch 5:  87%|████████▋ | 158/182 [32:09<04:49, 12.06s/it, training_loss=0.115]\u001b[A\n",
            "Epoch 5:  87%|████████▋ | 159/182 [32:09<04:41, 12.22s/it, training_loss=0.115]\u001b[A\n",
            "Epoch 5:  87%|████████▋ | 159/182 [32:20<04:41, 12.22s/it, training_loss=0.208]\u001b[A\n",
            "Epoch 5:  88%|████████▊ | 160/182 [32:20<04:22, 11.92s/it, training_loss=0.208]\u001b[A\n",
            "Epoch 5:  88%|████████▊ | 160/182 [32:32<04:22, 11.92s/it, training_loss=0.165]\u001b[A\n",
            "Epoch 5:  88%|████████▊ | 161/182 [32:32<04:08, 11.81s/it, training_loss=0.165]\u001b[A\n",
            "Epoch 5:  88%|████████▊ | 161/182 [32:44<04:08, 11.81s/it, training_loss=0.005]\u001b[A\n",
            "Epoch 5:  89%|████████▉ | 162/182 [32:44<04:00, 12.04s/it, training_loss=0.005]\u001b[A\n",
            "Epoch 5:  89%|████████▉ | 162/182 [32:57<04:00, 12.04s/it, training_loss=0.003]\u001b[A\n",
            "Epoch 5:  90%|████████▉ | 163/182 [32:57<03:52, 12.22s/it, training_loss=0.003]\u001b[A\n",
            "Epoch 5:  90%|████████▉ | 163/182 [33:09<03:52, 12.22s/it, training_loss=0.024]\u001b[A\n",
            "Epoch 5:  90%|█████████ | 164/182 [33:09<03:36, 12.01s/it, training_loss=0.024]\u001b[A\n",
            "Epoch 5:  90%|█████████ | 164/182 [33:20<03:36, 12.01s/it, training_loss=0.010]\u001b[A\n",
            "Epoch 5:  91%|█████████ | 165/182 [33:20<03:20, 11.77s/it, training_loss=0.010]\u001b[A\n",
            "Epoch 5:  91%|█████████ | 165/182 [33:32<03:20, 11.77s/it, training_loss=0.020]\u001b[A\n",
            "Epoch 5:  91%|█████████ | 166/182 [33:32<03:11, 11.99s/it, training_loss=0.020]\u001b[A\n",
            "Epoch 5:  91%|█████████ | 166/182 [33:45<03:11, 11.99s/it, training_loss=0.222]\u001b[A\n",
            "Epoch 5:  92%|█████████▏| 167/182 [33:45<03:02, 12.17s/it, training_loss=0.222]\u001b[A\n",
            "Epoch 5:  92%|█████████▏| 167/182 [33:57<03:02, 12.17s/it, training_loss=0.059]\u001b[A\n",
            "Epoch 5:  92%|█████████▏| 168/182 [33:57<02:49, 12.08s/it, training_loss=0.059]\u001b[A\n",
            "Epoch 5:  92%|█████████▏| 168/182 [34:08<02:49, 12.08s/it, training_loss=0.018]\u001b[A\n",
            "Epoch 5:  93%|█████████▎| 169/182 [34:08<02:32, 11.73s/it, training_loss=0.018]\u001b[A\n",
            "Epoch 5:  93%|█████████▎| 169/182 [34:20<02:32, 11.73s/it, training_loss=0.135]\u001b[A\n",
            "Epoch 5:  93%|█████████▎| 170/182 [34:20<02:23, 11.97s/it, training_loss=0.135]\u001b[A\n",
            "Epoch 5:  93%|█████████▎| 170/182 [34:35<02:23, 11.97s/it, training_loss=0.006]\u001b[A\n",
            "Epoch 5:  94%|█████████▍| 171/182 [34:35<02:20, 12.74s/it, training_loss=0.006]\u001b[A\n",
            "Epoch 5:  94%|█████████▍| 171/182 [34:45<02:20, 12.74s/it, training_loss=0.004]\u001b[A\n",
            "Epoch 5:  95%|█████████▍| 172/182 [34:45<02:01, 12.13s/it, training_loss=0.004]\u001b[A\n",
            "Epoch 5:  95%|█████████▍| 172/182 [34:58<02:01, 12.13s/it, training_loss=0.004]\u001b[A\n",
            "Epoch 5:  95%|█████████▌| 173/182 [34:58<01:50, 12.24s/it, training_loss=0.004]\u001b[A\n",
            "Epoch 5:  95%|█████████▌| 173/182 [35:10<01:50, 12.24s/it, training_loss=0.005]\u001b[A\n",
            "Epoch 5:  96%|█████████▌| 174/182 [35:10<01:38, 12.35s/it, training_loss=0.005]\u001b[A\n",
            "Epoch 5:  96%|█████████▌| 174/182 [35:23<01:38, 12.35s/it, training_loss=0.076]\u001b[A\n",
            "Epoch 5:  96%|█████████▌| 175/182 [35:23<01:26, 12.40s/it, training_loss=0.076]\u001b[A\n",
            "Epoch 5:  96%|█████████▌| 175/182 [35:33<01:26, 12.40s/it, training_loss=0.012]\u001b[A\n",
            "Epoch 5:  97%|█████████▋| 176/182 [35:33<01:10, 11.78s/it, training_loss=0.012]\u001b[A\n",
            "Epoch 5:  97%|█████████▋| 176/182 [35:46<01:10, 11.78s/it, training_loss=0.111]\u001b[A\n",
            "Epoch 5:  97%|█████████▋| 177/182 [35:46<00:59, 11.98s/it, training_loss=0.111]\u001b[A\n",
            "Epoch 5:  97%|█████████▋| 177/182 [35:59<00:59, 11.98s/it, training_loss=0.010]\u001b[A\n",
            "Epoch 5:  98%|█████████▊| 178/182 [35:59<00:49, 12.46s/it, training_loss=0.010]\u001b[A\n",
            "Epoch 5:  98%|█████████▊| 178/182 [36:12<00:49, 12.46s/it, training_loss=0.007]\u001b[A\n",
            "Epoch 5:  98%|█████████▊| 179/182 [36:12<00:37, 12.47s/it, training_loss=0.007]\u001b[A\n",
            "Epoch 5:  98%|█████████▊| 179/182 [36:22<00:37, 12.47s/it, training_loss=0.009]\u001b[A\n",
            "Epoch 5:  99%|█████████▉| 180/182 [36:22<00:23, 11.85s/it, training_loss=0.009]\u001b[A\n",
            "Epoch 5:  99%|█████████▉| 180/182 [36:34<00:23, 11.85s/it, training_loss=0.035]\u001b[A\n",
            "Epoch 5:  99%|█████████▉| 181/182 [36:34<00:11, 11.95s/it, training_loss=0.035]\u001b[A\n",
            "Epoch 5:  99%|█████████▉| 181/182 [36:36<00:11, 11.95s/it, training_loss=0.003]\u001b[A\n",
            "Epoch 5: 100%|██████████| 182/182 [36:36<00:00,  8.97s/it, training_loss=0.003]\u001b[A\n",
            " 50%|█████     | 4/8 [3:15:05<2:38:13, 2373.49s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            " Epoch {epoch}\n",
            "Training loss: {loss_train_avg}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "  0%|          | 0/46 [00:00<?, ?it/s]\u001b[A\n",
            "  2%|▏         | 1/46 [00:04<03:03,  4.09s/it]\u001b[A\n",
            "  4%|▍         | 2/46 [00:07<02:42,  3.69s/it]\u001b[A\n",
            "  7%|▋         | 3/46 [00:11<02:44,  3.82s/it]\u001b[A\n",
            "  9%|▊         | 4/46 [00:16<03:00,  4.29s/it]\u001b[A\n",
            " 11%|█         | 5/46 [00:20<02:49,  4.12s/it]\u001b[A\n",
            " 13%|█▎        | 6/46 [00:23<02:32,  3.80s/it]\u001b[A\n",
            " 15%|█▌        | 7/46 [00:26<02:20,  3.60s/it]\u001b[A\n",
            " 17%|█▋        | 8/46 [00:30<02:24,  3.81s/it]\u001b[A\n",
            " 20%|█▉        | 9/46 [00:35<02:28,  4.01s/it]\u001b[A\n",
            " 22%|██▏       | 10/46 [00:38<02:15,  3.76s/it]\u001b[A\n",
            " 24%|██▍       | 11/46 [00:41<02:05,  3.58s/it]\u001b[A\n",
            " 26%|██▌       | 12/46 [00:45<02:03,  3.62s/it]\u001b[A\n",
            " 28%|██▊       | 13/46 [00:50<02:13,  4.03s/it]\u001b[A\n",
            " 30%|███       | 14/46 [00:53<02:00,  3.78s/it]\u001b[A\n",
            " 33%|███▎      | 15/46 [00:56<01:51,  3.61s/it]\u001b[A\n",
            " 35%|███▍      | 16/46 [01:00<01:44,  3.49s/it]\u001b[A\n",
            " 37%|███▋      | 17/46 [01:05<01:56,  4.01s/it]\u001b[A\n",
            " 39%|███▉      | 18/46 [01:08<01:47,  3.84s/it]\u001b[A\n",
            " 41%|████▏     | 19/46 [01:11<01:38,  3.64s/it]\u001b[A\n",
            " 43%|████▎     | 20/46 [01:15<01:31,  3.50s/it]\u001b[A\n",
            " 46%|████▌     | 21/46 [01:19<01:36,  3.87s/it]\u001b[A\n",
            " 48%|████▊     | 22/46 [01:23<01:33,  3.88s/it]\u001b[A\n",
            " 50%|█████     | 23/46 [01:26<01:24,  3.68s/it]\u001b[A\n",
            " 52%|█████▏    | 24/46 [01:30<01:17,  3.53s/it]\u001b[A\n",
            " 54%|█████▍    | 25/46 [01:34<01:18,  3.72s/it]\u001b[A\n",
            " 57%|█████▋    | 26/46 [01:38<01:19,  3.95s/it]\u001b[A\n",
            " 59%|█████▊    | 27/46 [01:41<01:10,  3.72s/it]\u001b[A\n",
            " 61%|██████    | 28/46 [01:45<01:04,  3.56s/it]\u001b[A\n",
            " 63%|██████▎   | 29/46 [01:48<01:00,  3.56s/it]\u001b[A\n",
            " 65%|██████▌   | 30/46 [01:53<01:04,  4.02s/it]\u001b[A\n",
            " 67%|██████▋   | 31/46 [01:57<00:56,  3.78s/it]\u001b[A\n",
            " 70%|██████▉   | 32/46 [02:00<00:50,  3.60s/it]\u001b[A\n",
            " 72%|███████▏  | 33/46 [02:03<00:45,  3.49s/it]\u001b[A\n",
            " 74%|███████▍  | 34/46 [02:08<00:47,  3.98s/it]\u001b[A\n",
            " 76%|███████▌  | 35/46 [02:12<00:42,  3.86s/it]\u001b[A\n",
            " 78%|███████▊  | 36/46 [02:15<00:36,  3.66s/it]\u001b[A\n",
            " 80%|████████  | 37/46 [02:18<00:31,  3.52s/it]\u001b[A\n",
            " 83%|████████▎ | 38/46 [02:23<00:30,  3.82s/it]\u001b[A\n",
            " 85%|████████▍ | 39/46 [02:27<00:27,  3.93s/it]\u001b[A\n",
            " 87%|████████▋ | 40/46 [02:30<00:22,  3.71s/it]\u001b[A\n",
            " 89%|████████▉ | 41/46 [02:33<00:17,  3.56s/it]\u001b[A\n",
            " 91%|█████████▏| 42/46 [02:37<00:14,  3.68s/it]\u001b[A\n",
            " 93%|█████████▎| 43/46 [02:42<00:12,  4.00s/it]\u001b[A\n",
            " 96%|█████████▌| 44/46 [02:45<00:07,  3.76s/it]\u001b[A\n",
            " 98%|█████████▊| 45/46 [02:48<00:03,  3.59s/it]\u001b[A\n",
            "100%|██████████| 46/46 [02:50<00:00,  3.70s/it]\n",
            " 62%|██████▎   | 5/8 [3:17:55<1:58:37, 2372.59s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy:111/128\n",
            " -> 0.8671875\n",
            "Accuracy:69/107\n",
            " -> 0.6448598130841121\n",
            "Accuracy:112/128\n",
            " -> 0.875\n",
            "Validation loss: 0.737116464069518\n",
            "F1 Score (weighted): 0.8026840645134823\n",
            "Accuracy Score: 0.8044077134986226\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "Epoch 6:   0%|          | 0/182 [00:00<?, ?it/s]\u001b[A\n",
            "Epoch 6:   0%|          | 0/182 [00:17<?, ?it/s, training_loss=0.137]\u001b[A\n",
            "Epoch 6:   1%|          | 1/182 [00:17<52:44, 17.49s/it, training_loss=0.137]\u001b[A\n",
            "Epoch 6:   1%|          | 1/182 [00:30<52:44, 17.49s/it, training_loss=0.008]\u001b[A\n",
            "Epoch 6:   1%|          | 2/182 [00:30<45:03, 15.02s/it, training_loss=0.008]\u001b[A\n",
            "Epoch 6:   1%|          | 2/182 [00:43<45:03, 15.02s/it, training_loss=0.089]\u001b[A\n",
            "Epoch 6:   2%|▏         | 3/182 [00:43<41:17, 13.84s/it, training_loss=0.089]\u001b[A\n",
            "Epoch 6:   2%|▏         | 3/182 [00:53<41:17, 13.84s/it, training_loss=0.003]\u001b[A\n",
            "Epoch 6:   2%|▏         | 4/182 [00:53<37:08, 12.52s/it, training_loss=0.003]\u001b[A\n",
            "Epoch 6:   2%|▏         | 4/182 [01:06<37:08, 12.52s/it, training_loss=0.049]\u001b[A\n",
            "Epoch 6:   3%|▎         | 5/182 [01:06<36:56, 12.52s/it, training_loss=0.049]\u001b[A\n",
            "Epoch 6:   3%|▎         | 5/182 [01:18<36:56, 12.52s/it, training_loss=0.016]\u001b[A\n",
            "Epoch 6:   3%|▎         | 6/182 [01:18<36:46, 12.54s/it, training_loss=0.016]\u001b[A\n",
            "Epoch 6:   3%|▎         | 6/182 [01:31<36:46, 12.54s/it, training_loss=0.075]\u001b[A\n",
            "Epoch 6:   4%|▍         | 7/182 [01:31<36:36, 12.55s/it, training_loss=0.075]\u001b[A\n",
            "Epoch 6:   4%|▍         | 7/182 [01:41<36:36, 12.55s/it, training_loss=0.003]\u001b[A\n",
            "Epoch 6:   4%|▍         | 8/182 [01:41<34:32, 11.91s/it, training_loss=0.003]\u001b[A\n",
            "Epoch 6:   4%|▍         | 8/182 [01:54<34:32, 11.91s/it, training_loss=0.005]\u001b[A\n",
            "Epoch 6:   5%|▍         | 9/182 [01:54<34:38, 12.01s/it, training_loss=0.005]\u001b[A\n",
            "Epoch 6:   5%|▍         | 9/182 [02:06<34:38, 12.01s/it, training_loss=0.259]\u001b[A\n",
            "Epoch 6:   5%|▌         | 10/182 [02:06<34:57, 12.19s/it, training_loss=0.259]\u001b[A\n",
            "Epoch 6:   5%|▌         | 10/182 [02:19<34:57, 12.19s/it, training_loss=0.005]\u001b[A\n",
            "Epoch 6:   6%|▌         | 11/182 [02:19<35:04, 12.31s/it, training_loss=0.005]\u001b[A\n",
            "Epoch 6:   6%|▌         | 11/182 [02:29<35:04, 12.31s/it, training_loss=0.182]\u001b[A\n",
            "Epoch 6:   7%|▋         | 12/182 [02:29<33:27, 11.81s/it, training_loss=0.182]\u001b[A\n",
            "Epoch 6:   7%|▋         | 12/182 [02:41<33:27, 11.81s/it, training_loss=0.006]\u001b[A\n",
            "Epoch 6:   7%|▋         | 13/182 [02:41<33:23, 11.86s/it, training_loss=0.006]\u001b[A\n",
            "Epoch 6:   7%|▋         | 13/182 [02:54<33:23, 11.86s/it, training_loss=0.004]\u001b[A\n",
            "Epoch 6:   8%|▊         | 14/182 [02:54<33:51, 12.09s/it, training_loss=0.004]\u001b[A\n",
            "Epoch 6:   8%|▊         | 14/182 [03:07<33:51, 12.09s/it, training_loss=0.003]\u001b[A\n",
            "Epoch 6:   8%|▊         | 15/182 [03:07<34:05, 12.25s/it, training_loss=0.003]\u001b[A\n",
            "Epoch 6:   8%|▊         | 15/182 [03:18<34:05, 12.25s/it, training_loss=0.004]\u001b[A\n",
            "Epoch 6:   9%|▉         | 16/182 [03:18<32:57, 11.91s/it, training_loss=0.004]\u001b[A\n",
            "Epoch 6:   9%|▉         | 16/182 [03:29<32:57, 11.91s/it, training_loss=0.003]\u001b[A\n",
            "Epoch 6:   9%|▉         | 17/182 [03:29<32:29, 11.82s/it, training_loss=0.003]\u001b[A\n",
            "Epoch 6:   9%|▉         | 17/182 [03:42<32:29, 11.82s/it, training_loss=0.013]\u001b[A\n",
            "Epoch 6:  10%|▉         | 18/182 [03:42<33:00, 12.08s/it, training_loss=0.013]\u001b[A\n",
            "Epoch 6:  10%|▉         | 18/182 [03:55<33:00, 12.08s/it, training_loss=0.012]\u001b[A\n",
            "Epoch 6:  10%|█         | 19/182 [03:55<33:19, 12.27s/it, training_loss=0.012]\u001b[A\n",
            "Epoch 6:  10%|█         | 19/182 [04:06<33:19, 12.27s/it, training_loss=0.056]\u001b[A\n",
            "Epoch 6:  11%|█         | 20/182 [04:06<32:37, 12.08s/it, training_loss=0.056]\u001b[A\n",
            "Epoch 6:  11%|█         | 20/182 [04:18<32:37, 12.08s/it, training_loss=0.003]\u001b[A\n",
            "Epoch 6:  12%|█▏        | 21/182 [04:18<31:37, 11.79s/it, training_loss=0.003]\u001b[A\n",
            "Epoch 6:  12%|█▏        | 21/182 [04:30<31:37, 11.79s/it, training_loss=0.016]\u001b[A\n",
            "Epoch 6:  12%|█▏        | 22/182 [04:30<32:03, 12.02s/it, training_loss=0.016]\u001b[A\n",
            "Epoch 6:  12%|█▏        | 22/182 [04:43<32:03, 12.02s/it, training_loss=0.014]\u001b[A\n",
            "Epoch 6:  13%|█▎        | 23/182 [04:43<32:20, 12.20s/it, training_loss=0.014]\u001b[A\n",
            "Epoch 6:  13%|█▎        | 23/182 [04:55<32:20, 12.20s/it, training_loss=0.143]\u001b[A\n",
            "Epoch 6:  13%|█▎        | 24/182 [04:55<31:53, 12.11s/it, training_loss=0.143]\u001b[A\n",
            "Epoch 6:  13%|█▎        | 24/182 [05:05<31:53, 12.11s/it, training_loss=0.160]\u001b[A\n",
            "Epoch 6:  14%|█▎        | 25/182 [05:05<30:40, 11.72s/it, training_loss=0.160]\u001b[A\n",
            "Epoch 6:  14%|█▎        | 25/182 [05:18<30:40, 11.72s/it, training_loss=0.010]\u001b[A\n",
            "Epoch 6:  14%|█▍        | 26/182 [05:18<31:10, 11.99s/it, training_loss=0.010]\u001b[A\n",
            "Epoch 6:  14%|█▍        | 26/182 [05:33<31:10, 11.99s/it, training_loss=0.004]\u001b[A\n",
            "Epoch 6:  15%|█▍        | 27/182 [05:33<33:23, 12.93s/it, training_loss=0.004]\u001b[A\n",
            "Epoch 6:  15%|█▍        | 27/182 [05:44<33:23, 12.93s/it, training_loss=0.003]\u001b[A\n",
            "Epoch 6:  15%|█▌        | 28/182 [05:44<31:20, 12.21s/it, training_loss=0.003]\u001b[A\n",
            "Epoch 6:  15%|█▌        | 28/182 [05:56<31:20, 12.21s/it, training_loss=0.003]\u001b[A\n",
            "Epoch 6:  16%|█▌        | 29/182 [05:56<31:06, 12.20s/it, training_loss=0.003]\u001b[A\n",
            "Epoch 6:  16%|█▌        | 29/182 [06:09<31:06, 12.20s/it, training_loss=0.003]\u001b[A\n",
            "Epoch 6:  16%|█▋        | 30/182 [06:09<31:13, 12.33s/it, training_loss=0.003]\u001b[A\n",
            "Epoch 6:  16%|█▋        | 30/182 [06:21<31:13, 12.33s/it, training_loss=0.007]\u001b[A\n",
            "Epoch 6:  17%|█▋        | 31/182 [06:21<31:15, 12.42s/it, training_loss=0.007]\u001b[A\n",
            "Epoch 6:  17%|█▋        | 31/182 [06:32<31:15, 12.42s/it, training_loss=0.003]\u001b[A\n",
            "Epoch 6:  18%|█▊        | 32/182 [06:32<29:54, 11.96s/it, training_loss=0.003]\u001b[A\n",
            "Epoch 6:  18%|█▊        | 32/182 [06:44<29:54, 11.96s/it, training_loss=0.007]\u001b[A\n",
            "Epoch 6:  18%|█▊        | 33/182 [06:44<29:32, 11.89s/it, training_loss=0.007]\u001b[A\n",
            "Epoch 6:  18%|█▊        | 33/182 [06:56<29:32, 11.89s/it, training_loss=0.004]\u001b[A\n",
            "Epoch 6:  19%|█▊        | 34/182 [06:56<29:49, 12.09s/it, training_loss=0.004]\u001b[A\n",
            "Epoch 6:  19%|█▊        | 34/182 [07:09<29:49, 12.09s/it, training_loss=0.003]\u001b[A\n",
            "Epoch 6:  19%|█▉        | 35/182 [07:09<30:00, 12.25s/it, training_loss=0.003]\u001b[A\n",
            "Epoch 6:  19%|█▉        | 35/182 [07:20<30:00, 12.25s/it, training_loss=0.212]\u001b[A\n",
            "Epoch 6:  20%|█▉        | 36/182 [07:20<29:02, 11.93s/it, training_loss=0.212]\u001b[A\n",
            "Epoch 6:  20%|█▉        | 36/182 [07:32<29:02, 11.93s/it, training_loss=0.146]\u001b[A\n",
            "Epoch 6:  20%|██        | 37/182 [07:32<28:27, 11.78s/it, training_loss=0.146]\u001b[A\n",
            "Epoch 6:  20%|██        | 37/182 [07:44<28:27, 11.78s/it, training_loss=0.005]\u001b[A\n",
            "Epoch 6:  21%|██        | 38/182 [07:44<28:50, 12.02s/it, training_loss=0.005]\u001b[A\n",
            "Epoch 6:  21%|██        | 38/182 [07:57<28:50, 12.02s/it, training_loss=0.097]\u001b[A\n",
            "Epoch 6:  21%|██▏       | 39/182 [07:57<29:05, 12.21s/it, training_loss=0.097]\u001b[A\n",
            "Epoch 6:  21%|██▏       | 39/182 [08:08<29:05, 12.21s/it, training_loss=0.008]\u001b[A\n",
            "Epoch 6:  22%|██▏       | 40/182 [08:08<28:29, 12.04s/it, training_loss=0.008]\u001b[A\n",
            "Epoch 6:  22%|██▏       | 40/182 [08:19<28:29, 12.04s/it, training_loss=0.044]\u001b[A\n",
            "Epoch 6:  23%|██▎       | 41/182 [08:19<27:33, 11.73s/it, training_loss=0.044]\u001b[A\n",
            "Epoch 6:  23%|██▎       | 41/182 [08:32<27:33, 11.73s/it, training_loss=0.006]\u001b[A\n",
            "Epoch 6:  23%|██▎       | 42/182 [08:32<27:59, 12.00s/it, training_loss=0.006]\u001b[A\n",
            "Epoch 6:  23%|██▎       | 42/182 [08:45<27:59, 12.00s/it, training_loss=0.009]\u001b[A\n",
            "Epoch 6:  24%|██▎       | 43/182 [08:45<28:14, 12.19s/it, training_loss=0.009]\u001b[A\n",
            "Epoch 6:  24%|██▎       | 43/182 [08:57<28:14, 12.19s/it, training_loss=0.047]\u001b[A\n",
            "Epoch 6:  24%|██▍       | 44/182 [08:57<27:58, 12.17s/it, training_loss=0.047]\u001b[A\n",
            "Epoch 6:  24%|██▍       | 44/182 [09:08<27:58, 12.17s/it, training_loss=0.003]\u001b[A\n",
            "Epoch 6:  25%|██▍       | 45/182 [09:08<26:50, 11.75s/it, training_loss=0.003]\u001b[A\n",
            "Epoch 6:  25%|██▍       | 45/182 [09:20<26:50, 11.75s/it, training_loss=0.005]\u001b[A\n",
            "Epoch 6:  25%|██▌       | 46/182 [09:20<27:14, 12.02s/it, training_loss=0.005]\u001b[A\n",
            "Epoch 6:  25%|██▌       | 46/182 [09:33<27:14, 12.02s/it, training_loss=0.008]\u001b[A\n",
            "Epoch 6:  26%|██▌       | 47/182 [09:33<27:30, 12.23s/it, training_loss=0.008]\u001b[A\n",
            "Epoch 6:  26%|██▌       | 47/182 [09:46<27:30, 12.23s/it, training_loss=0.005]\u001b[A\n",
            "Epoch 6:  26%|██▋       | 48/182 [09:46<27:34, 12.34s/it, training_loss=0.005]\u001b[A\n",
            "Epoch 6:  26%|██▋       | 48/182 [09:56<27:34, 12.34s/it, training_loss=0.003]\u001b[A\n",
            "Epoch 6:  27%|██▋       | 49/182 [09:56<26:06, 11.78s/it, training_loss=0.003]\u001b[A\n",
            "Epoch 6:  27%|██▋       | 49/182 [10:08<26:06, 11.78s/it, training_loss=0.005]\u001b[A\n",
            "Epoch 6:  27%|██▋       | 50/182 [10:08<26:20, 11.97s/it, training_loss=0.005]\u001b[A\n",
            "Epoch 6:  27%|██▋       | 50/182 [10:21<26:20, 11.97s/it, training_loss=0.006]\u001b[A\n",
            "Epoch 6:  28%|██▊       | 51/182 [10:21<26:36, 12.18s/it, training_loss=0.006]\u001b[A\n",
            "Epoch 6:  28%|██▊       | 51/182 [10:34<26:36, 12.18s/it, training_loss=0.026]\u001b[A\n",
            "Epoch 6:  29%|██▊       | 52/182 [10:34<26:42, 12.33s/it, training_loss=0.026]\u001b[A\n",
            "Epoch 6:  29%|██▊       | 52/182 [10:45<26:42, 12.33s/it, training_loss=0.005]\u001b[A\n",
            "Epoch 6:  29%|██▉       | 53/182 [10:45<25:27, 11.84s/it, training_loss=0.005]\u001b[A\n",
            "Epoch 6:  29%|██▉       | 53/182 [10:59<25:27, 11.84s/it, training_loss=0.007]\u001b[A\n",
            "Epoch 6:  30%|██▉       | 54/182 [10:59<26:51, 12.59s/it, training_loss=0.007]\u001b[A\n",
            "Epoch 6:  30%|██▉       | 54/182 [11:11<26:51, 12.59s/it, training_loss=0.003]\u001b[A\n",
            "Epoch 6:  30%|███       | 55/182 [11:11<26:36, 12.57s/it, training_loss=0.003]\u001b[A\n",
            "Epoch 6:  30%|███       | 55/182 [11:24<26:36, 12.57s/it, training_loss=0.020]\u001b[A\n",
            "Epoch 6:  31%|███       | 56/182 [11:24<26:24, 12.57s/it, training_loss=0.020]\u001b[A\n",
            "Epoch 6:  31%|███       | 56/182 [11:36<26:24, 12.57s/it, training_loss=0.006]\u001b[A\n",
            "Epoch 6:  31%|███▏      | 57/182 [11:36<26:02, 12.50s/it, training_loss=0.006]\u001b[A\n",
            "Epoch 6:  31%|███▏      | 57/182 [11:47<26:02, 12.50s/it, training_loss=0.004]\u001b[A\n",
            "Epoch 6:  32%|███▏      | 58/182 [11:47<24:39, 11.93s/it, training_loss=0.004]\u001b[A\n",
            "Epoch 6:  32%|███▏      | 58/182 [11:59<24:39, 11.93s/it, training_loss=0.022]\u001b[A\n",
            "Epoch 6:  32%|███▏      | 59/182 [11:59<24:51, 12.13s/it, training_loss=0.022]\u001b[A\n",
            "Epoch 6:  32%|███▏      | 59/182 [12:12<24:51, 12.13s/it, training_loss=0.010]\u001b[A\n",
            "Epoch 6:  33%|███▎      | 60/182 [12:12<24:57, 12.27s/it, training_loss=0.010]\u001b[A\n",
            "Epoch 6:  33%|███▎      | 60/182 [12:25<24:57, 12.27s/it, training_loss=0.031]\u001b[A\n",
            "Epoch 6:  34%|███▎      | 61/182 [12:25<25:00, 12.40s/it, training_loss=0.031]\u001b[A\n",
            "Epoch 6:  34%|███▎      | 61/182 [12:35<25:00, 12.40s/it, training_loss=0.215]\u001b[A\n",
            "Epoch 6:  34%|███▍      | 62/182 [12:35<23:40, 11.84s/it, training_loss=0.215]\u001b[A\n",
            "Epoch 6:  34%|███▍      | 62/182 [12:48<23:40, 11.84s/it, training_loss=0.233]\u001b[A\n",
            "Epoch 6:  35%|███▍      | 63/182 [12:48<23:43, 11.96s/it, training_loss=0.233]\u001b[A\n",
            "Epoch 6:  35%|███▍      | 63/182 [13:00<23:43, 11.96s/it, training_loss=0.009]\u001b[A\n",
            "Epoch 6:  35%|███▌      | 64/182 [13:00<23:56, 12.17s/it, training_loss=0.009]\u001b[A\n",
            "Epoch 6:  35%|███▌      | 64/182 [13:13<23:56, 12.17s/it, training_loss=0.003]\u001b[A\n",
            "Epoch 6:  36%|███▌      | 65/182 [13:13<24:01, 12.32s/it, training_loss=0.003]\u001b[A\n",
            "Epoch 6:  36%|███▌      | 65/182 [13:24<24:01, 12.32s/it, training_loss=0.004]\u001b[A\n",
            "Epoch 6:  36%|███▋      | 66/182 [13:24<22:53, 11.84s/it, training_loss=0.004]\u001b[A\n",
            "Epoch 6:  36%|███▋      | 66/182 [13:36<22:53, 11.84s/it, training_loss=0.084]\u001b[A\n",
            "Epoch 6:  37%|███▋      | 67/182 [13:36<22:48, 11.90s/it, training_loss=0.084]\u001b[A\n",
            "Epoch 6:  37%|███▋      | 67/182 [13:48<22:48, 11.90s/it, training_loss=0.004]\u001b[A\n",
            "Epoch 6:  37%|███▋      | 68/182 [13:48<23:03, 12.13s/it, training_loss=0.004]\u001b[A\n",
            "Epoch 6:  37%|███▋      | 68/182 [14:04<23:03, 12.13s/it, training_loss=0.004]\u001b[A\n",
            "Epoch 6:  38%|███▊      | 69/182 [14:04<24:43, 13.13s/it, training_loss=0.004]\u001b[A\n",
            "Epoch 6:  38%|███▊      | 69/182 [14:17<24:43, 13.13s/it, training_loss=0.003]\u001b[A\n",
            "Epoch 6:  38%|███▊      | 70/182 [14:17<24:20, 13.04s/it, training_loss=0.003]\u001b[A\n",
            "Epoch 6:  38%|███▊      | 70/182 [14:27<24:20, 13.04s/it, training_loss=0.025]\u001b[A\n",
            "Epoch 6:  39%|███▉      | 71/182 [14:27<22:47, 12.32s/it, training_loss=0.025]\u001b[A\n",
            "Epoch 6:  39%|███▉      | 71/182 [14:40<22:47, 12.32s/it, training_loss=0.022]\u001b[A\n",
            "Epoch 6:  40%|███▉      | 72/182 [14:40<22:46, 12.43s/it, training_loss=0.022]\u001b[A\n",
            "Epoch 6:  40%|███▉      | 72/182 [14:53<22:46, 12.43s/it, training_loss=0.032]\u001b[A\n",
            "Epoch 6:  40%|████      | 73/182 [14:53<22:42, 12.50s/it, training_loss=0.032]\u001b[A\n",
            "Epoch 6:  40%|████      | 73/182 [15:05<22:42, 12.50s/it, training_loss=0.002]\u001b[A\n",
            "Epoch 6:  41%|████      | 74/182 [15:05<22:32, 12.52s/it, training_loss=0.002]\u001b[A\n",
            "Epoch 6:  41%|████      | 74/182 [15:16<22:32, 12.52s/it, training_loss=0.004]\u001b[A\n",
            "Epoch 6:  41%|████      | 75/182 [15:16<21:14, 11.91s/it, training_loss=0.004]\u001b[A\n",
            "Epoch 6:  41%|████      | 75/182 [15:28<21:14, 11.91s/it, training_loss=0.002]\u001b[A\n",
            "Epoch 6:  42%|████▏     | 76/182 [15:28<21:13, 12.01s/it, training_loss=0.002]\u001b[A\n",
            "Epoch 6:  42%|████▏     | 76/182 [15:41<21:13, 12.01s/it, training_loss=0.003]\u001b[A\n",
            "Epoch 6:  42%|████▏     | 77/182 [15:41<21:20, 12.19s/it, training_loss=0.003]\u001b[A\n",
            "Epoch 6:  42%|████▏     | 77/182 [15:53<21:20, 12.19s/it, training_loss=0.208]\u001b[A\n",
            "Epoch 6:  43%|████▎     | 78/182 [15:53<21:22, 12.33s/it, training_loss=0.208]\u001b[A\n",
            "Epoch 6:  43%|████▎     | 78/182 [16:04<21:22, 12.33s/it, training_loss=0.037]\u001b[A\n",
            "Epoch 6:  43%|████▎     | 79/182 [16:04<20:26, 11.91s/it, training_loss=0.037]\u001b[A\n",
            "Epoch 6:  43%|████▎     | 79/182 [16:18<20:26, 11.91s/it, training_loss=0.006]\u001b[A\n",
            "Epoch 6:  44%|████▍     | 80/182 [16:18<21:15, 12.50s/it, training_loss=0.006]\u001b[A\n",
            "Epoch 6:  44%|████▍     | 80/182 [16:31<21:15, 12.50s/it, training_loss=0.002]\u001b[A\n",
            "Epoch 6:  45%|████▍     | 81/182 [16:31<21:16, 12.63s/it, training_loss=0.002]\u001b[A\n",
            "Epoch 6:  45%|████▍     | 81/182 [16:44<21:16, 12.63s/it, training_loss=0.003]\u001b[A\n",
            "Epoch 6:  45%|████▌     | 82/182 [16:44<21:07, 12.67s/it, training_loss=0.003]\u001b[A\n",
            "Epoch 6:  45%|████▌     | 82/182 [16:56<21:07, 12.67s/it, training_loss=0.165]\u001b[A\n",
            "Epoch 6:  46%|████▌     | 83/182 [16:56<20:54, 12.67s/it, training_loss=0.165]\u001b[A\n",
            "Epoch 6:  46%|████▌     | 83/182 [17:07<20:54, 12.67s/it, training_loss=0.221]\u001b[A\n",
            "Epoch 6:  46%|████▌     | 84/182 [17:07<19:39, 12.03s/it, training_loss=0.221]\u001b[A\n",
            "Epoch 6:  46%|████▌     | 84/182 [17:19<19:39, 12.03s/it, training_loss=0.005]\u001b[A\n",
            "Epoch 6:  47%|████▋     | 85/182 [17:19<19:32, 12.09s/it, training_loss=0.005]\u001b[A\n",
            "Epoch 6:  47%|████▋     | 85/182 [17:32<19:32, 12.09s/it, training_loss=0.003]\u001b[A\n",
            "Epoch 6:  47%|████▋     | 86/182 [17:32<19:34, 12.24s/it, training_loss=0.003]\u001b[A\n",
            "Epoch 6:  47%|████▋     | 86/182 [17:44<19:34, 12.24s/it, training_loss=0.003]\u001b[A\n",
            "Epoch 6:  48%|████▊     | 87/182 [17:44<19:35, 12.38s/it, training_loss=0.003]\u001b[A\n",
            "Epoch 6:  48%|████▊     | 87/182 [17:55<19:35, 12.38s/it, training_loss=0.004]\u001b[A\n",
            "Epoch 6:  48%|████▊     | 88/182 [17:55<18:36, 11.88s/it, training_loss=0.004]\u001b[A\n",
            "Epoch 6:  48%|████▊     | 88/182 [18:07<18:36, 11.88s/it, training_loss=0.003]\u001b[A\n",
            "Epoch 6:  49%|████▉     | 89/182 [18:07<18:26, 11.90s/it, training_loss=0.003]\u001b[A\n",
            "Epoch 6:  49%|████▉     | 89/182 [18:20<18:26, 11.90s/it, training_loss=0.043]\u001b[A\n",
            "Epoch 6:  49%|████▉     | 90/182 [18:20<18:33, 12.10s/it, training_loss=0.043]\u001b[A\n",
            "Epoch 6:  49%|████▉     | 90/182 [18:32<18:33, 12.10s/it, training_loss=0.003]\u001b[A\n",
            "Epoch 6:  50%|█████     | 91/182 [18:32<18:37, 12.28s/it, training_loss=0.003]\u001b[A\n",
            "Epoch 6:  50%|█████     | 91/182 [18:43<18:37, 12.28s/it, training_loss=0.002]\u001b[A\n",
            "Epoch 6:  51%|█████     | 92/182 [18:43<17:50, 11.90s/it, training_loss=0.002]\u001b[A\n",
            "Epoch 6:  51%|█████     | 92/182 [18:55<17:50, 11.90s/it, training_loss=0.002]\u001b[A\n",
            "Epoch 6:  51%|█████     | 93/182 [18:55<17:33, 11.84s/it, training_loss=0.002]\u001b[A\n",
            "Epoch 6:  51%|█████     | 93/182 [19:08<17:33, 11.84s/it, training_loss=0.004]\u001b[A\n",
            "Epoch 6:  52%|█████▏    | 94/182 [19:08<17:41, 12.06s/it, training_loss=0.004]\u001b[A\n",
            "Epoch 6:  52%|█████▏    | 94/182 [19:20<17:41, 12.06s/it, training_loss=0.223]\u001b[A\n",
            "Epoch 6:  52%|█████▏    | 95/182 [19:20<17:44, 12.24s/it, training_loss=0.223]\u001b[A\n",
            "Epoch 6:  52%|█████▏    | 95/182 [19:32<17:44, 12.24s/it, training_loss=0.005]\u001b[A\n",
            "Epoch 6:  53%|█████▎    | 96/182 [19:32<17:06, 11.94s/it, training_loss=0.005]\u001b[A\n",
            "Epoch 6:  53%|█████▎    | 96/182 [19:43<17:06, 11.94s/it, training_loss=0.061]\u001b[A\n",
            "Epoch 6:  53%|█████▎    | 97/182 [19:43<16:42, 11.79s/it, training_loss=0.061]\u001b[A\n",
            "Epoch 6:  53%|█████▎    | 97/182 [19:56<16:42, 11.79s/it, training_loss=0.212]\u001b[A\n",
            "Epoch 6:  54%|█████▍    | 98/182 [19:56<16:51, 12.05s/it, training_loss=0.212]\u001b[A\n",
            "Epoch 6:  54%|█████▍    | 98/182 [20:08<16:51, 12.05s/it, training_loss=0.002]\u001b[A\n",
            "Epoch 6:  54%|█████▍    | 99/182 [20:08<16:56, 12.24s/it, training_loss=0.002]\u001b[A\n",
            "Epoch 6:  54%|█████▍    | 99/182 [20:20<16:56, 12.24s/it, training_loss=0.003]\u001b[A\n",
            "Epoch 6:  55%|█████▍    | 100/182 [20:20<16:29, 12.06s/it, training_loss=0.003]\u001b[A\n",
            "Epoch 6:  55%|█████▍    | 100/182 [20:31<16:29, 12.06s/it, training_loss=0.003]\u001b[A\n",
            "Epoch 6:  55%|█████▌    | 101/182 [20:31<15:53, 11.78s/it, training_loss=0.003]\u001b[A\n",
            "Epoch 6:  55%|█████▌    | 101/182 [20:44<15:53, 11.78s/it, training_loss=0.003]\u001b[A\n",
            "Epoch 6:  56%|█████▌    | 102/182 [20:44<16:01, 12.02s/it, training_loss=0.003]\u001b[A\n",
            "Epoch 6:  56%|█████▌    | 102/182 [20:56<16:01, 12.02s/it, training_loss=0.004]\u001b[A\n",
            "Epoch 6:  57%|█████▋    | 103/182 [20:56<16:06, 12.23s/it, training_loss=0.004]\u001b[A\n",
            "Epoch 6:  57%|█████▋    | 103/182 [21:08<16:06, 12.23s/it, training_loss=0.006]\u001b[A\n",
            "Epoch 6:  57%|█████▋    | 104/182 [21:08<15:50, 12.18s/it, training_loss=0.006]\u001b[A\n",
            "Epoch 6:  57%|█████▋    | 104/182 [21:19<15:50, 12.18s/it, training_loss=0.013]\u001b[A\n",
            "Epoch 6:  58%|█████▊    | 105/182 [21:19<15:03, 11.74s/it, training_loss=0.013]\u001b[A\n",
            "Epoch 6:  58%|█████▊    | 105/182 [21:32<15:03, 11.74s/it, training_loss=0.002]\u001b[A\n",
            "Epoch 6:  58%|█████▊    | 106/182 [21:32<15:11, 12.00s/it, training_loss=0.002]\u001b[A\n",
            "Epoch 6:  58%|█████▊    | 106/182 [21:47<15:11, 12.00s/it, training_loss=0.194]\u001b[A\n",
            "Epoch 6:  59%|█████▉    | 107/182 [21:47<16:08, 12.91s/it, training_loss=0.194]\u001b[A\n",
            "Epoch 6:  59%|█████▉    | 107/182 [21:58<16:08, 12.91s/it, training_loss=0.003]\u001b[A\n",
            "Epoch 6:  59%|█████▉    | 108/182 [21:58<15:10, 12.31s/it, training_loss=0.003]\u001b[A\n",
            "Epoch 6:  59%|█████▉    | 108/182 [22:10<15:10, 12.31s/it, training_loss=0.111]\u001b[A\n",
            "Epoch 6:  60%|█████▉    | 109/182 [22:10<14:53, 12.24s/it, training_loss=0.111]\u001b[A\n",
            "Epoch 6:  60%|█████▉    | 109/182 [22:22<14:53, 12.24s/it, training_loss=0.002]\u001b[A\n",
            "Epoch 6:  60%|██████    | 110/182 [22:22<14:49, 12.36s/it, training_loss=0.002]\u001b[A\n",
            "Epoch 6:  60%|██████    | 110/182 [22:35<14:49, 12.36s/it, training_loss=0.003]\u001b[A\n",
            "Epoch 6:  61%|██████    | 111/182 [22:35<14:43, 12.44s/it, training_loss=0.003]\u001b[A\n",
            "Epoch 6:  61%|██████    | 111/182 [22:46<14:43, 12.44s/it, training_loss=0.004]\u001b[A\n",
            "Epoch 6:  62%|██████▏   | 112/182 [22:46<14:02, 12.03s/it, training_loss=0.004]\u001b[A\n",
            "Epoch 6:  62%|██████▏   | 112/182 [22:58<14:02, 12.03s/it, training_loss=0.002]\u001b[A\n",
            "Epoch 6:  62%|██████▏   | 113/182 [22:58<13:41, 11.91s/it, training_loss=0.002]\u001b[A\n",
            "Epoch 6:  62%|██████▏   | 113/182 [23:10<13:41, 11.91s/it, training_loss=0.221]\u001b[A\n",
            "Epoch 6:  63%|██████▎   | 114/182 [23:10<13:45, 12.13s/it, training_loss=0.221]\u001b[A\n",
            "Epoch 6:  63%|██████▎   | 114/182 [23:23<13:45, 12.13s/it, training_loss=0.002]\u001b[A\n",
            "Epoch 6:  63%|██████▎   | 115/182 [23:23<13:43, 12.29s/it, training_loss=0.002]\u001b[A\n",
            "Epoch 6:  63%|██████▎   | 115/182 [23:35<13:43, 12.29s/it, training_loss=0.002]\u001b[A\n",
            "Epoch 6:  64%|██████▎   | 116/182 [23:35<13:20, 12.12s/it, training_loss=0.002]\u001b[A\n",
            "Epoch 6:  64%|██████▎   | 116/182 [23:46<13:20, 12.12s/it, training_loss=0.005]\u001b[A\n",
            "Epoch 6:  64%|██████▍   | 117/182 [23:46<12:50, 11.85s/it, training_loss=0.005]\u001b[A\n",
            "Epoch 6:  64%|██████▍   | 117/182 [23:59<12:50, 11.85s/it, training_loss=0.002]\u001b[A\n",
            "Epoch 6:  65%|██████▍   | 118/182 [23:59<12:54, 12.10s/it, training_loss=0.002]\u001b[A\n",
            "Epoch 6:  65%|██████▍   | 118/182 [24:11<12:54, 12.10s/it, training_loss=0.096]\u001b[A\n",
            "Epoch 6:  65%|██████▌   | 119/182 [24:11<12:52, 12.26s/it, training_loss=0.096]\u001b[A\n",
            "Epoch 6:  65%|██████▌   | 119/182 [24:23<12:52, 12.26s/it, training_loss=0.027]\u001b[A\n",
            "Epoch 6:  66%|██████▌   | 120/182 [24:23<12:35, 12.19s/it, training_loss=0.027]\u001b[A\n",
            "Epoch 6:  66%|██████▌   | 120/182 [24:34<12:35, 12.19s/it, training_loss=0.080]\u001b[A\n",
            "Epoch 6:  66%|██████▋   | 121/182 [24:34<11:58, 11.77s/it, training_loss=0.080]\u001b[A\n",
            "Epoch 6:  66%|██████▋   | 121/182 [24:47<11:58, 11.77s/it, training_loss=0.002]\u001b[A\n",
            "Epoch 6:  67%|██████▋   | 122/182 [24:47<12:01, 12.03s/it, training_loss=0.002]\u001b[A\n",
            "Epoch 6:  67%|██████▋   | 122/182 [24:59<12:01, 12.03s/it, training_loss=0.129]\u001b[A\n",
            "Epoch 6:  68%|██████▊   | 123/182 [24:59<12:01, 12.23s/it, training_loss=0.129]\u001b[A\n",
            "Epoch 6:  68%|██████▊   | 123/182 [25:12<12:01, 12.23s/it, training_loss=0.002]\u001b[A\n",
            "Epoch 6:  68%|██████▊   | 124/182 [25:12<11:53, 12.30s/it, training_loss=0.002]\u001b[A\n",
            "Epoch 6:  68%|██████▊   | 124/182 [25:22<11:53, 12.30s/it, training_loss=0.002]\u001b[A\n",
            "Epoch 6:  69%|██████▊   | 125/182 [25:22<11:10, 11.76s/it, training_loss=0.002]\u001b[A\n",
            "Epoch 6:  69%|██████▊   | 125/182 [25:35<11:10, 11.76s/it, training_loss=0.002]\u001b[A\n",
            "Epoch 6:  69%|██████▉   | 126/182 [25:35<11:12, 12.01s/it, training_loss=0.002]\u001b[A\n",
            "Epoch 6:  69%|██████▉   | 126/182 [25:48<11:12, 12.01s/it, training_loss=0.002]\u001b[A\n",
            "Epoch 6:  70%|██████▉   | 127/182 [25:48<11:11, 12.21s/it, training_loss=0.002]\u001b[A\n",
            "Epoch 6:  70%|██████▉   | 127/182 [26:00<11:11, 12.21s/it, training_loss=0.002]\u001b[A\n",
            "Epoch 6:  70%|███████   | 128/182 [26:00<11:05, 12.33s/it, training_loss=0.002]\u001b[A\n",
            "Epoch 6:  70%|███████   | 128/182 [26:11<11:05, 12.33s/it, training_loss=0.003]\u001b[A\n",
            "Epoch 6:  71%|███████   | 129/182 [26:11<10:24, 11.79s/it, training_loss=0.003]\u001b[A\n",
            "Epoch 6:  71%|███████   | 129/182 [26:23<10:24, 11.79s/it, training_loss=0.005]\u001b[A\n",
            "Epoch 6:  71%|███████▏  | 130/182 [26:23<10:18, 11.89s/it, training_loss=0.005]\u001b[A\n",
            "Epoch 6:  71%|███████▏  | 130/182 [26:36<10:18, 11.89s/it, training_loss=0.006]\u001b[A\n",
            "Epoch 6:  72%|███████▏  | 131/182 [26:36<10:18, 12.12s/it, training_loss=0.006]\u001b[A\n",
            "Epoch 6:  72%|███████▏  | 131/182 [26:48<10:18, 12.12s/it, training_loss=0.207]\u001b[A\n",
            "Epoch 6:  73%|███████▎  | 132/182 [26:48<10:12, 12.25s/it, training_loss=0.207]\u001b[A\n",
            "Epoch 6:  73%|███████▎  | 132/182 [26:59<10:12, 12.25s/it, training_loss=0.003]\u001b[A\n",
            "Epoch 6:  73%|███████▎  | 133/182 [26:59<09:40, 11.84s/it, training_loss=0.003]\u001b[A\n",
            "Epoch 6:  73%|███████▎  | 133/182 [27:11<09:40, 11.84s/it, training_loss=0.098]\u001b[A\n",
            "Epoch 6:  74%|███████▎  | 134/182 [27:11<09:29, 11.86s/it, training_loss=0.098]\u001b[A\n",
            "Epoch 6:  74%|███████▎  | 134/182 [27:26<09:29, 11.86s/it, training_loss=0.448]\u001b[A\n",
            "Epoch 6:  74%|███████▍  | 135/182 [27:26<10:01, 12.80s/it, training_loss=0.448]\u001b[A\n",
            "Epoch 6:  74%|███████▍  | 135/182 [27:39<10:01, 12.80s/it, training_loss=0.038]\u001b[A\n",
            "Epoch 6:  75%|███████▍  | 136/182 [27:39<09:46, 12.76s/it, training_loss=0.038]\u001b[A\n",
            "Epoch 6:  75%|███████▍  | 136/182 [27:49<09:46, 12.76s/it, training_loss=0.102]\u001b[A\n",
            "Epoch 6:  75%|███████▌  | 137/182 [27:49<09:05, 12.11s/it, training_loss=0.102]\u001b[A\n",
            "Epoch 6:  75%|███████▌  | 137/182 [28:01<09:05, 12.11s/it, training_loss=0.084]\u001b[A\n",
            "Epoch 6:  76%|███████▌  | 138/182 [28:01<08:53, 12.13s/it, training_loss=0.084]\u001b[A\n",
            "Epoch 6:  76%|███████▌  | 138/182 [28:14<08:53, 12.13s/it, training_loss=0.002]\u001b[A\n",
            "Epoch 6:  76%|███████▋  | 139/182 [28:14<08:48, 12.29s/it, training_loss=0.002]\u001b[A\n",
            "Epoch 6:  76%|███████▋  | 139/182 [28:27<08:48, 12.29s/it, training_loss=0.057]\u001b[A\n",
            "Epoch 6:  77%|███████▋  | 140/182 [28:27<08:41, 12.41s/it, training_loss=0.057]\u001b[A\n",
            "Epoch 6:  77%|███████▋  | 140/182 [28:38<08:41, 12.41s/it, training_loss=0.003]\u001b[A\n",
            "Epoch 6:  77%|███████▋  | 141/182 [28:38<08:13, 12.03s/it, training_loss=0.003]\u001b[A\n",
            "Epoch 6:  77%|███████▋  | 141/182 [28:49<08:13, 12.03s/it, training_loss=0.002]\u001b[A\n",
            "Epoch 6:  78%|███████▊  | 142/182 [28:49<07:56, 11.90s/it, training_loss=0.002]\u001b[A\n",
            "Epoch 6:  78%|███████▊  | 142/182 [29:02<07:56, 11.90s/it, training_loss=0.002]\u001b[A\n",
            "Epoch 6:  79%|███████▊  | 143/182 [29:02<07:52, 12.11s/it, training_loss=0.002]\u001b[A\n",
            "Epoch 6:  79%|███████▊  | 143/182 [29:15<07:52, 12.11s/it, training_loss=0.177]\u001b[A\n",
            "Epoch 6:  79%|███████▉  | 144/182 [29:15<07:46, 12.28s/it, training_loss=0.177]\u001b[A\n",
            "Epoch 6:  79%|███████▉  | 144/182 [29:26<07:46, 12.28s/it, training_loss=0.031]\u001b[A\n",
            "Epoch 6:  80%|███████▉  | 145/182 [29:26<07:24, 12.02s/it, training_loss=0.031]\u001b[A\n",
            "Epoch 6:  80%|███████▉  | 145/182 [29:38<07:24, 12.02s/it, training_loss=0.002]\u001b[A\n",
            "Epoch 6:  80%|████████  | 146/182 [29:38<07:06, 11.84s/it, training_loss=0.002]\u001b[A\n",
            "Epoch 6:  80%|████████  | 146/182 [29:50<07:06, 11.84s/it, training_loss=0.007]\u001b[A\n",
            "Epoch 6:  81%|████████  | 147/182 [29:50<07:02, 12.07s/it, training_loss=0.007]\u001b[A\n",
            "Epoch 6:  81%|████████  | 147/182 [30:03<07:02, 12.07s/it, training_loss=0.020]\u001b[A\n",
            "Epoch 6:  81%|████████▏ | 148/182 [30:03<06:56, 12.25s/it, training_loss=0.020]\u001b[A\n",
            "Epoch 6:  81%|████████▏ | 148/182 [30:15<06:56, 12.25s/it, training_loss=0.006]\u001b[A\n",
            "Epoch 6:  82%|████████▏ | 149/182 [30:15<06:42, 12.19s/it, training_loss=0.006]\u001b[A\n",
            "Epoch 6:  82%|████████▏ | 149/182 [30:26<06:42, 12.19s/it, training_loss=0.014]\u001b[A\n",
            "Epoch 6:  82%|████████▏ | 150/182 [30:26<06:17, 11.79s/it, training_loss=0.014]\u001b[A\n",
            "Epoch 6:  82%|████████▏ | 150/182 [30:38<06:17, 11.79s/it, training_loss=0.168]\u001b[A\n",
            "Epoch 6:  83%|████████▎ | 151/182 [30:38<06:13, 12.04s/it, training_loss=0.168]\u001b[A\n",
            "Epoch 6:  83%|████████▎ | 151/182 [30:51<06:13, 12.04s/it, training_loss=0.002]\u001b[A\n",
            "Epoch 6:  84%|████████▎ | 152/182 [30:51<06:06, 12.23s/it, training_loss=0.002]\u001b[A\n",
            "Epoch 6:  84%|████████▎ | 152/182 [31:03<06:06, 12.23s/it, training_loss=0.150]\u001b[A\n",
            "Epoch 6:  84%|████████▍ | 153/182 [31:03<05:56, 12.28s/it, training_loss=0.150]\u001b[A\n",
            "Epoch 6:  84%|████████▍ | 153/182 [31:14<05:56, 12.28s/it, training_loss=0.003]\u001b[A\n",
            "Epoch 6:  85%|████████▍ | 154/182 [31:14<05:28, 11.75s/it, training_loss=0.003]\u001b[A\n",
            "Epoch 6:  85%|████████▍ | 154/182 [31:27<05:28, 11.75s/it, training_loss=0.002]\u001b[A\n",
            "Epoch 6:  85%|████████▌ | 155/182 [31:27<05:24, 12.01s/it, training_loss=0.002]\u001b[A\n",
            "Epoch 6:  85%|████████▌ | 155/182 [31:39<05:24, 12.01s/it, training_loss=0.017]\u001b[A\n",
            "Epoch 6:  86%|████████▌ | 156/182 [31:39<05:17, 12.21s/it, training_loss=0.017]\u001b[A\n",
            "Epoch 6:  86%|████████▌ | 156/182 [31:52<05:17, 12.21s/it, training_loss=0.003]\u001b[A\n",
            "Epoch 6:  86%|████████▋ | 157/182 [31:52<05:09, 12.36s/it, training_loss=0.003]\u001b[A\n",
            "Epoch 6:  86%|████████▋ | 157/182 [32:03<05:09, 12.36s/it, training_loss=0.022]\u001b[A\n",
            "Epoch 6:  87%|████████▋ | 158/182 [32:03<04:43, 11.82s/it, training_loss=0.022]\u001b[A\n",
            "Epoch 6:  87%|████████▋ | 158/182 [32:15<04:43, 11.82s/it, training_loss=0.012]\u001b[A\n",
            "Epoch 6:  87%|████████▋ | 159/182 [32:15<04:34, 11.94s/it, training_loss=0.012]\u001b[A\n",
            "Epoch 6:  87%|████████▋ | 159/182 [32:27<04:34, 11.94s/it, training_loss=0.002]\u001b[A\n",
            "Epoch 6:  88%|████████▊ | 160/182 [32:27<04:27, 12.14s/it, training_loss=0.002]\u001b[A\n",
            "Epoch 6:  88%|████████▊ | 160/182 [32:40<04:27, 12.14s/it, training_loss=0.008]\u001b[A\n",
            "Epoch 6:  88%|████████▊ | 161/182 [32:40<04:18, 12.31s/it, training_loss=0.008]\u001b[A\n",
            "Epoch 6:  88%|████████▊ | 161/182 [32:55<04:18, 12.31s/it, training_loss=0.011]\u001b[A\n",
            "Epoch 6:  89%|████████▉ | 162/182 [32:55<04:20, 13.05s/it, training_loss=0.011]\u001b[A\n",
            "Epoch 6:  89%|████████▉ | 162/182 [33:05<04:20, 13.05s/it, training_loss=0.004]\u001b[A\n",
            "Epoch 6:  90%|████████▉ | 163/182 [33:05<03:53, 12.27s/it, training_loss=0.004]\u001b[A\n",
            "Epoch 6:  90%|████████▉ | 163/182 [33:18<03:53, 12.27s/it, training_loss=0.006]\u001b[A\n",
            "Epoch 6:  90%|█████████ | 164/182 [33:18<03:42, 12.36s/it, training_loss=0.006]\u001b[A\n",
            "Epoch 6:  90%|█████████ | 164/182 [33:31<03:42, 12.36s/it, training_loss=0.113]\u001b[A\n",
            "Epoch 6:  91%|█████████ | 165/182 [33:31<03:32, 12.47s/it, training_loss=0.113]\u001b[A\n",
            "Epoch 6:  91%|█████████ | 165/182 [33:43<03:32, 12.47s/it, training_loss=0.020]\u001b[A\n",
            "Epoch 6:  91%|█████████ | 166/182 [33:43<03:20, 12.55s/it, training_loss=0.020]\u001b[A\n",
            "Epoch 6:  91%|█████████ | 166/182 [33:54<03:20, 12.55s/it, training_loss=0.206]\u001b[A\n",
            "Epoch 6:  92%|█████████▏| 167/182 [33:54<03:00, 12.03s/it, training_loss=0.206]\u001b[A\n",
            "Epoch 6:  92%|█████████▏| 167/182 [34:06<03:00, 12.03s/it, training_loss=0.004]\u001b[A\n",
            "Epoch 6:  92%|█████████▏| 168/182 [34:06<02:48, 12.03s/it, training_loss=0.004]\u001b[A\n",
            "Epoch 6:  92%|█████████▏| 168/182 [34:19<02:48, 12.03s/it, training_loss=0.002]\u001b[A\n",
            "Epoch 6:  93%|█████████▎| 169/182 [34:19<02:38, 12.20s/it, training_loss=0.002]\u001b[A\n",
            "Epoch 6:  93%|█████████▎| 169/182 [34:31<02:38, 12.20s/it, training_loss=0.003]\u001b[A\n",
            "Epoch 6:  93%|█████████▎| 170/182 [34:31<02:27, 12.33s/it, training_loss=0.003]\u001b[A\n",
            "Epoch 6:  93%|█████████▎| 170/182 [34:43<02:27, 12.33s/it, training_loss=0.002]\u001b[A\n",
            "Epoch 6:  94%|█████████▍| 171/182 [34:43<02:11, 11.97s/it, training_loss=0.002]\u001b[A\n",
            "Epoch 6:  94%|█████████▍| 171/182 [34:54<02:11, 11.97s/it, training_loss=0.003]\u001b[A\n",
            "Epoch 6:  95%|█████████▍| 172/182 [34:54<01:59, 11.91s/it, training_loss=0.003]\u001b[A\n",
            "Epoch 6:  95%|█████████▍| 172/182 [35:07<01:59, 11.91s/it, training_loss=0.002]\u001b[A\n",
            "Epoch 6:  95%|█████████▌| 173/182 [35:07<01:49, 12.17s/it, training_loss=0.002]\u001b[A\n",
            "Epoch 6:  95%|█████████▌| 173/182 [35:20<01:49, 12.17s/it, training_loss=0.245]\u001b[A\n",
            "Epoch 6:  96%|█████████▌| 174/182 [35:20<01:39, 12.38s/it, training_loss=0.245]\u001b[A\n",
            "Epoch 6:  96%|█████████▌| 174/182 [35:32<01:39, 12.38s/it, training_loss=0.003]\u001b[A\n",
            "Epoch 6:  96%|█████████▌| 175/182 [35:32<01:25, 12.26s/it, training_loss=0.003]\u001b[A\n",
            "Epoch 6:  96%|█████████▌| 175/182 [35:43<01:25, 12.26s/it, training_loss=0.006]\u001b[A\n",
            "Epoch 6:  97%|█████████▋| 176/182 [35:43<01:11, 11.92s/it, training_loss=0.006]\u001b[A\n",
            "Epoch 6:  97%|█████████▋| 176/182 [35:56<01:11, 11.92s/it, training_loss=0.002]\u001b[A\n",
            "Epoch 6:  97%|█████████▋| 177/182 [35:56<01:00, 12.12s/it, training_loss=0.002]\u001b[A\n",
            "Epoch 6:  97%|█████████▋| 177/182 [36:08<01:00, 12.12s/it, training_loss=0.003]\u001b[A\n",
            "Epoch 6:  98%|█████████▊| 178/182 [36:08<00:49, 12.26s/it, training_loss=0.003]\u001b[A\n",
            "Epoch 6:  98%|█████████▊| 178/182 [36:20<00:49, 12.26s/it, training_loss=0.125]\u001b[A\n",
            "Epoch 6:  98%|█████████▊| 179/182 [36:20<00:36, 12.23s/it, training_loss=0.125]\u001b[A\n",
            "Epoch 6:  98%|█████████▊| 179/182 [36:31<00:36, 12.23s/it, training_loss=0.229]\u001b[A\n",
            "Epoch 6:  99%|█████████▉| 180/182 [36:31<00:23, 11.77s/it, training_loss=0.229]\u001b[A\n",
            "Epoch 6:  99%|█████████▉| 180/182 [36:44<00:23, 11.77s/it, training_loss=0.026]\u001b[A\n",
            "Epoch 6:  99%|█████████▉| 181/182 [36:44<00:12, 12.02s/it, training_loss=0.026]\u001b[A\n",
            "Epoch 6:  99%|█████████▉| 181/182 [36:46<00:12, 12.02s/it, training_loss=0.001]\u001b[A\n",
            "Epoch 6: 100%|██████████| 182/182 [36:46<00:00,  9.03s/it, training_loss=0.001]\u001b[A\n",
            " 62%|██████▎   | 5/8 [3:54:44<1:58:37, 2372.59s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            " Epoch {epoch}\n",
            "Training loss: {loss_train_avg}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "  0%|          | 0/46 [00:00<?, ?it/s]\u001b[A\n",
            "  2%|▏         | 1/46 [00:05<03:50,  5.13s/it]\u001b[A\n",
            "  4%|▍         | 2/46 [00:08<03:00,  4.11s/it]\u001b[A\n",
            "  7%|▋         | 3/46 [00:12<02:55,  4.09s/it]\u001b[A\n",
            "  9%|▊         | 4/46 [00:16<02:54,  4.15s/it]\u001b[A\n",
            " 11%|█         | 5/46 [00:21<02:59,  4.37s/it]\u001b[A\n",
            " 13%|█▎        | 6/46 [00:24<02:39,  3.98s/it]\u001b[A\n",
            " 15%|█▌        | 7/46 [00:28<02:26,  3.75s/it]\u001b[A\n",
            " 17%|█▋        | 8/46 [00:31<02:20,  3.69s/it]\u001b[A\n",
            " 20%|█▉        | 9/46 [00:36<02:33,  4.14s/it]\u001b[A\n",
            " 22%|██▏       | 10/46 [00:40<02:19,  3.87s/it]\u001b[A\n",
            " 24%|██▍       | 11/46 [00:43<02:08,  3.67s/it]\u001b[A\n",
            " 26%|██▌       | 12/46 [00:46<02:00,  3.54s/it]\u001b[A\n",
            " 28%|██▊       | 13/46 [00:51<02:13,  4.06s/it]\u001b[A\n",
            " 30%|███       | 14/46 [00:55<02:04,  3.89s/it]\u001b[A\n",
            " 33%|███▎      | 15/46 [00:58<01:54,  3.70s/it]\u001b[A\n",
            " 35%|███▍      | 16/46 [01:01<01:46,  3.57s/it]\u001b[A\n",
            " 37%|███▋      | 17/46 [01:06<01:54,  3.96s/it]\u001b[A\n",
            " 39%|███▉      | 18/46 [01:10<01:50,  3.93s/it]\u001b[A\n",
            " 41%|████▏     | 19/46 [01:13<01:40,  3.72s/it]\u001b[A\n",
            " 43%|████▎     | 20/46 [01:16<01:32,  3.57s/it]\u001b[A\n",
            " 46%|████▌     | 21/46 [01:21<01:35,  3.83s/it]\u001b[A\n",
            " 48%|████▊     | 22/46 [01:27<01:44,  4.37s/it]\u001b[A\n",
            " 50%|█████     | 23/46 [01:31<01:41,  4.40s/it]\u001b[A\n",
            " 52%|█████▏    | 24/46 [01:34<01:29,  4.05s/it]\u001b[A\n",
            " 54%|█████▍    | 25/46 [01:38<01:20,  3.81s/it]\u001b[A\n",
            " 57%|█████▋    | 26/46 [01:42<01:22,  4.14s/it]\u001b[A\n",
            " 59%|█████▊    | 27/46 [01:46<01:16,  4.05s/it]\u001b[A\n",
            " 61%|██████    | 28/46 [01:49<01:08,  3.80s/it]\u001b[A\n",
            " 63%|██████▎   | 29/46 [01:53<01:01,  3.64s/it]\u001b[A\n",
            " 65%|██████▌   | 30/46 [01:57<01:02,  3.90s/it]\u001b[A\n",
            " 67%|██████▋   | 31/46 [02:02<01:00,  4.01s/it]\u001b[A\n",
            " 70%|██████▉   | 32/46 [02:05<00:52,  3.78s/it]\u001b[A\n",
            " 72%|███████▏  | 33/46 [02:08<00:46,  3.61s/it]\u001b[A\n",
            " 74%|███████▍  | 34/46 [02:12<00:44,  3.74s/it]\u001b[A\n",
            " 76%|███████▌  | 35/46 [02:17<00:44,  4.03s/it]\u001b[A\n",
            " 78%|███████▊  | 36/46 [02:20<00:37,  3.79s/it]\u001b[A\n",
            " 80%|████████  | 37/46 [02:23<00:32,  3.63s/it]\u001b[A\n",
            " 83%|████████▎ | 38/46 [02:27<00:29,  3.63s/it]\u001b[A\n",
            " 85%|████████▍ | 39/46 [02:32<00:28,  4.08s/it]\u001b[A\n",
            " 87%|████████▋ | 40/46 [02:35<00:23,  3.83s/it]\u001b[A\n",
            " 89%|████████▉ | 41/46 [02:38<00:18,  3.66s/it]\u001b[A\n",
            " 91%|█████████▏| 42/46 [02:42<00:14,  3.53s/it]\u001b[A\n",
            " 93%|█████████▎| 43/46 [02:47<00:12,  4.06s/it]\u001b[A\n",
            " 96%|█████████▌| 44/46 [02:51<00:07,  3.89s/it]\u001b[A\n",
            " 98%|█████████▊| 45/46 [02:54<00:03,  3.70s/it]\u001b[A\n",
            "100%|██████████| 46/46 [02:55<00:00,  3.82s/it]\n",
            " 75%|███████▌  | 6/8 [3:57:39<1:19:13, 2376.66s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy:110/128\n",
            " -> 0.859375\n",
            "Accuracy:79/107\n",
            " -> 0.7383177570093458\n",
            "Accuracy:104/128\n",
            " -> 0.8125\n",
            "Validation loss: 0.7868337020196993\n",
            "F1 Score (weighted): 0.8076114122784048\n",
            "Accuracy Score: 0.8071625344352618\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "Epoch 7:   0%|          | 0/182 [00:00<?, ?it/s]\u001b[A\n",
            "Epoch 7:   0%|          | 0/182 [00:12<?, ?it/s, training_loss=0.004]\u001b[A\n",
            "Epoch 7:   1%|          | 1/182 [00:12<38:04, 12.62s/it, training_loss=0.004]\u001b[A\n",
            "Epoch 7:   1%|          | 1/182 [00:25<38:04, 12.62s/it, training_loss=0.035]\u001b[A\n",
            "Epoch 7:   1%|          | 2/182 [00:25<38:43, 12.91s/it, training_loss=0.035]\u001b[A\n",
            "Epoch 7:   1%|          | 2/182 [00:37<38:43, 12.91s/it, training_loss=0.002]\u001b[A\n",
            "Epoch 7:   2%|▏         | 3/182 [00:37<36:25, 12.21s/it, training_loss=0.002]\u001b[A\n",
            "Epoch 7:   2%|▏         | 3/182 [00:51<36:25, 12.21s/it, training_loss=0.005]\u001b[A\n",
            "Epoch 7:   2%|▏         | 4/182 [00:51<39:08, 13.19s/it, training_loss=0.005]\u001b[A\n",
            "Epoch 7:   2%|▏         | 4/182 [01:04<39:08, 13.19s/it, training_loss=0.003]\u001b[A\n",
            "Epoch 7:   3%|▎         | 5/182 [01:04<38:23, 13.01s/it, training_loss=0.003]\u001b[A\n",
            "Epoch 7:   3%|▎         | 5/182 [01:17<38:23, 13.01s/it, training_loss=0.002]\u001b[A\n",
            "Epoch 7:   3%|▎         | 6/182 [01:17<37:47, 12.89s/it, training_loss=0.002]\u001b[A\n",
            "Epoch 7:   3%|▎         | 6/182 [01:28<37:47, 12.89s/it, training_loss=0.018]\u001b[A\n",
            "Epoch 7:   4%|▍         | 7/182 [01:28<36:17, 12.44s/it, training_loss=0.018]\u001b[A\n",
            "Epoch 7:   4%|▍         | 7/182 [01:39<36:17, 12.44s/it, training_loss=0.032]\u001b[A\n",
            "Epoch 7:   4%|▍         | 8/182 [01:39<34:57, 12.06s/it, training_loss=0.032]\u001b[A\n",
            "Epoch 7:   4%|▍         | 8/182 [01:52<34:57, 12.06s/it, training_loss=0.149]\u001b[A\n",
            "Epoch 7:   5%|▍         | 9/182 [01:52<35:16, 12.23s/it, training_loss=0.149]\u001b[A\n",
            "Epoch 7:   5%|▍         | 9/182 [02:05<35:16, 12.23s/it, training_loss=0.020]\u001b[A\n",
            "Epoch 7:   5%|▌         | 10/182 [02:05<35:30, 12.39s/it, training_loss=0.020]\u001b[A\n",
            "Epoch 7:   5%|▌         | 10/182 [02:17<35:30, 12.39s/it, training_loss=0.003]\u001b[A\n",
            "Epoch 7:   6%|▌         | 11/182 [02:17<34:48, 12.22s/it, training_loss=0.003]\u001b[A\n",
            "Epoch 7:   6%|▌         | 11/182 [02:28<34:48, 12.22s/it, training_loss=0.005]\u001b[A\n",
            "Epoch 7:   7%|▋         | 12/182 [02:28<33:31, 11.83s/it, training_loss=0.005]\u001b[A\n",
            "Epoch 7:   7%|▋         | 12/182 [02:40<33:31, 11.83s/it, training_loss=0.002]\u001b[A\n",
            "Epoch 7:   7%|▋         | 13/182 [02:40<33:58, 12.06s/it, training_loss=0.002]\u001b[A\n",
            "Epoch 7:   7%|▋         | 13/182 [02:53<33:58, 12.06s/it, training_loss=0.002]\u001b[A\n",
            "Epoch 7:   8%|▊         | 14/182 [02:53<34:17, 12.25s/it, training_loss=0.002]\u001b[A\n",
            "Epoch 7:   8%|▊         | 14/182 [03:05<34:17, 12.25s/it, training_loss=0.002]\u001b[A\n",
            "Epoch 7:   8%|▊         | 15/182 [03:05<34:08, 12.26s/it, training_loss=0.002]\u001b[A\n",
            "Epoch 7:   8%|▊         | 15/182 [03:16<34:08, 12.26s/it, training_loss=0.002]\u001b[A\n",
            "Epoch 7:   9%|▉         | 16/182 [03:16<32:40, 11.81s/it, training_loss=0.002]\u001b[A\n",
            "Epoch 7:   9%|▉         | 16/182 [03:28<32:40, 11.81s/it, training_loss=0.112]\u001b[A\n",
            "Epoch 7:   9%|▉         | 17/182 [03:28<33:07, 12.04s/it, training_loss=0.112]\u001b[A\n",
            "Epoch 7:   9%|▉         | 17/182 [03:41<33:07, 12.04s/it, training_loss=0.003]\u001b[A\n",
            "Epoch 7:  10%|▉         | 18/182 [03:41<33:29, 12.25s/it, training_loss=0.003]\u001b[A\n",
            "Epoch 7:  10%|▉         | 18/182 [03:54<33:29, 12.25s/it, training_loss=0.002]\u001b[A\n",
            "Epoch 7:  10%|█         | 19/182 [03:54<33:39, 12.39s/it, training_loss=0.002]\u001b[A\n",
            "Epoch 7:  10%|█         | 19/182 [04:07<33:39, 12.39s/it, training_loss=0.004]\u001b[A\n",
            "Epoch 7:  11%|█         | 20/182 [04:07<33:49, 12.53s/it, training_loss=0.004]\u001b[A\n",
            "Epoch 7:  11%|█         | 20/182 [04:19<33:49, 12.53s/it, training_loss=0.003]\u001b[A\n",
            "Epoch 7:  12%|█▏        | 21/182 [04:19<33:44, 12.57s/it, training_loss=0.003]\u001b[A\n",
            "Epoch 7:  12%|█▏        | 21/182 [04:32<33:44, 12.57s/it, training_loss=0.002]\u001b[A\n",
            "Epoch 7:  12%|█▏        | 22/182 [04:32<33:34, 12.59s/it, training_loss=0.002]\u001b[A\n",
            "Epoch 7:  12%|█▏        | 22/182 [04:45<33:34, 12.59s/it, training_loss=0.003]\u001b[A\n",
            "Epoch 7:  13%|█▎        | 23/182 [04:45<33:27, 12.63s/it, training_loss=0.003]\u001b[A\n",
            "Epoch 7:  13%|█▎        | 23/182 [04:56<33:27, 12.63s/it, training_loss=0.002]\u001b[A\n",
            "Epoch 7:  13%|█▎        | 24/182 [04:56<32:05, 12.19s/it, training_loss=0.002]\u001b[A\n",
            "Epoch 7:  13%|█▎        | 24/182 [05:08<32:05, 12.19s/it, training_loss=0.238]\u001b[A\n",
            "Epoch 7:  14%|█▎        | 25/182 [05:08<31:37, 12.08s/it, training_loss=0.238]\u001b[A\n",
            "Epoch 7:  14%|█▎        | 25/182 [05:20<31:37, 12.08s/it, training_loss=0.002]\u001b[A\n",
            "Epoch 7:  14%|█▍        | 26/182 [05:20<31:52, 12.26s/it, training_loss=0.002]\u001b[A\n",
            "Epoch 7:  14%|█▍        | 26/182 [05:33<31:52, 12.26s/it, training_loss=0.002]\u001b[A\n",
            "Epoch 7:  15%|█▍        | 27/182 [05:33<31:57, 12.37s/it, training_loss=0.002]\u001b[A\n",
            "Epoch 7:  15%|█▍        | 27/182 [05:45<31:57, 12.37s/it, training_loss=0.003]\u001b[A\n",
            "Epoch 7:  15%|█▌        | 28/182 [05:45<31:04, 12.10s/it, training_loss=0.003]\u001b[A\n",
            "Epoch 7:  15%|█▌        | 28/182 [05:56<31:04, 12.10s/it, training_loss=0.003]\u001b[A\n",
            "Epoch 7:  16%|█▌        | 29/182 [05:56<30:13, 11.86s/it, training_loss=0.003]\u001b[A\n",
            "Epoch 7:  16%|█▌        | 29/182 [06:08<30:13, 11.86s/it, training_loss=0.003]\u001b[A\n",
            "Epoch 7:  16%|█▋        | 30/182 [06:08<30:35, 12.08s/it, training_loss=0.003]\u001b[A\n",
            "Epoch 7:  16%|█▋        | 30/182 [06:21<30:35, 12.08s/it, training_loss=0.002]\u001b[A\n",
            "Epoch 7:  17%|█▋        | 31/182 [06:21<30:49, 12.25s/it, training_loss=0.002]\u001b[A\n",
            "Epoch 7:  17%|█▋        | 31/182 [06:33<30:49, 12.25s/it, training_loss=0.004]\u001b[A\n",
            "Epoch 7:  18%|█▊        | 32/182 [06:33<30:15, 12.10s/it, training_loss=0.004]\u001b[A\n",
            "Epoch 7:  18%|█▊        | 32/182 [06:44<30:15, 12.10s/it, training_loss=0.003]\u001b[A\n",
            "Epoch 7:  18%|█▊        | 33/182 [06:44<29:11, 11.76s/it, training_loss=0.003]\u001b[A\n",
            "Epoch 7:  18%|█▊        | 33/182 [06:56<29:11, 11.76s/it, training_loss=0.008]\u001b[A\n",
            "Epoch 7:  19%|█▊        | 34/182 [06:56<29:32, 11.98s/it, training_loss=0.008]\u001b[A\n",
            "Epoch 7:  19%|█▊        | 34/182 [07:09<29:32, 11.98s/it, training_loss=0.019]\u001b[A\n",
            "Epoch 7:  19%|█▉        | 35/182 [07:09<29:49, 12.17s/it, training_loss=0.019]\u001b[A\n",
            "Epoch 7:  19%|█▉        | 35/182 [07:21<29:49, 12.17s/it, training_loss=0.002]\u001b[A\n",
            "Epoch 7:  20%|█▉        | 36/182 [07:21<29:32, 12.14s/it, training_loss=0.002]\u001b[A\n",
            "Epoch 7:  20%|█▉        | 36/182 [07:32<29:32, 12.14s/it, training_loss=0.003]\u001b[A\n",
            "Epoch 7:  20%|██        | 37/182 [07:32<28:22, 11.74s/it, training_loss=0.003]\u001b[A\n",
            "Epoch 7:  20%|██        | 37/182 [07:44<28:22, 11.74s/it, training_loss=0.010]\u001b[A\n",
            "Epoch 7:  21%|██        | 38/182 [07:44<28:45, 11.98s/it, training_loss=0.010]\u001b[A\n",
            "Epoch 7:  21%|██        | 38/182 [07:57<28:45, 11.98s/it, training_loss=0.002]\u001b[A\n",
            "Epoch 7:  21%|██▏       | 39/182 [07:57<29:03, 12.19s/it, training_loss=0.002]\u001b[A\n",
            "Epoch 7:  21%|██▏       | 39/182 [08:09<29:03, 12.19s/it, training_loss=0.189]\u001b[A\n",
            "Epoch 7:  22%|██▏       | 40/182 [08:09<29:00, 12.26s/it, training_loss=0.189]\u001b[A\n",
            "Epoch 7:  22%|██▏       | 40/182 [08:20<29:00, 12.26s/it, training_loss=0.002]\u001b[A\n",
            "Epoch 7:  23%|██▎       | 41/182 [08:20<27:35, 11.74s/it, training_loss=0.002]\u001b[A\n",
            "Epoch 7:  23%|██▎       | 41/182 [08:32<27:35, 11.74s/it, training_loss=0.002]\u001b[A\n",
            "Epoch 7:  23%|██▎       | 42/182 [08:32<27:53, 11.96s/it, training_loss=0.002]\u001b[A\n",
            "Epoch 7:  23%|██▎       | 42/182 [08:45<27:53, 11.96s/it, training_loss=0.001]\u001b[A\n",
            "Epoch 7:  24%|██▎       | 43/182 [08:45<28:11, 12.17s/it, training_loss=0.001]\u001b[A\n",
            "Epoch 7:  24%|██▎       | 43/182 [08:58<28:11, 12.17s/it, training_loss=0.003]\u001b[A\n",
            "Epoch 7:  24%|██▍       | 44/182 [08:58<28:17, 12.30s/it, training_loss=0.003]\u001b[A\n",
            "Epoch 7:  24%|██▍       | 44/182 [09:08<28:17, 12.30s/it, training_loss=0.002]\u001b[A\n",
            "Epoch 7:  25%|██▍       | 45/182 [09:08<26:55, 11.79s/it, training_loss=0.002]\u001b[A\n",
            "Epoch 7:  25%|██▍       | 45/182 [09:21<26:55, 11.79s/it, training_loss=0.003]\u001b[A\n",
            "Epoch 7:  25%|██▌       | 46/182 [09:21<27:03, 11.94s/it, training_loss=0.003]\u001b[A\n",
            "Epoch 7:  25%|██▌       | 46/182 [09:33<27:03, 11.94s/it, training_loss=0.003]\u001b[A\n",
            "Epoch 7:  26%|██▌       | 47/182 [09:33<27:22, 12.17s/it, training_loss=0.003]\u001b[A\n",
            "Epoch 7:  26%|██▌       | 47/182 [09:48<27:22, 12.17s/it, training_loss=0.010]\u001b[A\n",
            "Epoch 7:  26%|██▋       | 48/182 [09:48<28:56, 12.96s/it, training_loss=0.010]\u001b[A\n",
            "Epoch 7:  26%|██▋       | 48/182 [10:01<28:56, 12.96s/it, training_loss=0.002]\u001b[A\n",
            "Epoch 7:  27%|██▋       | 49/182 [10:01<28:28, 12.85s/it, training_loss=0.002]\u001b[A\n",
            "Epoch 7:  27%|██▋       | 49/182 [10:11<28:28, 12.85s/it, training_loss=0.009]\u001b[A\n",
            "Epoch 7:  27%|██▋       | 50/182 [10:11<26:41, 12.14s/it, training_loss=0.009]\u001b[A\n",
            "Epoch 7:  27%|██▋       | 50/182 [10:24<26:41, 12.14s/it, training_loss=0.115]\u001b[A\n",
            "Epoch 7:  28%|██▊       | 51/182 [10:24<26:44, 12.25s/it, training_loss=0.115]\u001b[A\n",
            "Epoch 7:  28%|██▊       | 51/182 [10:36<26:44, 12.25s/it, training_loss=0.156]\u001b[A\n",
            "Epoch 7:  29%|██▊       | 52/182 [10:36<26:45, 12.35s/it, training_loss=0.156]\u001b[A\n",
            "Epoch 7:  29%|██▊       | 52/182 [10:49<26:45, 12.35s/it, training_loss=0.002]\u001b[A\n",
            "Epoch 7:  29%|██▉       | 53/182 [10:49<26:39, 12.40s/it, training_loss=0.002]\u001b[A\n",
            "Epoch 7:  29%|██▉       | 53/182 [10:59<26:39, 12.40s/it, training_loss=0.002]\u001b[A\n",
            "Epoch 7:  30%|██▉       | 54/182 [10:59<25:14, 11.83s/it, training_loss=0.002]\u001b[A\n",
            "Epoch 7:  30%|██▉       | 54/182 [11:12<25:14, 11.83s/it, training_loss=0.002]\u001b[A\n",
            "Epoch 7:  30%|███       | 55/182 [11:12<25:21, 11.98s/it, training_loss=0.002]\u001b[A\n",
            "Epoch 7:  30%|███       | 55/182 [11:24<25:21, 11.98s/it, training_loss=0.002]\u001b[A\n",
            "Epoch 7:  31%|███       | 56/182 [11:24<25:33, 12.17s/it, training_loss=0.002]\u001b[A\n",
            "Epoch 7:  31%|███       | 56/182 [11:37<25:33, 12.17s/it, training_loss=0.002]\u001b[A\n",
            "Epoch 7:  31%|███▏      | 57/182 [11:37<25:47, 12.38s/it, training_loss=0.002]\u001b[A\n",
            "Epoch 7:  31%|███▏      | 57/182 [11:48<25:47, 12.38s/it, training_loss=0.002]\u001b[A\n",
            "Epoch 7:  32%|███▏      | 58/182 [11:48<24:50, 12.02s/it, training_loss=0.002]\u001b[A\n",
            "Epoch 7:  32%|███▏      | 58/182 [12:00<24:50, 12.02s/it, training_loss=0.003]\u001b[A\n",
            "Epoch 7:  32%|███▏      | 59/182 [12:00<24:31, 11.97s/it, training_loss=0.003]\u001b[A\n",
            "Epoch 7:  32%|███▏      | 59/182 [12:13<24:31, 11.97s/it, training_loss=0.002]\u001b[A\n",
            "Epoch 7:  33%|███▎      | 60/182 [12:13<24:45, 12.17s/it, training_loss=0.002]\u001b[A\n",
            "Epoch 7:  33%|███▎      | 60/182 [12:25<24:45, 12.17s/it, training_loss=0.004]\u001b[A\n",
            "Epoch 7:  34%|███▎      | 61/182 [12:25<24:53, 12.34s/it, training_loss=0.004]\u001b[A\n",
            "Epoch 7:  34%|███▎      | 61/182 [12:37<24:53, 12.34s/it, training_loss=0.032]\u001b[A\n",
            "Epoch 7:  34%|███▍      | 62/182 [12:37<24:15, 12.13s/it, training_loss=0.032]\u001b[A\n",
            "Epoch 7:  34%|███▍      | 62/182 [12:48<24:15, 12.13s/it, training_loss=0.007]\u001b[A\n",
            "Epoch 7:  35%|███▍      | 63/182 [12:48<23:30, 11.85s/it, training_loss=0.007]\u001b[A\n",
            "Epoch 7:  35%|███▍      | 63/182 [13:01<23:30, 11.85s/it, training_loss=0.003]\u001b[A\n",
            "Epoch 7:  35%|███▌      | 64/182 [13:01<23:44, 12.07s/it, training_loss=0.003]\u001b[A\n",
            "Epoch 7:  35%|███▌      | 64/182 [13:14<23:44, 12.07s/it, training_loss=0.004]\u001b[A\n",
            "Epoch 7:  36%|███▌      | 65/182 [13:14<23:52, 12.24s/it, training_loss=0.004]\u001b[A\n",
            "Epoch 7:  36%|███▌      | 65/182 [13:26<23:52, 12.24s/it, training_loss=0.010]\u001b[A\n",
            "Epoch 7:  36%|███▋      | 66/182 [13:26<23:38, 12.23s/it, training_loss=0.010]\u001b[A\n",
            "Epoch 7:  36%|███▋      | 66/182 [13:37<23:38, 12.23s/it, training_loss=0.084]\u001b[A\n",
            "Epoch 7:  37%|███▋      | 67/182 [13:37<22:35, 11.79s/it, training_loss=0.084]\u001b[A\n",
            "Epoch 7:  37%|███▋      | 67/182 [13:49<22:35, 11.79s/it, training_loss=0.002]\u001b[A\n",
            "Epoch 7:  37%|███▋      | 68/182 [13:49<22:52, 12.04s/it, training_loss=0.002]\u001b[A\n",
            "Epoch 7:  37%|███▋      | 68/182 [14:02<22:52, 12.04s/it, training_loss=0.002]\u001b[A\n",
            "Epoch 7:  38%|███▊      | 69/182 [14:02<23:02, 12.24s/it, training_loss=0.002]\u001b[A\n",
            "Epoch 7:  38%|███▊      | 69/182 [14:14<23:02, 12.24s/it, training_loss=0.004]\u001b[A\n",
            "Epoch 7:  38%|███▊      | 70/182 [14:14<23:02, 12.34s/it, training_loss=0.004]\u001b[A\n",
            "Epoch 7:  38%|███▊      | 70/182 [14:25<23:02, 12.34s/it, training_loss=0.005]\u001b[A\n",
            "Epoch 7:  39%|███▉      | 71/182 [14:25<21:50, 11.80s/it, training_loss=0.005]\u001b[A\n",
            "Epoch 7:  39%|███▉      | 71/182 [14:38<21:50, 11.80s/it, training_loss=0.189]\u001b[A\n",
            "Epoch 7:  40%|███▉      | 72/182 [14:38<22:02, 12.02s/it, training_loss=0.189]\u001b[A\n",
            "Epoch 7:  40%|███▉      | 72/182 [14:50<22:02, 12.02s/it, training_loss=0.003]\u001b[A\n",
            "Epoch 7:  40%|████      | 73/182 [14:50<22:12, 12.22s/it, training_loss=0.003]\u001b[A\n",
            "Epoch 7:  40%|████      | 73/182 [15:03<22:12, 12.22s/it, training_loss=0.003]\u001b[A\n",
            "Epoch 7:  41%|████      | 74/182 [15:03<22:27, 12.47s/it, training_loss=0.003]\u001b[A\n",
            "Epoch 7:  41%|████      | 74/182 [15:15<22:27, 12.47s/it, training_loss=0.067]\u001b[A\n",
            "Epoch 7:  41%|████      | 75/182 [15:15<22:04, 12.37s/it, training_loss=0.067]\u001b[A\n",
            "Epoch 7:  41%|████      | 75/182 [15:28<22:04, 12.37s/it, training_loss=0.002]\u001b[A\n",
            "Epoch 7:  42%|████▏     | 76/182 [15:28<22:05, 12.51s/it, training_loss=0.002]\u001b[A\n",
            "Epoch 7:  42%|████▏     | 76/182 [15:41<22:05, 12.51s/it, training_loss=0.005]\u001b[A\n",
            "Epoch 7:  42%|████▏     | 77/182 [15:41<22:00, 12.57s/it, training_loss=0.005]\u001b[A\n",
            "Epoch 7:  42%|████▏     | 77/182 [15:52<22:00, 12.57s/it, training_loss=0.001]\u001b[A\n",
            "Epoch 7:  43%|████▎     | 78/182 [15:52<21:04, 12.16s/it, training_loss=0.001]\u001b[A\n",
            "Epoch 7:  43%|████▎     | 78/182 [16:04<21:04, 12.16s/it, training_loss=0.229]\u001b[A\n",
            "Epoch 7:  43%|████▎     | 79/182 [16:04<20:32, 11.97s/it, training_loss=0.229]\u001b[A\n",
            "Epoch 7:  43%|████▎     | 79/182 [16:19<20:32, 11.97s/it, training_loss=0.002]\u001b[A\n",
            "Epoch 7:  44%|████▍     | 80/182 [16:19<21:54, 12.88s/it, training_loss=0.002]\u001b[A\n",
            "Epoch 7:  44%|████▍     | 80/182 [16:32<21:54, 12.88s/it, training_loss=0.002]\u001b[A\n",
            "Epoch 7:  45%|████▍     | 81/182 [16:32<21:49, 12.96s/it, training_loss=0.002]\u001b[A\n",
            "Epoch 7:  45%|████▍     | 81/182 [16:44<21:49, 12.96s/it, training_loss=0.074]\u001b[A\n",
            "Epoch 7:  45%|████▌     | 82/182 [16:44<21:26, 12.87s/it, training_loss=0.074]\u001b[A\n",
            "Epoch 7:  45%|████▌     | 82/182 [16:56<21:26, 12.87s/it, training_loss=0.002]\u001b[A\n",
            "Epoch 7:  46%|████▌     | 83/182 [16:56<20:26, 12.39s/it, training_loss=0.002]\u001b[A\n",
            "Epoch 7:  46%|████▌     | 83/182 [17:07<20:26, 12.39s/it, training_loss=0.003]\u001b[A\n",
            "Epoch 7:  46%|████▌     | 84/182 [17:07<19:46, 12.10s/it, training_loss=0.003]\u001b[A\n",
            "Epoch 7:  46%|████▌     | 84/182 [17:20<19:46, 12.10s/it, training_loss=0.002]\u001b[A\n",
            "Epoch 7:  47%|████▋     | 85/182 [17:20<19:49, 12.27s/it, training_loss=0.002]\u001b[A\n",
            "Epoch 7:  47%|████▋     | 85/182 [17:32<19:49, 12.27s/it, training_loss=0.002]\u001b[A\n",
            "Epoch 7:  47%|████▋     | 86/182 [17:33<19:49, 12.39s/it, training_loss=0.002]\u001b[A\n",
            "Epoch 7:  47%|████▋     | 86/182 [17:44<19:49, 12.39s/it, training_loss=0.002]\u001b[A\n",
            "Epoch 7:  48%|████▊     | 87/182 [17:44<19:13, 12.14s/it, training_loss=0.002]\u001b[A\n",
            "Epoch 7:  48%|████▊     | 87/182 [17:55<19:13, 12.14s/it, training_loss=0.002]\u001b[A\n",
            "Epoch 7:  48%|████▊     | 88/182 [17:55<18:34, 11.86s/it, training_loss=0.002]\u001b[A\n",
            "Epoch 7:  48%|████▊     | 88/182 [18:08<18:34, 11.86s/it, training_loss=0.001]\u001b[A\n",
            "Epoch 7:  49%|████▉     | 89/182 [18:08<18:43, 12.08s/it, training_loss=0.001]\u001b[A\n",
            "Epoch 7:  49%|████▉     | 89/182 [18:20<18:43, 12.08s/it, training_loss=0.002]\u001b[A\n",
            "Epoch 7:  49%|████▉     | 90/182 [18:20<18:45, 12.24s/it, training_loss=0.002]\u001b[A\n",
            "Epoch 7:  49%|████▉     | 90/182 [18:32<18:45, 12.24s/it, training_loss=0.002]\u001b[A\n",
            "Epoch 7:  50%|█████     | 91/182 [18:32<18:27, 12.17s/it, training_loss=0.002]\u001b[A\n",
            "Epoch 7:  50%|█████     | 91/182 [18:43<18:27, 12.17s/it, training_loss=0.002]\u001b[A\n",
            "Epoch 7:  51%|█████     | 92/182 [18:43<17:39, 11.77s/it, training_loss=0.002]\u001b[A\n",
            "Epoch 7:  51%|█████     | 92/182 [18:56<17:39, 11.77s/it, training_loss=0.001]\u001b[A\n",
            "Epoch 7:  51%|█████     | 93/182 [18:56<17:48, 12.01s/it, training_loss=0.001]\u001b[A\n",
            "Epoch 7:  51%|█████     | 93/182 [19:09<17:48, 12.01s/it, training_loss=0.005]\u001b[A\n",
            "Epoch 7:  52%|█████▏    | 94/182 [19:09<17:54, 12.21s/it, training_loss=0.005]\u001b[A\n",
            "Epoch 7:  52%|█████▏    | 94/182 [19:21<17:54, 12.21s/it, training_loss=0.002]\u001b[A\n",
            "Epoch 7:  52%|█████▏    | 95/182 [19:21<17:44, 12.24s/it, training_loss=0.002]\u001b[A\n",
            "Epoch 7:  52%|█████▏    | 95/182 [19:31<17:44, 12.24s/it, training_loss=0.002]\u001b[A\n",
            "Epoch 7:  53%|█████▎    | 96/182 [19:31<16:47, 11.71s/it, training_loss=0.002]\u001b[A\n",
            "Epoch 7:  53%|█████▎    | 96/182 [19:44<16:47, 11.71s/it, training_loss=0.002]\u001b[A\n",
            "Epoch 7:  53%|█████▎    | 97/182 [19:44<16:57, 11.97s/it, training_loss=0.002]\u001b[A\n",
            "Epoch 7:  53%|█████▎    | 97/182 [19:57<16:57, 11.97s/it, training_loss=0.002]\u001b[A\n",
            "Epoch 7:  54%|█████▍    | 98/182 [19:57<17:04, 12.20s/it, training_loss=0.002]\u001b[A\n",
            "Epoch 7:  54%|█████▍    | 98/182 [20:09<17:04, 12.20s/it, training_loss=0.056]\u001b[A\n",
            "Epoch 7:  54%|█████▍    | 99/182 [20:09<17:01, 12.31s/it, training_loss=0.056]\u001b[A\n",
            "Epoch 7:  54%|█████▍    | 99/182 [20:20<17:01, 12.31s/it, training_loss=0.002]\u001b[A\n",
            "Epoch 7:  55%|█████▍    | 100/182 [20:20<16:03, 11.75s/it, training_loss=0.002]\u001b[A\n",
            "Epoch 7:  55%|█████▍    | 100/182 [20:34<16:03, 11.75s/it, training_loss=0.073]\u001b[A\n",
            "Epoch 7:  55%|█████▌    | 101/182 [20:34<17:05, 12.66s/it, training_loss=0.073]\u001b[A\n",
            "Epoch 7:  55%|█████▌    | 101/182 [20:47<17:05, 12.66s/it, training_loss=0.004]\u001b[A\n",
            "Epoch 7:  56%|█████▌    | 102/182 [20:47<16:51, 12.65s/it, training_loss=0.004]\u001b[A\n",
            "Epoch 7:  56%|█████▌    | 102/182 [20:58<16:51, 12.65s/it, training_loss=0.169]\u001b[A\n",
            "Epoch 7:  57%|█████▋    | 103/182 [20:58<15:58, 12.14s/it, training_loss=0.169]\u001b[A\n",
            "Epoch 7:  57%|█████▋    | 103/182 [21:10<15:58, 12.14s/it, training_loss=0.001]\u001b[A\n",
            "Epoch 7:  57%|█████▋    | 104/182 [21:10<15:37, 12.02s/it, training_loss=0.001]\u001b[A\n",
            "Epoch 7:  57%|█████▋    | 104/182 [21:22<15:37, 12.02s/it, training_loss=0.185]\u001b[A\n",
            "Epoch 7:  58%|█████▊    | 105/182 [21:22<15:37, 12.18s/it, training_loss=0.185]\u001b[A\n",
            "Epoch 7:  58%|█████▊    | 105/182 [21:35<15:37, 12.18s/it, training_loss=0.064]\u001b[A\n",
            "Epoch 7:  58%|█████▊    | 106/182 [21:35<15:36, 12.32s/it, training_loss=0.064]\u001b[A\n",
            "Epoch 7:  58%|█████▊    | 106/182 [21:46<15:36, 12.32s/it, training_loss=0.002]\u001b[A\n",
            "Epoch 7:  59%|█████▉    | 107/182 [21:46<14:59, 11.99s/it, training_loss=0.002]\u001b[A\n",
            "Epoch 7:  59%|█████▉    | 107/182 [21:58<14:59, 11.99s/it, training_loss=0.003]\u001b[A\n",
            "Epoch 7:  59%|█████▉    | 108/182 [21:58<14:37, 11.86s/it, training_loss=0.003]\u001b[A\n",
            "Epoch 7:  59%|█████▉    | 108/182 [22:10<14:37, 11.86s/it, training_loss=0.236]\u001b[A\n",
            "Epoch 7:  60%|█████▉    | 109/182 [22:10<14:41, 12.08s/it, training_loss=0.236]\u001b[A\n",
            "Epoch 7:  60%|█████▉    | 109/182 [22:23<14:41, 12.08s/it, training_loss=0.142]\u001b[A\n",
            "Epoch 7:  60%|██████    | 110/182 [22:23<14:40, 12.23s/it, training_loss=0.142]\u001b[A\n",
            "Epoch 7:  60%|██████    | 110/182 [22:34<14:40, 12.23s/it, training_loss=0.002]\u001b[A\n",
            "Epoch 7:  61%|██████    | 111/182 [22:34<14:12, 12.01s/it, training_loss=0.002]\u001b[A\n",
            "Epoch 7:  61%|██████    | 111/182 [22:46<14:12, 12.01s/it, training_loss=0.011]\u001b[A\n",
            "Epoch 7:  62%|██████▏   | 112/182 [22:46<13:42, 11.74s/it, training_loss=0.011]\u001b[A\n",
            "Epoch 7:  62%|██████▏   | 112/182 [22:58<13:42, 11.74s/it, training_loss=0.002]\u001b[A\n",
            "Epoch 7:  62%|██████▏   | 113/182 [22:58<13:48, 12.00s/it, training_loss=0.002]\u001b[A\n",
            "Epoch 7:  62%|██████▏   | 113/182 [23:11<13:48, 12.00s/it, training_loss=0.004]\u001b[A\n",
            "Epoch 7:  63%|██████▎   | 114/182 [23:11<13:49, 12.20s/it, training_loss=0.004]\u001b[A\n",
            "Epoch 7:  63%|██████▎   | 114/182 [23:23<13:49, 12.20s/it, training_loss=0.002]\u001b[A\n",
            "Epoch 7:  63%|██████▎   | 115/182 [23:23<13:34, 12.15s/it, training_loss=0.002]\u001b[A\n",
            "Epoch 7:  63%|██████▎   | 115/182 [23:34<13:34, 12.15s/it, training_loss=0.012]\u001b[A\n",
            "Epoch 7:  64%|██████▎   | 116/182 [23:34<12:57, 11.78s/it, training_loss=0.012]\u001b[A\n",
            "Epoch 7:  64%|██████▎   | 116/182 [23:46<12:57, 11.78s/it, training_loss=0.416]\u001b[A\n",
            "Epoch 7:  64%|██████▍   | 117/182 [23:46<13:02, 12.04s/it, training_loss=0.416]\u001b[A\n",
            "Epoch 7:  64%|██████▍   | 117/182 [23:59<13:02, 12.04s/it, training_loss=0.003]\u001b[A\n",
            "Epoch 7:  65%|██████▍   | 118/182 [23:59<13:04, 12.26s/it, training_loss=0.003]\u001b[A\n",
            "Epoch 7:  65%|██████▍   | 118/182 [24:12<13:04, 12.26s/it, training_loss=0.002]\u001b[A\n",
            "Epoch 7:  65%|██████▌   | 119/182 [24:12<12:55, 12.31s/it, training_loss=0.002]\u001b[A\n",
            "Epoch 7:  65%|██████▌   | 119/182 [24:22<12:55, 12.31s/it, training_loss=0.002]\u001b[A\n",
            "Epoch 7:  66%|██████▌   | 120/182 [24:22<12:11, 11.79s/it, training_loss=0.002]\u001b[A\n",
            "Epoch 7:  66%|██████▌   | 120/182 [24:35<12:11, 11.79s/it, training_loss=0.001]\u001b[A\n",
            "Epoch 7:  66%|██████▋   | 121/182 [24:35<12:14, 12.04s/it, training_loss=0.001]\u001b[A\n",
            "Epoch 7:  66%|██████▋   | 121/182 [24:47<12:14, 12.04s/it, training_loss=0.002]\u001b[A\n",
            "Epoch 7:  67%|██████▋   | 122/182 [24:47<12:13, 12.22s/it, training_loss=0.002]\u001b[A\n",
            "Epoch 7:  67%|██████▋   | 122/182 [25:00<12:13, 12.22s/it, training_loss=0.190]\u001b[A\n",
            "Epoch 7:  68%|██████▊   | 123/182 [25:00<12:08, 12.36s/it, training_loss=0.190]\u001b[A\n",
            "Epoch 7:  68%|██████▊   | 123/182 [25:11<12:08, 12.36s/it, training_loss=0.002]\u001b[A\n",
            "Epoch 7:  68%|██████▊   | 124/182 [25:11<11:24, 11.81s/it, training_loss=0.002]\u001b[A\n",
            "Epoch 7:  68%|██████▊   | 124/182 [25:23<11:24, 11.81s/it, training_loss=0.005]\u001b[A\n",
            "Epoch 7:  69%|██████▊   | 125/182 [25:23<11:20, 11.94s/it, training_loss=0.005]\u001b[A\n",
            "Epoch 7:  69%|██████▊   | 125/182 [25:36<11:20, 11.94s/it, training_loss=0.012]\u001b[A\n",
            "Epoch 7:  69%|██████▉   | 126/182 [25:36<11:21, 12.17s/it, training_loss=0.012]\u001b[A\n",
            "Epoch 7:  69%|██████▉   | 126/182 [25:49<11:21, 12.17s/it, training_loss=0.093]\u001b[A\n",
            "Epoch 7:  70%|██████▉   | 127/182 [25:49<11:26, 12.47s/it, training_loss=0.093]\u001b[A\n",
            "Epoch 7:  70%|██████▉   | 127/182 [26:01<11:26, 12.47s/it, training_loss=0.002]\u001b[A\n",
            "Epoch 7:  70%|███████   | 128/182 [26:01<11:07, 12.36s/it, training_loss=0.002]\u001b[A\n",
            "Epoch 7:  70%|███████   | 128/182 [26:14<11:07, 12.36s/it, training_loss=0.001]\u001b[A\n",
            "Epoch 7:  71%|███████   | 129/182 [26:14<10:59, 12.45s/it, training_loss=0.001]\u001b[A\n",
            "Epoch 7:  71%|███████   | 129/182 [26:26<10:59, 12.45s/it, training_loss=0.044]\u001b[A\n",
            "Epoch 7:  71%|███████▏  | 130/182 [26:26<10:51, 12.53s/it, training_loss=0.044]\u001b[A\n",
            "Epoch 7:  71%|███████▏  | 130/182 [26:39<10:51, 12.53s/it, training_loss=0.012]\u001b[A\n",
            "Epoch 7:  72%|███████▏  | 131/182 [26:39<10:39, 12.54s/it, training_loss=0.012]\u001b[A\n",
            "Epoch 7:  72%|███████▏  | 131/182 [26:49<10:39, 12.54s/it, training_loss=0.002]\u001b[A\n",
            "Epoch 7:  73%|███████▎  | 132/182 [26:49<09:56, 11.94s/it, training_loss=0.002]\u001b[A\n",
            "Epoch 7:  73%|███████▎  | 132/182 [27:02<09:56, 11.94s/it, training_loss=0.184]\u001b[A\n",
            "Epoch 7:  73%|███████▎  | 133/182 [27:02<09:54, 12.13s/it, training_loss=0.184]\u001b[A\n",
            "Epoch 7:  73%|███████▎  | 133/182 [27:15<09:54, 12.13s/it, training_loss=0.079]\u001b[A\n",
            "Epoch 7:  74%|███████▎  | 134/182 [27:15<09:49, 12.29s/it, training_loss=0.079]\u001b[A\n",
            "Epoch 7:  74%|███████▎  | 134/182 [27:27<09:49, 12.29s/it, training_loss=0.221]\u001b[A\n",
            "Epoch 7:  74%|███████▍  | 135/182 [27:27<09:42, 12.39s/it, training_loss=0.221]\u001b[A\n",
            "Epoch 7:  74%|███████▍  | 135/182 [27:38<09:42, 12.39s/it, training_loss=0.004]\u001b[A\n",
            "Epoch 7:  75%|███████▍  | 136/182 [27:38<09:08, 11.92s/it, training_loss=0.004]\u001b[A\n",
            "Epoch 7:  75%|███████▍  | 136/182 [27:50<09:08, 11.92s/it, training_loss=0.011]\u001b[A\n",
            "Epoch 7:  75%|███████▌  | 137/182 [27:50<08:57, 11.95s/it, training_loss=0.011]\u001b[A\n",
            "Epoch 7:  75%|███████▌  | 137/182 [28:03<08:57, 11.95s/it, training_loss=0.006]\u001b[A\n",
            "Epoch 7:  76%|███████▌  | 138/182 [28:03<08:54, 12.15s/it, training_loss=0.006]\u001b[A\n",
            "Epoch 7:  76%|███████▌  | 138/182 [28:15<08:54, 12.15s/it, training_loss=0.016]\u001b[A\n",
            "Epoch 7:  76%|███████▋  | 139/182 [28:15<08:48, 12.29s/it, training_loss=0.016]\u001b[A\n",
            "Epoch 7:  76%|███████▋  | 139/182 [28:26<08:48, 12.29s/it, training_loss=0.011]\u001b[A\n",
            "Epoch 7:  77%|███████▋  | 140/182 [28:26<08:18, 11.87s/it, training_loss=0.011]\u001b[A\n",
            "Epoch 7:  77%|███████▋  | 140/182 [28:38<08:18, 11.87s/it, training_loss=0.002]\u001b[A\n",
            "Epoch 7:  77%|███████▋  | 141/182 [28:38<08:04, 11.81s/it, training_loss=0.002]\u001b[A\n",
            "Epoch 7:  77%|███████▋  | 141/182 [28:50<08:04, 11.81s/it, training_loss=0.002]\u001b[A\n",
            "Epoch 7:  78%|███████▊  | 142/182 [28:50<08:01, 12.03s/it, training_loss=0.002]\u001b[A\n",
            "Epoch 7:  78%|███████▊  | 142/182 [29:03<08:01, 12.03s/it, training_loss=0.002]\u001b[A\n",
            "Epoch 7:  79%|███████▊  | 143/182 [29:03<07:56, 12.21s/it, training_loss=0.002]\u001b[A\n",
            "Epoch 7:  79%|███████▊  | 143/182 [29:14<07:56, 12.21s/it, training_loss=0.241]\u001b[A\n",
            "Epoch 7:  79%|███████▉  | 144/182 [29:14<07:31, 11.89s/it, training_loss=0.241]\u001b[A\n",
            "Epoch 7:  79%|███████▉  | 144/182 [29:26<07:31, 11.89s/it, training_loss=0.001]\u001b[A\n",
            "Epoch 7:  80%|███████▉  | 145/182 [29:26<07:15, 11.76s/it, training_loss=0.001]\u001b[A\n",
            "Epoch 7:  80%|███████▉  | 145/182 [29:38<07:15, 11.76s/it, training_loss=0.126]\u001b[A\n",
            "Epoch 7:  80%|████████  | 146/182 [29:38<07:11, 11.99s/it, training_loss=0.126]\u001b[A\n",
            "Epoch 7:  80%|████████  | 146/182 [29:51<07:11, 11.99s/it, training_loss=0.047]\u001b[A\n",
            "Epoch 7:  81%|████████  | 147/182 [29:51<07:06, 12.18s/it, training_loss=0.047]\u001b[A\n",
            "Epoch 7:  81%|████████  | 147/182 [30:02<07:06, 12.18s/it, training_loss=0.002]\u001b[A\n",
            "Epoch 7:  81%|████████▏ | 148/182 [30:02<06:46, 11.96s/it, training_loss=0.002]\u001b[A\n",
            "Epoch 7:  81%|████████▏ | 148/182 [30:13<06:46, 11.96s/it, training_loss=0.191]\u001b[A\n",
            "Epoch 7:  82%|████████▏ | 149/182 [30:13<06:26, 11.71s/it, training_loss=0.191]\u001b[A\n",
            "Epoch 7:  82%|████████▏ | 149/182 [30:26<06:26, 11.71s/it, training_loss=0.009]\u001b[A\n",
            "Epoch 7:  82%|████████▏ | 150/182 [30:26<06:22, 11.96s/it, training_loss=0.009]\u001b[A\n",
            "Epoch 7:  82%|████████▏ | 150/182 [30:38<06:22, 11.96s/it, training_loss=0.002]\u001b[A\n",
            "Epoch 7:  83%|████████▎ | 151/182 [30:38<06:16, 12.13s/it, training_loss=0.002]\u001b[A\n",
            "Epoch 7:  83%|████████▎ | 151/182 [30:50<06:16, 12.13s/it, training_loss=0.016]\u001b[A\n",
            "Epoch 7:  84%|████████▎ | 152/182 [30:50<05:59, 11.98s/it, training_loss=0.016]\u001b[A\n",
            "Epoch 7:  84%|████████▎ | 152/182 [31:01<05:59, 11.98s/it, training_loss=0.067]\u001b[A\n",
            "Epoch 7:  84%|████████▍ | 153/182 [31:01<05:38, 11.68s/it, training_loss=0.067]\u001b[A\n",
            "Epoch 7:  84%|████████▍ | 153/182 [31:14<05:38, 11.68s/it, training_loss=0.024]\u001b[A\n",
            "Epoch 7:  85%|████████▍ | 154/182 [31:14<05:33, 11.93s/it, training_loss=0.024]\u001b[A\n",
            "Epoch 7:  85%|████████▍ | 154/182 [31:29<05:33, 11.93s/it, training_loss=0.004]\u001b[A\n",
            "Epoch 7:  85%|████████▌ | 155/182 [31:29<05:47, 12.86s/it, training_loss=0.004]\u001b[A\n",
            "Epoch 7:  85%|████████▌ | 155/182 [31:40<05:47, 12.86s/it, training_loss=0.122]\u001b[A\n",
            "Epoch 7:  86%|████████▌ | 156/182 [31:40<05:20, 12.32s/it, training_loss=0.122]\u001b[A\n",
            "Epoch 7:  86%|████████▌ | 156/182 [31:51<05:20, 12.32s/it, training_loss=0.001]\u001b[A\n",
            "Epoch 7:  86%|████████▋ | 157/182 [31:51<05:02, 12.09s/it, training_loss=0.001]\u001b[A\n",
            "Epoch 7:  86%|████████▋ | 157/182 [32:04<05:02, 12.09s/it, training_loss=0.003]\u001b[A\n",
            "Epoch 7:  87%|████████▋ | 158/182 [32:04<04:53, 12.25s/it, training_loss=0.003]\u001b[A\n",
            "Epoch 7:  87%|████████▋ | 158/182 [32:16<04:53, 12.25s/it, training_loss=0.001]\u001b[A\n",
            "Epoch 7:  87%|████████▋ | 159/182 [32:16<04:44, 12.36s/it, training_loss=0.001]\u001b[A\n",
            "Epoch 7:  87%|████████▋ | 159/182 [32:28<04:44, 12.36s/it, training_loss=0.002]\u001b[A\n",
            "Epoch 7:  88%|████████▊ | 160/182 [32:28<04:25, 12.09s/it, training_loss=0.002]\u001b[A\n",
            "Epoch 7:  88%|████████▊ | 160/182 [32:39<04:25, 12.09s/it, training_loss=0.003]\u001b[A\n",
            "Epoch 7:  88%|████████▊ | 161/182 [32:39<04:07, 11.79s/it, training_loss=0.003]\u001b[A\n",
            "Epoch 7:  88%|████████▊ | 161/182 [32:51<04:07, 11.79s/it, training_loss=0.003]\u001b[A\n",
            "Epoch 7:  89%|████████▉ | 162/182 [32:51<03:59, 11.99s/it, training_loss=0.003]\u001b[A\n",
            "Epoch 7:  89%|████████▉ | 162/182 [33:04<03:59, 11.99s/it, training_loss=0.002]\u001b[A\n",
            "Epoch 7:  90%|████████▉ | 163/182 [33:04<03:51, 12.18s/it, training_loss=0.002]\u001b[A\n",
            "Epoch 7:  90%|████████▉ | 163/182 [33:16<03:51, 12.18s/it, training_loss=0.001]\u001b[A\n",
            "Epoch 7:  90%|█████████ | 164/182 [33:16<03:36, 12.02s/it, training_loss=0.001]\u001b[A\n",
            "Epoch 7:  90%|█████████ | 164/182 [33:27<03:36, 12.02s/it, training_loss=0.002]\u001b[A\n",
            "Epoch 7:  91%|█████████ | 165/182 [33:27<03:19, 11.71s/it, training_loss=0.002]\u001b[A\n",
            "Epoch 7:  91%|█████████ | 165/182 [33:39<03:19, 11.71s/it, training_loss=0.003]\u001b[A\n",
            "Epoch 7:  91%|█████████ | 166/182 [33:39<03:11, 11.94s/it, training_loss=0.003]\u001b[A\n",
            "Epoch 7:  91%|█████████ | 166/182 [33:52<03:11, 11.94s/it, training_loss=0.002]\u001b[A\n",
            "Epoch 7:  92%|█████████▏| 167/182 [33:52<03:02, 12.15s/it, training_loss=0.002]\u001b[A\n",
            "Epoch 7:  92%|█████████▏| 167/182 [34:04<03:02, 12.15s/it, training_loss=0.117]\u001b[A\n",
            "Epoch 7:  92%|█████████▏| 168/182 [34:04<02:49, 12.14s/it, training_loss=0.117]\u001b[A\n",
            "Epoch 7:  92%|█████████▏| 168/182 [34:15<02:49, 12.14s/it, training_loss=0.013]\u001b[A\n",
            "Epoch 7:  93%|█████████▎| 169/182 [34:15<02:32, 11.74s/it, training_loss=0.013]\u001b[A\n",
            "Epoch 7:  93%|█████████▎| 169/182 [34:27<02:32, 11.74s/it, training_loss=0.242]\u001b[A\n",
            "Epoch 7:  93%|█████████▎| 170/182 [34:27<02:24, 12.01s/it, training_loss=0.242]\u001b[A\n",
            "Epoch 7:  93%|█████████▎| 170/182 [34:40<02:24, 12.01s/it, training_loss=0.002]\u001b[A\n",
            "Epoch 7:  94%|█████████▍| 171/182 [34:40<02:14, 12.21s/it, training_loss=0.002]\u001b[A\n",
            "Epoch 7:  94%|█████████▍| 171/182 [34:52<02:14, 12.21s/it, training_loss=0.004]\u001b[A\n",
            "Epoch 7:  95%|█████████▍| 172/182 [34:52<02:02, 12.23s/it, training_loss=0.004]\u001b[A\n",
            "Epoch 7:  95%|█████████▍| 172/182 [35:03<02:02, 12.23s/it, training_loss=0.002]\u001b[A\n",
            "Epoch 7:  95%|█████████▌| 173/182 [35:03<01:45, 11.73s/it, training_loss=0.002]\u001b[A\n",
            "Epoch 7:  95%|█████████▌| 173/182 [35:15<01:45, 11.73s/it, training_loss=0.004]\u001b[A\n",
            "Epoch 7:  96%|█████████▌| 174/182 [35:15<01:35, 11.96s/it, training_loss=0.004]\u001b[A\n",
            "Epoch 7:  96%|█████████▌| 174/182 [35:28<01:35, 11.96s/it, training_loss=0.002]\u001b[A\n",
            "Epoch 7:  96%|█████████▌| 175/182 [35:28<01:25, 12.17s/it, training_loss=0.002]\u001b[A\n",
            "Epoch 7:  96%|█████████▌| 175/182 [35:41<01:25, 12.17s/it, training_loss=0.002]\u001b[A\n",
            "Epoch 7:  97%|█████████▋| 176/182 [35:41<01:13, 12.28s/it, training_loss=0.002]\u001b[A\n",
            "Epoch 7:  97%|█████████▋| 176/182 [35:51<01:13, 12.28s/it, training_loss=0.002]\u001b[A\n",
            "Epoch 7:  97%|█████████▋| 177/182 [35:51<00:58, 11.72s/it, training_loss=0.002]\u001b[A\n",
            "Epoch 7:  97%|█████████▋| 177/182 [36:03<00:58, 11.72s/it, training_loss=0.001]\u001b[A\n",
            "Epoch 7:  98%|█████████▊| 178/182 [36:03<00:47, 11.93s/it, training_loss=0.001]\u001b[A\n",
            "Epoch 7:  98%|█████████▊| 178/182 [36:16<00:47, 11.93s/it, training_loss=0.002]\u001b[A\n",
            "Epoch 7:  98%|█████████▊| 179/182 [36:16<00:36, 12.12s/it, training_loss=0.002]\u001b[A\n",
            "Epoch 7:  98%|█████████▊| 179/182 [36:29<00:36, 12.12s/it, training_loss=0.074]\u001b[A\n",
            "Epoch 7:  99%|█████████▉| 180/182 [36:29<00:24, 12.27s/it, training_loss=0.074]\u001b[A\n",
            "Epoch 7:  99%|█████████▉| 180/182 [36:39<00:24, 12.27s/it, training_loss=0.002]\u001b[A\n",
            "Epoch 7:  99%|█████████▉| 181/182 [36:39<00:11, 11.78s/it, training_loss=0.002]\u001b[A\n",
            "Epoch 7:  99%|█████████▉| 181/182 [36:42<00:11, 11.78s/it, training_loss=0.001]\u001b[A\n",
            "Epoch 7: 100%|██████████| 182/182 [36:42<00:00,  9.18s/it, training_loss=0.001]\u001b[A\n",
            " 75%|███████▌  | 6/8 [4:34:28<1:19:13, 2376.66s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            " Epoch {epoch}\n",
            "Training loss: {loss_train_avg}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "  0%|          | 0/46 [00:00<?, ?it/s]\u001b[A\n",
            "  2%|▏         | 1/46 [00:03<02:33,  3.41s/it]\u001b[A\n",
            "  4%|▍         | 2/46 [00:08<03:26,  4.68s/it]\u001b[A\n",
            "  7%|▋         | 3/46 [00:16<04:09,  5.80s/it]\u001b[A\n",
            "  9%|▊         | 4/46 [00:19<03:21,  4.79s/it]\u001b[A\n",
            " 11%|█         | 5/46 [00:22<02:53,  4.23s/it]\u001b[A\n",
            " 13%|█▎        | 6/46 [00:25<02:35,  3.89s/it]\u001b[A\n",
            " 15%|█▌        | 7/46 [00:31<02:48,  4.32s/it]\u001b[A\n",
            " 17%|█▋        | 8/46 [00:34<02:35,  4.09s/it]\u001b[A\n",
            " 20%|█▉        | 9/46 [00:37<02:21,  3.82s/it]\u001b[A\n",
            " 22%|██▏       | 10/46 [00:41<02:11,  3.64s/it]\u001b[A\n",
            " 24%|██▍       | 11/46 [00:45<02:19,  3.99s/it]\u001b[A\n",
            " 26%|██▌       | 12/46 [00:49<02:15,  3.99s/it]\u001b[A\n",
            " 28%|██▊       | 13/46 [00:53<02:04,  3.77s/it]\u001b[A\n",
            " 30%|███       | 14/46 [00:56<01:55,  3.62s/it]\u001b[A\n",
            " 33%|███▎      | 15/46 [01:00<01:59,  3.84s/it]\u001b[A\n",
            " 35%|███▍      | 16/46 [01:05<02:00,  4.01s/it]\u001b[A\n",
            " 37%|███▋      | 17/46 [01:08<01:49,  3.78s/it]\u001b[A\n",
            " 39%|███▉      | 18/46 [01:11<01:41,  3.63s/it]\u001b[A\n",
            " 41%|████▏     | 19/46 [01:15<01:40,  3.71s/it]\u001b[A\n",
            " 43%|████▎     | 20/46 [01:20<01:45,  4.05s/it]\u001b[A\n",
            " 46%|████▌     | 21/46 [01:23<01:35,  3.82s/it]\u001b[A\n",
            " 48%|████▊     | 22/46 [01:26<01:27,  3.64s/it]\u001b[A\n",
            " 50%|█████     | 23/46 [01:30<01:22,  3.58s/it]\u001b[A\n",
            " 52%|█████▏    | 24/46 [01:35<01:30,  4.10s/it]\u001b[A\n",
            " 54%|█████▍    | 25/46 [01:38<01:20,  3.85s/it]\u001b[A\n",
            " 57%|█████▋    | 26/46 [01:42<01:13,  3.67s/it]\u001b[A\n",
            " 59%|█████▊    | 27/46 [01:45<01:07,  3.54s/it]\u001b[A\n",
            " 61%|██████    | 28/46 [01:50<01:12,  4.01s/it]\u001b[A\n",
            " 63%|██████▎   | 29/46 [01:54<01:06,  3.90s/it]\u001b[A\n",
            " 65%|██████▌   | 30/46 [01:57<00:59,  3.71s/it]\u001b[A\n",
            " 67%|██████▋   | 31/46 [02:00<00:53,  3.57s/it]\u001b[A\n",
            " 70%|██████▉   | 32/46 [02:05<00:55,  3.93s/it]\u001b[A\n",
            " 72%|███████▏  | 33/46 [02:09<00:51,  3.95s/it]\u001b[A\n",
            " 74%|███████▍  | 34/46 [02:12<00:44,  3.74s/it]\u001b[A\n",
            " 76%|███████▌  | 35/46 [02:15<00:39,  3.59s/it]\u001b[A\n",
            " 78%|███████▊  | 36/46 [02:20<00:38,  3.81s/it]\u001b[A\n",
            " 80%|████████  | 37/46 [02:24<00:35,  4.00s/it]\u001b[A\n",
            " 83%|████████▎ | 38/46 [02:27<00:30,  3.77s/it]\u001b[A\n",
            " 85%|████████▍ | 39/46 [02:31<00:25,  3.62s/it]\u001b[A\n",
            " 87%|████████▋ | 40/46 [02:35<00:22,  3.70s/it]\u001b[A\n",
            " 89%|████████▉ | 41/46 [02:39<00:20,  4.05s/it]\u001b[A\n",
            " 91%|█████████▏| 42/46 [02:43<00:15,  3.81s/it]\u001b[A\n",
            " 93%|█████████▎| 43/46 [02:46<00:10,  3.65s/it]\u001b[A\n",
            " 96%|█████████▌| 44/46 [02:49<00:07,  3.57s/it]\u001b[A\n",
            " 98%|█████████▊| 45/46 [02:55<00:04,  4.09s/it]\u001b[A\n",
            "100%|██████████| 46/46 [02:56<00:00,  3.84s/it]\n",
            " 88%|████████▊ | 7/8 [4:37:24<39:39, 2379.44s/it]  "
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy:112/128\n",
            " -> 0.875\n",
            "Accuracy:75/107\n",
            " -> 0.7009345794392523\n",
            "Accuracy:110/128\n",
            " -> 0.859375\n",
            "Validation loss: 0.8398268774819925\n",
            "F1 Score (weighted): 0.8171412241555298\n",
            "Accuracy Score: 0.8181818181818182\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "Epoch 8:   0%|          | 0/182 [00:00<?, ?it/s]\u001b[A\n",
            "Epoch 8:   0%|          | 0/182 [00:10<?, ?it/s, training_loss=0.003]\u001b[A\n",
            "Epoch 8:   1%|          | 1/182 [00:10<33:09, 10.99s/it, training_loss=0.003]\u001b[A\n",
            "Epoch 8:   1%|          | 1/182 [00:22<33:09, 10.99s/it, training_loss=0.016]\u001b[A\n",
            "Epoch 8:   1%|          | 2/182 [00:22<34:30, 11.51s/it, training_loss=0.016]\u001b[A\n",
            "Epoch 8:   1%|          | 2/182 [00:35<34:30, 11.51s/it, training_loss=0.002]\u001b[A\n",
            "Epoch 8:   2%|▏         | 3/182 [00:35<35:41, 11.96s/it, training_loss=0.002]\u001b[A\n",
            "Epoch 8:   2%|▏         | 3/182 [00:47<35:41, 11.96s/it, training_loss=0.004]\u001b[A\n",
            "Epoch 8:   2%|▏         | 4/182 [00:47<36:14, 12.21s/it, training_loss=0.004]\u001b[A\n",
            "Epoch 8:   2%|▏         | 4/182 [01:01<36:14, 12.21s/it, training_loss=0.003]\u001b[A\n",
            "Epoch 8:   3%|▎         | 5/182 [01:01<36:56, 12.52s/it, training_loss=0.003]\u001b[A\n",
            "Epoch 8:   3%|▎         | 5/182 [01:15<36:56, 12.52s/it, training_loss=0.002]\u001b[A\n",
            "Epoch 8:   3%|▎         | 6/182 [01:15<38:38, 13.18s/it, training_loss=0.002]\u001b[A\n",
            "Epoch 8:   3%|▎         | 6/182 [01:27<38:38, 13.18s/it, training_loss=0.006]\u001b[A\n",
            "Epoch 8:   4%|▍         | 7/182 [01:27<37:48, 12.96s/it, training_loss=0.006]\u001b[A\n",
            "Epoch 8:   4%|▍         | 7/182 [01:40<37:48, 12.96s/it, training_loss=0.002]\u001b[A\n",
            "Epoch 8:   4%|▍         | 8/182 [01:40<37:13, 12.84s/it, training_loss=0.002]\u001b[A\n",
            "Epoch 8:   4%|▍         | 8/182 [01:52<37:13, 12.84s/it, training_loss=0.003]\u001b[A\n",
            "Epoch 8:   5%|▍         | 9/182 [01:52<35:56, 12.47s/it, training_loss=0.003]\u001b[A\n",
            "Epoch 8:   5%|▍         | 9/182 [02:03<35:56, 12.47s/it, training_loss=0.001]\u001b[A\n",
            "Epoch 8:   5%|▌         | 10/182 [02:03<34:25, 12.01s/it, training_loss=0.001]\u001b[A\n",
            "Epoch 8:   5%|▌         | 10/182 [02:15<34:25, 12.01s/it, training_loss=0.002]\u001b[A\n",
            "Epoch 8:   6%|▌         | 11/182 [02:15<34:45, 12.20s/it, training_loss=0.002]\u001b[A\n",
            "Epoch 8:   6%|▌         | 11/182 [02:28<34:45, 12.20s/it, training_loss=0.002]\u001b[A\n",
            "Epoch 8:   7%|▋         | 12/182 [02:28<34:57, 12.34s/it, training_loss=0.002]\u001b[A\n",
            "Epoch 8:   7%|▋         | 12/182 [02:40<34:57, 12.34s/it, training_loss=0.001]\u001b[A\n",
            "Epoch 8:   7%|▋         | 13/182 [02:40<34:29, 12.24s/it, training_loss=0.001]\u001b[A\n",
            "Epoch 8:   7%|▋         | 13/182 [02:54<34:29, 12.24s/it, training_loss=0.009]\u001b[A\n",
            "Epoch 8:   8%|▊         | 14/182 [02:54<35:37, 12.73s/it, training_loss=0.009]\u001b[A\n",
            "Epoch 8:   8%|▊         | 14/182 [03:05<35:37, 12.73s/it, training_loss=0.028]\u001b[A\n",
            "Epoch 8:   8%|▊         | 15/182 [03:05<34:23, 12.36s/it, training_loss=0.028]\u001b[A\n",
            "Epoch 8:   8%|▊         | 15/182 [03:18<34:23, 12.36s/it, training_loss=0.004]\u001b[A\n",
            "Epoch 8:   9%|▉         | 16/182 [03:18<34:25, 12.44s/it, training_loss=0.004]\u001b[A\n",
            "Epoch 8:   9%|▉         | 16/182 [03:31<34:25, 12.44s/it, training_loss=0.029]\u001b[A\n",
            "Epoch 8:   9%|▉         | 17/182 [03:31<34:22, 12.50s/it, training_loss=0.029]\u001b[A\n",
            "Epoch 8:   9%|▉         | 17/182 [03:42<34:22, 12.50s/it, training_loss=0.002]\u001b[A\n",
            "Epoch 8:  10%|▉         | 18/182 [03:42<33:19, 12.19s/it, training_loss=0.002]\u001b[A\n",
            "Epoch 8:  10%|▉         | 18/182 [03:53<33:19, 12.19s/it, training_loss=0.002]\u001b[A\n",
            "Epoch 8:  10%|█         | 19/182 [03:53<32:14, 11.87s/it, training_loss=0.002]\u001b[A\n",
            "Epoch 8:  10%|█         | 19/182 [04:06<32:14, 11.87s/it, training_loss=0.132]\u001b[A\n",
            "Epoch 8:  11%|█         | 20/182 [04:06<32:37, 12.08s/it, training_loss=0.132]\u001b[A\n",
            "Epoch 8:  11%|█         | 20/182 [04:18<32:37, 12.08s/it, training_loss=0.003]\u001b[A\n",
            "Epoch 8:  12%|█▏        | 21/182 [04:18<32:52, 12.25s/it, training_loss=0.003]\u001b[A\n",
            "Epoch 8:  12%|█▏        | 21/182 [04:30<32:52, 12.25s/it, training_loss=0.002]\u001b[A\n",
            "Epoch 8:  12%|█▏        | 22/182 [04:30<32:18, 12.12s/it, training_loss=0.002]\u001b[A\n",
            "Epoch 8:  12%|█▏        | 22/182 [04:41<32:18, 12.12s/it, training_loss=0.001]\u001b[A\n",
            "Epoch 8:  13%|█▎        | 23/182 [04:41<31:13, 11.78s/it, training_loss=0.001]\u001b[A\n",
            "Epoch 8:  13%|█▎        | 23/182 [04:54<31:13, 11.78s/it, training_loss=0.002]\u001b[A\n",
            "Epoch 8:  13%|█▎        | 24/182 [04:54<31:35, 12.00s/it, training_loss=0.002]\u001b[A\n",
            "Epoch 8:  13%|█▎        | 24/182 [05:06<31:35, 12.00s/it, training_loss=0.002]\u001b[A\n",
            "Epoch 8:  14%|█▎        | 25/182 [05:06<31:54, 12.20s/it, training_loss=0.002]\u001b[A\n",
            "Epoch 8:  14%|█▎        | 25/182 [05:19<31:54, 12.20s/it, training_loss=0.002]\u001b[A\n",
            "Epoch 8:  14%|█▍        | 26/182 [05:19<31:46, 12.22s/it, training_loss=0.002]\u001b[A\n",
            "Epoch 8:  14%|█▍        | 26/182 [05:29<31:46, 12.22s/it, training_loss=0.004]\u001b[A\n",
            "Epoch 8:  15%|█▍        | 27/182 [05:29<30:19, 11.74s/it, training_loss=0.004]\u001b[A\n",
            "Epoch 8:  15%|█▍        | 27/182 [05:42<30:19, 11.74s/it, training_loss=0.142]\u001b[A\n",
            "Epoch 8:  15%|█▌        | 28/182 [05:42<30:43, 11.97s/it, training_loss=0.142]\u001b[A\n",
            "Epoch 8:  15%|█▌        | 28/182 [05:54<30:43, 11.97s/it, training_loss=0.002]\u001b[A\n",
            "Epoch 8:  16%|█▌        | 29/182 [05:54<31:00, 12.16s/it, training_loss=0.002]\u001b[A\n",
            "Epoch 8:  16%|█▌        | 29/182 [06:07<31:00, 12.16s/it, training_loss=0.014]\u001b[A\n",
            "Epoch 8:  16%|█▋        | 30/182 [06:07<31:03, 12.26s/it, training_loss=0.014]\u001b[A\n",
            "Epoch 8:  16%|█▋        | 30/182 [06:17<31:03, 12.26s/it, training_loss=0.003]\u001b[A\n",
            "Epoch 8:  17%|█▋        | 31/182 [06:17<29:31, 11.73s/it, training_loss=0.003]\u001b[A\n",
            "Epoch 8:  17%|█▋        | 31/182 [06:30<29:31, 11.73s/it, training_loss=0.002]\u001b[A\n",
            "Epoch 8:  18%|█▊        | 32/182 [06:30<29:52, 11.95s/it, training_loss=0.002]\u001b[A\n",
            "Epoch 8:  18%|█▊        | 32/182 [06:42<29:52, 11.95s/it, training_loss=0.138]\u001b[A\n",
            "Epoch 8:  18%|█▊        | 33/182 [06:42<30:10, 12.15s/it, training_loss=0.138]\u001b[A\n",
            "Epoch 8:  18%|█▊        | 33/182 [06:55<30:10, 12.15s/it, training_loss=0.001]\u001b[A\n",
            "Epoch 8:  19%|█▊        | 34/182 [06:55<30:16, 12.27s/it, training_loss=0.001]\u001b[A\n",
            "Epoch 8:  19%|█▊        | 34/182 [07:06<30:16, 12.27s/it, training_loss=0.023]\u001b[A\n",
            "Epoch 8:  19%|█▉        | 35/182 [07:06<28:47, 11.75s/it, training_loss=0.023]\u001b[A\n",
            "Epoch 8:  19%|█▉        | 35/182 [07:18<28:47, 11.75s/it, training_loss=0.164]\u001b[A\n",
            "Epoch 8:  20%|█▉        | 36/182 [07:18<28:53, 11.88s/it, training_loss=0.164]\u001b[A\n",
            "Epoch 8:  20%|█▉        | 36/182 [07:30<28:53, 11.88s/it, training_loss=0.001]\u001b[A\n",
            "Epoch 8:  20%|██        | 37/182 [07:30<29:15, 12.10s/it, training_loss=0.001]\u001b[A\n",
            "Epoch 8:  20%|██        | 37/182 [07:43<29:15, 12.10s/it, training_loss=0.142]\u001b[A\n",
            "Epoch 8:  21%|██        | 38/182 [07:43<29:24, 12.25s/it, training_loss=0.142]\u001b[A\n",
            "Epoch 8:  21%|██        | 38/182 [07:54<29:24, 12.25s/it, training_loss=0.002]\u001b[A\n",
            "Epoch 8:  21%|██▏       | 39/182 [07:54<28:12, 11.83s/it, training_loss=0.002]\u001b[A\n",
            "Epoch 8:  21%|██▏       | 39/182 [08:06<28:12, 11.83s/it, training_loss=0.001]\u001b[A\n",
            "Epoch 8:  22%|██▏       | 40/182 [08:06<27:58, 11.82s/it, training_loss=0.001]\u001b[A\n",
            "Epoch 8:  22%|██▏       | 40/182 [08:21<27:58, 11.82s/it, training_loss=0.265]\u001b[A\n",
            "Epoch 8:  23%|██▎       | 41/182 [08:21<29:59, 12.76s/it, training_loss=0.265]\u001b[A\n",
            "Epoch 8:  23%|██▎       | 41/182 [08:33<29:59, 12.76s/it, training_loss=0.002]\u001b[A\n",
            "Epoch 8:  23%|██▎       | 42/182 [08:33<29:38, 12.71s/it, training_loss=0.002]\u001b[A\n",
            "Epoch 8:  23%|██▎       | 42/182 [08:46<29:38, 12.71s/it, training_loss=0.002]\u001b[A\n",
            "Epoch 8:  24%|██▎       | 43/182 [08:46<29:19, 12.66s/it, training_loss=0.002]\u001b[A\n",
            "Epoch 8:  24%|██▎       | 43/182 [08:56<29:19, 12.66s/it, training_loss=0.001]\u001b[A\n",
            "Epoch 8:  24%|██▍       | 44/182 [08:56<27:35, 12.00s/it, training_loss=0.001]\u001b[A\n",
            "Epoch 8:  24%|██▍       | 44/182 [09:08<27:35, 12.00s/it, training_loss=0.003]\u001b[A\n",
            "Epoch 8:  25%|██▍       | 45/182 [09:08<27:30, 12.05s/it, training_loss=0.003]\u001b[A\n",
            "Epoch 8:  25%|██▍       | 45/182 [09:21<27:30, 12.05s/it, training_loss=0.002]\u001b[A\n",
            "Epoch 8:  25%|██▌       | 46/182 [09:21<27:37, 12.19s/it, training_loss=0.002]\u001b[A\n",
            "Epoch 8:  25%|██▌       | 46/182 [09:33<27:37, 12.19s/it, training_loss=0.001]\u001b[A\n",
            "Epoch 8:  26%|██▌       | 47/182 [09:33<27:42, 12.31s/it, training_loss=0.001]\u001b[A\n",
            "Epoch 8:  26%|██▌       | 47/182 [09:44<27:42, 12.31s/it, training_loss=0.001]\u001b[A\n",
            "Epoch 8:  26%|██▋       | 48/182 [09:44<26:29, 11.86s/it, training_loss=0.001]\u001b[A\n",
            "Epoch 8:  26%|██▋       | 48/182 [09:56<26:29, 11.86s/it, training_loss=0.108]\u001b[A\n",
            "Epoch 8:  27%|██▋       | 49/182 [09:56<26:18, 11.87s/it, training_loss=0.108]\u001b[A\n",
            "Epoch 8:  27%|██▋       | 49/182 [10:09<26:18, 11.87s/it, training_loss=0.112]\u001b[A\n",
            "Epoch 8:  27%|██▋       | 50/182 [10:09<26:36, 12.10s/it, training_loss=0.112]\u001b[A\n",
            "Epoch 8:  27%|██▋       | 50/182 [10:21<26:36, 12.10s/it, training_loss=0.002]\u001b[A\n",
            "Epoch 8:  28%|██▊       | 51/182 [10:21<26:45, 12.26s/it, training_loss=0.002]\u001b[A\n",
            "Epoch 8:  28%|██▊       | 51/182 [10:32<26:45, 12.26s/it, training_loss=0.005]\u001b[A\n",
            "Epoch 8:  29%|██▊       | 52/182 [10:32<25:46, 11.90s/it, training_loss=0.005]\u001b[A\n",
            "Epoch 8:  29%|██▊       | 52/182 [10:44<25:46, 11.90s/it, training_loss=0.002]\u001b[A\n",
            "Epoch 8:  29%|██▉       | 53/182 [10:44<25:19, 11.78s/it, training_loss=0.002]\u001b[A\n",
            "Epoch 8:  29%|██▉       | 53/182 [10:57<25:19, 11.78s/it, training_loss=0.003]\u001b[A\n",
            "Epoch 8:  30%|██▉       | 54/182 [10:57<25:38, 12.02s/it, training_loss=0.003]\u001b[A\n",
            "Epoch 8:  30%|██▉       | 54/182 [11:09<25:38, 12.02s/it, training_loss=0.001]\u001b[A\n",
            "Epoch 8:  30%|███       | 55/182 [11:09<25:49, 12.20s/it, training_loss=0.001]\u001b[A\n",
            "Epoch 8:  30%|███       | 55/182 [11:21<25:49, 12.20s/it, training_loss=0.007]\u001b[A\n",
            "Epoch 8:  31%|███       | 56/182 [11:21<25:07, 11.96s/it, training_loss=0.007]\u001b[A\n",
            "Epoch 8:  31%|███       | 56/182 [11:32<25:07, 11.96s/it, training_loss=0.002]\u001b[A\n",
            "Epoch 8:  31%|███▏      | 57/182 [11:32<24:30, 11.76s/it, training_loss=0.002]\u001b[A\n",
            "Epoch 8:  31%|███▏      | 57/182 [11:44<24:30, 11.76s/it, training_loss=0.002]\u001b[A\n",
            "Epoch 8:  32%|███▏      | 58/182 [11:44<24:48, 12.01s/it, training_loss=0.002]\u001b[A\n",
            "Epoch 8:  32%|███▏      | 58/182 [11:57<24:48, 12.01s/it, training_loss=0.227]\u001b[A\n",
            "Epoch 8:  32%|███▏      | 59/182 [11:57<24:59, 12.19s/it, training_loss=0.227]\u001b[A\n",
            "Epoch 8:  32%|███▏      | 59/182 [12:09<24:59, 12.19s/it, training_loss=0.088]\u001b[A\n",
            "Epoch 8:  33%|███▎      | 60/182 [12:09<24:29, 12.05s/it, training_loss=0.088]\u001b[A\n",
            "Epoch 8:  33%|███▎      | 60/182 [12:20<24:29, 12.05s/it, training_loss=0.005]\u001b[A\n",
            "Epoch 8:  34%|███▎      | 61/182 [12:20<23:37, 11.72s/it, training_loss=0.005]\u001b[A\n",
            "Epoch 8:  34%|███▎      | 61/182 [12:32<23:37, 11.72s/it, training_loss=0.001]\u001b[A\n",
            "Epoch 8:  34%|███▍      | 62/182 [12:32<23:56, 11.97s/it, training_loss=0.001]\u001b[A\n",
            "Epoch 8:  34%|███▍      | 62/182 [12:45<23:56, 11.97s/it, training_loss=0.002]\u001b[A\n",
            "Epoch 8:  35%|███▍      | 63/182 [12:45<24:07, 12.16s/it, training_loss=0.002]\u001b[A\n",
            "Epoch 8:  35%|███▍      | 63/182 [12:57<24:07, 12.16s/it, training_loss=0.002]\u001b[A\n",
            "Epoch 8:  35%|███▌      | 64/182 [12:57<23:46, 12.09s/it, training_loss=0.002]\u001b[A\n",
            "Epoch 8:  35%|███▌      | 64/182 [13:08<23:46, 12.09s/it, training_loss=0.002]\u001b[A\n",
            "Epoch 8:  36%|███▌      | 65/182 [13:08<22:50, 11.72s/it, training_loss=0.002]\u001b[A\n",
            "Epoch 8:  36%|███▌      | 65/182 [13:20<22:50, 11.72s/it, training_loss=0.002]\u001b[A\n",
            "Epoch 8:  36%|███▋      | 66/182 [13:20<23:08, 11.97s/it, training_loss=0.002]\u001b[A\n",
            "Epoch 8:  36%|███▋      | 66/182 [13:33<23:08, 11.97s/it, training_loss=0.001]\u001b[A\n",
            "Epoch 8:  37%|███▋      | 67/182 [13:33<23:19, 12.17s/it, training_loss=0.001]\u001b[A\n",
            "Epoch 8:  37%|███▋      | 67/182 [13:45<23:19, 12.17s/it, training_loss=0.001]\u001b[A\n",
            "Epoch 8:  37%|███▋      | 68/182 [13:45<23:16, 12.25s/it, training_loss=0.001]\u001b[A\n",
            "Epoch 8:  37%|███▋      | 68/182 [13:58<23:16, 12.25s/it, training_loss=0.002]\u001b[A\n",
            "Epoch 8:  38%|███▊      | 69/182 [13:58<23:26, 12.45s/it, training_loss=0.002]\u001b[A\n",
            "Epoch 8:  38%|███▊      | 69/182 [14:11<23:26, 12.45s/it, training_loss=0.002]\u001b[A\n",
            "Epoch 8:  38%|███▊      | 70/182 [14:11<23:21, 12.51s/it, training_loss=0.002]\u001b[A\n",
            "Epoch 8:  38%|███▊      | 70/182 [14:24<23:21, 12.51s/it, training_loss=0.001]\u001b[A\n",
            "Epoch 8:  39%|███▉      | 71/182 [14:24<23:13, 12.56s/it, training_loss=0.001]\u001b[A\n",
            "Epoch 8:  39%|███▉      | 71/182 [14:35<23:13, 12.56s/it, training_loss=0.187]\u001b[A\n",
            "Epoch 8:  40%|███▉      | 72/182 [14:35<22:26, 12.24s/it, training_loss=0.187]\u001b[A\n",
            "Epoch 8:  40%|███▉      | 72/182 [14:46<22:26, 12.24s/it, training_loss=0.001]\u001b[A\n",
            "Epoch 8:  40%|████      | 73/182 [14:46<21:40, 11.94s/it, training_loss=0.001]\u001b[A\n",
            "Epoch 8:  40%|████      | 73/182 [14:59<21:40, 11.94s/it, training_loss=0.002]\u001b[A\n",
            "Epoch 8:  41%|████      | 74/182 [14:59<21:52, 12.15s/it, training_loss=0.002]\u001b[A\n",
            "Epoch 8:  41%|████      | 74/182 [15:12<21:52, 12.15s/it, training_loss=0.002]\u001b[A\n",
            "Epoch 8:  41%|████      | 75/182 [15:12<21:56, 12.31s/it, training_loss=0.002]\u001b[A\n",
            "Epoch 8:  41%|████      | 75/182 [15:23<21:56, 12.31s/it, training_loss=0.002]\u001b[A\n",
            "Epoch 8:  42%|████▏     | 76/182 [15:23<21:32, 12.19s/it, training_loss=0.002]\u001b[A\n",
            "Epoch 8:  42%|████▏     | 76/182 [15:35<21:32, 12.19s/it, training_loss=0.093]\u001b[A\n",
            "Epoch 8:  42%|████▏     | 77/182 [15:35<20:44, 11.85s/it, training_loss=0.093]\u001b[A\n",
            "Epoch 8:  42%|████▏     | 77/182 [15:50<20:44, 11.85s/it, training_loss=0.001]\u001b[A\n",
            "Epoch 8:  43%|████▎     | 78/182 [15:50<22:21, 12.90s/it, training_loss=0.001]\u001b[A\n",
            "Epoch 8:  43%|████▎     | 78/182 [16:03<22:21, 12.90s/it, training_loss=0.001]\u001b[A\n",
            "Epoch 8:  43%|████▎     | 79/182 [16:03<22:02, 12.84s/it, training_loss=0.001]\u001b[A\n",
            "Epoch 8:  43%|████▎     | 79/182 [16:15<22:02, 12.84s/it, training_loss=0.001]\u001b[A\n",
            "Epoch 8:  44%|████▍     | 80/182 [16:15<21:30, 12.65s/it, training_loss=0.001]\u001b[A\n",
            "Epoch 8:  44%|████▍     | 80/182 [16:26<21:30, 12.65s/it, training_loss=0.001]\u001b[A\n",
            "Epoch 8:  45%|████▍     | 81/182 [16:26<20:21, 12.09s/it, training_loss=0.001]\u001b[A\n",
            "Epoch 8:  45%|████▍     | 81/182 [16:38<20:21, 12.09s/it, training_loss=0.001]\u001b[A\n",
            "Epoch 8:  45%|████▌     | 82/182 [16:38<20:22, 12.23s/it, training_loss=0.001]\u001b[A\n",
            "Epoch 8:  45%|████▌     | 82/182 [16:51<20:22, 12.23s/it, training_loss=0.001]\u001b[A\n",
            "Epoch 8:  46%|████▌     | 83/182 [16:51<20:24, 12.36s/it, training_loss=0.001]\u001b[A\n",
            "Epoch 8:  46%|████▌     | 83/182 [17:03<20:24, 12.36s/it, training_loss=0.001]\u001b[A\n",
            "Epoch 8:  46%|████▌     | 84/182 [17:03<20:08, 12.33s/it, training_loss=0.001]\u001b[A\n",
            "Epoch 8:  46%|████▌     | 84/182 [17:14<20:08, 12.33s/it, training_loss=0.001]\u001b[A\n",
            "Epoch 8:  47%|████▋     | 85/182 [17:14<19:05, 11.81s/it, training_loss=0.001]\u001b[A\n",
            "Epoch 8:  47%|████▋     | 85/182 [17:26<19:05, 11.81s/it, training_loss=0.001]\u001b[A\n",
            "Epoch 8:  47%|████▋     | 86/182 [17:26<19:16, 12.05s/it, training_loss=0.001]\u001b[A\n",
            "Epoch 8:  47%|████▋     | 86/182 [17:39<19:16, 12.05s/it, training_loss=0.002]\u001b[A\n",
            "Epoch 8:  48%|████▊     | 87/182 [17:39<19:19, 12.21s/it, training_loss=0.002]\u001b[A\n",
            "Epoch 8:  48%|████▊     | 87/182 [17:51<19:19, 12.21s/it, training_loss=0.001]\u001b[A\n",
            "Epoch 8:  48%|████▊     | 88/182 [17:51<19:15, 12.29s/it, training_loss=0.001]\u001b[A\n",
            "Epoch 8:  48%|████▊     | 88/182 [18:02<19:15, 12.29s/it, training_loss=0.001]\u001b[A\n",
            "Epoch 8:  49%|████▉     | 89/182 [18:02<18:14, 11.77s/it, training_loss=0.001]\u001b[A\n",
            "Epoch 8:  49%|████▉     | 89/182 [18:14<18:14, 11.77s/it, training_loss=0.002]\u001b[A\n",
            "Epoch 8:  49%|████▉     | 90/182 [18:14<18:23, 12.00s/it, training_loss=0.002]\u001b[A\n",
            "Epoch 8:  49%|████▉     | 90/182 [18:27<18:23, 12.00s/it, training_loss=0.002]\u001b[A\n",
            "Epoch 8:  50%|█████     | 91/182 [18:27<18:30, 12.20s/it, training_loss=0.002]\u001b[A\n",
            "Epoch 8:  50%|█████     | 91/182 [18:40<18:30, 12.20s/it, training_loss=0.010]\u001b[A\n",
            "Epoch 8:  51%|█████     | 92/182 [18:40<18:31, 12.35s/it, training_loss=0.010]\u001b[A\n",
            "Epoch 8:  51%|█████     | 92/182 [18:51<18:31, 12.35s/it, training_loss=0.012]\u001b[A\n",
            "Epoch 8:  51%|█████     | 93/182 [18:51<17:38, 11.90s/it, training_loss=0.012]\u001b[A\n",
            "Epoch 8:  51%|█████     | 93/182 [19:03<17:38, 11.90s/it, training_loss=0.002]\u001b[A\n",
            "Epoch 8:  52%|█████▏    | 94/182 [19:03<17:34, 11.98s/it, training_loss=0.002]\u001b[A\n",
            "Epoch 8:  52%|█████▏    | 94/182 [19:18<17:34, 11.98s/it, training_loss=0.003]\u001b[A\n",
            "Epoch 8:  52%|█████▏    | 95/182 [19:18<18:47, 12.96s/it, training_loss=0.003]\u001b[A\n",
            "Epoch 8:  52%|█████▏    | 95/182 [19:30<18:47, 12.96s/it, training_loss=0.002]\u001b[A\n",
            "Epoch 8:  53%|█████▎    | 96/182 [19:30<18:16, 12.75s/it, training_loss=0.002]\u001b[A\n",
            "Epoch 8:  53%|█████▎    | 96/182 [19:41<18:16, 12.75s/it, training_loss=0.002]\u001b[A\n",
            "Epoch 8:  53%|█████▎    | 97/182 [19:41<17:12, 12.15s/it, training_loss=0.002]\u001b[A\n",
            "Epoch 8:  53%|█████▎    | 97/182 [19:54<17:12, 12.15s/it, training_loss=0.008]\u001b[A\n",
            "Epoch 8:  54%|█████▍    | 98/182 [19:54<17:12, 12.29s/it, training_loss=0.008]\u001b[A\n",
            "Epoch 8:  54%|█████▍    | 98/182 [20:06<17:12, 12.29s/it, training_loss=0.002]\u001b[A\n",
            "Epoch 8:  54%|█████▍    | 99/182 [20:06<17:10, 12.41s/it, training_loss=0.002]\u001b[A\n",
            "Epoch 8:  54%|█████▍    | 99/182 [20:19<17:10, 12.41s/it, training_loss=0.003]\u001b[A\n",
            "Epoch 8:  55%|█████▍    | 100/182 [20:19<17:02, 12.47s/it, training_loss=0.003]\u001b[A\n",
            "Epoch 8:  55%|█████▍    | 100/182 [20:29<17:02, 12.47s/it, training_loss=0.002]\u001b[A\n",
            "Epoch 8:  55%|█████▌    | 101/182 [20:29<16:02, 11.89s/it, training_loss=0.002]\u001b[A\n",
            "Epoch 8:  55%|█████▌    | 101/182 [20:42<16:02, 11.89s/it, training_loss=0.002]\u001b[A\n",
            "Epoch 8:  56%|█████▌    | 102/182 [20:42<16:04, 12.06s/it, training_loss=0.002]\u001b[A\n",
            "Epoch 8:  56%|█████▌    | 102/182 [20:55<16:04, 12.06s/it, training_loss=0.001]\u001b[A\n",
            "Epoch 8:  57%|█████▋    | 103/182 [20:55<16:10, 12.28s/it, training_loss=0.001]\u001b[A\n",
            "Epoch 8:  57%|█████▋    | 103/182 [21:08<16:10, 12.28s/it, training_loss=0.055]\u001b[A\n",
            "Epoch 8:  57%|█████▋    | 104/182 [21:08<16:09, 12.43s/it, training_loss=0.055]\u001b[A\n",
            "Epoch 8:  57%|█████▋    | 104/182 [21:18<16:09, 12.43s/it, training_loss=0.028]\u001b[A\n",
            "Epoch 8:  58%|█████▊    | 105/182 [21:18<15:19, 11.94s/it, training_loss=0.028]\u001b[A\n",
            "Epoch 8:  58%|█████▊    | 105/182 [21:30<15:19, 11.94s/it, training_loss=0.001]\u001b[A\n",
            "Epoch 8:  58%|█████▊    | 106/182 [21:31<15:12, 12.01s/it, training_loss=0.001]\u001b[A\n",
            "Epoch 8:  58%|█████▊    | 106/182 [21:43<15:12, 12.01s/it, training_loss=0.002]\u001b[A\n",
            "Epoch 8:  59%|█████▉    | 107/182 [21:43<15:15, 12.21s/it, training_loss=0.002]\u001b[A\n",
            "Epoch 8:  59%|█████▉    | 107/182 [21:56<15:15, 12.21s/it, training_loss=0.002]\u001b[A\n",
            "Epoch 8:  59%|█████▉    | 108/182 [21:56<15:14, 12.36s/it, training_loss=0.002]\u001b[A\n",
            "Epoch 8:  59%|█████▉    | 108/182 [22:07<15:14, 12.36s/it, training_loss=0.002]\u001b[A\n",
            "Epoch 8:  60%|█████▉    | 109/182 [22:07<14:37, 12.02s/it, training_loss=0.002]\u001b[A\n",
            "Epoch 8:  60%|█████▉    | 109/182 [22:19<14:37, 12.02s/it, training_loss=0.237]\u001b[A\n",
            "Epoch 8:  60%|██████    | 110/182 [22:19<14:17, 11.91s/it, training_loss=0.237]\u001b[A\n",
            "Epoch 8:  60%|██████    | 110/182 [22:31<14:17, 11.91s/it, training_loss=0.003]\u001b[A\n",
            "Epoch 8:  61%|██████    | 111/182 [22:31<14:21, 12.14s/it, training_loss=0.003]\u001b[A\n",
            "Epoch 8:  61%|██████    | 111/182 [22:44<14:21, 12.14s/it, training_loss=0.001]\u001b[A\n",
            "Epoch 8:  62%|██████▏   | 112/182 [22:44<14:22, 12.33s/it, training_loss=0.001]\u001b[A\n",
            "Epoch 8:  62%|██████▏   | 112/182 [22:56<14:22, 12.33s/it, training_loss=0.047]\u001b[A\n",
            "Epoch 8:  62%|██████▏   | 113/182 [22:56<13:59, 12.17s/it, training_loss=0.047]\u001b[A\n",
            "Epoch 8:  62%|██████▏   | 113/182 [23:07<13:59, 12.17s/it, training_loss=0.002]\u001b[A\n",
            "Epoch 8:  63%|██████▎   | 114/182 [23:07<13:27, 11.87s/it, training_loss=0.002]\u001b[A\n",
            "Epoch 8:  63%|██████▎   | 114/182 [23:20<13:27, 11.87s/it, training_loss=0.001]\u001b[A\n",
            "Epoch 8:  63%|██████▎   | 115/182 [23:20<13:29, 12.08s/it, training_loss=0.001]\u001b[A\n",
            "Epoch 8:  63%|██████▎   | 115/182 [23:32<13:29, 12.08s/it, training_loss=0.001]\u001b[A\n",
            "Epoch 8:  64%|██████▎   | 116/182 [23:32<13:29, 12.27s/it, training_loss=0.001]\u001b[A\n",
            "Epoch 8:  64%|██████▎   | 116/182 [23:45<13:29, 12.27s/it, training_loss=0.010]\u001b[A\n",
            "Epoch 8:  64%|██████▍   | 117/182 [23:45<13:16, 12.26s/it, training_loss=0.010]\u001b[A\n",
            "Epoch 8:  64%|██████▍   | 117/182 [23:55<13:16, 12.26s/it, training_loss=0.002]\u001b[A\n",
            "Epoch 8:  65%|██████▍   | 118/182 [23:55<12:35, 11.80s/it, training_loss=0.002]\u001b[A\n",
            "Epoch 8:  65%|██████▍   | 118/182 [24:08<12:35, 11.80s/it, training_loss=0.032]\u001b[A\n",
            "Epoch 8:  65%|██████▌   | 119/182 [24:08<12:40, 12.07s/it, training_loss=0.032]\u001b[A\n",
            "Epoch 8:  65%|██████▌   | 119/182 [24:21<12:40, 12.07s/it, training_loss=0.010]\u001b[A\n",
            "Epoch 8:  66%|██████▌   | 120/182 [24:21<12:43, 12.32s/it, training_loss=0.010]\u001b[A\n",
            "Epoch 8:  66%|██████▌   | 120/182 [24:36<12:43, 12.32s/it, training_loss=0.001]\u001b[A\n",
            "Epoch 8:  66%|██████▋   | 121/182 [24:36<13:12, 13.00s/it, training_loss=0.001]\u001b[A\n",
            "Epoch 8:  66%|██████▋   | 121/182 [24:47<13:12, 13.00s/it, training_loss=0.002]\u001b[A\n",
            "Epoch 8:  67%|██████▋   | 122/182 [24:47<12:39, 12.66s/it, training_loss=0.002]\u001b[A\n",
            "Epoch 8:  67%|██████▋   | 122/182 [24:58<12:39, 12.66s/it, training_loss=0.005]\u001b[A\n",
            "Epoch 8:  68%|██████▊   | 123/182 [24:59<11:57, 12.17s/it, training_loss=0.005]\u001b[A\n",
            "Epoch 8:  68%|██████▊   | 123/182 [25:11<11:57, 12.17s/it, training_loss=0.002]\u001b[A\n",
            "Epoch 8:  68%|██████▊   | 124/182 [25:11<11:54, 12.32s/it, training_loss=0.002]\u001b[A\n",
            "Epoch 8:  68%|██████▊   | 124/182 [25:24<11:54, 12.32s/it, training_loss=0.002]\u001b[A\n",
            "Epoch 8:  69%|██████▊   | 125/182 [25:24<11:48, 12.42s/it, training_loss=0.002]\u001b[A\n",
            "Epoch 8:  69%|██████▊   | 125/182 [25:36<11:48, 12.42s/it, training_loss=0.002]\u001b[A\n",
            "Epoch 8:  69%|██████▉   | 126/182 [25:36<11:33, 12.38s/it, training_loss=0.002]\u001b[A\n",
            "Epoch 8:  69%|██████▉   | 126/182 [25:47<11:33, 12.38s/it, training_loss=0.001]\u001b[A\n",
            "Epoch 8:  70%|██████▉   | 127/182 [25:47<10:53, 11.88s/it, training_loss=0.001]\u001b[A\n",
            "Epoch 8:  70%|██████▉   | 127/182 [25:59<10:53, 11.88s/it, training_loss=0.001]\u001b[A\n",
            "Epoch 8:  70%|███████   | 128/182 [25:59<10:54, 12.11s/it, training_loss=0.001]\u001b[A\n",
            "Epoch 8:  70%|███████   | 128/182 [26:12<10:54, 12.11s/it, training_loss=0.002]\u001b[A\n",
            "Epoch 8:  71%|███████   | 129/182 [26:12<10:51, 12.29s/it, training_loss=0.002]\u001b[A\n",
            "Epoch 8:  71%|███████   | 129/182 [26:25<10:51, 12.29s/it, training_loss=0.002]\u001b[A\n",
            "Epoch 8:  71%|███████▏  | 130/182 [26:25<10:42, 12.36s/it, training_loss=0.002]\u001b[A\n",
            "Epoch 8:  71%|███████▏  | 130/182 [26:35<10:42, 12.36s/it, training_loss=0.001]\u001b[A\n",
            "Epoch 8:  72%|███████▏  | 131/182 [26:35<10:02, 11.82s/it, training_loss=0.001]\u001b[A\n",
            "Epoch 8:  72%|███████▏  | 131/182 [26:47<10:02, 11.82s/it, training_loss=0.001]\u001b[A\n",
            "Epoch 8:  73%|███████▎  | 132/182 [26:48<09:57, 11.94s/it, training_loss=0.001]\u001b[A\n",
            "Epoch 8:  73%|███████▎  | 132/182 [27:00<09:57, 11.94s/it, training_loss=0.002]\u001b[A\n",
            "Epoch 8:  73%|███████▎  | 133/182 [27:00<09:56, 12.17s/it, training_loss=0.002]\u001b[A\n",
            "Epoch 8:  73%|███████▎  | 133/182 [27:13<09:56, 12.17s/it, training_loss=0.014]\u001b[A\n",
            "Epoch 8:  74%|███████▎  | 134/182 [27:13<09:50, 12.30s/it, training_loss=0.014]\u001b[A\n",
            "Epoch 8:  74%|███████▎  | 134/182 [27:23<09:50, 12.30s/it, training_loss=0.008]\u001b[A\n",
            "Epoch 8:  74%|███████▍  | 135/182 [27:23<09:14, 11.80s/it, training_loss=0.008]\u001b[A\n",
            "Epoch 8:  74%|███████▍  | 135/182 [27:35<09:14, 11.80s/it, training_loss=0.001]\u001b[A\n",
            "Epoch 8:  75%|███████▍  | 136/182 [27:36<09:06, 11.88s/it, training_loss=0.001]\u001b[A\n",
            "Epoch 8:  75%|███████▍  | 136/182 [27:48<09:06, 11.88s/it, training_loss=0.002]\u001b[A\n",
            "Epoch 8:  75%|███████▌  | 137/182 [27:48<09:05, 12.12s/it, training_loss=0.002]\u001b[A\n",
            "Epoch 8:  75%|███████▌  | 137/182 [28:01<09:05, 12.12s/it, training_loss=0.001]\u001b[A\n",
            "Epoch 8:  76%|███████▌  | 138/182 [28:01<09:00, 12.28s/it, training_loss=0.001]\u001b[A\n",
            "Epoch 8:  76%|███████▌  | 138/182 [28:12<09:00, 12.28s/it, training_loss=0.002]\u001b[A\n",
            "Epoch 8:  76%|███████▋  | 139/182 [28:12<08:33, 11.95s/it, training_loss=0.002]\u001b[A\n",
            "Epoch 8:  76%|███████▋  | 139/182 [28:24<08:33, 11.95s/it, training_loss=0.002]\u001b[A\n",
            "Epoch 8:  77%|███████▋  | 140/182 [28:24<08:17, 11.85s/it, training_loss=0.002]\u001b[A\n",
            "Epoch 8:  77%|███████▋  | 140/182 [28:36<08:17, 11.85s/it, training_loss=0.001]\u001b[A\n",
            "Epoch 8:  77%|███████▋  | 141/182 [28:36<08:15, 12.08s/it, training_loss=0.001]\u001b[A\n",
            "Epoch 8:  77%|███████▋  | 141/182 [28:49<08:15, 12.08s/it, training_loss=0.002]\u001b[A\n",
            "Epoch 8:  78%|███████▊  | 142/182 [28:49<08:10, 12.27s/it, training_loss=0.002]\u001b[A\n",
            "Epoch 8:  78%|███████▊  | 142/182 [29:00<08:10, 12.27s/it, training_loss=0.001]\u001b[A\n",
            "Epoch 8:  79%|███████▊  | 143/182 [29:00<07:49, 12.04s/it, training_loss=0.001]\u001b[A\n",
            "Epoch 8:  79%|███████▊  | 143/182 [29:12<07:49, 12.04s/it, training_loss=0.001]\u001b[A\n",
            "Epoch 8:  79%|███████▉  | 144/182 [29:12<07:28, 11.81s/it, training_loss=0.001]\u001b[A\n",
            "Epoch 8:  79%|███████▉  | 144/182 [29:24<07:28, 11.81s/it, training_loss=0.002]\u001b[A\n",
            "Epoch 8:  80%|███████▉  | 145/182 [29:24<07:26, 12.08s/it, training_loss=0.002]\u001b[A\n",
            "Epoch 8:  80%|███████▉  | 145/182 [29:39<07:26, 12.08s/it, training_loss=0.001]\u001b[A\n",
            "Epoch 8:  80%|████████  | 146/182 [29:39<07:45, 12.92s/it, training_loss=0.001]\u001b[A\n",
            "Epoch 8:  80%|████████  | 146/182 [29:52<07:45, 12.92s/it, training_loss=0.001]\u001b[A\n",
            "Epoch 8:  81%|████████  | 147/182 [29:52<07:28, 12.82s/it, training_loss=0.001]\u001b[A\n",
            "Epoch 8:  81%|████████  | 147/182 [30:03<07:28, 12.82s/it, training_loss=0.002]\u001b[A\n",
            "Epoch 8:  81%|████████▏ | 148/182 [30:03<06:54, 12.19s/it, training_loss=0.002]\u001b[A\n",
            "Epoch 8:  81%|████████▏ | 148/182 [30:15<06:54, 12.19s/it, training_loss=0.002]\u001b[A\n",
            "Epoch 8:  82%|████████▏ | 149/182 [30:15<06:41, 12.18s/it, training_loss=0.002]\u001b[A\n",
            "Epoch 8:  82%|████████▏ | 149/182 [30:27<06:41, 12.18s/it, training_loss=0.051]\u001b[A\n",
            "Epoch 8:  82%|████████▏ | 150/182 [30:27<06:34, 12.32s/it, training_loss=0.051]\u001b[A\n",
            "Epoch 8:  82%|████████▏ | 150/182 [30:40<06:34, 12.32s/it, training_loss=0.002]\u001b[A\n",
            "Epoch 8:  83%|████████▎ | 151/182 [30:40<06:25, 12.43s/it, training_loss=0.002]\u001b[A\n",
            "Epoch 8:  83%|████████▎ | 151/182 [30:51<06:25, 12.43s/it, training_loss=0.001]\u001b[A\n",
            "Epoch 8:  84%|████████▎ | 152/182 [30:51<05:59, 12.00s/it, training_loss=0.001]\u001b[A\n",
            "Epoch 8:  84%|████████▎ | 152/182 [31:03<05:59, 12.00s/it, training_loss=0.170]\u001b[A\n",
            "Epoch 8:  84%|████████▍ | 153/182 [31:03<05:46, 11.94s/it, training_loss=0.170]\u001b[A\n",
            "Epoch 8:  84%|████████▍ | 153/182 [31:16<05:46, 11.94s/it, training_loss=0.200]\u001b[A\n",
            "Epoch 8:  85%|████████▍ | 154/182 [31:16<05:40, 12.15s/it, training_loss=0.200]\u001b[A\n",
            "Epoch 8:  85%|████████▍ | 154/182 [31:28<05:40, 12.15s/it, training_loss=0.001]\u001b[A\n",
            "Epoch 8:  85%|████████▌ | 155/182 [31:28<05:32, 12.33s/it, training_loss=0.001]\u001b[A\n",
            "Epoch 8:  85%|████████▌ | 155/182 [31:40<05:32, 12.33s/it, training_loss=0.001]\u001b[A\n",
            "Epoch 8:  86%|████████▌ | 156/182 [31:40<05:13, 12.05s/it, training_loss=0.001]\u001b[A\n",
            "Epoch 8:  86%|████████▌ | 156/182 [31:51<05:13, 12.05s/it, training_loss=0.002]\u001b[A\n",
            "Epoch 8:  86%|████████▋ | 157/182 [31:51<04:55, 11.84s/it, training_loss=0.002]\u001b[A\n",
            "Epoch 8:  86%|████████▋ | 157/182 [32:04<04:55, 11.84s/it, training_loss=0.002]\u001b[A\n",
            "Epoch 8:  87%|████████▋ | 158/182 [32:04<04:50, 12.09s/it, training_loss=0.002]\u001b[A\n",
            "Epoch 8:  87%|████████▋ | 158/182 [32:16<04:50, 12.09s/it, training_loss=0.226]\u001b[A\n",
            "Epoch 8:  87%|████████▋ | 159/182 [32:16<04:42, 12.28s/it, training_loss=0.226]\u001b[A\n",
            "Epoch 8:  87%|████████▋ | 159/182 [32:28<04:42, 12.28s/it, training_loss=0.001]\u001b[A\n",
            "Epoch 8:  88%|████████▊ | 160/182 [32:28<04:27, 12.14s/it, training_loss=0.001]\u001b[A\n",
            "Epoch 8:  88%|████████▊ | 160/182 [32:39<04:27, 12.14s/it, training_loss=0.003]\u001b[A\n",
            "Epoch 8:  88%|████████▊ | 161/182 [32:39<04:08, 11.82s/it, training_loss=0.003]\u001b[A\n",
            "Epoch 8:  88%|████████▊ | 161/182 [32:52<04:08, 11.82s/it, training_loss=0.001]\u001b[A\n",
            "Epoch 8:  89%|████████▉ | 162/182 [32:52<04:01, 12.08s/it, training_loss=0.001]\u001b[A\n",
            "Epoch 8:  89%|████████▉ | 162/182 [33:05<04:01, 12.08s/it, training_loss=0.008]\u001b[A\n",
            "Epoch 8:  90%|████████▉ | 163/182 [33:05<03:53, 12.28s/it, training_loss=0.008]\u001b[A\n",
            "Epoch 8:  90%|████████▉ | 163/182 [33:17<03:53, 12.28s/it, training_loss=0.001]\u001b[A\n",
            "Epoch 8:  90%|█████████ | 164/182 [33:17<03:41, 12.32s/it, training_loss=0.001]\u001b[A\n",
            "Epoch 8:  90%|█████████ | 164/182 [33:28<03:41, 12.32s/it, training_loss=0.002]\u001b[A\n",
            "Epoch 8:  91%|█████████ | 165/182 [33:28<03:20, 11.82s/it, training_loss=0.002]\u001b[A\n",
            "Epoch 8:  91%|█████████ | 165/182 [33:40<03:20, 11.82s/it, training_loss=0.001]\u001b[A\n",
            "Epoch 8:  91%|█████████ | 166/182 [33:40<03:12, 12.06s/it, training_loss=0.001]\u001b[A\n",
            "Epoch 8:  91%|█████████ | 166/182 [33:53<03:12, 12.06s/it, training_loss=0.001]\u001b[A\n",
            "Epoch 8:  92%|█████████▏| 167/182 [33:53<03:03, 12.26s/it, training_loss=0.001]\u001b[A\n",
            "Epoch 8:  92%|█████████▏| 167/182 [34:06<03:03, 12.26s/it, training_loss=0.001]\u001b[A\n",
            "Epoch 8:  92%|█████████▏| 168/182 [34:06<02:53, 12.39s/it, training_loss=0.001]\u001b[A\n",
            "Epoch 8:  92%|█████████▏| 168/182 [34:17<02:53, 12.39s/it, training_loss=0.002]\u001b[A\n",
            "Epoch 8:  93%|█████████▎| 169/182 [34:17<02:34, 11.89s/it, training_loss=0.002]\u001b[A\n",
            "Epoch 8:  93%|█████████▎| 169/182 [34:29<02:34, 11.89s/it, training_loss=0.001]\u001b[A\n",
            "Epoch 8:  93%|█████████▎| 170/182 [34:29<02:24, 12.05s/it, training_loss=0.001]\u001b[A\n",
            "Epoch 8:  93%|█████████▎| 170/182 [34:44<02:24, 12.05s/it, training_loss=0.150]\u001b[A\n",
            "Epoch 8:  94%|█████████▍| 171/182 [34:44<02:23, 13.07s/it, training_loss=0.150]\u001b[A\n",
            "Epoch 8:  94%|█████████▍| 171/182 [34:57<02:23, 13.07s/it, training_loss=0.002]\u001b[A\n",
            "Epoch 8:  95%|█████████▍| 172/182 [34:57<02:09, 12.92s/it, training_loss=0.002]\u001b[A\n",
            "Epoch 8:  95%|█████████▍| 172/182 [35:08<02:09, 12.92s/it, training_loss=0.001]\u001b[A\n",
            "Epoch 8:  95%|█████████▌| 173/182 [35:08<01:49, 12.22s/it, training_loss=0.001]\u001b[A\n",
            "Epoch 8:  95%|█████████▌| 173/182 [35:20<01:49, 12.22s/it, training_loss=0.001]\u001b[A\n",
            "Epoch 8:  96%|█████████▌| 174/182 [35:20<01:38, 12.30s/it, training_loss=0.001]\u001b[A\n",
            "Epoch 8:  96%|█████████▌| 174/182 [35:33<01:38, 12.30s/it, training_loss=0.004]\u001b[A\n",
            "Epoch 8:  96%|█████████▌| 175/182 [35:33<01:26, 12.42s/it, training_loss=0.004]\u001b[A\n",
            "Epoch 8:  96%|█████████▌| 175/182 [35:45<01:26, 12.42s/it, training_loss=0.002]\u001b[A\n",
            "Epoch 8:  97%|█████████▋| 176/182 [35:45<01:14, 12.48s/it, training_loss=0.002]\u001b[A\n",
            "Epoch 8:  97%|█████████▋| 176/182 [35:56<01:14, 12.48s/it, training_loss=0.001]\u001b[A\n",
            "Epoch 8:  97%|█████████▋| 177/182 [35:56<00:59, 11.92s/it, training_loss=0.001]\u001b[A\n",
            "Epoch 8:  97%|█████████▋| 177/182 [36:08<00:59, 11.92s/it, training_loss=0.005]\u001b[A\n",
            "Epoch 8:  98%|█████████▊| 178/182 [36:08<00:48, 12.03s/it, training_loss=0.005]\u001b[A\n",
            "Epoch 8:  98%|█████████▊| 178/182 [36:21<00:48, 12.03s/it, training_loss=0.061]\u001b[A\n",
            "Epoch 8:  98%|█████████▊| 179/182 [36:21<00:36, 12.22s/it, training_loss=0.061]\u001b[A\n",
            "Epoch 8:  98%|█████████▊| 179/182 [36:34<00:36, 12.22s/it, training_loss=0.002]\u001b[A\n",
            "Epoch 8:  99%|█████████▉| 180/182 [36:34<00:24, 12.36s/it, training_loss=0.002]\u001b[A\n",
            "Epoch 8:  99%|█████████▉| 180/182 [36:45<00:24, 12.36s/it, training_loss=0.014]\u001b[A\n",
            "Epoch 8:  99%|█████████▉| 181/182 [36:45<00:11, 11.95s/it, training_loss=0.014]\u001b[A\n",
            "Epoch 8:  99%|█████████▉| 181/182 [36:48<00:11, 11.95s/it, training_loss=0.002]\u001b[A\n",
            "Epoch 8: 100%|██████████| 182/182 [36:48<00:00,  9.28s/it, training_loss=0.002]\u001b[A\n",
            " 88%|████████▊ | 7/8 [5:14:19<39:39, 2379.44s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            " Epoch {epoch}\n",
            "Training loss: {loss_train_avg}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "  0%|          | 0/46 [00:00<?, ?it/s]\u001b[A\n",
            "  2%|▏         | 1/46 [00:03<02:28,  3.30s/it]\u001b[A\n",
            "  4%|▍         | 2/46 [00:07<02:57,  4.04s/it]\u001b[A\n",
            "  7%|▋         | 3/46 [00:13<03:21,  4.69s/it]\u001b[A\n",
            "  9%|▊         | 4/46 [00:16<02:56,  4.20s/it]\u001b[A\n",
            " 11%|█         | 5/46 [00:20<02:38,  3.87s/it]\u001b[A\n",
            " 13%|█▎        | 6/46 [00:24<02:46,  4.15s/it]\u001b[A\n",
            " 15%|█▌        | 7/46 [00:28<02:41,  4.14s/it]\u001b[A\n",
            " 17%|█▋        | 8/46 [00:32<02:26,  3.86s/it]\u001b[A\n",
            " 20%|█▉        | 9/46 [00:35<02:15,  3.67s/it]\u001b[A\n",
            " 22%|██▏       | 10/46 [00:39<02:18,  3.84s/it]\u001b[A\n",
            " 24%|██▍       | 11/46 [00:44<02:22,  4.06s/it]\u001b[A\n",
            " 26%|██▌       | 12/46 [00:47<02:09,  3.82s/it]\u001b[A\n",
            " 28%|██▊       | 13/46 [00:50<02:00,  3.66s/it]\u001b[A\n",
            " 30%|███       | 14/46 [00:54<01:58,  3.72s/it]\u001b[A\n",
            " 33%|███▎      | 15/46 [00:59<02:06,  4.09s/it]\u001b[A\n",
            " 35%|███▍      | 16/46 [01:02<01:55,  3.85s/it]\u001b[A\n",
            " 37%|███▋      | 17/46 [01:06<01:46,  3.68s/it]\u001b[A\n",
            " 39%|███▉      | 18/46 [01:09<01:42,  3.65s/it]\u001b[A\n",
            " 41%|████▏     | 19/46 [01:15<01:52,  4.17s/it]\u001b[A\n",
            " 43%|████▎     | 20/46 [01:18<01:42,  3.92s/it]\u001b[A\n",
            " 46%|████▌     | 21/46 [01:21<01:33,  3.74s/it]\u001b[A\n",
            " 48%|████▊     | 22/46 [01:25<01:26,  3.60s/it]\u001b[A\n",
            " 50%|█████     | 23/46 [01:30<01:34,  4.09s/it]\u001b[A\n",
            " 52%|█████▏    | 24/46 [01:33<01:27,  3.96s/it]\u001b[A\n",
            " 54%|█████▍    | 25/46 [01:37<01:19,  3.77s/it]\u001b[A\n",
            " 57%|█████▋    | 26/46 [01:40<01:12,  3.64s/it]\u001b[A\n",
            " 59%|█████▊    | 27/46 [01:45<01:17,  4.07s/it]\u001b[A\n",
            " 61%|██████    | 28/46 [01:49<01:12,  4.01s/it]\u001b[A\n",
            " 63%|██████▎   | 29/46 [01:52<01:05,  3.83s/it]\u001b[A\n",
            " 65%|██████▌   | 30/46 [01:56<00:59,  3.70s/it]\u001b[A\n",
            " 67%|██████▋   | 31/46 [02:01<01:00,  4.04s/it]\u001b[A\n",
            " 70%|██████▉   | 32/46 [02:05<00:57,  4.08s/it]\u001b[A\n",
            " 72%|███████▏  | 33/46 [02:08<00:50,  3.85s/it]\u001b[A\n",
            " 74%|███████▍  | 34/46 [02:11<00:44,  3.69s/it]\u001b[A\n",
            " 76%|███████▌  | 35/46 [02:16<00:43,  3.99s/it]\u001b[A\n",
            " 78%|███████▊  | 36/46 [02:21<00:41,  4.18s/it]\u001b[A\n",
            " 80%|████████  | 37/46 [02:24<00:35,  3.94s/it]\u001b[A\n",
            " 83%|████████▎ | 38/46 [02:28<00:30,  3.79s/it]\u001b[A\n",
            " 85%|████████▍ | 39/46 [02:32<00:28,  4.00s/it]\u001b[A\n",
            " 87%|████████▋ | 40/46 [02:37<00:25,  4.20s/it]\u001b[A\n",
            " 89%|████████▉ | 41/46 [02:42<00:22,  4.44s/it]\u001b[A\n",
            " 91%|█████████▏| 42/46 [02:46<00:17,  4.38s/it]\u001b[A\n",
            " 93%|█████████▎| 43/46 [02:51<00:14,  4.70s/it]\u001b[A\n",
            " 96%|█████████▌| 44/46 [02:55<00:08,  4.36s/it]\u001b[A\n",
            " 98%|█████████▊| 45/46 [02:59<00:04,  4.10s/it]\u001b[A\n",
            "100%|██████████| 46/46 [03:00<00:00,  3.92s/it]\n",
            "100%|██████████| 8/8 [5:17:19<00:00, 2379.99s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy:112/128\n",
            " -> 0.875\n",
            "Accuracy:77/107\n",
            " -> 0.719626168224299\n",
            "Accuracy:109/128\n",
            " -> 0.8515625\n",
            "Validation loss: 0.8471860542397379\n",
            "F1 Score (weighted): 0.8206512342636693\n",
            "Accuracy Score: 0.8209366391184573\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        }
      ],
      "source": [
        "from tqdm import tqdm\n",
        "\n",
        "for epoch in tqdm(range(1, epochs+1)):\n",
        "    \n",
        "    model.train()\n",
        "    \n",
        "    loss_train_total = 0\n",
        "    \n",
        "    progress_bar = tqdm(dataloader_train, \n",
        "                        desc = 'Epoch {:1d}'.format(epoch), \n",
        "                        leave = False, \n",
        "                        disable = False)\n",
        "    \n",
        "    for batch in progress_bar:\n",
        "        \n",
        "        model.zero_grad() #set gradient to 0\n",
        "    \n",
        "        batch = tuple(b.to(device) for b in batch)\n",
        "        \n",
        "        inputs = {'input_ids': batch[0], \n",
        "                  'attention_mask': batch[1], \n",
        "                  'labels': batch[2]}\n",
        "        \n",
        "        outputs = model(**inputs) #unpack the dict straight into inputs\n",
        "        \n",
        "        loss = outputs[0]\n",
        "        loss_train_total += loss.item()\n",
        "        loss.backward()\n",
        "        \n",
        "        torch.nn.utils.clip_grad_norm_(model.parameters(), 1.0)\n",
        "        \n",
        "        optimizer.step()\n",
        "        scheduler.step()\n",
        "        progress_bar.set_postfix({'training_loss': '{:.3f}'.format(loss.item() / len(batch))})\n",
        "        \n",
        "    torch.save(model.state_dict(), f'/content/gdrive/MyDrive/NLP/BERT_ft_epoch{epoch}.model')\n",
        "    \n",
        "    tqdm.write('\\n Epoch {epoch}')\n",
        "    \n",
        "    loss_train_ave = loss_train_total / len(dataloader_train)\n",
        "    tqdm.write('Training loss: {loss_train_avg}')\n",
        "    \n",
        "    val_loss, predictions, true_vals = evaluate(dataloader_val)\n",
        "    true_vals.shape\n",
        "    accuracy = accuracy_per_class(predictions, true_vals)\n",
        "\n",
        "    val_f1 = f1_score_func(predictions, true_vals)\n",
        "    tqdm.write(f'Validation loss: {val_loss}')\n",
        "    tqdm.write(f'F1 Score (weighted): {val_f1}')\n",
        "    tqdm.write(f'Accuracy Score: {accuracy}')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 47,
      "metadata": {
        "id": "tPQEu0MvcrLJ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1109bf5f-a423-4e71-c794-e2f4aeb04723"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 46/46 [03:03<00:00,  3.98s/it]\n"
          ]
        }
      ],
      "source": [
        "_, predictions, true_vals = evaluate(dataloader_val)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 48,
      "metadata": {
        "id": "uAaDclgnspW3",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ecab33c8-14b9-4e98-cbd3-8532c94b0332"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy:0/128\n",
            " -> 0.0\n",
            "Accuracy:0/107\n",
            " -> 0.0\n",
            "Accuracy:128/128\n",
            " -> 1.0\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.3526170798898072"
            ]
          },
          "metadata": {},
          "execution_count": 48
        }
      ],
      "source": [
        "true_vals.shape\n",
        "accuracy_per_class(predictions, true_vals)"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "mount_file_id": "15LJzeGhGZBWboYjAF0vXgAnVMaYVClB5",
      "authorship_tag": "ABX9TyPnPL6ZQuxmOOqSZvU15pCf",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}