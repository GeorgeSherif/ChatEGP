{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "mount_file_id": "15LJzeGhGZBWboYjAF0vXgAnVMaYVClB5",
      "authorship_tag": "ABX9TyNn2YcXXf5OhEMuUAUirpSf",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/GeorgeSherif/ChatEGP/blob/main/Translate_Ar_En.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Installing & Importing the Necessary Libraries and Mounting the drive**"
      ],
      "metadata": {
        "id": "OAw4nlDbEZUQ"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 36,
      "metadata": {
        "id": "SDVJd_TDyswW",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4acfcad1-1bcc-4251-d836-e6cbfef5a6f1"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: transformers in /usr/local/lib/python3.10/dist-packages (4.28.1)\n",
            "Requirement already satisfied: sentencepiece in /usr/local/lib/python3.10/dist-packages (0.1.98)\n",
            "Requirement already satisfied: nltk in /usr/local/lib/python3.10/dist-packages (3.8.1)\n",
            "Requirement already satisfied: protobuf in /usr/local/lib/python3.10/dist-packages (3.20.3)\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.10/dist-packages (2.0.0+cu118)\n",
            "Requirement already satisfied: pygal in /usr/local/lib/python3.10/dist-packages (3.0.0)\n",
            "Requirement already satisfied: simpletransformers in /usr/local/lib/python3.10/dist-packages (0.63.11)\n",
            "Requirement already satisfied: torchvision in /usr/local/lib/python3.10/dist-packages (0.15.1+cu118)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (2022.10.31)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from transformers) (23.1)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.10/dist-packages (from transformers) (4.65.0)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (6.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from transformers) (3.12.0)\n",
            "Requirement already satisfied: tokenizers!=0.11.3,<0.14,>=0.11.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.13.3)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (1.22.4)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.11.0 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.14.1)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from transformers) (2.27.1)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.10/dist-packages (from nltk) (8.1.3)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.10/dist-packages (from nltk) (1.2.0)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch) (3.1)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch) (1.11.1)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.10/dist-packages (from torch) (4.5.0)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch) (3.1.2)\n",
            "Requirement already satisfied: triton==2.0.0 in /usr/local/lib/python3.10/dist-packages (from torch) (2.0.0)\n",
            "Requirement already satisfied: lit in /usr/local/lib/python3.10/dist-packages (from triton==2.0.0->torch) (16.0.2)\n",
            "Requirement already satisfied: cmake in /usr/local/lib/python3.10/dist-packages (from triton==2.0.0->torch) (3.25.2)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.10/dist-packages (from simpletransformers) (1.10.1)\n",
            "Requirement already satisfied: tensorboard in /usr/local/lib/python3.10/dist-packages (from simpletransformers) (2.12.2)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.10/dist-packages (from simpletransformers) (1.2.2)\n",
            "Requirement already satisfied: wandb>=0.10.32 in /usr/local/lib/python3.10/dist-packages (from simpletransformers) (0.15.0)\n",
            "Requirement already satisfied: seqeval in /usr/local/lib/python3.10/dist-packages (from simpletransformers) (1.2.2)\n",
            "Requirement already satisfied: streamlit in /usr/local/lib/python3.10/dist-packages (from simpletransformers) (1.22.0)\n",
            "Requirement already satisfied: datasets in /usr/local/lib/python3.10/dist-packages (from simpletransformers) (2.12.0)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.10/dist-packages (from simpletransformers) (1.5.3)\n",
            "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in /usr/local/lib/python3.10/dist-packages (from torchvision) (8.4.0)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.11.0->transformers) (2023.4.0)\n",
            "Requirement already satisfied: GitPython!=3.1.29,>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from wandb>=0.10.32->simpletransformers) (3.1.31)\n",
            "Requirement already satisfied: appdirs>=1.4.3 in /usr/local/lib/python3.10/dist-packages (from wandb>=0.10.32->simpletransformers) (1.4.4)\n",
            "Requirement already satisfied: sentry-sdk>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from wandb>=0.10.32->simpletransformers) (1.21.1)\n",
            "Requirement already satisfied: docker-pycreds>=0.4.0 in /usr/local/lib/python3.10/dist-packages (from wandb>=0.10.32->simpletransformers) (0.4.0)\n",
            "Requirement already satisfied: psutil>=5.0.0 in /usr/local/lib/python3.10/dist-packages (from wandb>=0.10.32->simpletransformers) (5.9.5)\n",
            "Requirement already satisfied: pathtools in /usr/local/lib/python3.10/dist-packages (from wandb>=0.10.32->simpletransformers) (0.1.2)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.10/dist-packages (from wandb>=0.10.32->simpletransformers) (67.7.2)\n",
            "Requirement already satisfied: setproctitle in /usr/local/lib/python3.10/dist-packages (from wandb>=0.10.32->simpletransformers) (1.3.2)\n",
            "Requirement already satisfied: charset-normalizer~=2.0.0 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2.0.12)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (3.4)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2022.12.7)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (1.26.15)\n",
            "Requirement already satisfied: aiohttp in /usr/local/lib/python3.10/dist-packages (from datasets->simpletransformers) (3.8.4)\n",
            "Requirement already satisfied: multiprocess in /usr/local/lib/python3.10/dist-packages (from datasets->simpletransformers) (0.70.14)\n",
            "Requirement already satisfied: pyarrow>=8.0.0 in /usr/local/lib/python3.10/dist-packages (from datasets->simpletransformers) (9.0.0)\n",
            "Requirement already satisfied: xxhash in /usr/local/lib/python3.10/dist-packages (from datasets->simpletransformers) (3.2.0)\n",
            "Requirement already satisfied: dill<0.3.7,>=0.3.0 in /usr/local/lib/python3.10/dist-packages (from datasets->simpletransformers) (0.3.6)\n",
            "Requirement already satisfied: responses<0.19 in /usr/local/lib/python3.10/dist-packages (from datasets->simpletransformers) (0.18.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch) (2.1.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas->simpletransformers) (2022.7.1)\n",
            "Requirement already satisfied: python-dateutil>=2.8.1 in /usr/local/lib/python3.10/dist-packages (from pandas->simpletransformers) (2.8.2)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn->simpletransformers) (3.1.0)\n",
            "Requirement already satisfied: altair<5,>=3.2.0 in /usr/local/lib/python3.10/dist-packages (from streamlit->simpletransformers) (4.2.2)\n",
            "Requirement already satisfied: validators>=0.2 in /usr/local/lib/python3.10/dist-packages (from streamlit->simpletransformers) (0.20.0)\n",
            "Requirement already satisfied: rich>=10.11.0 in /usr/local/lib/python3.10/dist-packages (from streamlit->simpletransformers) (13.3.4)\n",
            "Requirement already satisfied: blinker>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from streamlit->simpletransformers) (1.6.2)\n",
            "Requirement already satisfied: tzlocal>=1.1 in /usr/local/lib/python3.10/dist-packages (from streamlit->simpletransformers) (4.3)\n",
            "Requirement already satisfied: toml in /usr/local/lib/python3.10/dist-packages (from streamlit->simpletransformers) (0.10.2)\n",
            "Requirement already satisfied: tornado>=6.0.3 in /usr/local/lib/python3.10/dist-packages (from streamlit->simpletransformers) (6.2)\n",
            "Requirement already satisfied: pympler>=0.9 in /usr/local/lib/python3.10/dist-packages (from streamlit->simpletransformers) (1.0.1)\n",
            "Requirement already satisfied: tenacity<9,>=8.0.0 in /usr/local/lib/python3.10/dist-packages (from streamlit->simpletransformers) (8.2.2)\n",
            "Requirement already satisfied: cachetools>=4.0 in /usr/local/lib/python3.10/dist-packages (from streamlit->simpletransformers) (5.3.0)\n",
            "Requirement already satisfied: watchdog in /usr/local/lib/python3.10/dist-packages (from streamlit->simpletransformers) (3.0.0)\n",
            "Requirement already satisfied: pydeck>=0.1.dev5 in /usr/local/lib/python3.10/dist-packages (from streamlit->simpletransformers) (0.8.1b0)\n",
            "Requirement already satisfied: importlib-metadata>=1.4 in /usr/local/lib/python3.10/dist-packages (from streamlit->simpletransformers) (6.6.0)\n",
            "Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->torch) (1.3.0)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.10/dist-packages (from tensorboard->simpletransformers) (3.4.3)\n",
            "Requirement already satisfied: wheel>=0.26 in /usr/local/lib/python3.10/dist-packages (from tensorboard->simpletransformers) (0.40.0)\n",
            "Requirement already satisfied: tensorboard-plugin-wit>=1.6.0 in /usr/local/lib/python3.10/dist-packages (from tensorboard->simpletransformers) (1.8.1)\n",
            "Requirement already satisfied: werkzeug>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from tensorboard->simpletransformers) (2.3.0)\n",
            "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in /usr/local/lib/python3.10/dist-packages (from tensorboard->simpletransformers) (0.7.0)\n",
            "Requirement already satisfied: grpcio>=1.48.2 in /usr/local/lib/python3.10/dist-packages (from tensorboard->simpletransformers) (1.54.0)\n",
            "Requirement already satisfied: google-auth<3,>=1.6.3 in /usr/local/lib/python3.10/dist-packages (from tensorboard->simpletransformers) (2.17.3)\n",
            "Requirement already satisfied: absl-py>=0.4 in /usr/local/lib/python3.10/dist-packages (from tensorboard->simpletransformers) (1.4.0)\n",
            "Requirement already satisfied: google-auth-oauthlib<1.1,>=0.5 in /usr/local/lib/python3.10/dist-packages (from tensorboard->simpletransformers) (1.0.0)\n",
            "Requirement already satisfied: entrypoints in /usr/local/lib/python3.10/dist-packages (from altair<5,>=3.2.0->streamlit->simpletransformers) (0.4)\n",
            "Requirement already satisfied: toolz in /usr/local/lib/python3.10/dist-packages (from altair<5,>=3.2.0->streamlit->simpletransformers) (0.12.0)\n",
            "Requirement already satisfied: jsonschema>=3.0 in /usr/local/lib/python3.10/dist-packages (from altair<5,>=3.2.0->streamlit->simpletransformers) (4.3.3)\n",
            "Requirement already satisfied: six>=1.4.0 in /usr/local/lib/python3.10/dist-packages (from docker-pycreds>=0.4.0->wandb>=0.10.32->simpletransformers) (1.16.0)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets->simpletransformers) (23.1.0)\n",
            "Requirement already satisfied: async-timeout<5.0,>=4.0.0a3 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets->simpletransformers) (4.0.2)\n",
            "Requirement already satisfied: yarl<2.0,>=1.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets->simpletransformers) (1.9.2)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets->simpletransformers) (1.3.3)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets->simpletransformers) (6.0.4)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets->simpletransformers) (1.3.1)\n",
            "Requirement already satisfied: gitdb<5,>=4.0.1 in /usr/local/lib/python3.10/dist-packages (from GitPython!=3.1.29,>=1.0.0->wandb>=0.10.32->simpletransformers) (4.0.10)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.10/dist-packages (from google-auth<3,>=1.6.3->tensorboard->simpletransformers) (4.9)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.10/dist-packages (from google-auth<3,>=1.6.3->tensorboard->simpletransformers) (0.3.0)\n",
            "Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.10/dist-packages (from google-auth-oauthlib<1.1,>=0.5->tensorboard->simpletransformers) (1.3.1)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.10/dist-packages (from importlib-metadata>=1.4->streamlit->simpletransformers) (3.15.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.10/dist-packages (from rich>=10.11.0->streamlit->simpletransformers) (2.14.0)\n",
            "Requirement already satisfied: markdown-it-py<3.0.0,>=2.2.0 in /usr/local/lib/python3.10/dist-packages (from rich>=10.11.0->streamlit->simpletransformers) (2.2.0)\n",
            "Requirement already satisfied: pytz-deprecation-shim in /usr/local/lib/python3.10/dist-packages (from tzlocal>=1.1->streamlit->simpletransformers) (0.1.0.post0)\n",
            "Requirement already satisfied: decorator>=3.4.0 in /usr/local/lib/python3.10/dist-packages (from validators>=0.2->streamlit->simpletransformers) (4.4.2)\n",
            "Requirement already satisfied: smmap<6,>=3.0.1 in /usr/local/lib/python3.10/dist-packages (from gitdb<5,>=4.0.1->GitPython!=3.1.29,>=1.0.0->wandb>=0.10.32->simpletransformers) (5.0.0)\n",
            "Requirement already satisfied: pyrsistent!=0.17.0,!=0.17.1,!=0.17.2,>=0.14.0 in /usr/local/lib/python3.10/dist-packages (from jsonschema>=3.0->altair<5,>=3.2.0->streamlit->simpletransformers) (0.19.3)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.10/dist-packages (from markdown-it-py<3.0.0,>=2.2.0->rich>=10.11.0->streamlit->simpletransformers) (0.1.2)\n",
            "Requirement already satisfied: pyasn1<0.6.0,>=0.4.6 in /usr/local/lib/python3.10/dist-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard->simpletransformers) (0.5.0)\n",
            "Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.10/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<1.1,>=0.5->tensorboard->simpletransformers) (3.2.2)\n",
            "Requirement already satisfied: tzdata in /usr/local/lib/python3.10/dist-packages (from pytz-deprecation-shim->tzlocal>=1.1->streamlit->simpletransformers) (2023.3)\n"
          ]
        }
      ],
      "source": [
        "!pip3 install transformers sentencepiece nltk protobuf torch pygal simpletransformers torchvision\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "from IPython.display import display # Allows the use of display() for DataFrames\n",
        "drive.mount('/content/gdrive')\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9UP_-BDdA37e",
        "outputId": "96958b81-3399-4d88-d478-c8a2d805fc1b"
      },
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/gdrive; to attempt to forcibly remount, call drive.mount(\"/content/gdrive\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from nltk.corpus import stopwords\n",
        "import os\n",
        "import warnings\n",
        "import csv\n",
        "from textblob import TextBlob\n",
        "import re\n",
        "from nltk.stem.isri import ISRIStemmer\n",
        "import nltk\n",
        "nltk.download('stopwords')\n",
        "nltk.download('punkt')\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt \n",
        "import plotly.express as px\n",
        "import plotly.graph_objects as go\n",
        "import pygal as py\n",
        "import matplotlib\n",
        "plt.rcParams[\"figure.figsize\"] = (8,5)\n",
        "matplotlib.rc('xtick', labelsize=7) \n",
        "matplotlib.rc('ytick', labelsize=7) \n",
        "from textblob import TextBlob\n",
        "\n",
        "import torch\n",
        "import torchvision\n",
        "\n",
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "\n",
        "warnings.filterwarnings(\"ignore\", category=FutureWarning)\n",
        "%matplotlib inline "
      ],
      "metadata": {
        "id": "8eiG5KriE7bY",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4d2fe24e-4078-4964-ceba-9f59837c4a24"
      },
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "if torch.cuda.is_available():\n",
        "    device = torch.device('cuda')\n",
        "else:\n",
        "    device = torch.device('cpu')"
      ],
      "metadata": {
        "id": "Ah5YDfy94Jqg"
      },
      "execution_count": 39,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Approach 1: Evaluate the English Model (BERT)**\n",
        "\n",
        "\n",
        "*   English Train Data\n",
        "*   Arabic Test Data\n",
        "*   Train with the English Dataset\n",
        "*   Translate the Arabic Dataset\n",
        "*   Evaluate Model\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "haDPqEitD7k7"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Load the English Dataset"
      ],
      "metadata": {
        "id": "PcdWNYwxG7b8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df = pd.read_csv('/content/gdrive/MyDrive/NLP/English Dataset.csv' ,engine=\"python\", encoding = \"ISO-8859-1\")\n",
        "df['Sentiment'] = df['Sentiment'].replace(['negative','neutral','positive'],[0,1,2])\n",
        "df"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 423
        },
        "id": "GHd4hXPPG6Rn",
        "outputId": "9bfe5054-9f6b-4815-9ba3-d5ad0b531324"
      },
      "execution_count": 40,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "      Sentiment                                           Sentence\n",
              "0             1  According to Gran , the company has no plans t...\n",
              "1             1  Technopolis plans to develop in stages an area...\n",
              "2             0  The international electronic industry company ...\n",
              "3             2  With the new production plant the company woul...\n",
              "4             2  According to the company 's updated strategy f...\n",
              "...         ...                                                ...\n",
              "4841          0  LONDON MarketWatch -- Share prices ended lower...\n",
              "4842          1  Rinkuskiai 's beer sales fell by 6.5 per cent ...\n",
              "4843          0  Operating profit fell to EUR 35.4 mn from EUR ...\n",
              "4844          0  Net sales of the Paper segment decreased to EU...\n",
              "4845          0  Sales in Finland decreased by 10.5 % in Januar...\n",
              "\n",
              "[4846 rows x 2 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-655ae1f0-1b1b-42f4-a93e-ff4d68d2a531\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Sentiment</th>\n",
              "      <th>Sentence</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1</td>\n",
              "      <td>According to Gran , the company has no plans t...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1</td>\n",
              "      <td>Technopolis plans to develop in stages an area...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0</td>\n",
              "      <td>The international electronic industry company ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>2</td>\n",
              "      <td>With the new production plant the company woul...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>2</td>\n",
              "      <td>According to the company 's updated strategy f...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4841</th>\n",
              "      <td>0</td>\n",
              "      <td>LONDON MarketWatch -- Share prices ended lower...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4842</th>\n",
              "      <td>1</td>\n",
              "      <td>Rinkuskiai 's beer sales fell by 6.5 per cent ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4843</th>\n",
              "      <td>0</td>\n",
              "      <td>Operating profit fell to EUR 35.4 mn from EUR ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4844</th>\n",
              "      <td>0</td>\n",
              "      <td>Net sales of the Paper segment decreased to EU...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4845</th>\n",
              "      <td>0</td>\n",
              "      <td>Sales in Finland decreased by 10.5 % in Januar...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>4846 rows × 2 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-655ae1f0-1b1b-42f4-a93e-ff4d68d2a531')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-655ae1f0-1b1b-42f4-a93e-ff4d68d2a531 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-655ae1f0-1b1b-42f4-a93e-ff4d68d2a531');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 40
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "sns.countplot(y=\"Sentiment\",data=df)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 478
        },
        "id": "r5E8aFGXG6Zl",
        "outputId": "52e4a910-1f6c-4b98-b234-3b34d3c6dcb0"
      },
      "execution_count": 41,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<Axes: xlabel='count', ylabel='Sentiment'>"
            ]
          },
          "metadata": {},
          "execution_count": 41
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 800x500 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df.drop_duplicates(subset=['Sentence'],keep='first',inplace=True)\n",
        "df"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 423
        },
        "id": "yIn3Q46wlVV6",
        "outputId": "8fbdfe1a-c74d-4710-f466-f3e7c273ac80"
      },
      "execution_count": 42,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "      Sentiment                                           Sentence\n",
              "0             1  According to Gran , the company has no plans t...\n",
              "1             1  Technopolis plans to develop in stages an area...\n",
              "2             0  The international electronic industry company ...\n",
              "3             2  With the new production plant the company woul...\n",
              "4             2  According to the company 's updated strategy f...\n",
              "...         ...                                                ...\n",
              "4841          0  LONDON MarketWatch -- Share prices ended lower...\n",
              "4842          1  Rinkuskiai 's beer sales fell by 6.5 per cent ...\n",
              "4843          0  Operating profit fell to EUR 35.4 mn from EUR ...\n",
              "4844          0  Net sales of the Paper segment decreased to EU...\n",
              "4845          0  Sales in Finland decreased by 10.5 % in Januar...\n",
              "\n",
              "[4838 rows x 2 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-3b6c671c-445b-4a1f-916d-07686b1dcd4e\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Sentiment</th>\n",
              "      <th>Sentence</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1</td>\n",
              "      <td>According to Gran , the company has no plans t...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1</td>\n",
              "      <td>Technopolis plans to develop in stages an area...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0</td>\n",
              "      <td>The international electronic industry company ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>2</td>\n",
              "      <td>With the new production plant the company woul...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>2</td>\n",
              "      <td>According to the company 's updated strategy f...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4841</th>\n",
              "      <td>0</td>\n",
              "      <td>LONDON MarketWatch -- Share prices ended lower...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4842</th>\n",
              "      <td>1</td>\n",
              "      <td>Rinkuskiai 's beer sales fell by 6.5 per cent ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4843</th>\n",
              "      <td>0</td>\n",
              "      <td>Operating profit fell to EUR 35.4 mn from EUR ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4844</th>\n",
              "      <td>0</td>\n",
              "      <td>Net sales of the Paper segment decreased to EU...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4845</th>\n",
              "      <td>0</td>\n",
              "      <td>Sales in Finland decreased by 10.5 % in Januar...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>4838 rows × 2 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-3b6c671c-445b-4a1f-916d-07686b1dcd4e')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-3b6c671c-445b-4a1f-916d-07686b1dcd4e button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-3b6c671c-445b-4a1f-916d-07686b1dcd4e');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 42
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Determinig the sentiment using TextBlob Polarity"
      ],
      "metadata": {
        "id": "WUgy1Tc6XqT3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def preprocess(ReviewText):\n",
        "    ReviewText = ReviewText.str.replace(\"(<br/>)\", \"\")\n",
        "    ReviewText = ReviewText.str.replace('(<a).*(>).*(</a>)', '')\n",
        "    ReviewText = ReviewText.str.replace('(&amp)', '')\n",
        "    ReviewText = ReviewText.str.replace('(&gt)', '')\n",
        "    ReviewText = ReviewText.str.replace('(&lt)', '')\n",
        "    ReviewText = ReviewText.str.replace('(\\xa0)', '')\n",
        "    ReviewText = ReviewText.str.replace(',', '')\n",
        "    ReviewText = ReviewText.str.replace('--', '')    \n",
        "    ReviewText = ReviewText.str.replace('`', '')    \n",
        "\n",
        "    return ReviewText\n",
        "df['Review Text'] = preprocess(df['Sentence'])\n",
        "\n",
        "df['polarity'] = df['Sentence'].map(lambda text: TextBlob(text).sentiment.polarity)\n",
        "df['sentence_len'] = df['Review Text'].astype(str).apply(len)\n",
        "df['word_count'] = df['Sentence'].apply(lambda x: len(str(x).split()))"
      ],
      "metadata": {
        "id": "-3ssMm1PG6bz"
      },
      "execution_count": 43,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df = df.drop([\"sentence_len\", \"Sentence\",\"word_count\",\"polarity\" ] , axis =1)\n"
      ],
      "metadata": {
        "id": "l6UVSjnUrJZ7"
      },
      "execution_count": 44,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Sentiment Analysis using BERT"
      ],
      "metadata": {
        "id": "u_LkJij6lsOf"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "X_features = df[\"Review Text\"]\n",
        "Y_features = df[\"Sentiment\"]\n",
        "X_train, X_val, y_train, y_val = train_test_split(df.index.values, df.Sentiment.values, test_size=0.2, random_state=42, shuffle=True)"
      ],
      "metadata": {
        "id": "7fS-iD5jlygM"
      },
      "execution_count": 45,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import BertTokenizer,BertForSequenceClassification\n",
        "\n",
        "tokenizer = BertTokenizer.from_pretrained(\"bert-base-uncased\")\n",
        "model = BertForSequenceClassification.from_pretrained('bert-base-uncased',\n",
        "                                                      num_labels = 3,\n",
        "                                                      id2label={0: 'negative', 1: 'neutral', 2: 'positive'},\n",
        "                                                      output_attentions = False,\n",
        "                                                      output_hidden_states = False).to(device)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NFqRzcKbntvM",
        "outputId": "b9d8f0c1-75d7-4809-f7d6-990e16df67da"
      },
      "execution_count": 46,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertForSequenceClassification: ['cls.predictions.transform.LayerNorm.weight', 'cls.predictions.bias', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.transform.dense.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.decoder.weight', 'cls.seq_relationship.bias', 'cls.seq_relationship.weight']\n",
            "- This IS expected if you are initializing BertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing BertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df['data_type'] = ['not_set'] * df.shape[0]\n",
        "\n",
        "df.loc[X_train, 'data_type'] = 'train'\n",
        "df.loc[X_val, 'data_type'] = 'val'\n",
        "\n",
        "#groupby count\n",
        "df.groupby([ 'Sentiment', 'data_type']).count()\n",
        "df = df.rename(columns={'Review Text': 'Sentence'})\n"
      ],
      "metadata": {
        "id": "XvfkG7kv0MX1"
      },
      "execution_count": 47,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#encode train set\n",
        "encoded_data_train = tokenizer.batch_encode_plus(df[df.data_type == 'train'].Sentence.values,\n",
        "                                                add_special_tokens = True,\n",
        "                                                return_attention_mask = True,\n",
        "                                                pad_to_max_length = True,\n",
        "                                                max_length = 80,\n",
        "                                                return_tensors = 'pt')\n",
        "                                                \n",
        "#encode validation set\n",
        "encoded_data_val = tokenizer.batch_encode_plus( df[df.data_type == 'val'].Sentence.values,\n",
        "                                                add_special_tokens = True,\n",
        "                                                return_attention_mask = True,\n",
        "                                                pad_to_max_length = True,\n",
        "                                                max_length = 80,\n",
        "                                                return_tensors = 'pt')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_t00AHGuvgAo",
        "outputId": "5c43fae8-79cd-4d01-822d-05a75828b656"
      },
      "execution_count": 48,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#train set\n",
        "input_ids_train = encoded_data_train['input_ids']\n",
        "attention_masks_train = encoded_data_train['attention_mask']\n",
        "labels_train = torch.tensor(df[df.data_type == 'train'].Sentiment.values)\n",
        "\n",
        "#validation set\n",
        "input_ids_val = encoded_data_val['input_ids']\n",
        "attention_masks_val = encoded_data_val['attention_mask']\n",
        "labels_val = torch.tensor(df[df.data_type == 'val'].Sentiment.values)\n",
        "     "
      ],
      "metadata": {
        "id": "-J5twuCRxA7O"
      },
      "execution_count": 49,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from torch.utils.data import TensorDataset\n",
        "\n",
        "#train set\n",
        "dataset_train = TensorDataset(input_ids_train, \n",
        "                              attention_masks_train,\n",
        "                              labels_train)\n",
        "\n",
        "#validation set\n",
        "dataset_val = TensorDataset(input_ids_val, \n",
        "                             attention_masks_val, \n",
        "                             labels_val)"
      ],
      "metadata": {
        "id": "joRW8_E34QX3"
      },
      "execution_count": 50,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from torch.utils.data import DataLoader, RandomSampler, SequentialSampler\n",
        "\n",
        "batch_size = 8\n",
        "\n",
        "#train set\n",
        "dataloader_train = DataLoader(dataset_train,\n",
        "                              sampler = RandomSampler(dataset_train),\n",
        "                              batch_size = batch_size)\n",
        "\n",
        "#validation set\n",
        "dataloader_val = DataLoader(dataset_val,\n",
        "                              sampler = RandomSampler(dataset_val),\n",
        "                              batch_size = 8) #since we don't have to do backpropagation for this step"
      ],
      "metadata": {
        "id": "kue1cFIC4QaZ"
      },
      "execution_count": 51,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import AdamW, get_linear_schedule_with_warmup\n",
        "\n",
        "optimizer = AdamW(model.parameters(),\n",
        "                 lr = 1e-5,\n",
        "                 eps = 1e-7) #2e-5 > 5e-5\n",
        "                 \n",
        "epochs = 3\n",
        "\n",
        "scheduler = get_linear_schedule_with_warmup(optimizer,\n",
        "                                           num_warmup_steps = 0,\n",
        "                                           num_training_steps =len(dataloader_train)*epochs)\n"
      ],
      "metadata": {
        "id": "nfrQRiNf4Qc1"
      },
      "execution_count": 52,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def evaluate(dataloader_val):\n",
        "\n",
        "    #evaluation mode \n",
        "    model.eval()\n",
        "    \n",
        "    #tracking variables\n",
        "    loss_val_total = 0\n",
        "    predictions, true_vals = [], []\n",
        "    \n",
        "    for batch in tqdm(dataloader_val):\n",
        "        \n",
        "        #load into GPU\n",
        "        batch = tuple(b.to(device) for b in batch)\n",
        "        \n",
        "        #define inputs\n",
        "        inputs = {'input_ids':      batch[0],\n",
        "                  'attention_mask': batch[1],\n",
        "                  'labels':         batch[2]}\n",
        "\n",
        "        #compute logits\n",
        "        with torch.no_grad():        \n",
        "            outputs = model(**inputs)\n",
        "        \n",
        "        #compute loss\n",
        "        loss = outputs[0]\n",
        "        logits = outputs[1]\n",
        "        loss_val_total += loss.item()\n",
        "\n",
        "        #compute accuracy\n",
        "        logits = logits.detach().cpu().numpy()\n",
        "        label_ids = inputs['labels'].cpu().numpy()\n",
        "        predictions.append(logits)\n",
        "        true_vals.append(label_ids)\n",
        "    \n",
        "    #compute average loss\n",
        "    loss_val_avg = loss_val_total/len(dataloader_val) \n",
        "    \n",
        "    predictions = np.concatenate(predictions, axis=0)\n",
        "    true_vals = np.concatenate(true_vals, axis=0)\n",
        "            \n",
        "    return loss_val_avg, predictions, true_vals"
      ],
      "metadata": {
        "id": "_hTFuvA04Xg_"
      },
      "execution_count": 53,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import f1_score\n",
        "\n",
        "def f1_score_func(preds, labels):\n",
        "    preds_flat = np.argmax(preds, axis = 1).flatten()\n",
        "    labels_flat = labels.flatten()\n",
        "    return f1_score(labels_flat, preds_flat, average = 'weighted')"
      ],
      "metadata": {
        "id": "sIzdaLGr4ara"
      },
      "execution_count": 54,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#accuracy score\n",
        "def accuracy_per_class(preds, labels):\n",
        "    label_dict_inverse = {v: k for k, v in label_dict.items()}\n",
        "    \n",
        "    #make prediction\n",
        "    preds_flat = np.argmax(preds, axis=1).flatten()\n",
        "    labels_flat = labels.flatten()\n",
        "    \n",
        "    for label in np.unique(labels_flat):\n",
        "        y_preds = preds_flat[labels_flat==label]\n",
        "        y_true = labels_flat[labels_flat==label]\n",
        "        #print(f'Class: {label_dict_inverse[label]}')\n",
        "        print(f'Accuracy:{len(y_preds[y_preds==label])}/{len(y_true)}\\n -> {len(y_preds[y_preds==label]) / len(y_true)}')"
      ],
      "metadata": {
        "id": "Z9CCDzC14dMH"
      },
      "execution_count": 55,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import random\n",
        "\n",
        "seed_val = 17\n",
        "random.seed(seed_val)\n",
        "np.random.seed(seed_val)\n",
        "torch.manual_seed(seed_val)\n",
        "torch.cuda.manual_seed_all(seed_val)"
      ],
      "metadata": {
        "id": "OehAW6vX4e7B"
      },
      "execution_count": 56,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from tqdm import tqdm\n",
        "\n",
        "for epoch in tqdm(range(1, epochs+1)):\n",
        "    \n",
        "    model.train()\n",
        "    \n",
        "    loss_train_total = 0\n",
        "    \n",
        "    progress_bar = tqdm(dataloader_train, \n",
        "                        desc = 'Epoch {:1d}'.format(epoch), \n",
        "                        leave = False, \n",
        "                        disable = False)\n",
        "    \n",
        "    for batch in progress_bar:\n",
        "        \n",
        "        model.zero_grad() #set gradient to 0\n",
        "    \n",
        "        batch = tuple(b.to(device) for b in batch)\n",
        "        \n",
        "        inputs = {'input_ids': batch[0], \n",
        "                  'attention_mask': batch[1], \n",
        "                  'labels': batch[2]}\n",
        "        \n",
        "        outputs = model(**inputs) #unpack the dict straight into inputs\n",
        "        \n",
        "        loss = outputs[0]\n",
        "        loss_train_total += loss.item()\n",
        "        loss.backward()\n",
        "        \n",
        "        torch.nn.utils.clip_grad_norm_(model.parameters(), 1.0)\n",
        "        \n",
        "        optimizer.step()\n",
        "        scheduler.step()\n",
        "        progress_bar.set_postfix({'training_loss': '{:.3f}'.format(loss.item() / len(batch))})\n",
        "        \n",
        "    torch.save(model.state_dict(), f'/content/gdrive/MyDrive/NLP/BERT_ft_epoch{epoch}.model')\n",
        "    \n",
        "    tqdm.write('\\n Epoch {epoch}')\n",
        "    \n",
        "    loss_train_ave = loss_train_total / len(dataloader_train)\n",
        "    tqdm.write('Training loss: {loss_train_avg}')\n",
        "    \n",
        "    val_loss, predictions, true_vals = evaluate(dataloader_val)\n",
        "    val_f1 = f1_score_func(predictions, true_vals)\n",
        "    tqdm.write(f'Validation loss: {val_loss}')\n",
        "    tqdm.write(f'F1 Score (weighted): {val_f1}')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "d5EMKCDo4hmk",
        "outputId": "b3c3958f-da02-4464-896a-5a3cd75c56cd"
      },
      "execution_count": 57,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "  0%|          | 0/3 [00:00<?, ?it/s]\n",
            "Epoch 1:   0%|          | 0/484 [00:00<?, ?it/s]\u001b[A\n",
            "Epoch 1:   0%|          | 0/484 [00:16<?, ?it/s, training_loss=0.422]\u001b[A\n",
            "Epoch 1:   0%|          | 1/484 [00:16<2:13:58, 16.64s/it, training_loss=0.422]\u001b[A\n",
            "Epoch 1:   0%|          | 1/484 [00:33<2:13:58, 16.64s/it, training_loss=0.366]\u001b[A\n",
            "Epoch 1:   0%|          | 2/484 [00:33<2:13:09, 16.58s/it, training_loss=0.366]\u001b[A\n",
            "Epoch 1:   0%|          | 2/484 [00:49<2:13:09, 16.58s/it, training_loss=0.323]\u001b[A\n",
            "Epoch 1:   1%|          | 3/484 [00:49<2:11:19, 16.38s/it, training_loss=0.323]\u001b[A\n",
            "Epoch 1:   1%|          | 3/484 [01:09<2:11:19, 16.38s/it, training_loss=0.325]\u001b[A\n",
            "Epoch 1:   1%|          | 4/484 [01:09<2:23:30, 17.94s/it, training_loss=0.325]\u001b[A\n",
            "Epoch 1:   1%|          | 4/484 [01:30<2:23:30, 17.94s/it, training_loss=0.416]\u001b[A\n",
            "Epoch 1:   1%|          | 5/484 [01:30<2:31:41, 19.00s/it, training_loss=0.416]\u001b[A\n",
            "Epoch 1:   1%|          | 5/484 [01:46<2:31:41, 19.00s/it, training_loss=0.379]\u001b[A\n",
            "Epoch 1:   1%|          | 6/484 [01:46<2:23:54, 18.06s/it, training_loss=0.379]\u001b[A\n",
            "Epoch 1:   1%|          | 6/484 [02:01<2:23:54, 18.06s/it, training_loss=0.358]\u001b[A\n",
            "Epoch 1:   1%|▏         | 7/484 [02:01<2:14:59, 16.98s/it, training_loss=0.358]\u001b[A\n",
            "Epoch 1:   1%|▏         | 7/484 [02:08<2:14:59, 16.98s/it, training_loss=0.317]\u001b[A\n",
            "Epoch 1:   2%|▏         | 8/484 [02:08<1:48:16, 13.65s/it, training_loss=0.317]\u001b[A\n",
            "Epoch 1:   2%|▏         | 8/484 [02:18<1:48:16, 13.65s/it, training_loss=0.410]\u001b[A\n",
            "Epoch 1:   2%|▏         | 9/484 [02:18<1:40:29, 12.69s/it, training_loss=0.410]\u001b[A\n",
            "Epoch 1:   2%|▏         | 9/484 [02:25<1:40:29, 12.69s/it, training_loss=0.328]\u001b[A\n",
            "Epoch 1:   2%|▏         | 10/484 [02:25<1:25:39, 10.84s/it, training_loss=0.328]\u001b[A\n",
            "Epoch 1:   2%|▏         | 10/484 [02:33<1:25:39, 10.84s/it, training_loss=0.394]\u001b[A\n",
            "Epoch 1:   2%|▏         | 11/484 [02:33<1:19:59, 10.15s/it, training_loss=0.394]\u001b[A\n",
            "Epoch 1:   2%|▏         | 11/484 [02:47<1:19:59, 10.15s/it, training_loss=0.281]\u001b[A\n",
            "Epoch 1:   2%|▏         | 12/484 [02:47<1:27:25, 11.11s/it, training_loss=0.281]\u001b[A\n",
            "Epoch 1:   2%|▏         | 12/484 [02:58<1:27:25, 11.11s/it, training_loss=0.405]\u001b[A\n",
            "Epoch 1:   3%|▎         | 13/484 [02:58<1:26:32, 11.02s/it, training_loss=0.405]\u001b[A\n",
            "Epoch 1:   3%|▎         | 13/484 [03:06<1:26:32, 11.02s/it, training_loss=0.383]\u001b[A\n",
            "Epoch 1:   3%|▎         | 14/484 [03:06<1:20:28, 10.27s/it, training_loss=0.383]\u001b[A\n",
            "Epoch 1:   3%|▎         | 14/484 [03:16<1:20:28, 10.27s/it, training_loss=0.400]\u001b[A\n",
            "Epoch 1:   3%|▎         | 15/484 [03:16<1:20:22, 10.28s/it, training_loss=0.400]\u001b[A\n",
            "Epoch 1:   3%|▎         | 15/484 [03:23<1:20:22, 10.28s/it, training_loss=0.367]\u001b[A\n",
            "Epoch 1:   3%|▎         | 16/484 [03:23<1:11:51,  9.21s/it, training_loss=0.367]\u001b[A\n",
            "Epoch 1:   3%|▎         | 16/484 [03:31<1:11:51,  9.21s/it, training_loss=0.385]\u001b[A\n",
            "Epoch 1:   4%|▎         | 17/484 [03:31<1:09:20,  8.91s/it, training_loss=0.385]\u001b[A\n",
            "Epoch 1:   4%|▎         | 17/484 [03:39<1:09:20,  8.91s/it, training_loss=0.317]\u001b[A\n",
            "Epoch 1:   4%|▎         | 18/484 [03:39<1:06:43,  8.59s/it, training_loss=0.317]\u001b[A\n",
            "Epoch 1:   4%|▎         | 18/484 [03:46<1:06:43,  8.59s/it, training_loss=0.381]\u001b[A\n",
            "Epoch 1:   4%|▍         | 19/484 [03:46<1:02:25,  8.05s/it, training_loss=0.381]\u001b[A\n",
            "Epoch 1:   4%|▍         | 19/484 [03:55<1:02:25,  8.05s/it, training_loss=0.324]\u001b[A\n",
            "Epoch 1:   4%|▍         | 20/484 [03:55<1:05:00,  8.41s/it, training_loss=0.324]\u001b[A\n",
            "Epoch 1:   4%|▍         | 20/484 [04:03<1:05:00,  8.41s/it, training_loss=0.341]\u001b[A\n",
            "Epoch 1:   4%|▍         | 21/484 [04:03<1:03:33,  8.24s/it, training_loss=0.341]\u001b[A\n",
            "Epoch 1:   4%|▍         | 21/484 [04:13<1:03:33,  8.24s/it, training_loss=0.310]\u001b[A\n",
            "Epoch 1:   5%|▍         | 22/484 [04:13<1:06:46,  8.67s/it, training_loss=0.310]\u001b[A\n",
            "Epoch 1:   5%|▍         | 22/484 [04:19<1:06:46,  8.67s/it, training_loss=0.346]\u001b[A\n",
            "Epoch 1:   5%|▍         | 23/484 [04:19<1:01:51,  8.05s/it, training_loss=0.346]\u001b[A\n",
            "Epoch 1:   5%|▍         | 23/484 [04:29<1:01:51,  8.05s/it, training_loss=0.297]\u001b[A\n",
            "Epoch 1:   5%|▍         | 24/484 [04:29<1:04:37,  8.43s/it, training_loss=0.297]\u001b[A\n",
            "Epoch 1:   5%|▍         | 24/484 [04:35<1:04:37,  8.43s/it, training_loss=0.362]\u001b[A\n",
            "Epoch 1:   5%|▌         | 25/484 [04:36<1:00:52,  7.96s/it, training_loss=0.362]\u001b[A\n",
            "Epoch 1:   5%|▌         | 25/484 [04:43<1:00:52,  7.96s/it, training_loss=0.354]\u001b[A\n",
            "Epoch 1:   5%|▌         | 26/484 [04:43<1:00:35,  7.94s/it, training_loss=0.354]\u001b[A\n",
            "Epoch 1:   5%|▌         | 26/484 [04:51<1:00:35,  7.94s/it, training_loss=0.300]\u001b[A\n",
            "Epoch 1:   6%|▌         | 27/484 [04:51<1:00:45,  7.98s/it, training_loss=0.300]\u001b[A\n",
            "Epoch 1:   6%|▌         | 27/484 [04:59<1:00:45,  7.98s/it, training_loss=0.336]\u001b[A\n",
            "Epoch 1:   6%|▌         | 28/484 [04:59<1:00:31,  7.96s/it, training_loss=0.336]\u001b[A\n",
            "Epoch 1:   6%|▌         | 28/484 [05:08<1:00:31,  7.96s/it, training_loss=0.256]\u001b[A\n",
            "Epoch 1:   6%|▌         | 29/484 [05:08<1:02:41,  8.27s/it, training_loss=0.256]\u001b[A\n",
            "Epoch 1:   6%|▌         | 29/484 [05:15<1:02:41,  8.27s/it, training_loss=0.348]\u001b[A\n",
            "Epoch 1:   6%|▌         | 30/484 [05:15<58:43,  7.76s/it, training_loss=0.348]  \u001b[A\n",
            "Epoch 1:   6%|▌         | 30/484 [05:25<58:43,  7.76s/it, training_loss=0.360]\u001b[A\n",
            "Epoch 1:   6%|▋         | 31/484 [05:25<1:02:58,  8.34s/it, training_loss=0.360]\u001b[A\n",
            "Epoch 1:   6%|▋         | 31/484 [05:31<1:02:58,  8.34s/it, training_loss=0.353]\u001b[A\n",
            "Epoch 1:   7%|▋         | 32/484 [05:31<59:02,  7.84s/it, training_loss=0.353]  \u001b[A\n",
            "Epoch 1:   7%|▋         | 32/484 [05:40<59:02,  7.84s/it, training_loss=0.296]\u001b[A\n",
            "Epoch 1:   7%|▋         | 33/484 [05:40<1:01:19,  8.16s/it, training_loss=0.296]\u001b[A\n",
            "Epoch 1:   7%|▋         | 33/484 [05:49<1:01:19,  8.16s/it, training_loss=0.296]\u001b[A\n",
            "Epoch 1:   7%|▋         | 34/484 [05:49<1:02:05,  8.28s/it, training_loss=0.296]\u001b[A\n",
            "Epoch 1:   7%|▋         | 34/484 [05:57<1:02:05,  8.28s/it, training_loss=0.378]\u001b[A\n",
            "Epoch 1:   7%|▋         | 35/484 [05:57<1:02:16,  8.32s/it, training_loss=0.378]\u001b[A\n",
            "Epoch 1:   7%|▋         | 35/484 [06:05<1:02:16,  8.32s/it, training_loss=0.291]\u001b[A\n",
            "Epoch 1:   7%|▋         | 36/484 [06:05<1:00:57,  8.16s/it, training_loss=0.291]\u001b[A\n",
            "Epoch 1:   7%|▋         | 36/484 [06:13<1:00:57,  8.16s/it, training_loss=0.284]\u001b[A\n",
            "Epoch 1:   8%|▊         | 37/484 [06:13<1:00:18,  8.09s/it, training_loss=0.284]\u001b[A\n",
            "Epoch 1:   8%|▊         | 37/484 [06:22<1:00:18,  8.09s/it, training_loss=0.309]\u001b[A\n",
            "Epoch 1:   8%|▊         | 38/484 [06:22<1:02:16,  8.38s/it, training_loss=0.309]\u001b[A\n",
            "Epoch 1:   8%|▊         | 38/484 [06:29<1:02:16,  8.38s/it, training_loss=0.313]\u001b[A\n",
            "Epoch 1:   8%|▊         | 39/484 [06:29<58:19,  7.86s/it, training_loss=0.313]  \u001b[A\n",
            "Epoch 1:   8%|▊         | 39/484 [06:38<58:19,  7.86s/it, training_loss=0.291]\u001b[A\n",
            "Epoch 1:   8%|▊         | 40/484 [06:38<1:02:16,  8.42s/it, training_loss=0.291]\u001b[A\n",
            "Epoch 1:   8%|▊         | 40/484 [06:45<1:02:16,  8.42s/it, training_loss=0.324]\u001b[A\n",
            "Epoch 1:   8%|▊         | 41/484 [06:45<58:00,  7.86s/it, training_loss=0.324]  \u001b[A\n",
            "Epoch 1:   8%|▊         | 41/484 [06:54<58:00,  7.86s/it, training_loss=0.375]\u001b[A\n",
            "Epoch 1:   9%|▊         | 42/484 [06:54<1:00:51,  8.26s/it, training_loss=0.375]\u001b[A\n",
            "Epoch 1:   9%|▊         | 42/484 [07:01<1:00:51,  8.26s/it, training_loss=0.200]\u001b[A\n",
            "Epoch 1:   9%|▉         | 43/484 [07:01<57:48,  7.87s/it, training_loss=0.200]  \u001b[A\n",
            "Epoch 1:   9%|▉         | 43/484 [07:09<57:48,  7.87s/it, training_loss=0.267]\u001b[A\n",
            "Epoch 1:   9%|▉         | 44/484 [07:09<58:00,  7.91s/it, training_loss=0.267]\u001b[A\n",
            "Epoch 1:   9%|▉         | 44/484 [07:17<58:00,  7.91s/it, training_loss=0.330]\u001b[A\n",
            "Epoch 1:   9%|▉         | 45/484 [07:17<58:08,  7.95s/it, training_loss=0.330]\u001b[A\n",
            "Epoch 1:   9%|▉         | 45/484 [07:24<58:08,  7.95s/it, training_loss=0.313]\u001b[A\n",
            "Epoch 1:  10%|▉         | 46/484 [07:24<55:08,  7.55s/it, training_loss=0.313]\u001b[A\n",
            "Epoch 1:  10%|▉         | 46/484 [07:34<55:08,  7.55s/it, training_loss=0.264]\u001b[A\n",
            "Epoch 1:  10%|▉         | 47/484 [07:34<1:01:42,  8.47s/it, training_loss=0.264]\u001b[A\n",
            "Epoch 1:  10%|▉         | 47/484 [07:43<1:01:42,  8.47s/it, training_loss=0.289]\u001b[A\n",
            "Epoch 1:  10%|▉         | 48/484 [07:43<1:01:56,  8.52s/it, training_loss=0.289]\u001b[A\n",
            "Epoch 1:  10%|▉         | 48/484 [07:52<1:01:56,  8.52s/it, training_loss=0.362]\u001b[A\n",
            "Epoch 1:  10%|█         | 49/484 [07:52<1:03:07,  8.71s/it, training_loss=0.362]\u001b[A\n",
            "Epoch 1:  10%|█         | 49/484 [07:59<1:03:07,  8.71s/it, training_loss=0.334]\u001b[A\n",
            "Epoch 1:  10%|█         | 50/484 [07:59<58:22,  8.07s/it, training_loss=0.334]  \u001b[A\n",
            "Epoch 1:  10%|█         | 50/484 [08:08<58:22,  8.07s/it, training_loss=0.231]\u001b[A\n",
            "Epoch 1:  11%|█         | 51/484 [08:08<1:01:41,  8.55s/it, training_loss=0.231]\u001b[A\n",
            "Epoch 1:  11%|█         | 51/484 [08:15<1:01:41,  8.55s/it, training_loss=0.398]\u001b[A\n",
            "Epoch 1:  11%|█         | 52/484 [08:15<57:23,  7.97s/it, training_loss=0.398]  \u001b[A\n",
            "Epoch 1:  11%|█         | 52/484 [08:24<57:23,  7.97s/it, training_loss=0.334]\u001b[A\n",
            "Epoch 1:  11%|█         | 53/484 [08:24<58:44,  8.18s/it, training_loss=0.334]\u001b[A\n",
            "Epoch 1:  11%|█         | 53/484 [08:31<58:44,  8.18s/it, training_loss=0.279]\u001b[A\n",
            "Epoch 1:  11%|█         | 54/484 [08:31<57:13,  7.99s/it, training_loss=0.279]\u001b[A\n",
            "Epoch 1:  11%|█         | 54/484 [08:38<57:13,  7.99s/it, training_loss=0.233]\u001b[A\n",
            "Epoch 1:  11%|█▏        | 55/484 [08:38<55:27,  7.76s/it, training_loss=0.233]\u001b[A\n",
            "Epoch 1:  11%|█▏        | 55/484 [08:47<55:27,  7.76s/it, training_loss=0.217]\u001b[A\n",
            "Epoch 1:  12%|█▏        | 56/484 [08:47<57:32,  8.07s/it, training_loss=0.217]\u001b[A\n",
            "Epoch 1:  12%|█▏        | 56/484 [08:54<57:32,  8.07s/it, training_loss=0.378]\u001b[A\n",
            "Epoch 1:  12%|█▏        | 57/484 [08:54<54:12,  7.62s/it, training_loss=0.378]\u001b[A\n",
            "Epoch 1:  12%|█▏        | 57/484 [09:03<54:12,  7.62s/it, training_loss=0.335]\u001b[A\n",
            "Epoch 1:  12%|█▏        | 58/484 [09:03<58:28,  8.24s/it, training_loss=0.335]\u001b[A\n",
            "Epoch 1:  12%|█▏        | 58/484 [09:10<58:28,  8.24s/it, training_loss=0.308]\u001b[A\n",
            "Epoch 1:  12%|█▏        | 59/484 [09:10<54:51,  7.75s/it, training_loss=0.308]\u001b[A\n",
            "Epoch 1:  12%|█▏        | 59/484 [09:19<54:51,  7.75s/it, training_loss=0.427]\u001b[A\n",
            "Epoch 1:  12%|█▏        | 60/484 [09:19<57:05,  8.08s/it, training_loss=0.427]\u001b[A\n",
            "Epoch 1:  12%|█▏        | 60/484 [09:26<57:05,  8.08s/it, training_loss=0.288]\u001b[A\n",
            "Epoch 1:  13%|█▎        | 61/484 [09:26<55:18,  7.85s/it, training_loss=0.288]\u001b[A\n",
            "Epoch 1:  13%|█▎        | 61/484 [09:34<55:18,  7.85s/it, training_loss=0.290]\u001b[A\n",
            "Epoch 1:  13%|█▎        | 62/484 [09:34<54:31,  7.75s/it, training_loss=0.290]\u001b[A\n",
            "Epoch 1:  13%|█▎        | 62/484 [09:42<54:31,  7.75s/it, training_loss=0.336]\u001b[A\n",
            "Epoch 1:  13%|█▎        | 63/484 [09:42<56:04,  7.99s/it, training_loss=0.336]\u001b[A\n",
            "Epoch 1:  13%|█▎        | 63/484 [09:49<56:04,  7.99s/it, training_loss=0.259]\u001b[A\n",
            "Epoch 1:  13%|█▎        | 64/484 [09:49<53:02,  7.58s/it, training_loss=0.259]\u001b[A\n",
            "Epoch 1:  13%|█▎        | 64/484 [09:59<53:02,  7.58s/it, training_loss=0.429]\u001b[A\n",
            "Epoch 1:  13%|█▎        | 65/484 [09:59<57:20,  8.21s/it, training_loss=0.429]\u001b[A\n",
            "Epoch 1:  13%|█▎        | 65/484 [10:05<57:20,  8.21s/it, training_loss=0.225]\u001b[A\n",
            "Epoch 1:  14%|█▎        | 66/484 [10:05<53:47,  7.72s/it, training_loss=0.225]\u001b[A\n",
            "Epoch 1:  14%|█▎        | 66/484 [10:14<53:47,  7.72s/it, training_loss=0.397]\u001b[A\n",
            "Epoch 1:  14%|█▍        | 67/484 [10:14<56:50,  8.18s/it, training_loss=0.397]\u001b[A\n",
            "Epoch 1:  14%|█▍        | 67/484 [10:21<56:50,  8.18s/it, training_loss=0.261]\u001b[A\n",
            "Epoch 1:  14%|█▍        | 68/484 [10:21<54:05,  7.80s/it, training_loss=0.261]\u001b[A\n",
            "Epoch 1:  14%|█▍        | 68/484 [10:29<54:05,  7.80s/it, training_loss=0.256]\u001b[A\n",
            "Epoch 1:  14%|█▍        | 69/484 [10:29<54:00,  7.81s/it, training_loss=0.256]\u001b[A\n",
            "Epoch 1:  14%|█▍        | 69/484 [10:37<54:00,  7.81s/it, training_loss=0.273]\u001b[A\n",
            "Epoch 1:  14%|█▍        | 70/484 [10:37<54:34,  7.91s/it, training_loss=0.273]\u001b[A\n",
            "Epoch 1:  14%|█▍        | 70/484 [10:44<54:34,  7.91s/it, training_loss=0.353]\u001b[A\n",
            "Epoch 1:  15%|█▍        | 71/484 [10:44<51:55,  7.54s/it, training_loss=0.353]\u001b[A\n",
            "Epoch 1:  15%|█▍        | 71/484 [10:53<51:55,  7.54s/it, training_loss=0.247]\u001b[A\n",
            "Epoch 1:  15%|█▍        | 72/484 [10:53<55:43,  8.11s/it, training_loss=0.247]\u001b[A\n",
            "Epoch 1:  15%|█▍        | 72/484 [11:00<55:43,  8.11s/it, training_loss=0.269]\u001b[A\n",
            "Epoch 1:  15%|█▌        | 73/484 [11:00<52:21,  7.64s/it, training_loss=0.269]\u001b[A\n",
            "Epoch 1:  15%|█▌        | 73/484 [11:09<52:21,  7.64s/it, training_loss=0.235]\u001b[A\n",
            "Epoch 1:  15%|█▌        | 74/484 [11:09<55:48,  8.17s/it, training_loss=0.235]\u001b[A\n",
            "Epoch 1:  15%|█▌        | 74/484 [11:16<55:48,  8.17s/it, training_loss=0.279]\u001b[A\n",
            "Epoch 1:  15%|█▌        | 75/484 [11:16<52:45,  7.74s/it, training_loss=0.279]\u001b[A\n",
            "Epoch 1:  15%|█▌        | 75/484 [11:24<52:45,  7.74s/it, training_loss=0.216]\u001b[A\n",
            "Epoch 1:  16%|█▌        | 76/484 [11:24<53:13,  7.83s/it, training_loss=0.216]\u001b[A\n",
            "Epoch 1:  16%|█▌        | 76/484 [11:32<53:13,  7.83s/it, training_loss=0.236]\u001b[A\n",
            "Epoch 1:  16%|█▌        | 77/484 [11:32<53:19,  7.86s/it, training_loss=0.236]\u001b[A\n",
            "Epoch 1:  16%|█▌        | 77/484 [11:39<53:19,  7.86s/it, training_loss=0.152]\u001b[A\n",
            "Epoch 1:  16%|█▌        | 78/484 [11:39<50:59,  7.53s/it, training_loss=0.152]\u001b[A\n",
            "Epoch 1:  16%|█▌        | 78/484 [11:48<50:59,  7.53s/it, training_loss=0.189]\u001b[A\n",
            "Epoch 1:  16%|█▋        | 79/484 [11:48<54:29,  8.07s/it, training_loss=0.189]\u001b[A\n",
            "Epoch 1:  16%|█▋        | 79/484 [11:55<54:29,  8.07s/it, training_loss=0.177]\u001b[A\n",
            "Epoch 1:  17%|█▋        | 80/484 [11:55<51:25,  7.64s/it, training_loss=0.177]\u001b[A\n",
            "Epoch 1:  17%|█▋        | 80/484 [12:04<51:25,  7.64s/it, training_loss=0.285]\u001b[A\n",
            "Epoch 1:  17%|█▋        | 81/484 [12:04<55:11,  8.22s/it, training_loss=0.285]\u001b[A\n",
            "Epoch 1:  17%|█▋        | 81/484 [12:11<55:11,  8.22s/it, training_loss=0.251]\u001b[A\n",
            "Epoch 1:  17%|█▋        | 82/484 [12:11<52:22,  7.82s/it, training_loss=0.251]\u001b[A\n",
            "Epoch 1:  17%|█▋        | 82/484 [12:22<52:22,  7.82s/it, training_loss=0.167]\u001b[A\n",
            "Epoch 1:  17%|█▋        | 83/484 [12:22<58:27,  8.75s/it, training_loss=0.167]\u001b[A\n",
            "Epoch 1:  17%|█▋        | 83/484 [12:30<58:27,  8.75s/it, training_loss=0.289]\u001b[A\n",
            "Epoch 1:  17%|█▋        | 84/484 [12:30<56:45,  8.51s/it, training_loss=0.289]\u001b[A\n",
            "Epoch 1:  17%|█▋        | 84/484 [12:37<56:45,  8.51s/it, training_loss=0.258]\u001b[A\n",
            "Epoch 1:  18%|█▊        | 85/484 [12:37<53:09,  7.99s/it, training_loss=0.258]\u001b[A\n",
            "Epoch 1:  18%|█▊        | 85/484 [12:46<53:09,  7.99s/it, training_loss=0.207]\u001b[A\n",
            "Epoch 1:  18%|█▊        | 86/484 [12:46<55:34,  8.38s/it, training_loss=0.207]\u001b[A\n",
            "Epoch 1:  18%|█▊        | 86/484 [12:53<55:34,  8.38s/it, training_loss=0.138]\u001b[A\n",
            "Epoch 1:  18%|█▊        | 87/484 [12:53<52:00,  7.86s/it, training_loss=0.138]\u001b[A\n",
            "Epoch 1:  18%|█▊        | 87/484 [13:04<52:00,  7.86s/it, training_loss=0.186]\u001b[A\n",
            "Epoch 1:  18%|█▊        | 88/484 [13:04<57:33,  8.72s/it, training_loss=0.186]\u001b[A\n",
            "Epoch 1:  18%|█▊        | 88/484 [13:10<57:33,  8.72s/it, training_loss=0.167]\u001b[A\n",
            "Epoch 1:  18%|█▊        | 89/484 [13:10<53:14,  8.09s/it, training_loss=0.167]\u001b[A\n",
            "Epoch 1:  18%|█▊        | 89/484 [13:19<53:14,  8.09s/it, training_loss=0.258]\u001b[A\n",
            "Epoch 1:  19%|█▊        | 90/484 [13:19<53:55,  8.21s/it, training_loss=0.258]\u001b[A\n",
            "Epoch 1:  19%|█▊        | 90/484 [13:26<53:55,  8.21s/it, training_loss=0.072]\u001b[A\n",
            "Epoch 1:  19%|█▉        | 91/484 [13:26<52:26,  8.01s/it, training_loss=0.072]\u001b[A\n",
            "Epoch 1:  19%|█▉        | 91/484 [13:33<52:26,  8.01s/it, training_loss=0.389]\u001b[A\n",
            "Epoch 1:  19%|█▉        | 92/484 [13:33<50:34,  7.74s/it, training_loss=0.389]\u001b[A\n",
            "Epoch 1:  19%|█▉        | 92/484 [13:42<50:34,  7.74s/it, training_loss=0.392]\u001b[A\n",
            "Epoch 1:  19%|█▉        | 93/484 [13:42<52:50,  8.11s/it, training_loss=0.392]\u001b[A\n",
            "Epoch 1:  19%|█▉        | 93/484 [13:49<52:50,  8.11s/it, training_loss=0.154]\u001b[A\n",
            "Epoch 1:  19%|█▉        | 94/484 [13:49<49:47,  7.66s/it, training_loss=0.154]\u001b[A\n",
            "Epoch 1:  19%|█▉        | 94/484 [13:59<49:47,  7.66s/it, training_loss=0.379]\u001b[A\n",
            "Epoch 1:  20%|█▉        | 95/484 [13:59<53:33,  8.26s/it, training_loss=0.379]\u001b[A\n",
            "Epoch 1:  20%|█▉        | 95/484 [14:05<53:33,  8.26s/it, training_loss=0.254]\u001b[A\n",
            "Epoch 1:  20%|█▉        | 96/484 [14:05<50:17,  7.78s/it, training_loss=0.254]\u001b[A\n",
            "Epoch 1:  20%|█▉        | 96/484 [14:14<50:17,  7.78s/it, training_loss=0.274]\u001b[A\n",
            "Epoch 1:  20%|██        | 97/484 [14:14<52:19,  8.11s/it, training_loss=0.274]\u001b[A\n",
            "Epoch 1:  20%|██        | 97/484 [14:21<52:19,  8.11s/it, training_loss=0.166]\u001b[A\n",
            "Epoch 1:  20%|██        | 98/484 [14:21<50:35,  7.86s/it, training_loss=0.166]\u001b[A\n",
            "Epoch 1:  20%|██        | 98/484 [14:29<50:35,  7.86s/it, training_loss=0.230]\u001b[A\n",
            "Epoch 1:  20%|██        | 99/484 [14:29<49:36,  7.73s/it, training_loss=0.230]\u001b[A\n",
            "Epoch 1:  20%|██        | 99/484 [14:37<49:36,  7.73s/it, training_loss=0.264]\u001b[A\n",
            "Epoch 1:  21%|██        | 100/484 [14:37<51:10,  8.00s/it, training_loss=0.264]\u001b[A\n",
            "Epoch 1:  21%|██        | 100/484 [14:44<51:10,  8.00s/it, training_loss=0.169]\u001b[A\n",
            "Epoch 1:  21%|██        | 101/484 [14:44<48:17,  7.57s/it, training_loss=0.169]\u001b[A\n",
            "Epoch 1:  21%|██        | 101/484 [14:54<48:17,  7.57s/it, training_loss=0.372]\u001b[A\n",
            "Epoch 1:  21%|██        | 102/484 [14:54<52:09,  8.19s/it, training_loss=0.372]\u001b[A\n",
            "Epoch 1:  21%|██        | 102/484 [15:00<52:09,  8.19s/it, training_loss=0.299]\u001b[A\n",
            "Epoch 1:  21%|██▏       | 103/484 [15:00<48:49,  7.69s/it, training_loss=0.299]\u001b[A\n",
            "Epoch 1:  21%|██▏       | 103/484 [15:09<48:49,  7.69s/it, training_loss=0.146]\u001b[A\n",
            "Epoch 1:  21%|██▏       | 104/484 [15:09<51:23,  8.11s/it, training_loss=0.146]\u001b[A\n",
            "Epoch 1:  21%|██▏       | 104/484 [15:16<51:23,  8.11s/it, training_loss=0.309]\u001b[A\n",
            "Epoch 1:  22%|██▏       | 105/484 [15:16<49:15,  7.80s/it, training_loss=0.309]\u001b[A\n",
            "Epoch 1:  22%|██▏       | 105/484 [15:24<49:15,  7.80s/it, training_loss=0.270]\u001b[A\n",
            "Epoch 1:  22%|██▏       | 106/484 [15:24<48:50,  7.75s/it, training_loss=0.270]\u001b[A\n",
            "Epoch 1:  22%|██▏       | 106/484 [15:32<48:50,  7.75s/it, training_loss=0.274]\u001b[A\n",
            "Epoch 1:  22%|██▏       | 107/484 [15:32<49:45,  7.92s/it, training_loss=0.274]\u001b[A\n",
            "Epoch 1:  22%|██▏       | 107/484 [15:39<49:45,  7.92s/it, training_loss=0.210]\u001b[A\n",
            "Epoch 1:  22%|██▏       | 108/484 [15:39<47:20,  7.55s/it, training_loss=0.210]\u001b[A\n",
            "Epoch 1:  22%|██▏       | 108/484 [15:49<47:20,  7.55s/it, training_loss=0.286]\u001b[A\n",
            "Epoch 1:  23%|██▎       | 109/484 [15:49<51:03,  8.17s/it, training_loss=0.286]\u001b[A\n",
            "Epoch 1:  23%|██▎       | 109/484 [15:55<51:03,  8.17s/it, training_loss=0.241]\u001b[A\n",
            "Epoch 1:  23%|██▎       | 110/484 [15:55<47:54,  7.69s/it, training_loss=0.241]\u001b[A\n",
            "Epoch 1:  23%|██▎       | 110/484 [16:04<47:54,  7.69s/it, training_loss=0.154]\u001b[A\n",
            "Epoch 1:  23%|██▎       | 111/484 [16:04<50:38,  8.15s/it, training_loss=0.154]\u001b[A\n",
            "Epoch 1:  23%|██▎       | 111/484 [16:11<50:38,  8.15s/it, training_loss=0.205]\u001b[A\n",
            "Epoch 1:  23%|██▎       | 112/484 [16:11<48:19,  7.79s/it, training_loss=0.205]\u001b[A\n",
            "Epoch 1:  23%|██▎       | 112/484 [16:19<48:19,  7.79s/it, training_loss=0.403]\u001b[A\n",
            "Epoch 1:  23%|██▎       | 113/484 [16:19<48:15,  7.80s/it, training_loss=0.403]\u001b[A\n",
            "Epoch 1:  23%|██▎       | 113/484 [16:27<48:15,  7.80s/it, training_loss=0.217]\u001b[A\n",
            "Epoch 1:  24%|██▎       | 114/484 [16:27<48:50,  7.92s/it, training_loss=0.217]\u001b[A\n",
            "Epoch 1:  24%|██▎       | 114/484 [16:34<48:50,  7.92s/it, training_loss=0.382]\u001b[A\n",
            "Epoch 1:  24%|██▍       | 115/484 [16:34<46:27,  7.56s/it, training_loss=0.382]\u001b[A\n",
            "Epoch 1:  24%|██▍       | 115/484 [16:44<46:27,  7.56s/it, training_loss=0.182]\u001b[A\n",
            "Epoch 1:  24%|██▍       | 116/484 [16:44<49:55,  8.14s/it, training_loss=0.182]\u001b[A\n",
            "Epoch 1:  24%|██▍       | 116/484 [16:50<49:55,  8.14s/it, training_loss=0.197]\u001b[A\n",
            "Epoch 1:  24%|██▍       | 117/484 [16:50<47:06,  7.70s/it, training_loss=0.197]\u001b[A\n",
            "Epoch 1:  24%|██▍       | 117/484 [17:01<47:06,  7.70s/it, training_loss=0.140]\u001b[A\n",
            "Epoch 1:  24%|██▍       | 118/484 [17:01<52:54,  8.67s/it, training_loss=0.140]\u001b[A\n",
            "Epoch 1:  24%|██▍       | 118/484 [17:09<52:54,  8.67s/it, training_loss=0.380]\u001b[A\n",
            "Epoch 1:  25%|██▍       | 119/484 [17:09<51:58,  8.54s/it, training_loss=0.380]\u001b[A\n",
            "Epoch 1:  25%|██▍       | 119/484 [17:16<51:58,  8.54s/it, training_loss=0.225]\u001b[A\n",
            "Epoch 1:  25%|██▍       | 120/484 [17:16<48:21,  7.97s/it, training_loss=0.225]\u001b[A\n",
            "Epoch 1:  25%|██▍       | 120/484 [17:26<48:21,  7.97s/it, training_loss=0.134]\u001b[A\n",
            "Epoch 1:  25%|██▌       | 121/484 [17:26<52:11,  8.63s/it, training_loss=0.134]\u001b[A\n",
            "Epoch 1:  25%|██▌       | 121/484 [17:33<52:11,  8.63s/it, training_loss=0.241]\u001b[A\n",
            "Epoch 1:  25%|██▌       | 122/484 [17:33<48:18,  8.01s/it, training_loss=0.241]\u001b[A\n",
            "Epoch 1:  25%|██▌       | 122/484 [17:42<48:18,  8.01s/it, training_loss=0.393]\u001b[A\n",
            "Epoch 1:  25%|██▌       | 123/484 [17:42<50:43,  8.43s/it, training_loss=0.393]\u001b[A\n",
            "Epoch 1:  25%|██▌       | 123/484 [17:49<50:43,  8.43s/it, training_loss=0.166]\u001b[A\n",
            "Epoch 1:  26%|██▌       | 124/484 [17:49<47:45,  7.96s/it, training_loss=0.166]\u001b[A\n",
            "Epoch 1:  26%|██▌       | 124/484 [17:57<47:45,  7.96s/it, training_loss=0.207]\u001b[A\n",
            "Epoch 1:  26%|██▌       | 125/484 [17:57<47:49,  7.99s/it, training_loss=0.207]\u001b[A\n",
            "Epoch 1:  26%|██▌       | 125/484 [18:05<47:49,  7.99s/it, training_loss=0.195]\u001b[A\n",
            "Epoch 1:  26%|██▌       | 126/484 [18:05<47:32,  7.97s/it, training_loss=0.195]\u001b[A\n",
            "Epoch 1:  26%|██▌       | 126/484 [18:12<47:32,  7.97s/it, training_loss=0.198]\u001b[A\n",
            "Epoch 1:  26%|██▌       | 127/484 [18:12<45:16,  7.61s/it, training_loss=0.198]\u001b[A\n",
            "Epoch 1:  26%|██▌       | 127/484 [18:21<45:16,  7.61s/it, training_loss=0.136]\u001b[A\n",
            "Epoch 1:  26%|██▋       | 128/484 [18:21<48:19,  8.14s/it, training_loss=0.136]\u001b[A\n",
            "Epoch 1:  26%|██▋       | 128/484 [18:28<48:19,  8.14s/it, training_loss=0.237]\u001b[A\n",
            "Epoch 1:  27%|██▋       | 129/484 [18:28<45:19,  7.66s/it, training_loss=0.237]\u001b[A\n",
            "Epoch 1:  27%|██▋       | 129/484 [18:37<45:19,  7.66s/it, training_loss=0.169]\u001b[A\n",
            "Epoch 1:  27%|██▋       | 130/484 [18:37<48:28,  8.22s/it, training_loss=0.169]\u001b[A\n",
            "Epoch 1:  27%|██▋       | 130/484 [18:44<48:28,  8.22s/it, training_loss=0.217]\u001b[A\n",
            "Epoch 1:  27%|██▋       | 131/484 [18:44<45:38,  7.76s/it, training_loss=0.217]\u001b[A\n",
            "Epoch 1:  27%|██▋       | 131/484 [18:52<45:38,  7.76s/it, training_loss=0.198]\u001b[A\n",
            "Epoch 1:  27%|██▋       | 132/484 [18:52<46:40,  7.96s/it, training_loss=0.198]\u001b[A\n",
            "Epoch 1:  27%|██▋       | 132/484 [19:00<46:40,  7.96s/it, training_loss=0.292]\u001b[A\n",
            "Epoch 1:  27%|██▋       | 133/484 [19:00<46:03,  7.87s/it, training_loss=0.292]\u001b[A\n",
            "Epoch 1:  27%|██▋       | 133/484 [19:07<46:03,  7.87s/it, training_loss=0.234]\u001b[A\n",
            "Epoch 1:  28%|██▊       | 134/484 [19:07<44:21,  7.60s/it, training_loss=0.234]\u001b[A\n",
            "Epoch 1:  28%|██▊       | 134/484 [19:16<44:21,  7.60s/it, training_loss=0.242]\u001b[A\n",
            "Epoch 1:  28%|██▊       | 135/484 [19:16<46:48,  8.05s/it, training_loss=0.242]\u001b[A\n",
            "Epoch 1:  28%|██▊       | 135/484 [19:23<46:48,  8.05s/it, training_loss=0.275]\u001b[A\n",
            "Epoch 1:  28%|██▊       | 136/484 [19:23<44:12,  7.62s/it, training_loss=0.275]\u001b[A\n",
            "Epoch 1:  28%|██▊       | 136/484 [19:32<44:12,  7.62s/it, training_loss=0.245]\u001b[A\n",
            "Epoch 1:  28%|██▊       | 137/484 [19:32<47:40,  8.24s/it, training_loss=0.245]\u001b[A\n",
            "Epoch 1:  28%|██▊       | 137/484 [19:39<47:40,  8.24s/it, training_loss=0.194]\u001b[A\n",
            "Epoch 1:  29%|██▊       | 138/484 [19:39<44:42,  7.75s/it, training_loss=0.194]\u001b[A\n",
            "Epoch 1:  29%|██▊       | 138/484 [19:48<44:42,  7.75s/it, training_loss=0.147]\u001b[A\n",
            "Epoch 1:  29%|██▊       | 139/484 [19:48<46:29,  8.09s/it, training_loss=0.147]\u001b[A\n",
            "Epoch 1:  29%|██▊       | 139/484 [19:55<46:29,  8.09s/it, training_loss=0.359]\u001b[A\n",
            "Epoch 1:  29%|██▉       | 140/484 [19:55<45:00,  7.85s/it, training_loss=0.359]\u001b[A\n",
            "Epoch 1:  29%|██▉       | 140/484 [20:03<45:00,  7.85s/it, training_loss=0.197]\u001b[A\n",
            "Epoch 1:  29%|██▉       | 141/484 [20:03<44:07,  7.72s/it, training_loss=0.197]\u001b[A\n",
            "Epoch 1:  29%|██▉       | 141/484 [20:11<44:07,  7.72s/it, training_loss=0.175]\u001b[A\n",
            "Epoch 1:  29%|██▉       | 142/484 [20:11<45:25,  7.97s/it, training_loss=0.175]\u001b[A\n",
            "Epoch 1:  29%|██▉       | 142/484 [20:18<45:25,  7.97s/it, training_loss=0.294]\u001b[A\n",
            "Epoch 1:  30%|██▉       | 143/484 [20:18<42:53,  7.55s/it, training_loss=0.294]\u001b[A\n",
            "Epoch 1:  30%|██▉       | 143/484 [20:27<42:53,  7.55s/it, training_loss=0.225]\u001b[A\n",
            "Epoch 1:  30%|██▉       | 144/484 [20:27<46:27,  8.20s/it, training_loss=0.225]\u001b[A\n",
            "Epoch 1:  30%|██▉       | 144/484 [20:34<46:27,  8.20s/it, training_loss=0.146]\u001b[A\n",
            "Epoch 1:  30%|██▉       | 145/484 [20:34<43:36,  7.72s/it, training_loss=0.146]\u001b[A\n",
            "Epoch 1:  30%|██▉       | 145/484 [20:43<43:36,  7.72s/it, training_loss=0.171]\u001b[A\n",
            "Epoch 1:  30%|███       | 146/484 [20:43<45:38,  8.10s/it, training_loss=0.171]\u001b[A\n",
            "Epoch 1:  30%|███       | 146/484 [20:50<45:38,  8.10s/it, training_loss=0.201]\u001b[A\n",
            "Epoch 1:  30%|███       | 147/484 [20:50<43:55,  7.82s/it, training_loss=0.201]\u001b[A\n",
            "Epoch 1:  30%|███       | 147/484 [20:58<43:55,  7.82s/it, training_loss=0.260]\u001b[A\n",
            "Epoch 1:  31%|███       | 148/484 [20:58<43:25,  7.75s/it, training_loss=0.260]\u001b[A\n",
            "Epoch 1:  31%|███       | 148/484 [21:06<43:25,  7.75s/it, training_loss=0.156]\u001b[A\n",
            "Epoch 1:  31%|███       | 149/484 [21:06<44:19,  7.94s/it, training_loss=0.156]\u001b[A\n",
            "Epoch 1:  31%|███       | 149/484 [21:13<44:19,  7.94s/it, training_loss=0.492]\u001b[A\n",
            "Epoch 1:  31%|███       | 150/484 [21:13<42:01,  7.55s/it, training_loss=0.492]\u001b[A\n",
            "Epoch 1:  31%|███       | 150/484 [21:23<42:01,  7.55s/it, training_loss=0.196]\u001b[A\n",
            "Epoch 1:  31%|███       | 151/484 [21:23<45:27,  8.19s/it, training_loss=0.196]\u001b[A\n",
            "Epoch 1:  31%|███       | 151/484 [21:29<45:27,  8.19s/it, training_loss=0.236]\u001b[A\n",
            "Epoch 1:  31%|███▏      | 152/484 [21:29<42:39,  7.71s/it, training_loss=0.236]\u001b[A\n",
            "Epoch 1:  31%|███▏      | 152/484 [21:40<42:39,  7.71s/it, training_loss=0.216]\u001b[A\n",
            "Epoch 1:  32%|███▏      | 153/484 [21:40<47:01,  8.52s/it, training_loss=0.216]\u001b[A\n",
            "Epoch 1:  32%|███▏      | 153/484 [21:49<47:01,  8.52s/it, training_loss=0.240]\u001b[A\n",
            "Epoch 1:  32%|███▏      | 154/484 [21:49<47:45,  8.68s/it, training_loss=0.240]\u001b[A\n",
            "Epoch 1:  32%|███▏      | 154/484 [21:55<47:45,  8.68s/it, training_loss=0.242]\u001b[A\n",
            "Epoch 1:  32%|███▏      | 155/484 [21:55<44:22,  8.09s/it, training_loss=0.242]\u001b[A\n",
            "Epoch 1:  32%|███▏      | 155/484 [22:05<44:22,  8.09s/it, training_loss=0.116]\u001b[A\n",
            "Epoch 1:  32%|███▏      | 156/484 [22:05<46:50,  8.57s/it, training_loss=0.116]\u001b[A\n",
            "Epoch 1:  32%|███▏      | 156/484 [22:12<46:50,  8.57s/it, training_loss=0.260]\u001b[A\n",
            "Epoch 1:  32%|███▏      | 157/484 [22:12<43:32,  7.99s/it, training_loss=0.260]\u001b[A\n",
            "Epoch 1:  32%|███▏      | 157/484 [22:20<43:32,  7.99s/it, training_loss=0.245]\u001b[A\n",
            "Epoch 1:  33%|███▎      | 158/484 [22:20<44:38,  8.22s/it, training_loss=0.245]\u001b[A\n",
            "Epoch 1:  33%|███▎      | 158/484 [22:28<44:38,  8.22s/it, training_loss=0.220]\u001b[A\n",
            "Epoch 1:  33%|███▎      | 159/484 [22:28<43:19,  8.00s/it, training_loss=0.220]\u001b[A\n",
            "Epoch 1:  33%|███▎      | 159/484 [22:35<43:19,  8.00s/it, training_loss=0.142]\u001b[A\n",
            "Epoch 1:  33%|███▎      | 160/484 [22:35<42:02,  7.79s/it, training_loss=0.142]\u001b[A\n",
            "Epoch 1:  33%|███▎      | 160/484 [22:44<42:02,  7.79s/it, training_loss=0.255]\u001b[A\n",
            "Epoch 1:  33%|███▎      | 161/484 [22:44<43:26,  8.07s/it, training_loss=0.255]\u001b[A\n",
            "Epoch 1:  33%|███▎      | 161/484 [22:50<43:26,  8.07s/it, training_loss=0.200]\u001b[A\n",
            "Epoch 1:  33%|███▎      | 162/484 [22:50<40:52,  7.62s/it, training_loss=0.200]\u001b[A\n",
            "Epoch 1:  33%|███▎      | 162/484 [23:00<40:52,  7.62s/it, training_loss=0.353]\u001b[A\n",
            "Epoch 1:  34%|███▎      | 163/484 [23:00<44:04,  8.24s/it, training_loss=0.353]\u001b[A\n",
            "Epoch 1:  34%|███▎      | 163/484 [23:07<44:04,  8.24s/it, training_loss=0.158]\u001b[A\n",
            "Epoch 1:  34%|███▍      | 164/484 [23:07<41:17,  7.74s/it, training_loss=0.158]\u001b[A\n",
            "Epoch 1:  34%|███▍      | 164/484 [23:16<41:17,  7.74s/it, training_loss=0.153]\u001b[A\n",
            "Epoch 1:  34%|███▍      | 165/484 [23:16<43:05,  8.10s/it, training_loss=0.153]\u001b[A\n",
            "Epoch 1:  34%|███▍      | 165/484 [23:23<43:05,  8.10s/it, training_loss=0.167]\u001b[A\n",
            "Epoch 1:  34%|███▍      | 166/484 [23:23<41:34,  7.85s/it, training_loss=0.167]\u001b[A\n",
            "Epoch 1:  34%|███▍      | 166/484 [23:31<41:34,  7.85s/it, training_loss=0.253]\u001b[A\n",
            "Epoch 1:  35%|███▍      | 167/484 [23:31<41:04,  7.77s/it, training_loss=0.253]\u001b[A\n",
            "Epoch 1:  35%|███▍      | 167/484 [23:39<41:04,  7.77s/it, training_loss=0.281]\u001b[A\n",
            "Epoch 1:  35%|███▍      | 168/484 [23:39<41:58,  7.97s/it, training_loss=0.281]\u001b[A\n",
            "Epoch 1:  35%|███▍      | 168/484 [23:46<41:58,  7.97s/it, training_loss=0.240]\u001b[A\n",
            "Epoch 1:  35%|███▍      | 169/484 [23:46<39:43,  7.57s/it, training_loss=0.240]\u001b[A\n",
            "Epoch 1:  35%|███▍      | 169/484 [23:55<39:43,  7.57s/it, training_loss=0.159]\u001b[A\n",
            "Epoch 1:  35%|███▌      | 170/484 [23:55<42:55,  8.20s/it, training_loss=0.159]\u001b[A\n",
            "Epoch 1:  35%|███▌      | 170/484 [24:02<42:55,  8.20s/it, training_loss=0.245]\u001b[A\n",
            "Epoch 1:  35%|███▌      | 171/484 [24:02<40:16,  7.72s/it, training_loss=0.245]\u001b[A\n",
            "Epoch 1:  35%|███▌      | 171/484 [24:11<40:16,  7.72s/it, training_loss=0.208]\u001b[A\n",
            "Epoch 1:  36%|███▌      | 172/484 [24:11<42:36,  8.19s/it, training_loss=0.208]\u001b[A\n",
            "Epoch 1:  36%|███▌      | 172/484 [24:18<42:36,  8.19s/it, training_loss=0.199]\u001b[A\n",
            "Epoch 1:  36%|███▌      | 173/484 [24:18<40:32,  7.82s/it, training_loss=0.199]\u001b[A\n",
            "Epoch 1:  36%|███▌      | 173/484 [24:26<40:32,  7.82s/it, training_loss=0.366]\u001b[A\n",
            "Epoch 1:  36%|███▌      | 174/484 [24:26<40:43,  7.88s/it, training_loss=0.366]\u001b[A\n",
            "Epoch 1:  36%|███▌      | 174/484 [24:34<40:43,  7.88s/it, training_loss=0.202]\u001b[A\n",
            "Epoch 1:  36%|███▌      | 175/484 [24:34<40:59,  7.96s/it, training_loss=0.202]\u001b[A\n",
            "Epoch 1:  36%|███▌      | 175/484 [24:41<40:59,  7.96s/it, training_loss=0.164]\u001b[A\n",
            "Epoch 1:  36%|███▋      | 176/484 [24:41<38:59,  7.59s/it, training_loss=0.164]\u001b[A\n",
            "Epoch 1:  36%|███▋      | 176/484 [24:50<38:59,  7.59s/it, training_loss=0.260]\u001b[A\n",
            "Epoch 1:  37%|███▋      | 177/484 [24:51<41:47,  8.17s/it, training_loss=0.260]\u001b[A\n",
            "Epoch 1:  37%|███▋      | 177/484 [24:57<41:47,  8.17s/it, training_loss=0.232]\u001b[A\n",
            "Epoch 1:  37%|███▋      | 178/484 [24:57<39:15,  7.70s/it, training_loss=0.232]\u001b[A\n",
            "Epoch 1:  37%|███▋      | 178/484 [25:07<39:15,  7.70s/it, training_loss=0.124]\u001b[A\n",
            "Epoch 1:  37%|███▋      | 179/484 [25:07<41:47,  8.22s/it, training_loss=0.124]\u001b[A\n",
            "Epoch 1:  37%|███▋      | 179/484 [25:13<41:47,  8.22s/it, training_loss=0.150]\u001b[A\n",
            "Epoch 1:  37%|███▋      | 180/484 [25:13<39:26,  7.78s/it, training_loss=0.150]\u001b[A\n",
            "Epoch 1:  37%|███▋      | 180/484 [25:22<39:26,  7.78s/it, training_loss=0.136]\u001b[A\n",
            "Epoch 1:  37%|███▋      | 181/484 [25:22<39:57,  7.91s/it, training_loss=0.136]\u001b[A\n",
            "Epoch 1:  37%|███▋      | 181/484 [25:29<39:57,  7.91s/it, training_loss=0.258]\u001b[A\n",
            "Epoch 1:  38%|███▊      | 182/484 [25:29<39:40,  7.88s/it, training_loss=0.258]\u001b[A\n",
            "Epoch 1:  38%|███▊      | 182/484 [25:36<39:40,  7.88s/it, training_loss=0.254]\u001b[A\n",
            "Epoch 1:  38%|███▊      | 183/484 [25:36<37:58,  7.57s/it, training_loss=0.254]\u001b[A\n",
            "Epoch 1:  38%|███▊      | 183/484 [25:46<37:58,  7.57s/it, training_loss=0.130]\u001b[A\n",
            "Epoch 1:  38%|███▊      | 184/484 [25:46<40:34,  8.11s/it, training_loss=0.130]\u001b[A\n",
            "Epoch 1:  38%|███▊      | 184/484 [25:52<40:34,  8.11s/it, training_loss=0.165]\u001b[A\n",
            "Epoch 1:  38%|███▊      | 185/484 [25:52<38:17,  7.68s/it, training_loss=0.165]\u001b[A\n",
            "Epoch 1:  38%|███▊      | 185/484 [26:02<38:17,  7.68s/it, training_loss=0.210]\u001b[A\n",
            "Epoch 1:  38%|███▊      | 186/484 [26:02<41:09,  8.29s/it, training_loss=0.210]\u001b[A\n",
            "Epoch 1:  38%|███▊      | 186/484 [26:09<41:09,  8.29s/it, training_loss=0.097]\u001b[A\n",
            "Epoch 1:  39%|███▊      | 187/484 [26:09<38:35,  7.80s/it, training_loss=0.097]\u001b[A\n",
            "Epoch 1:  39%|███▊      | 187/484 [26:19<38:35,  7.80s/it, training_loss=0.132]\u001b[A\n",
            "Epoch 1:  39%|███▉      | 188/484 [26:19<42:04,  8.53s/it, training_loss=0.132]\u001b[A\n",
            "Epoch 1:  39%|███▉      | 188/484 [26:28<42:04,  8.53s/it, training_loss=0.268]\u001b[A\n",
            "Epoch 1:  39%|███▉      | 189/484 [26:28<43:04,  8.76s/it, training_loss=0.268]\u001b[A\n",
            "Epoch 1:  39%|███▉      | 189/484 [26:35<43:04,  8.76s/it, training_loss=0.172]\u001b[A\n",
            "Epoch 1:  39%|███▉      | 190/484 [26:35<39:44,  8.11s/it, training_loss=0.172]\u001b[A\n",
            "Epoch 1:  39%|███▉      | 190/484 [26:44<39:44,  8.11s/it, training_loss=0.173]\u001b[A\n",
            "Epoch 1:  39%|███▉      | 191/484 [26:44<41:53,  8.58s/it, training_loss=0.173]\u001b[A\n",
            "Epoch 1:  39%|███▉      | 191/484 [26:51<41:53,  8.58s/it, training_loss=0.181]\u001b[A\n",
            "Epoch 1:  40%|███▉      | 192/484 [26:51<38:54,  7.99s/it, training_loss=0.181]\u001b[A\n",
            "Epoch 1:  40%|███▉      | 192/484 [27:00<38:54,  7.99s/it, training_loss=0.180]\u001b[A\n",
            "Epoch 1:  40%|███▉      | 193/484 [27:00<39:50,  8.22s/it, training_loss=0.180]\u001b[A\n",
            "Epoch 1:  40%|███▉      | 193/484 [27:07<39:50,  8.22s/it, training_loss=0.222]\u001b[A\n",
            "Epoch 1:  40%|████      | 194/484 [27:07<38:43,  8.01s/it, training_loss=0.222]\u001b[A\n",
            "Epoch 1:  40%|████      | 194/484 [27:15<38:43,  8.01s/it, training_loss=0.179]\u001b[A\n",
            "Epoch 1:  40%|████      | 195/484 [27:15<37:28,  7.78s/it, training_loss=0.179]\u001b[A\n",
            "Epoch 1:  40%|████      | 195/484 [27:23<37:28,  7.78s/it, training_loss=0.229]\u001b[A\n",
            "Epoch 1:  40%|████      | 196/484 [27:23<38:55,  8.11s/it, training_loss=0.229]\u001b[A\n",
            "Epoch 1:  40%|████      | 196/484 [27:30<38:55,  8.11s/it, training_loss=0.211]\u001b[A\n",
            "Epoch 1:  41%|████      | 197/484 [27:30<36:46,  7.69s/it, training_loss=0.211]\u001b[A\n",
            "Epoch 1:  41%|████      | 197/484 [27:40<36:46,  7.69s/it, training_loss=0.123]\u001b[A\n",
            "Epoch 1:  41%|████      | 198/484 [27:40<39:37,  8.31s/it, training_loss=0.123]\u001b[A\n",
            "Epoch 1:  41%|████      | 198/484 [27:47<39:37,  8.31s/it, training_loss=0.207]\u001b[A\n",
            "Epoch 1:  41%|████      | 199/484 [27:47<37:07,  7.81s/it, training_loss=0.207]\u001b[A\n",
            "Epoch 1:  41%|████      | 199/484 [27:56<37:07,  7.81s/it, training_loss=0.167]\u001b[A\n",
            "Epoch 1:  41%|████▏     | 200/484 [27:56<38:53,  8.22s/it, training_loss=0.167]\u001b[A\n",
            "Epoch 1:  41%|████▏     | 200/484 [28:03<38:53,  8.22s/it, training_loss=0.140]\u001b[A\n",
            "Epoch 1:  42%|████▏     | 201/484 [28:03<37:08,  7.87s/it, training_loss=0.140]\u001b[A\n",
            "Epoch 1:  42%|████▏     | 201/484 [28:11<37:08,  7.87s/it, training_loss=0.298]\u001b[A\n",
            "Epoch 1:  42%|████▏     | 202/484 [28:11<36:48,  7.83s/it, training_loss=0.298]\u001b[A\n",
            "Epoch 1:  42%|████▏     | 202/484 [28:19<36:48,  7.83s/it, training_loss=0.202]\u001b[A\n",
            "Epoch 1:  42%|████▏     | 203/484 [28:19<37:20,  7.97s/it, training_loss=0.202]\u001b[A\n",
            "Epoch 1:  42%|████▏     | 203/484 [28:25<37:20,  7.97s/it, training_loss=0.364]\u001b[A\n",
            "Epoch 1:  42%|████▏     | 204/484 [28:25<35:22,  7.58s/it, training_loss=0.364]\u001b[A\n",
            "Epoch 1:  42%|████▏     | 204/484 [28:35<35:22,  7.58s/it, training_loss=0.129]\u001b[A\n",
            "Epoch 1:  42%|████▏     | 205/484 [28:35<38:08,  8.20s/it, training_loss=0.129]\u001b[A\n",
            "Epoch 1:  42%|████▏     | 205/484 [28:42<38:08,  8.20s/it, training_loss=0.212]\u001b[A\n",
            "Epoch 1:  43%|████▎     | 206/484 [28:42<35:45,  7.72s/it, training_loss=0.212]\u001b[A\n",
            "Epoch 1:  43%|████▎     | 206/484 [28:51<35:45,  7.72s/it, training_loss=0.143]\u001b[A\n",
            "Epoch 1:  43%|████▎     | 207/484 [28:51<37:51,  8.20s/it, training_loss=0.143]\u001b[A\n",
            "Epoch 1:  43%|████▎     | 207/484 [28:58<37:51,  8.20s/it, training_loss=0.157]\u001b[A\n",
            "Epoch 1:  43%|████▎     | 208/484 [28:58<35:57,  7.82s/it, training_loss=0.157]\u001b[A\n",
            "Epoch 1:  43%|████▎     | 208/484 [29:06<35:57,  7.82s/it, training_loss=0.154]\u001b[A\n",
            "Epoch 1:  43%|████▎     | 209/484 [29:06<36:06,  7.88s/it, training_loss=0.154]\u001b[A\n",
            "Epoch 1:  43%|████▎     | 209/484 [29:14<36:06,  7.88s/it, training_loss=0.155]\u001b[A\n",
            "Epoch 1:  43%|████▎     | 210/484 [29:14<36:18,  7.95s/it, training_loss=0.155]\u001b[A\n",
            "Epoch 1:  43%|████▎     | 210/484 [29:21<36:18,  7.95s/it, training_loss=0.140]\u001b[A\n",
            "Epoch 1:  44%|████▎     | 211/484 [29:21<34:27,  7.57s/it, training_loss=0.140]\u001b[A\n",
            "Epoch 1:  44%|████▎     | 211/484 [29:30<34:27,  7.57s/it, training_loss=0.253]\u001b[A\n",
            "Epoch 1:  44%|████▍     | 212/484 [29:30<36:57,  8.15s/it, training_loss=0.253]\u001b[A\n",
            "Epoch 1:  44%|████▍     | 212/484 [29:37<36:57,  8.15s/it, training_loss=0.238]\u001b[A\n",
            "Epoch 1:  44%|████▍     | 213/484 [29:37<34:51,  7.72s/it, training_loss=0.238]\u001b[A\n",
            "Epoch 1:  44%|████▍     | 213/484 [29:47<34:51,  7.72s/it, training_loss=0.155]\u001b[A\n",
            "Epoch 1:  44%|████▍     | 214/484 [29:47<37:08,  8.26s/it, training_loss=0.155]\u001b[A\n",
            "Epoch 1:  44%|████▍     | 214/484 [29:53<37:08,  8.26s/it, training_loss=0.146]\u001b[A\n",
            "Epoch 1:  44%|████▍     | 215/484 [29:53<34:55,  7.79s/it, training_loss=0.146]\u001b[A\n",
            "Epoch 1:  44%|████▍     | 215/484 [30:02<34:55,  7.79s/it, training_loss=0.314]\u001b[A\n",
            "Epoch 1:  45%|████▍     | 216/484 [30:02<35:31,  7.95s/it, training_loss=0.314]\u001b[A\n",
            "Epoch 1:  45%|████▍     | 216/484 [30:09<35:31,  7.95s/it, training_loss=0.155]\u001b[A\n",
            "Epoch 1:  45%|████▍     | 217/484 [30:09<35:15,  7.92s/it, training_loss=0.155]\u001b[A\n",
            "Epoch 1:  45%|████▍     | 217/484 [30:16<35:15,  7.92s/it, training_loss=0.121]\u001b[A\n",
            "Epoch 1:  45%|████▌     | 218/484 [30:16<33:47,  7.62s/it, training_loss=0.121]\u001b[A\n",
            "Epoch 1:  45%|████▌     | 218/484 [30:26<33:47,  7.62s/it, training_loss=0.072]\u001b[A\n",
            "Epoch 1:  45%|████▌     | 219/484 [30:26<35:44,  8.09s/it, training_loss=0.072]\u001b[A\n",
            "Epoch 1:  45%|████▌     | 219/484 [30:32<35:44,  8.09s/it, training_loss=0.184]\u001b[A\n",
            "Epoch 1:  45%|████▌     | 220/484 [30:32<33:47,  7.68s/it, training_loss=0.184]\u001b[A\n",
            "Epoch 1:  45%|████▌     | 220/484 [30:42<33:47,  7.68s/it, training_loss=0.186]\u001b[A\n",
            "Epoch 1:  46%|████▌     | 221/484 [30:42<36:18,  8.28s/it, training_loss=0.186]\u001b[A\n",
            "Epoch 1:  46%|████▌     | 221/484 [30:49<36:18,  8.28s/it, training_loss=0.269]\u001b[A\n",
            "Epoch 1:  46%|████▌     | 222/484 [30:49<33:57,  7.78s/it, training_loss=0.269]\u001b[A\n",
            "Epoch 1:  46%|████▌     | 222/484 [30:58<33:57,  7.78s/it, training_loss=0.166]\u001b[A\n",
            "Epoch 1:  46%|████▌     | 223/484 [30:58<35:47,  8.23s/it, training_loss=0.166]\u001b[A\n",
            "Epoch 1:  46%|████▌     | 223/484 [31:08<35:47,  8.23s/it, training_loss=0.147]\u001b[A\n",
            "Epoch 1:  46%|████▋     | 224/484 [31:08<38:00,  8.77s/it, training_loss=0.147]\u001b[A\n",
            "Epoch 1:  46%|████▋     | 224/484 [31:14<38:00,  8.77s/it, training_loss=0.125]\u001b[A\n",
            "Epoch 1:  46%|████▋     | 225/484 [31:14<35:02,  8.12s/it, training_loss=0.125]\u001b[A\n",
            "Epoch 1:  46%|████▋     | 225/484 [31:23<35:02,  8.12s/it, training_loss=0.182]\u001b[A\n",
            "Epoch 1:  47%|████▋     | 226/484 [31:23<36:07,  8.40s/it, training_loss=0.182]\u001b[A\n",
            "Epoch 1:  47%|████▋     | 226/484 [31:31<36:07,  8.40s/it, training_loss=0.120]\u001b[A\n",
            "Epoch 1:  47%|████▋     | 227/484 [31:31<34:22,  8.03s/it, training_loss=0.120]\u001b[A\n",
            "Epoch 1:  47%|████▋     | 227/484 [31:38<34:22,  8.03s/it, training_loss=0.205]\u001b[A\n",
            "Epoch 1:  47%|████▋     | 228/484 [31:38<34:01,  7.98s/it, training_loss=0.205]\u001b[A\n",
            "Epoch 1:  47%|████▋     | 228/484 [31:47<34:01,  7.98s/it, training_loss=0.152]\u001b[A\n",
            "Epoch 1:  47%|████▋     | 229/484 [31:47<34:18,  8.07s/it, training_loss=0.152]\u001b[A\n",
            "Epoch 1:  47%|████▋     | 229/484 [31:53<34:18,  8.07s/it, training_loss=0.184]\u001b[A\n",
            "Epoch 1:  48%|████▊     | 230/484 [31:53<32:19,  7.63s/it, training_loss=0.184]\u001b[A\n",
            "Epoch 1:  48%|████▊     | 230/484 [32:03<32:19,  7.63s/it, training_loss=0.171]\u001b[A\n",
            "Epoch 1:  48%|████▊     | 231/484 [32:03<34:41,  8.23s/it, training_loss=0.171]\u001b[A\n",
            "Epoch 1:  48%|████▊     | 231/484 [32:10<34:41,  8.23s/it, training_loss=0.190]\u001b[A\n",
            "Epoch 1:  48%|████▊     | 232/484 [32:10<32:31,  7.74s/it, training_loss=0.190]\u001b[A\n",
            "Epoch 1:  48%|████▊     | 232/484 [32:19<32:31,  7.74s/it, training_loss=0.147]\u001b[A\n",
            "Epoch 1:  48%|████▊     | 233/484 [32:19<34:19,  8.20s/it, training_loss=0.147]\u001b[A\n",
            "Epoch 1:  48%|████▊     | 233/484 [32:26<34:19,  8.20s/it, training_loss=0.120]\u001b[A\n",
            "Epoch 1:  48%|████▊     | 234/484 [32:26<32:29,  7.80s/it, training_loss=0.120]\u001b[A\n",
            "Epoch 1:  48%|████▊     | 234/484 [32:34<32:29,  7.80s/it, training_loss=0.192]\u001b[A\n",
            "Epoch 1:  49%|████▊     | 235/484 [32:34<32:36,  7.86s/it, training_loss=0.192]\u001b[A\n",
            "Epoch 1:  49%|████▊     | 235/484 [32:42<32:36,  7.86s/it, training_loss=0.180]\u001b[A\n",
            "Epoch 1:  49%|████▉     | 236/484 [32:42<32:39,  7.90s/it, training_loss=0.180]\u001b[A\n",
            "Epoch 1:  49%|████▉     | 236/484 [32:48<32:39,  7.90s/it, training_loss=0.111]\u001b[A\n",
            "Epoch 1:  49%|████▉     | 237/484 [32:48<31:05,  7.55s/it, training_loss=0.111]\u001b[A\n",
            "Epoch 1:  49%|████▉     | 237/484 [32:58<31:05,  7.55s/it, training_loss=0.174]\u001b[A\n",
            "Epoch 1:  49%|████▉     | 238/484 [32:58<33:14,  8.11s/it, training_loss=0.174]\u001b[A\n",
            "Epoch 1:  49%|████▉     | 238/484 [33:05<33:14,  8.11s/it, training_loss=0.281]\u001b[A\n",
            "Epoch 1:  49%|████▉     | 239/484 [33:05<31:17,  7.66s/it, training_loss=0.281]\u001b[A\n",
            "Epoch 1:  49%|████▉     | 239/484 [33:14<31:17,  7.66s/it, training_loss=0.118]\u001b[A\n",
            "Epoch 1:  50%|████▉     | 240/484 [33:14<33:23,  8.21s/it, training_loss=0.118]\u001b[A\n",
            "Epoch 1:  50%|████▉     | 240/484 [33:21<33:23,  8.21s/it, training_loss=0.242]\u001b[A\n",
            "Epoch 1:  50%|████▉     | 241/484 [33:21<31:27,  7.77s/it, training_loss=0.242]\u001b[A\n",
            "Epoch 1:  50%|████▉     | 241/484 [33:29<31:27,  7.77s/it, training_loss=0.206]\u001b[A\n",
            "Epoch 1:  50%|█████     | 242/484 [33:29<32:07,  7.97s/it, training_loss=0.206]\u001b[A\n",
            "Epoch 1:  50%|█████     | 242/484 [33:38<32:07,  7.97s/it, training_loss=0.173]\u001b[A\n",
            "Epoch 1:  50%|█████     | 243/484 [33:38<32:38,  8.13s/it, training_loss=0.173]\u001b[A\n",
            "Epoch 1:  50%|█████     | 243/484 [33:45<32:38,  8.13s/it, training_loss=0.069]\u001b[A\n",
            "Epoch 1:  50%|█████     | 244/484 [33:45<31:02,  7.76s/it, training_loss=0.069]\u001b[A\n",
            "Epoch 1:  50%|█████     | 244/484 [33:54<31:02,  7.76s/it, training_loss=0.092]\u001b[A\n",
            "Epoch 1:  51%|█████     | 245/484 [33:54<32:41,  8.21s/it, training_loss=0.092]\u001b[A\n",
            "Epoch 1:  51%|█████     | 245/484 [34:00<32:41,  8.21s/it, training_loss=0.128]\u001b[A\n",
            "Epoch 1:  51%|█████     | 246/484 [34:00<30:39,  7.73s/it, training_loss=0.128]\u001b[A\n",
            "Epoch 1:  51%|█████     | 246/484 [34:10<30:39,  7.73s/it, training_loss=0.249]\u001b[A\n",
            "Epoch 1:  51%|█████     | 247/484 [34:10<32:52,  8.32s/it, training_loss=0.249]\u001b[A\n",
            "Epoch 1:  51%|█████     | 247/484 [34:17<32:52,  8.32s/it, training_loss=0.159]\u001b[A\n",
            "Epoch 1:  51%|█████     | 248/484 [34:17<30:42,  7.81s/it, training_loss=0.159]\u001b[A\n",
            "Epoch 1:  51%|█████     | 248/484 [34:25<30:42,  7.81s/it, training_loss=0.286]\u001b[A\n",
            "Epoch 1:  51%|█████▏    | 249/484 [34:25<31:36,  8.07s/it, training_loss=0.286]\u001b[A\n",
            "Epoch 1:  51%|█████▏    | 249/484 [34:33<31:36,  8.07s/it, training_loss=0.323]\u001b[A\n",
            "Epoch 1:  52%|█████▏    | 250/484 [34:33<30:54,  7.92s/it, training_loss=0.323]\u001b[A\n",
            "Epoch 1:  52%|█████▏    | 250/484 [34:40<30:54,  7.92s/it, training_loss=0.103]\u001b[A\n",
            "Epoch 1:  52%|█████▏    | 251/484 [34:40<29:51,  7.69s/it, training_loss=0.103]\u001b[A\n",
            "Epoch 1:  52%|█████▏    | 251/484 [34:49<29:51,  7.69s/it, training_loss=0.067]\u001b[A\n",
            "Epoch 1:  52%|█████▏    | 252/484 [34:49<31:07,  8.05s/it, training_loss=0.067]\u001b[A\n",
            "Epoch 1:  52%|█████▏    | 252/484 [34:56<31:07,  8.05s/it, training_loss=0.045]\u001b[A\n",
            "Epoch 1:  52%|█████▏    | 253/484 [34:56<29:13,  7.59s/it, training_loss=0.045]\u001b[A\n",
            "Epoch 1:  52%|█████▏    | 253/484 [35:05<29:13,  7.59s/it, training_loss=0.052]\u001b[A\n",
            "Epoch 1:  52%|█████▏    | 254/484 [35:05<31:27,  8.21s/it, training_loss=0.052]\u001b[A\n",
            "Epoch 1:  52%|█████▏    | 254/484 [35:12<31:27,  8.21s/it, training_loss=0.206]\u001b[A\n",
            "Epoch 1:  53%|█████▎    | 255/484 [35:12<29:29,  7.73s/it, training_loss=0.206]\u001b[A\n",
            "Epoch 1:  53%|█████▎    | 255/484 [35:21<29:29,  7.73s/it, training_loss=0.206]\u001b[A\n",
            "Epoch 1:  53%|█████▎    | 256/484 [35:21<30:34,  8.04s/it, training_loss=0.206]\u001b[A\n",
            "Epoch 1:  53%|█████▎    | 256/484 [35:28<30:34,  8.04s/it, training_loss=0.226]\u001b[A\n",
            "Epoch 1:  53%|█████▎    | 257/484 [35:28<29:38,  7.83s/it, training_loss=0.226]\u001b[A\n",
            "Epoch 1:  53%|█████▎    | 257/484 [35:35<29:38,  7.83s/it, training_loss=0.302]\u001b[A\n",
            "Epoch 1:  53%|█████▎    | 258/484 [35:35<28:54,  7.68s/it, training_loss=0.302]\u001b[A\n",
            "Epoch 1:  53%|█████▎    | 258/484 [35:47<28:54,  7.68s/it, training_loss=0.204]\u001b[A\n",
            "Epoch 1:  54%|█████▎    | 259/484 [35:47<33:01,  8.80s/it, training_loss=0.204]\u001b[A\n",
            "Epoch 1:  54%|█████▎    | 259/484 [35:54<33:01,  8.80s/it, training_loss=0.119]\u001b[A\n",
            "Epoch 1:  54%|█████▎    | 260/484 [35:54<31:01,  8.31s/it, training_loss=0.119]\u001b[A\n",
            "Epoch 1:  54%|█████▎    | 260/484 [36:02<31:01,  8.31s/it, training_loss=0.115]\u001b[A\n",
            "Epoch 1:  54%|█████▍    | 261/484 [36:02<31:12,  8.40s/it, training_loss=0.115]\u001b[A\n",
            "Epoch 1:  54%|█████▍    | 261/484 [36:10<31:12,  8.40s/it, training_loss=0.179]\u001b[A\n",
            "Epoch 1:  54%|█████▍    | 262/484 [36:10<30:08,  8.15s/it, training_loss=0.179]\u001b[A\n",
            "Epoch 1:  54%|█████▍    | 262/484 [36:17<30:08,  8.15s/it, training_loss=0.153]\u001b[A\n",
            "Epoch 1:  54%|█████▍    | 263/484 [36:17<28:50,  7.83s/it, training_loss=0.153]\u001b[A\n",
            "Epoch 1:  54%|█████▍    | 263/484 [36:26<28:50,  7.83s/it, training_loss=0.323]\u001b[A\n",
            "Epoch 1:  55%|█████▍    | 264/484 [36:26<29:53,  8.15s/it, training_loss=0.323]\u001b[A\n",
            "Epoch 1:  55%|█████▍    | 264/484 [36:33<29:53,  8.15s/it, training_loss=0.151]\u001b[A\n",
            "Epoch 1:  55%|█████▍    | 265/484 [36:33<28:01,  7.68s/it, training_loss=0.151]\u001b[A\n",
            "Epoch 1:  55%|█████▍    | 265/484 [36:42<28:01,  7.68s/it, training_loss=0.123]\u001b[A\n",
            "Epoch 1:  55%|█████▍    | 266/484 [36:42<30:02,  8.27s/it, training_loss=0.123]\u001b[A\n",
            "Epoch 1:  55%|█████▍    | 266/484 [36:49<30:02,  8.27s/it, training_loss=0.062]\u001b[A\n",
            "Epoch 1:  55%|█████▌    | 267/484 [36:49<28:00,  7.74s/it, training_loss=0.062]\u001b[A\n",
            "Epoch 1:  55%|█████▌    | 267/484 [36:58<28:00,  7.74s/it, training_loss=0.140]\u001b[A\n",
            "Epoch 1:  55%|█████▌    | 268/484 [36:58<29:00,  8.06s/it, training_loss=0.140]\u001b[A\n",
            "Epoch 1:  55%|█████▌    | 268/484 [37:05<29:00,  8.06s/it, training_loss=0.200]\u001b[A\n",
            "Epoch 1:  56%|█████▌    | 269/484 [37:05<28:06,  7.84s/it, training_loss=0.200]\u001b[A\n",
            "Epoch 1:  56%|█████▌    | 269/484 [37:12<28:06,  7.84s/it, training_loss=0.252]\u001b[A\n",
            "Epoch 1:  56%|█████▌    | 270/484 [37:12<27:23,  7.68s/it, training_loss=0.252]\u001b[A\n",
            "Epoch 1:  56%|█████▌    | 270/484 [37:21<27:23,  7.68s/it, training_loss=0.129]\u001b[A\n",
            "Epoch 1:  56%|█████▌    | 271/484 [37:21<28:17,  7.97s/it, training_loss=0.129]\u001b[A\n",
            "Epoch 1:  56%|█████▌    | 271/484 [37:27<28:17,  7.97s/it, training_loss=0.161]\u001b[A\n",
            "Epoch 1:  56%|█████▌    | 272/484 [37:27<26:45,  7.57s/it, training_loss=0.161]\u001b[A\n",
            "Epoch 1:  56%|█████▌    | 272/484 [37:37<26:45,  7.57s/it, training_loss=0.203]\u001b[A\n",
            "Epoch 1:  56%|█████▋    | 273/484 [37:37<28:53,  8.22s/it, training_loss=0.203]\u001b[A\n",
            "Epoch 1:  56%|█████▋    | 273/484 [37:44<28:53,  8.22s/it, training_loss=0.129]\u001b[A\n",
            "Epoch 1:  57%|█████▋    | 274/484 [37:44<27:01,  7.72s/it, training_loss=0.129]\u001b[A\n",
            "Epoch 1:  57%|█████▋    | 274/484 [37:53<27:01,  7.72s/it, training_loss=0.147]\u001b[A\n",
            "Epoch 1:  57%|█████▋    | 275/484 [37:53<28:19,  8.13s/it, training_loss=0.147]\u001b[A\n",
            "Epoch 1:  57%|█████▋    | 275/484 [38:00<28:19,  8.13s/it, training_loss=0.195]\u001b[A\n",
            "Epoch 1:  57%|█████▋    | 276/484 [38:00<27:08,  7.83s/it, training_loss=0.195]\u001b[A\n",
            "Epoch 1:  57%|█████▋    | 276/484 [38:08<27:08,  7.83s/it, training_loss=0.219]\u001b[A\n",
            "Epoch 1:  57%|█████▋    | 277/484 [38:08<26:56,  7.81s/it, training_loss=0.219]\u001b[A\n",
            "Epoch 1:  57%|█████▋    | 277/484 [38:16<26:56,  7.81s/it, training_loss=0.087]\u001b[A\n",
            "Epoch 1:  57%|█████▋    | 278/484 [38:16<27:16,  7.95s/it, training_loss=0.087]\u001b[A\n",
            "Epoch 1:  57%|█████▋    | 278/484 [38:23<27:16,  7.95s/it, training_loss=0.150]\u001b[A\n",
            "Epoch 1:  58%|█████▊    | 279/484 [38:23<25:45,  7.54s/it, training_loss=0.150]\u001b[A\n",
            "Epoch 1:  58%|█████▊    | 279/484 [38:32<25:45,  7.54s/it, training_loss=0.129]\u001b[A\n",
            "Epoch 1:  58%|█████▊    | 280/484 [38:32<27:46,  8.17s/it, training_loss=0.129]\u001b[A\n",
            "Epoch 1:  58%|█████▊    | 280/484 [38:39<27:46,  8.17s/it, training_loss=0.095]\u001b[A\n",
            "Epoch 1:  58%|█████▊    | 281/484 [38:39<26:03,  7.70s/it, training_loss=0.095]\u001b[A\n",
            "Epoch 1:  58%|█████▊    | 281/484 [38:48<26:03,  7.70s/it, training_loss=0.141]\u001b[A\n",
            "Epoch 1:  58%|█████▊    | 282/484 [38:48<27:23,  8.14s/it, training_loss=0.141]\u001b[A\n",
            "Epoch 1:  58%|█████▊    | 282/484 [38:55<27:23,  8.14s/it, training_loss=0.142]\u001b[A\n",
            "Epoch 1:  58%|█████▊    | 283/484 [38:55<26:03,  7.78s/it, training_loss=0.142]\u001b[A\n",
            "Epoch 1:  58%|█████▊    | 283/484 [39:03<26:03,  7.78s/it, training_loss=0.165]\u001b[A\n",
            "Epoch 1:  59%|█████▊    | 284/484 [39:03<26:02,  7.81s/it, training_loss=0.165]\u001b[A\n",
            "Epoch 1:  59%|█████▊    | 284/484 [39:11<26:02,  7.81s/it, training_loss=0.174]\u001b[A\n",
            "Epoch 1:  59%|█████▉    | 285/484 [39:11<26:13,  7.91s/it, training_loss=0.174]\u001b[A\n",
            "Epoch 1:  59%|█████▉    | 285/484 [39:18<26:13,  7.91s/it, training_loss=0.057]\u001b[A\n",
            "Epoch 1:  59%|█████▉    | 286/484 [39:18<24:50,  7.53s/it, training_loss=0.057]\u001b[A\n",
            "Epoch 1:  59%|█████▉    | 286/484 [39:27<24:50,  7.53s/it, training_loss=0.216]\u001b[A\n",
            "Epoch 1:  59%|█████▉    | 287/484 [39:27<26:45,  8.15s/it, training_loss=0.216]\u001b[A\n",
            "Epoch 1:  59%|█████▉    | 287/484 [39:34<26:45,  8.15s/it, training_loss=0.127]\u001b[A\n",
            "Epoch 1:  60%|█████▉    | 288/484 [39:34<25:05,  7.68s/it, training_loss=0.127]\u001b[A\n",
            "Epoch 1:  60%|█████▉    | 288/484 [39:43<25:05,  7.68s/it, training_loss=0.088]\u001b[A\n",
            "Epoch 1:  60%|█████▉    | 289/484 [39:43<26:33,  8.17s/it, training_loss=0.088]\u001b[A\n",
            "Epoch 1:  60%|█████▉    | 289/484 [39:50<26:33,  8.17s/it, training_loss=0.104]\u001b[A\n",
            "Epoch 1:  60%|█████▉    | 290/484 [39:50<25:09,  7.78s/it, training_loss=0.104]\u001b[A\n",
            "Epoch 1:  60%|█████▉    | 290/484 [39:58<25:09,  7.78s/it, training_loss=0.058]\u001b[A\n",
            "Epoch 1:  60%|██████    | 291/484 [39:58<25:24,  7.90s/it, training_loss=0.058]\u001b[A\n",
            "Epoch 1:  60%|██████    | 291/484 [40:06<25:24,  7.90s/it, training_loss=0.136]\u001b[A\n",
            "Epoch 1:  60%|██████    | 292/484 [40:06<25:18,  7.91s/it, training_loss=0.136]\u001b[A\n",
            "Epoch 1:  60%|██████    | 292/484 [40:13<25:18,  7.91s/it, training_loss=0.062]\u001b[A\n",
            "Epoch 1:  61%|██████    | 293/484 [40:13<24:04,  7.56s/it, training_loss=0.062]\u001b[A\n",
            "Epoch 1:  61%|██████    | 293/484 [40:24<24:04,  7.56s/it, training_loss=0.178]\u001b[A\n",
            "Epoch 1:  61%|██████    | 294/484 [40:24<26:56,  8.51s/it, training_loss=0.178]\u001b[A\n",
            "Epoch 1:  61%|██████    | 294/484 [40:32<26:56,  8.51s/it, training_loss=0.239]\u001b[A\n",
            "Epoch 1:  61%|██████    | 295/484 [40:32<26:26,  8.39s/it, training_loss=0.239]\u001b[A\n",
            "Epoch 1:  61%|██████    | 295/484 [40:41<26:26,  8.39s/it, training_loss=0.051]\u001b[A\n",
            "Epoch 1:  61%|██████    | 296/484 [40:41<27:28,  8.77s/it, training_loss=0.051]\u001b[A\n",
            "Epoch 1:  61%|██████    | 296/484 [40:48<27:28,  8.77s/it, training_loss=0.123]\u001b[A\n",
            "Epoch 1:  61%|██████▏   | 297/484 [40:48<25:19,  8.13s/it, training_loss=0.123]\u001b[A\n",
            "Epoch 1:  61%|██████▏   | 297/484 [40:57<25:19,  8.13s/it, training_loss=0.130]\u001b[A\n",
            "Epoch 1:  62%|██████▏   | 298/484 [40:57<25:45,  8.31s/it, training_loss=0.130]\u001b[A\n",
            "Epoch 1:  62%|██████▏   | 298/484 [41:04<25:45,  8.31s/it, training_loss=0.127]\u001b[A\n",
            "Epoch 1:  62%|██████▏   | 299/484 [41:04<24:51,  8.06s/it, training_loss=0.127]\u001b[A\n",
            "Epoch 1:  62%|██████▏   | 299/484 [41:12<24:51,  8.06s/it, training_loss=0.178]\u001b[A\n",
            "Epoch 1:  62%|██████▏   | 300/484 [41:12<24:05,  7.85s/it, training_loss=0.178]\u001b[A\n",
            "Epoch 1:  62%|██████▏   | 300/484 [41:20<24:05,  7.85s/it, training_loss=0.069]\u001b[A\n",
            "Epoch 1:  62%|██████▏   | 301/484 [41:20<24:49,  8.14s/it, training_loss=0.069]\u001b[A\n",
            "Epoch 1:  62%|██████▏   | 301/484 [41:27<24:49,  8.14s/it, training_loss=0.164]\u001b[A\n",
            "Epoch 1:  62%|██████▏   | 302/484 [41:27<23:20,  7.69s/it, training_loss=0.164]\u001b[A\n",
            "Epoch 1:  62%|██████▏   | 302/484 [41:37<23:20,  7.69s/it, training_loss=0.132]\u001b[A\n",
            "Epoch 1:  63%|██████▎   | 303/484 [41:37<25:05,  8.32s/it, training_loss=0.132]\u001b[A\n",
            "Epoch 1:  63%|██████▎   | 303/484 [41:43<25:05,  8.32s/it, training_loss=0.104]\u001b[A\n",
            "Epoch 1:  63%|██████▎   | 304/484 [41:43<23:26,  7.81s/it, training_loss=0.104]\u001b[A\n",
            "Epoch 1:  63%|██████▎   | 304/484 [41:53<23:26,  7.81s/it, training_loss=0.176]\u001b[A\n",
            "Epoch 1:  63%|██████▎   | 305/484 [41:53<24:28,  8.21s/it, training_loss=0.176]\u001b[A\n",
            "Epoch 1:  63%|██████▎   | 305/484 [42:00<24:28,  8.21s/it, training_loss=0.241]\u001b[A\n",
            "Epoch 1:  63%|██████▎   | 306/484 [42:00<23:23,  7.89s/it, training_loss=0.241]\u001b[A\n",
            "Epoch 1:  63%|██████▎   | 306/484 [42:07<23:23,  7.89s/it, training_loss=0.115]\u001b[A\n",
            "Epoch 1:  63%|██████▎   | 307/484 [42:07<23:08,  7.84s/it, training_loss=0.115]\u001b[A\n",
            "Epoch 1:  63%|██████▎   | 307/484 [42:16<23:08,  7.84s/it, training_loss=0.107]\u001b[A\n",
            "Epoch 1:  64%|██████▎   | 308/484 [42:16<23:24,  7.98s/it, training_loss=0.107]\u001b[A\n",
            "Epoch 1:  64%|██████▎   | 308/484 [42:22<23:24,  7.98s/it, training_loss=0.204]\u001b[A\n",
            "Epoch 1:  64%|██████▍   | 309/484 [42:22<22:02,  7.56s/it, training_loss=0.204]\u001b[A\n",
            "Epoch 1:  64%|██████▍   | 309/484 [42:32<22:02,  7.56s/it, training_loss=0.140]\u001b[A\n",
            "Epoch 1:  64%|██████▍   | 310/484 [42:32<23:42,  8.18s/it, training_loss=0.140]\u001b[A\n",
            "Epoch 1:  64%|██████▍   | 310/484 [42:38<23:42,  8.18s/it, training_loss=0.183]\u001b[A\n",
            "Epoch 1:  64%|██████▍   | 311/484 [42:38<22:11,  7.70s/it, training_loss=0.183]\u001b[A\n",
            "Epoch 1:  64%|██████▍   | 311/484 [42:48<22:11,  7.70s/it, training_loss=0.213]\u001b[A\n",
            "Epoch 1:  64%|██████▍   | 312/484 [42:48<23:19,  8.14s/it, training_loss=0.213]\u001b[A\n",
            "Epoch 1:  64%|██████▍   | 312/484 [42:55<23:19,  8.14s/it, training_loss=0.068]\u001b[A\n",
            "Epoch 1:  65%|██████▍   | 313/484 [42:55<22:12,  7.79s/it, training_loss=0.068]\u001b[A\n",
            "Epoch 1:  65%|██████▍   | 313/484 [43:02<22:12,  7.79s/it, training_loss=0.064]\u001b[A\n",
            "Epoch 1:  65%|██████▍   | 314/484 [43:02<22:07,  7.81s/it, training_loss=0.064]\u001b[A\n",
            "Epoch 1:  65%|██████▍   | 314/484 [43:11<22:07,  7.81s/it, training_loss=0.109]\u001b[A\n",
            "Epoch 1:  65%|██████▌   | 315/484 [43:11<22:20,  7.93s/it, training_loss=0.109]\u001b[A\n",
            "Epoch 1:  65%|██████▌   | 315/484 [43:17<22:20,  7.93s/it, training_loss=0.142]\u001b[A\n",
            "Epoch 1:  65%|██████▌   | 316/484 [43:17<21:08,  7.55s/it, training_loss=0.142]\u001b[A\n",
            "Epoch 1:  65%|██████▌   | 316/484 [43:27<21:08,  7.55s/it, training_loss=0.150]\u001b[A\n",
            "Epoch 1:  65%|██████▌   | 317/484 [43:27<22:46,  8.18s/it, training_loss=0.150]\u001b[A\n",
            "Epoch 1:  65%|██████▌   | 317/484 [43:34<22:46,  8.18s/it, training_loss=0.136]\u001b[A\n",
            "Epoch 1:  66%|██████▌   | 318/484 [43:34<21:23,  7.73s/it, training_loss=0.136]\u001b[A\n",
            "Epoch 1:  66%|██████▌   | 318/484 [43:43<21:23,  7.73s/it, training_loss=0.223]\u001b[A\n",
            "Epoch 1:  66%|██████▌   | 319/484 [43:43<22:43,  8.26s/it, training_loss=0.223]\u001b[A\n",
            "Epoch 1:  66%|██████▌   | 319/484 [43:50<22:43,  8.26s/it, training_loss=0.215]\u001b[A\n",
            "Epoch 1:  66%|██████▌   | 320/484 [43:50<21:22,  7.82s/it, training_loss=0.215]\u001b[A\n",
            "Epoch 1:  66%|██████▌   | 320/484 [43:58<21:22,  7.82s/it, training_loss=0.089]\u001b[A\n",
            "Epoch 1:  66%|██████▋   | 321/484 [43:58<21:40,  7.98s/it, training_loss=0.089]\u001b[A\n",
            "Epoch 1:  66%|██████▋   | 321/484 [44:06<21:40,  7.98s/it, training_loss=0.274]\u001b[A\n",
            "Epoch 1:  67%|██████▋   | 322/484 [44:06<21:22,  7.92s/it, training_loss=0.274]\u001b[A\n",
            "Epoch 1:  67%|██████▋   | 322/484 [44:13<21:22,  7.92s/it, training_loss=0.148]\u001b[A\n",
            "Epoch 1:  67%|██████▋   | 323/484 [44:13<20:32,  7.65s/it, training_loss=0.148]\u001b[A\n",
            "Epoch 1:  67%|██████▋   | 323/484 [44:22<20:32,  7.65s/it, training_loss=0.124]\u001b[A\n",
            "Epoch 1:  67%|██████▋   | 324/484 [44:22<21:30,  8.06s/it, training_loss=0.124]\u001b[A\n",
            "Epoch 1:  67%|██████▋   | 324/484 [44:29<21:30,  8.06s/it, training_loss=0.074]\u001b[A\n",
            "Epoch 1:  67%|██████▋   | 325/484 [44:29<20:12,  7.63s/it, training_loss=0.074]\u001b[A\n",
            "Epoch 1:  67%|██████▋   | 325/484 [44:38<20:12,  7.63s/it, training_loss=0.117]\u001b[A\n",
            "Epoch 1:  67%|██████▋   | 326/484 [44:38<21:42,  8.24s/it, training_loss=0.117]\u001b[A\n",
            "Epoch 1:  67%|██████▋   | 326/484 [44:45<21:42,  8.24s/it, training_loss=0.101]\u001b[A\n",
            "Epoch 1:  68%|██████▊   | 327/484 [44:45<20:16,  7.75s/it, training_loss=0.101]\u001b[A\n",
            "Epoch 1:  68%|██████▊   | 327/484 [44:54<20:16,  7.75s/it, training_loss=0.131]\u001b[A\n",
            "Epoch 1:  68%|██████▊   | 328/484 [44:54<20:49,  8.01s/it, training_loss=0.131]\u001b[A\n",
            "Epoch 1:  68%|██████▊   | 328/484 [45:01<20:49,  8.01s/it, training_loss=0.203]\u001b[A\n",
            "Epoch 1:  68%|██████▊   | 329/484 [45:01<20:19,  7.87s/it, training_loss=0.203]\u001b[A\n",
            "Epoch 1:  68%|██████▊   | 329/484 [45:12<20:19,  7.87s/it, training_loss=0.245]\u001b[A\n",
            "Epoch 1:  68%|██████▊   | 330/484 [45:12<22:42,  8.84s/it, training_loss=0.245]\u001b[A\n",
            "Epoch 1:  68%|██████▊   | 330/484 [45:21<22:42,  8.84s/it, training_loss=0.044]\u001b[A\n",
            "Epoch 1:  68%|██████▊   | 331/484 [45:21<22:03,  8.65s/it, training_loss=0.044]\u001b[A\n",
            "Epoch 1:  68%|██████▊   | 331/484 [45:27<22:03,  8.65s/it, training_loss=0.222]\u001b[A\n",
            "Epoch 1:  69%|██████▊   | 332/484 [45:27<20:22,  8.05s/it, training_loss=0.222]\u001b[A\n",
            "Epoch 1:  69%|██████▊   | 332/484 [45:37<20:22,  8.05s/it, training_loss=0.176]\u001b[A\n",
            "Epoch 1:  69%|██████▉   | 333/484 [45:37<21:25,  8.51s/it, training_loss=0.176]\u001b[A\n",
            "Epoch 1:  69%|██████▉   | 333/484 [45:43<21:25,  8.51s/it, training_loss=0.032]\u001b[A\n",
            "Epoch 1:  69%|██████▉   | 334/484 [45:43<19:49,  7.93s/it, training_loss=0.032]\u001b[A\n",
            "Epoch 1:  69%|██████▉   | 334/484 [45:53<19:49,  7.93s/it, training_loss=0.058]\u001b[A\n",
            "Epoch 1:  69%|██████▉   | 335/484 [45:53<20:42,  8.34s/it, training_loss=0.058]\u001b[A\n",
            "Epoch 1:  69%|██████▉   | 335/484 [46:00<20:42,  8.34s/it, training_loss=0.130]\u001b[A\n",
            "Epoch 1:  69%|██████▉   | 336/484 [46:00<19:33,  7.93s/it, training_loss=0.130]\u001b[A\n",
            "Epoch 1:  69%|██████▉   | 336/484 [46:08<19:33,  7.93s/it, training_loss=0.063]\u001b[A\n",
            "Epoch 1:  70%|██████▉   | 337/484 [46:08<19:32,  7.98s/it, training_loss=0.063]\u001b[A\n",
            "Epoch 1:  70%|██████▉   | 337/484 [46:16<19:32,  7.98s/it, training_loss=0.203]\u001b[A\n",
            "Epoch 1:  70%|██████▉   | 338/484 [46:16<19:23,  7.97s/it, training_loss=0.203]\u001b[A\n",
            "Epoch 1:  70%|██████▉   | 338/484 [46:22<19:23,  7.97s/it, training_loss=0.254]\u001b[A\n",
            "Epoch 1:  70%|███████   | 339/484 [46:22<18:19,  7.58s/it, training_loss=0.254]\u001b[A\n",
            "Epoch 1:  70%|███████   | 339/484 [46:32<18:19,  7.58s/it, training_loss=0.030]\u001b[A\n",
            "Epoch 1:  70%|███████   | 340/484 [46:32<19:30,  8.13s/it, training_loss=0.030]\u001b[A\n",
            "Epoch 1:  70%|███████   | 340/484 [46:38<19:30,  8.13s/it, training_loss=0.174]\u001b[A\n",
            "Epoch 1:  70%|███████   | 341/484 [46:38<18:16,  7.67s/it, training_loss=0.174]\u001b[A\n",
            "Epoch 1:  70%|███████   | 341/484 [46:48<18:16,  7.67s/it, training_loss=0.056]\u001b[A\n",
            "Epoch 1:  71%|███████   | 342/484 [46:48<19:21,  8.18s/it, training_loss=0.056]\u001b[A\n",
            "Epoch 1:  71%|███████   | 342/484 [46:54<19:21,  8.18s/it, training_loss=0.058]\u001b[A\n",
            "Epoch 1:  71%|███████   | 343/484 [46:54<18:11,  7.74s/it, training_loss=0.058]\u001b[A\n",
            "Epoch 1:  71%|███████   | 343/484 [47:03<18:11,  7.74s/it, training_loss=0.299]\u001b[A\n",
            "Epoch 1:  71%|███████   | 344/484 [47:03<18:19,  7.85s/it, training_loss=0.299]\u001b[A\n",
            "Epoch 1:  71%|███████   | 344/484 [47:10<18:19,  7.85s/it, training_loss=0.174]\u001b[A\n",
            "Epoch 1:  71%|███████▏  | 345/484 [47:10<18:15,  7.88s/it, training_loss=0.174]\u001b[A\n",
            "Epoch 1:  71%|███████▏  | 345/484 [47:17<18:15,  7.88s/it, training_loss=0.080]\u001b[A\n",
            "Epoch 1:  71%|███████▏  | 346/484 [47:17<17:18,  7.52s/it, training_loss=0.080]\u001b[A\n",
            "Epoch 1:  71%|███████▏  | 346/484 [47:27<17:18,  7.52s/it, training_loss=0.074]\u001b[A\n",
            "Epoch 1:  72%|███████▏  | 347/484 [47:27<18:26,  8.07s/it, training_loss=0.074]\u001b[A\n",
            "Epoch 1:  72%|███████▏  | 347/484 [47:33<18:26,  8.07s/it, training_loss=0.102]\u001b[A\n",
            "Epoch 1:  72%|███████▏  | 348/484 [47:33<17:17,  7.63s/it, training_loss=0.102]\u001b[A\n",
            "Epoch 1:  72%|███████▏  | 348/484 [47:43<17:17,  7.63s/it, training_loss=0.109]\u001b[A\n",
            "Epoch 1:  72%|███████▏  | 349/484 [47:43<18:24,  8.18s/it, training_loss=0.109]\u001b[A\n",
            "Epoch 1:  72%|███████▏  | 349/484 [47:49<18:24,  8.18s/it, training_loss=0.119]\u001b[A\n",
            "Epoch 1:  72%|███████▏  | 350/484 [47:49<17:16,  7.74s/it, training_loss=0.119]\u001b[A\n",
            "Epoch 1:  72%|███████▏  | 350/484 [47:57<17:16,  7.74s/it, training_loss=0.114]\u001b[A\n",
            "Epoch 1:  73%|███████▎  | 351/484 [47:57<17:25,  7.86s/it, training_loss=0.114]\u001b[A\n",
            "Epoch 1:  73%|███████▎  | 351/484 [48:05<17:25,  7.86s/it, training_loss=0.213]\u001b[A\n",
            "Epoch 1:  73%|███████▎  | 352/484 [48:05<17:19,  7.88s/it, training_loss=0.213]\u001b[A\n",
            "Epoch 1:  73%|███████▎  | 352/484 [48:12<17:19,  7.88s/it, training_loss=0.081]\u001b[A\n",
            "Epoch 1:  73%|███████▎  | 353/484 [48:12<16:30,  7.56s/it, training_loss=0.081]\u001b[A\n",
            "Epoch 1:  73%|███████▎  | 353/484 [48:21<16:30,  7.56s/it, training_loss=0.192]\u001b[A\n",
            "Epoch 1:  73%|███████▎  | 354/484 [48:21<17:29,  8.08s/it, training_loss=0.192]\u001b[A\n",
            "Epoch 1:  73%|███████▎  | 354/484 [48:28<17:29,  8.08s/it, training_loss=0.103]\u001b[A\n",
            "Epoch 1:  73%|███████▎  | 355/484 [48:28<16:25,  7.64s/it, training_loss=0.103]\u001b[A\n",
            "Epoch 1:  73%|███████▎  | 355/484 [48:38<16:25,  7.64s/it, training_loss=0.036]\u001b[A\n",
            "Epoch 1:  74%|███████▎  | 356/484 [48:38<17:33,  8.23s/it, training_loss=0.036]\u001b[A\n",
            "Epoch 1:  74%|███████▎  | 356/484 [48:44<17:33,  8.23s/it, training_loss=0.305]\u001b[A\n",
            "Epoch 1:  74%|███████▍  | 357/484 [48:44<16:22,  7.74s/it, training_loss=0.305]\u001b[A\n",
            "Epoch 1:  74%|███████▍  | 357/484 [48:53<16:22,  7.74s/it, training_loss=0.079]\u001b[A\n",
            "Epoch 1:  74%|███████▍  | 358/484 [48:53<16:37,  7.92s/it, training_loss=0.079]\u001b[A\n",
            "Epoch 1:  74%|███████▍  | 358/484 [49:00<16:37,  7.92s/it, training_loss=0.128]\u001b[A\n",
            "Epoch 1:  74%|███████▍  | 359/484 [49:00<16:24,  7.88s/it, training_loss=0.128]\u001b[A\n",
            "Epoch 1:  74%|███████▍  | 359/484 [49:07<16:24,  7.88s/it, training_loss=0.071]\u001b[A\n",
            "Epoch 1:  74%|███████▍  | 360/484 [49:07<15:40,  7.58s/it, training_loss=0.071]\u001b[A\n",
            "Epoch 1:  74%|███████▍  | 360/484 [49:16<15:40,  7.58s/it, training_loss=0.141]\u001b[A\n",
            "Epoch 1:  75%|███████▍  | 361/484 [49:16<16:30,  8.05s/it, training_loss=0.141]\u001b[A\n",
            "Epoch 1:  75%|███████▍  | 361/484 [49:23<16:30,  8.05s/it, training_loss=0.457]\u001b[A\n",
            "Epoch 1:  75%|███████▍  | 362/484 [49:23<15:28,  7.61s/it, training_loss=0.457]\u001b[A\n",
            "Epoch 1:  75%|███████▍  | 362/484 [49:33<15:28,  7.61s/it, training_loss=0.171]\u001b[A\n",
            "Epoch 1:  75%|███████▌  | 363/484 [49:33<16:37,  8.25s/it, training_loss=0.171]\u001b[A\n",
            "Epoch 1:  75%|███████▌  | 363/484 [49:39<16:37,  8.25s/it, training_loss=0.193]\u001b[A\n",
            "Epoch 1:  75%|███████▌  | 364/484 [49:39<15:33,  7.78s/it, training_loss=0.193]\u001b[A\n",
            "Epoch 1:  75%|███████▌  | 364/484 [49:49<15:33,  7.78s/it, training_loss=0.083]\u001b[A\n",
            "Epoch 1:  75%|███████▌  | 365/484 [49:49<16:26,  8.29s/it, training_loss=0.083]\u001b[A\n",
            "Epoch 1:  75%|███████▌  | 365/484 [49:59<16:26,  8.29s/it, training_loss=0.064]\u001b[A\n",
            "Epoch 1:  76%|███████▌  | 366/484 [49:59<17:14,  8.77s/it, training_loss=0.064]\u001b[A\n",
            "Epoch 1:  76%|███████▌  | 366/484 [50:05<17:14,  8.77s/it, training_loss=0.098]\u001b[A\n",
            "Epoch 1:  76%|███████▌  | 367/484 [50:05<15:50,  8.12s/it, training_loss=0.098]\u001b[A\n",
            "Epoch 1:  76%|███████▌  | 367/484 [50:15<15:50,  8.12s/it, training_loss=0.099]\u001b[A\n",
            "Epoch 1:  76%|███████▌  | 368/484 [50:15<16:19,  8.45s/it, training_loss=0.099]\u001b[A\n",
            "Epoch 1:  76%|███████▌  | 368/484 [50:22<16:19,  8.45s/it, training_loss=0.161]\u001b[A\n",
            "Epoch 1:  76%|███████▌  | 369/484 [50:22<15:21,  8.01s/it, training_loss=0.161]\u001b[A\n",
            "Epoch 1:  76%|███████▌  | 369/484 [50:29<15:21,  8.01s/it, training_loss=0.069]\u001b[A\n",
            "Epoch 1:  76%|███████▋  | 370/484 [50:29<15:07,  7.96s/it, training_loss=0.069]\u001b[A\n",
            "Epoch 1:  76%|███████▋  | 370/484 [50:38<15:07,  7.96s/it, training_loss=0.041]\u001b[A\n",
            "Epoch 1:  77%|███████▋  | 371/484 [50:38<15:07,  8.03s/it, training_loss=0.041]\u001b[A\n",
            "Epoch 1:  77%|███████▋  | 371/484 [50:44<15:07,  8.03s/it, training_loss=0.139]\u001b[A\n",
            "Epoch 1:  77%|███████▋  | 372/484 [50:44<14:14,  7.63s/it, training_loss=0.139]\u001b[A\n",
            "Epoch 1:  77%|███████▋  | 372/484 [50:54<14:14,  7.63s/it, training_loss=0.088]\u001b[A\n",
            "Epoch 1:  77%|███████▋  | 373/484 [50:54<15:11,  8.21s/it, training_loss=0.088]\u001b[A\n",
            "Epoch 1:  77%|███████▋  | 373/484 [51:01<15:11,  8.21s/it, training_loss=0.031]\u001b[A\n",
            "Epoch 1:  77%|███████▋  | 374/484 [51:01<14:09,  7.73s/it, training_loss=0.031]\u001b[A\n",
            "Epoch 1:  77%|███████▋  | 374/484 [51:10<14:09,  7.73s/it, training_loss=0.235]\u001b[A\n",
            "Epoch 1:  77%|███████▋  | 375/484 [51:10<14:54,  8.20s/it, training_loss=0.235]\u001b[A\n",
            "Epoch 1:  77%|███████▋  | 375/484 [51:17<14:54,  8.20s/it, training_loss=0.319]\u001b[A\n",
            "Epoch 1:  78%|███████▊  | 376/484 [51:17<14:00,  7.78s/it, training_loss=0.319]\u001b[A\n",
            "Epoch 1:  78%|███████▊  | 376/484 [51:25<14:00,  7.78s/it, training_loss=0.260]\u001b[A\n",
            "Epoch 1:  78%|███████▊  | 377/484 [51:25<13:58,  7.84s/it, training_loss=0.260]\u001b[A\n",
            "Epoch 1:  78%|███████▊  | 377/484 [51:33<13:58,  7.84s/it, training_loss=0.218]\u001b[A\n",
            "Epoch 1:  78%|███████▊  | 378/484 [51:33<13:55,  7.88s/it, training_loss=0.218]\u001b[A\n",
            "Epoch 1:  78%|███████▊  | 378/484 [51:39<13:55,  7.88s/it, training_loss=0.173]\u001b[A\n",
            "Epoch 1:  78%|███████▊  | 379/484 [51:39<13:10,  7.53s/it, training_loss=0.173]\u001b[A\n",
            "Epoch 1:  78%|███████▊  | 379/484 [51:49<13:10,  7.53s/it, training_loss=0.166]\u001b[A\n",
            "Epoch 1:  79%|███████▊  | 380/484 [51:49<14:04,  8.12s/it, training_loss=0.166]\u001b[A\n",
            "Epoch 1:  79%|███████▊  | 380/484 [51:55<14:04,  8.12s/it, training_loss=0.113]\u001b[A\n",
            "Epoch 1:  79%|███████▊  | 381/484 [51:55<13:09,  7.66s/it, training_loss=0.113]\u001b[A\n",
            "Epoch 1:  79%|███████▊  | 381/484 [52:05<13:09,  7.66s/it, training_loss=0.271]\u001b[A\n",
            "Epoch 1:  79%|███████▉  | 382/484 [52:05<13:58,  8.22s/it, training_loss=0.271]\u001b[A\n",
            "Epoch 1:  79%|███████▉  | 382/484 [52:12<13:58,  8.22s/it, training_loss=0.057]\u001b[A\n",
            "Epoch 1:  79%|███████▉  | 383/484 [52:12<13:05,  7.78s/it, training_loss=0.057]\u001b[A\n",
            "Epoch 1:  79%|███████▉  | 383/484 [52:20<13:05,  7.78s/it, training_loss=0.026]\u001b[A\n",
            "Epoch 1:  79%|███████▉  | 384/484 [52:20<13:10,  7.91s/it, training_loss=0.026]\u001b[A\n",
            "Epoch 1:  79%|███████▉  | 384/484 [52:28<13:10,  7.91s/it, training_loss=0.302]\u001b[A\n",
            "Epoch 1:  80%|███████▉  | 385/484 [52:28<13:03,  7.91s/it, training_loss=0.302]\u001b[A\n",
            "Epoch 1:  80%|███████▉  | 385/484 [52:35<13:03,  7.91s/it, training_loss=0.100]\u001b[A\n",
            "Epoch 1:  80%|███████▉  | 386/484 [52:35<12:23,  7.59s/it, training_loss=0.100]\u001b[A\n",
            "Epoch 1:  80%|███████▉  | 386/484 [52:44<12:23,  7.59s/it, training_loss=0.259]\u001b[A\n",
            "Epoch 1:  80%|███████▉  | 387/484 [52:44<13:04,  8.09s/it, training_loss=0.259]\u001b[A\n",
            "Epoch 1:  80%|███████▉  | 387/484 [52:50<13:04,  8.09s/it, training_loss=0.198]\u001b[A\n",
            "Epoch 1:  80%|████████  | 388/484 [52:50<12:12,  7.63s/it, training_loss=0.198]\u001b[A\n",
            "Epoch 1:  80%|████████  | 388/484 [53:00<12:12,  7.63s/it, training_loss=0.192]\u001b[A\n",
            "Epoch 1:  80%|████████  | 389/484 [53:00<12:59,  8.21s/it, training_loss=0.192]\u001b[A\n",
            "Epoch 1:  80%|████████  | 389/484 [53:07<12:59,  8.21s/it, training_loss=0.146]\u001b[A\n",
            "Epoch 1:  81%|████████  | 390/484 [53:07<12:05,  7.71s/it, training_loss=0.146]\u001b[A\n",
            "Epoch 1:  81%|████████  | 390/484 [53:15<12:05,  7.71s/it, training_loss=0.241]\u001b[A\n",
            "Epoch 1:  81%|████████  | 391/484 [53:15<12:17,  7.94s/it, training_loss=0.241]\u001b[A\n",
            "Epoch 1:  81%|████████  | 391/484 [53:23<12:17,  7.94s/it, training_loss=0.146]\u001b[A\n",
            "Epoch 1:  81%|████████  | 392/484 [53:23<12:03,  7.86s/it, training_loss=0.146]\u001b[A\n",
            "Epoch 1:  81%|████████  | 392/484 [53:30<12:03,  7.86s/it, training_loss=0.071]\u001b[A\n",
            "Epoch 1:  81%|████████  | 393/484 [53:30<11:30,  7.58s/it, training_loss=0.071]\u001b[A\n",
            "Epoch 1:  81%|████████  | 393/484 [53:39<11:30,  7.58s/it, training_loss=0.199]\u001b[A\n",
            "Epoch 1:  81%|████████▏ | 394/484 [53:39<12:04,  8.05s/it, training_loss=0.199]\u001b[A\n",
            "Epoch 1:  81%|████████▏ | 394/484 [53:45<12:04,  8.05s/it, training_loss=0.103]\u001b[A\n",
            "Epoch 1:  82%|████████▏ | 395/484 [53:45<11:17,  7.62s/it, training_loss=0.103]\u001b[A\n",
            "Epoch 1:  82%|████████▏ | 395/484 [53:55<11:17,  7.62s/it, training_loss=0.060]\u001b[A\n",
            "Epoch 1:  82%|████████▏ | 396/484 [53:55<12:10,  8.30s/it, training_loss=0.060]\u001b[A\n",
            "Epoch 1:  82%|████████▏ | 396/484 [54:02<12:10,  8.30s/it, training_loss=0.204]\u001b[A\n",
            "Epoch 1:  82%|████████▏ | 397/484 [54:02<11:17,  7.79s/it, training_loss=0.204]\u001b[A\n",
            "Epoch 1:  82%|████████▏ | 397/484 [54:11<11:17,  7.79s/it, training_loss=0.177]\u001b[A\n",
            "Epoch 1:  82%|████████▏ | 398/484 [54:11<11:35,  8.09s/it, training_loss=0.177]\u001b[A\n",
            "Epoch 1:  82%|████████▏ | 398/484 [54:18<11:35,  8.09s/it, training_loss=0.182]\u001b[A\n",
            "Epoch 1:  82%|████████▏ | 399/484 [54:18<11:11,  7.90s/it, training_loss=0.182]\u001b[A\n",
            "Epoch 1:  82%|████████▏ | 399/484 [54:26<11:11,  7.90s/it, training_loss=0.048]\u001b[A\n",
            "Epoch 1:  83%|████████▎ | 400/484 [54:26<10:51,  7.76s/it, training_loss=0.048]\u001b[A\n",
            "Epoch 1:  83%|████████▎ | 400/484 [54:37<10:51,  7.76s/it, training_loss=0.276]\u001b[A\n",
            "Epoch 1:  83%|████████▎ | 401/484 [54:37<12:04,  8.73s/it, training_loss=0.276]\u001b[A\n",
            "Epoch 1:  83%|████████▎ | 401/484 [54:44<12:04,  8.73s/it, training_loss=0.203]\u001b[A\n",
            "Epoch 1:  83%|████████▎ | 402/484 [54:44<11:26,  8.37s/it, training_loss=0.203]\u001b[A\n",
            "Epoch 1:  83%|████████▎ | 402/484 [54:52<11:26,  8.37s/it, training_loss=0.071]\u001b[A\n",
            "Epoch 1:  83%|████████▎ | 403/484 [54:52<11:02,  8.18s/it, training_loss=0.071]\u001b[A\n",
            "Epoch 1:  83%|████████▎ | 403/484 [55:00<11:02,  8.18s/it, training_loss=0.077]\u001b[A\n",
            "Epoch 1:  83%|████████▎ | 404/484 [55:00<10:57,  8.22s/it, training_loss=0.077]\u001b[A\n",
            "Epoch 1:  83%|████████▎ | 404/484 [55:07<10:57,  8.22s/it, training_loss=0.077]\u001b[A\n",
            "Epoch 1:  84%|████████▎ | 405/484 [55:07<10:10,  7.73s/it, training_loss=0.077]\u001b[A\n",
            "Epoch 1:  84%|████████▎ | 405/484 [55:16<10:10,  7.73s/it, training_loss=0.047]\u001b[A\n",
            "Epoch 1:  84%|████████▍ | 406/484 [55:16<10:48,  8.31s/it, training_loss=0.047]\u001b[A\n",
            "Epoch 1:  84%|████████▍ | 406/484 [55:23<10:48,  8.31s/it, training_loss=0.297]\u001b[A\n",
            "Epoch 1:  84%|████████▍ | 407/484 [55:23<10:00,  7.79s/it, training_loss=0.297]\u001b[A\n",
            "Epoch 1:  84%|████████▍ | 407/484 [55:32<10:00,  7.79s/it, training_loss=0.098]\u001b[A\n",
            "Epoch 1:  84%|████████▍ | 408/484 [55:32<10:25,  8.23s/it, training_loss=0.098]\u001b[A\n",
            "Epoch 1:  84%|████████▍ | 408/484 [55:39<10:25,  8.23s/it, training_loss=0.127]\u001b[A\n",
            "Epoch 1:  85%|████████▍ | 409/484 [55:39<09:48,  7.85s/it, training_loss=0.127]\u001b[A\n",
            "Epoch 1:  85%|████████▍ | 409/484 [55:47<09:48,  7.85s/it, training_loss=0.093]\u001b[A\n",
            "Epoch 1:  85%|████████▍ | 410/484 [55:47<09:44,  7.90s/it, training_loss=0.093]\u001b[A\n",
            "Epoch 1:  85%|████████▍ | 410/484 [55:55<09:44,  7.90s/it, training_loss=0.143]\u001b[A\n",
            "Epoch 1:  85%|████████▍ | 411/484 [55:55<09:39,  7.94s/it, training_loss=0.143]\u001b[A\n",
            "Epoch 1:  85%|████████▍ | 411/484 [56:02<09:39,  7.94s/it, training_loss=0.119]\u001b[A\n",
            "Epoch 1:  85%|████████▌ | 412/484 [56:02<09:03,  7.55s/it, training_loss=0.119]\u001b[A\n",
            "Epoch 1:  85%|████████▌ | 412/484 [56:11<09:03,  7.55s/it, training_loss=0.066]\u001b[A\n",
            "Epoch 1:  85%|████████▌ | 413/484 [56:11<09:38,  8.14s/it, training_loss=0.066]\u001b[A\n",
            "Epoch 1:  85%|████████▌ | 413/484 [56:18<09:38,  8.14s/it, training_loss=0.049]\u001b[A\n",
            "Epoch 1:  86%|████████▌ | 414/484 [56:18<08:56,  7.67s/it, training_loss=0.049]\u001b[A\n",
            "Epoch 1:  86%|████████▌ | 414/484 [56:27<08:56,  7.67s/it, training_loss=0.115]\u001b[A\n",
            "Epoch 1:  86%|████████▌ | 415/484 [56:27<09:25,  8.19s/it, training_loss=0.115]\u001b[A\n",
            "Epoch 1:  86%|████████▌ | 415/484 [56:34<09:25,  8.19s/it, training_loss=0.111]\u001b[A\n",
            "Epoch 1:  86%|████████▌ | 416/484 [56:34<08:47,  7.76s/it, training_loss=0.111]\u001b[A\n",
            "Epoch 1:  86%|████████▌ | 416/484 [56:42<08:47,  7.76s/it, training_loss=0.087]\u001b[A\n",
            "Epoch 1:  86%|████████▌ | 417/484 [56:42<08:45,  7.84s/it, training_loss=0.087]\u001b[A\n",
            "Epoch 1:  86%|████████▌ | 417/484 [56:50<08:45,  7.84s/it, training_loss=0.031]\u001b[A\n",
            "Epoch 1:  86%|████████▋ | 418/484 [56:50<08:38,  7.86s/it, training_loss=0.031]\u001b[A\n",
            "Epoch 1:  86%|████████▋ | 418/484 [56:57<08:38,  7.86s/it, training_loss=0.114]\u001b[A\n",
            "Epoch 1:  87%|████████▋ | 419/484 [56:57<08:07,  7.49s/it, training_loss=0.114]\u001b[A\n",
            "Epoch 1:  87%|████████▋ | 419/484 [57:06<08:07,  7.49s/it, training_loss=0.053]\u001b[A\n",
            "Epoch 1:  87%|████████▋ | 420/484 [57:06<08:36,  8.07s/it, training_loss=0.053]\u001b[A\n",
            "Epoch 1:  87%|████████▋ | 420/484 [57:13<08:36,  8.07s/it, training_loss=0.056]\u001b[A\n",
            "Epoch 1:  87%|████████▋ | 421/484 [57:13<07:59,  7.61s/it, training_loss=0.056]\u001b[A\n",
            "Epoch 1:  87%|████████▋ | 421/484 [57:22<07:59,  7.61s/it, training_loss=0.077]\u001b[A\n",
            "Epoch 1:  87%|████████▋ | 422/484 [57:22<08:23,  8.12s/it, training_loss=0.077]\u001b[A\n",
            "Epoch 1:  87%|████████▋ | 422/484 [57:29<08:23,  8.12s/it, training_loss=0.028]\u001b[A\n",
            "Epoch 1:  87%|████████▋ | 423/484 [57:29<07:50,  7.71s/it, training_loss=0.028]\u001b[A\n",
            "Epoch 1:  87%|████████▋ | 423/484 [57:37<07:50,  7.71s/it, training_loss=0.083]\u001b[A\n",
            "Epoch 1:  88%|████████▊ | 424/484 [57:37<07:49,  7.83s/it, training_loss=0.083]\u001b[A\n",
            "Epoch 1:  88%|████████▊ | 424/484 [57:45<07:49,  7.83s/it, training_loss=0.168]\u001b[A\n",
            "Epoch 1:  88%|████████▊ | 425/484 [57:45<07:44,  7.87s/it, training_loss=0.168]\u001b[A\n",
            "Epoch 1:  88%|████████▊ | 425/484 [57:51<07:44,  7.87s/it, training_loss=0.045]\u001b[A\n",
            "Epoch 1:  88%|████████▊ | 426/484 [57:52<07:16,  7.53s/it, training_loss=0.045]\u001b[A\n",
            "Epoch 1:  88%|████████▊ | 426/484 [58:01<07:16,  7.53s/it, training_loss=0.158]\u001b[A\n",
            "Epoch 1:  88%|████████▊ | 427/484 [58:01<07:40,  8.07s/it, training_loss=0.158]\u001b[A\n",
            "Epoch 1:  88%|████████▊ | 427/484 [58:07<07:40,  8.07s/it, training_loss=0.163]\u001b[A\n",
            "Epoch 1:  88%|████████▊ | 428/484 [58:07<07:06,  7.62s/it, training_loss=0.163]\u001b[A\n",
            "Epoch 1:  88%|████████▊ | 428/484 [58:17<07:06,  7.62s/it, training_loss=0.146]\u001b[A\n",
            "Epoch 1:  89%|████████▊ | 429/484 [58:17<07:30,  8.20s/it, training_loss=0.146]\u001b[A\n",
            "Epoch 1:  89%|████████▊ | 429/484 [58:24<07:30,  8.20s/it, training_loss=0.339]\u001b[A\n",
            "Epoch 1:  89%|████████▉ | 430/484 [58:24<06:57,  7.72s/it, training_loss=0.339]\u001b[A\n",
            "Epoch 1:  89%|████████▉ | 430/484 [58:32<06:57,  7.72s/it, training_loss=0.077]\u001b[A\n",
            "Epoch 1:  89%|████████▉ | 431/484 [58:32<06:57,  7.88s/it, training_loss=0.077]\u001b[A\n",
            "Epoch 1:  89%|████████▉ | 431/484 [58:40<06:57,  7.88s/it, training_loss=0.138]\u001b[A\n",
            "Epoch 1:  89%|████████▉ | 432/484 [58:40<06:47,  7.84s/it, training_loss=0.138]\u001b[A\n",
            "Epoch 1:  89%|████████▉ | 432/484 [58:46<06:47,  7.84s/it, training_loss=0.203]\u001b[A\n",
            "Epoch 1:  89%|████████▉ | 433/484 [58:46<06:23,  7.53s/it, training_loss=0.203]\u001b[A\n",
            "Epoch 1:  89%|████████▉ | 433/484 [58:56<06:23,  7.53s/it, training_loss=0.068]\u001b[A\n",
            "Epoch 1:  90%|████████▉ | 434/484 [58:56<06:41,  8.04s/it, training_loss=0.068]\u001b[A\n",
            "Epoch 1:  90%|████████▉ | 434/484 [59:02<06:41,  8.04s/it, training_loss=0.138]\u001b[A\n",
            "Epoch 1:  90%|████████▉ | 435/484 [59:02<06:11,  7.58s/it, training_loss=0.138]\u001b[A\n",
            "Epoch 1:  90%|████████▉ | 435/484 [59:12<06:11,  7.58s/it, training_loss=0.149]\u001b[A\n",
            "Epoch 1:  90%|█████████ | 436/484 [59:12<06:35,  8.25s/it, training_loss=0.149]\u001b[A\n",
            "Epoch 1:  90%|█████████ | 436/484 [59:21<06:35,  8.25s/it, training_loss=0.118]\u001b[A\n",
            "Epoch 1:  90%|█████████ | 437/484 [59:21<06:45,  8.62s/it, training_loss=0.118]\u001b[A\n",
            "Epoch 1:  90%|█████████ | 437/484 [59:28<06:45,  8.62s/it, training_loss=0.352]\u001b[A\n",
            "Epoch 1:  90%|█████████ | 438/484 [59:28<06:10,  8.06s/it, training_loss=0.352]\u001b[A\n",
            "Epoch 1:  90%|█████████ | 438/484 [59:37<06:10,  8.06s/it, training_loss=0.101]\u001b[A\n",
            "Epoch 1:  91%|█████████ | 439/484 [59:37<06:19,  8.42s/it, training_loss=0.101]\u001b[A\n",
            "Epoch 1:  91%|█████████ | 439/484 [59:44<06:19,  8.42s/it, training_loss=0.062]\u001b[A\n",
            "Epoch 1:  91%|█████████ | 440/484 [59:44<05:45,  7.85s/it, training_loss=0.062]\u001b[A\n",
            "Epoch 1:  91%|█████████ | 440/484 [59:53<05:45,  7.85s/it, training_loss=0.180]\u001b[A\n",
            "Epoch 1:  91%|█████████ | 441/484 [59:53<05:59,  8.36s/it, training_loss=0.180]\u001b[A\n",
            "Epoch 1:  91%|█████████ | 441/484 [1:00:00<05:59,  8.36s/it, training_loss=0.112]\u001b[A\n",
            "Epoch 1:  91%|█████████▏| 442/484 [1:00:00<05:29,  7.85s/it, training_loss=0.112]\u001b[A\n",
            "Epoch 1:  91%|█████████▏| 442/484 [1:00:08<05:29,  7.85s/it, training_loss=0.043]\u001b[A\n",
            "Epoch 1:  92%|█████████▏| 443/484 [1:00:08<05:26,  7.98s/it, training_loss=0.043]\u001b[A\n",
            "Epoch 1:  92%|█████████▏| 443/484 [1:00:16<05:26,  7.98s/it, training_loss=0.321]\u001b[A\n",
            "Epoch 1:  92%|█████████▏| 444/484 [1:00:16<05:15,  7.89s/it, training_loss=0.321]\u001b[A\n",
            "Epoch 1:  92%|█████████▏| 444/484 [1:00:23<05:15,  7.89s/it, training_loss=0.281]\u001b[A\n",
            "Epoch 1:  92%|█████████▏| 445/484 [1:00:23<04:55,  7.57s/it, training_loss=0.281]\u001b[A\n",
            "Epoch 1:  92%|█████████▏| 445/484 [1:00:32<04:55,  7.57s/it, training_loss=0.235]\u001b[A\n",
            "Epoch 1:  92%|█████████▏| 446/484 [1:00:32<05:05,  8.05s/it, training_loss=0.235]\u001b[A\n",
            "Epoch 1:  92%|█████████▏| 446/484 [1:00:39<05:05,  8.05s/it, training_loss=0.307]\u001b[A\n",
            "Epoch 1:  92%|█████████▏| 447/484 [1:00:39<04:40,  7.59s/it, training_loss=0.307]\u001b[A\n",
            "Epoch 1:  92%|█████████▏| 447/484 [1:00:48<04:40,  7.59s/it, training_loss=0.270]\u001b[A\n",
            "Epoch 1:  93%|█████████▎| 448/484 [1:00:48<04:54,  8.17s/it, training_loss=0.270]\u001b[A\n",
            "Epoch 1:  93%|█████████▎| 448/484 [1:00:55<04:54,  8.17s/it, training_loss=0.092]\u001b[A\n",
            "Epoch 1:  93%|█████████▎| 449/484 [1:00:55<04:28,  7.68s/it, training_loss=0.092]\u001b[A\n",
            "Epoch 1:  93%|█████████▎| 449/484 [1:01:03<04:28,  7.68s/it, training_loss=0.212]\u001b[A\n",
            "Epoch 1:  93%|█████████▎| 450/484 [1:01:03<04:27,  7.86s/it, training_loss=0.212]\u001b[A\n",
            "Epoch 1:  93%|█████████▎| 450/484 [1:01:11<04:27,  7.86s/it, training_loss=0.299]\u001b[A\n",
            "Epoch 1:  93%|█████████▎| 451/484 [1:01:11<04:17,  7.81s/it, training_loss=0.299]\u001b[A\n",
            "Epoch 1:  93%|█████████▎| 451/484 [1:01:17<04:17,  7.81s/it, training_loss=0.132]\u001b[A\n",
            "Epoch 1:  93%|█████████▎| 452/484 [1:01:17<04:00,  7.50s/it, training_loss=0.132]\u001b[A\n",
            "Epoch 1:  93%|█████████▎| 452/484 [1:01:27<04:00,  7.50s/it, training_loss=0.332]\u001b[A\n",
            "Epoch 1:  94%|█████████▎| 453/484 [1:01:27<04:07,  7.98s/it, training_loss=0.332]\u001b[A\n",
            "Epoch 1:  94%|█████████▎| 453/484 [1:01:33<04:07,  7.98s/it, training_loss=0.095]\u001b[A\n",
            "Epoch 1:  94%|█████████▍| 454/484 [1:01:33<03:46,  7.54s/it, training_loss=0.095]\u001b[A\n",
            "Epoch 1:  94%|█████████▍| 454/484 [1:01:43<03:46,  7.54s/it, training_loss=0.107]\u001b[A\n",
            "Epoch 1:  94%|█████████▍| 455/484 [1:01:43<03:55,  8.13s/it, training_loss=0.107]\u001b[A\n",
            "Epoch 1:  94%|█████████▍| 455/484 [1:01:49<03:55,  8.13s/it, training_loss=0.200]\u001b[A\n",
            "Epoch 1:  94%|█████████▍| 456/484 [1:01:49<03:34,  7.67s/it, training_loss=0.200]\u001b[A\n",
            "Epoch 1:  94%|█████████▍| 456/484 [1:01:57<03:34,  7.67s/it, training_loss=0.190]\u001b[A\n",
            "Epoch 1:  94%|█████████▍| 457/484 [1:01:57<03:32,  7.87s/it, training_loss=0.190]\u001b[A\n",
            "Epoch 1:  94%|█████████▍| 457/484 [1:02:06<03:32,  7.87s/it, training_loss=0.224]\u001b[A\n",
            "Epoch 1:  95%|█████████▍| 458/484 [1:02:06<03:30,  8.09s/it, training_loss=0.224]\u001b[A\n",
            "Epoch 1:  95%|█████████▍| 458/484 [1:02:13<03:30,  8.09s/it, training_loss=0.040]\u001b[A\n",
            "Epoch 1:  95%|█████████▍| 459/484 [1:02:13<03:12,  7.69s/it, training_loss=0.040]\u001b[A\n",
            "Epoch 1:  95%|█████████▍| 459/484 [1:02:22<03:12,  7.69s/it, training_loss=0.367]\u001b[A\n",
            "Epoch 1:  95%|█████████▌| 460/484 [1:02:22<03:15,  8.15s/it, training_loss=0.367]\u001b[A\n",
            "Epoch 1:  95%|█████████▌| 460/484 [1:02:29<03:15,  8.15s/it, training_loss=0.301]\u001b[A\n",
            "Epoch 1:  95%|█████████▌| 461/484 [1:02:29<02:56,  7.68s/it, training_loss=0.301]\u001b[A\n",
            "Epoch 1:  95%|█████████▌| 461/484 [1:02:38<02:56,  7.68s/it, training_loss=0.146]\u001b[A\n",
            "Epoch 1:  95%|█████████▌| 462/484 [1:02:38<03:01,  8.25s/it, training_loss=0.146]\u001b[A\n",
            "Epoch 1:  95%|█████████▌| 462/484 [1:02:45<03:01,  8.25s/it, training_loss=0.133]\u001b[A\n",
            "Epoch 1:  96%|█████████▌| 463/484 [1:02:45<02:42,  7.75s/it, training_loss=0.133]\u001b[A\n",
            "Epoch 1:  96%|█████████▌| 463/484 [1:02:53<02:42,  7.75s/it, training_loss=0.072]\u001b[A\n",
            "Epoch 1:  96%|█████████▌| 464/484 [1:02:53<02:38,  7.90s/it, training_loss=0.072]\u001b[A\n",
            "Epoch 1:  96%|█████████▌| 464/484 [1:03:01<02:38,  7.90s/it, training_loss=0.145]\u001b[A\n",
            "Epoch 1:  96%|█████████▌| 465/484 [1:03:01<02:29,  7.86s/it, training_loss=0.145]\u001b[A\n",
            "Epoch 1:  96%|█████████▌| 465/484 [1:03:08<02:29,  7.86s/it, training_loss=0.157]\u001b[A\n",
            "Epoch 1:  96%|█████████▋| 466/484 [1:03:08<02:15,  7.55s/it, training_loss=0.157]\u001b[A\n",
            "Epoch 1:  96%|█████████▋| 466/484 [1:03:17<02:15,  7.55s/it, training_loss=0.045]\u001b[A\n",
            "Epoch 1:  96%|█████████▋| 467/484 [1:03:17<02:16,  8.06s/it, training_loss=0.045]\u001b[A\n",
            "Epoch 1:  96%|█████████▋| 467/484 [1:03:24<02:16,  8.06s/it, training_loss=0.236]\u001b[A\n",
            "Epoch 1:  97%|█████████▋| 468/484 [1:03:24<02:02,  7.63s/it, training_loss=0.236]\u001b[A\n",
            "Epoch 1:  97%|█████████▋| 468/484 [1:03:33<02:02,  7.63s/it, training_loss=0.420]\u001b[A\n",
            "Epoch 1:  97%|█████████▋| 469/484 [1:03:33<02:03,  8.22s/it, training_loss=0.420]\u001b[A\n",
            "Epoch 1:  97%|█████████▋| 469/484 [1:03:40<02:03,  8.22s/it, training_loss=0.138]\u001b[A\n",
            "Epoch 1:  97%|█████████▋| 470/484 [1:03:40<01:48,  7.74s/it, training_loss=0.138]\u001b[A\n",
            "Epoch 1:  97%|█████████▋| 470/484 [1:03:48<01:48,  7.74s/it, training_loss=0.161]\u001b[A\n",
            "Epoch 1:  97%|█████████▋| 471/484 [1:03:48<01:44,  8.00s/it, training_loss=0.161]\u001b[A\n",
            "Epoch 1:  97%|█████████▋| 471/484 [1:03:58<01:44,  8.00s/it, training_loss=0.146]\u001b[A\n",
            "Epoch 1:  98%|█████████▊| 472/484 [1:03:58<01:40,  8.38s/it, training_loss=0.146]\u001b[A\n",
            "Epoch 1:  98%|█████████▊| 472/484 [1:04:08<01:40,  8.38s/it, training_loss=0.060]\u001b[A\n",
            "Epoch 1:  98%|█████████▊| 473/484 [1:04:08<01:38,  8.93s/it, training_loss=0.060]\u001b[A\n",
            "Epoch 1:  98%|█████████▊| 473/484 [1:04:15<01:38,  8.93s/it, training_loss=0.178]\u001b[A\n",
            "Epoch 1:  98%|█████████▊| 474/484 [1:04:15<01:24,  8.42s/it, training_loss=0.178]\u001b[A\n",
            "Epoch 1:  98%|█████████▊| 474/484 [1:04:23<01:24,  8.42s/it, training_loss=0.111]\u001b[A\n",
            "Epoch 1:  98%|█████████▊| 475/484 [1:04:23<01:13,  8.20s/it, training_loss=0.111]\u001b[A\n",
            "Epoch 1:  98%|█████████▊| 475/484 [1:04:31<01:13,  8.20s/it, training_loss=0.454]\u001b[A\n",
            "Epoch 1:  98%|█████████▊| 476/484 [1:04:31<01:06,  8.25s/it, training_loss=0.454]\u001b[A\n",
            "Epoch 1:  98%|█████████▊| 476/484 [1:04:38<01:06,  8.25s/it, training_loss=0.115]\u001b[A\n",
            "Epoch 1:  99%|█████████▊| 477/484 [1:04:38<00:54,  7.77s/it, training_loss=0.115]\u001b[A\n",
            "Epoch 1:  99%|█████████▊| 477/484 [1:04:47<00:54,  7.77s/it, training_loss=0.076]\u001b[A\n",
            "Epoch 1:  99%|█████████▉| 478/484 [1:04:47<00:50,  8.34s/it, training_loss=0.076]\u001b[A\n",
            "Epoch 1:  99%|█████████▉| 478/484 [1:04:54<00:50,  8.34s/it, training_loss=0.254]\u001b[A\n",
            "Epoch 1:  99%|█████████▉| 479/484 [1:04:54<00:39,  7.83s/it, training_loss=0.254]\u001b[A\n",
            "Epoch 1:  99%|█████████▉| 479/484 [1:05:03<00:39,  7.83s/it, training_loss=0.214]\u001b[A\n",
            "Epoch 1:  99%|█████████▉| 480/484 [1:05:03<00:33,  8.27s/it, training_loss=0.214]\u001b[A\n",
            "Epoch 1:  99%|█████████▉| 480/484 [1:05:10<00:33,  8.27s/it, training_loss=0.177]\u001b[A\n",
            "Epoch 1:  99%|█████████▉| 481/484 [1:05:10<00:23,  7.87s/it, training_loss=0.177]\u001b[A\n",
            "Epoch 1:  99%|█████████▉| 481/484 [1:05:18<00:23,  7.87s/it, training_loss=0.120]\u001b[A\n",
            "Epoch 1: 100%|█████████▉| 482/484 [1:05:18<00:15,  7.88s/it, training_loss=0.120]\u001b[A\n",
            "Epoch 1: 100%|█████████▉| 482/484 [1:05:26<00:15,  7.88s/it, training_loss=0.183]\u001b[A\n",
            "Epoch 1: 100%|█████████▉| 483/484 [1:05:26<00:07,  7.94s/it, training_loss=0.183]\u001b[A\n",
            "Epoch 1: 100%|█████████▉| 483/484 [1:05:32<00:07,  7.94s/it, training_loss=0.224]\u001b[A\n",
            "Epoch 1: 100%|██████████| 484/484 [1:05:32<00:00,  7.13s/it, training_loss=0.224]\u001b[A\n",
            "  0%|          | 0/3 [1:05:34<?, ?it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            " Epoch {epoch}\n",
            "Training loss: {loss_train_avg}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "  0%|          | 0/121 [00:00<?, ?it/s]\u001b[A\n",
            "  1%|          | 1/121 [00:03<06:35,  3.30s/it]\u001b[A\n",
            "  2%|▏         | 2/121 [00:06<06:10,  3.11s/it]\u001b[A\n",
            "  2%|▏         | 3/121 [00:08<05:28,  2.78s/it]\u001b[A\n",
            "  3%|▎         | 4/121 [00:11<05:15,  2.69s/it]\u001b[A\n",
            "  4%|▍         | 5/121 [00:13<05:06,  2.64s/it]\u001b[A\n",
            "  5%|▍         | 6/121 [00:15<04:37,  2.41s/it]\u001b[A\n",
            "  6%|▌         | 7/121 [00:18<04:37,  2.43s/it]\u001b[A\n",
            "  7%|▋         | 8/121 [00:21<05:04,  2.69s/it]\u001b[A\n",
            "  7%|▋         | 9/121 [00:24<05:13,  2.79s/it]\u001b[A\n",
            "  8%|▊         | 10/121 [00:26<04:50,  2.62s/it]\u001b[A\n",
            "  9%|▉         | 11/121 [00:28<04:25,  2.41s/it]\u001b[A\n",
            " 10%|▉         | 12/121 [00:30<04:07,  2.27s/it]\u001b[A\n",
            " 11%|█         | 13/121 [00:32<03:56,  2.19s/it]\u001b[A\n",
            " 12%|█▏        | 14/121 [00:34<03:47,  2.13s/it]\u001b[A\n",
            " 12%|█▏        | 15/121 [00:38<04:43,  2.67s/it]\u001b[A\n",
            " 13%|█▎        | 16/121 [00:43<06:02,  3.45s/it]\u001b[A\n",
            " 14%|█▍        | 17/121 [00:46<05:36,  3.23s/it]\u001b[A\n",
            " 15%|█▍        | 18/121 [00:48<04:53,  2.85s/it]\u001b[A\n",
            " 16%|█▌        | 19/121 [00:50<04:23,  2.58s/it]\u001b[A\n",
            " 17%|█▋        | 20/121 [00:52<04:02,  2.40s/it]\u001b[A\n",
            " 17%|█▋        | 21/121 [00:54<03:46,  2.26s/it]\u001b[A\n",
            " 18%|█▊        | 22/121 [00:56<03:39,  2.22s/it]\u001b[A\n",
            " 19%|█▉        | 23/121 [00:59<04:07,  2.53s/it]\u001b[A\n",
            " 20%|█▉        | 24/121 [01:02<04:21,  2.70s/it]\u001b[A\n",
            " 21%|██        | 25/121 [01:05<04:13,  2.64s/it]\u001b[A\n",
            " 21%|██▏       | 26/121 [01:07<03:51,  2.44s/it]\u001b[A\n",
            " 22%|██▏       | 27/121 [01:09<03:35,  2.29s/it]\u001b[A\n",
            " 23%|██▎       | 28/121 [01:11<03:23,  2.19s/it]\u001b[A\n",
            " 24%|██▍       | 29/121 [01:13<03:14,  2.12s/it]\u001b[A\n",
            " 25%|██▍       | 30/121 [01:15<03:20,  2.20s/it]\u001b[A\n",
            " 26%|██▌       | 31/121 [01:18<03:47,  2.52s/it]\u001b[A\n",
            " 26%|██▋       | 32/121 [01:21<03:58,  2.68s/it]\u001b[A\n",
            " 27%|██▋       | 33/121 [01:24<03:44,  2.56s/it]\u001b[A\n",
            " 28%|██▊       | 34/121 [01:26<03:26,  2.37s/it]\u001b[A\n",
            " 29%|██▉       | 35/121 [01:28<03:13,  2.25s/it]\u001b[A\n",
            " 30%|██▉       | 36/121 [01:29<03:03,  2.16s/it]\u001b[A\n",
            " 31%|███       | 37/121 [01:31<02:56,  2.10s/it]\u001b[A\n",
            " 31%|███▏      | 38/121 [01:34<03:05,  2.24s/it]\u001b[A\n",
            " 32%|███▏      | 39/121 [01:37<03:28,  2.54s/it]\u001b[A\n",
            " 33%|███▎      | 40/121 [01:40<03:36,  2.68s/it]\u001b[A\n",
            " 34%|███▍      | 41/121 [01:42<03:21,  2.51s/it]\u001b[A\n",
            " 35%|███▍      | 42/121 [01:44<03:05,  2.35s/it]\u001b[A\n",
            " 36%|███▌      | 43/121 [01:46<02:53,  2.23s/it]\u001b[A\n",
            " 36%|███▋      | 44/121 [01:48<02:45,  2.15s/it]\u001b[A\n",
            " 37%|███▋      | 45/121 [01:50<02:39,  2.09s/it]\u001b[A\n",
            " 38%|███▊      | 46/121 [01:53<02:54,  2.32s/it]\u001b[A\n",
            " 39%|███▉      | 47/121 [01:56<03:10,  2.58s/it]\u001b[A\n",
            " 40%|███▉      | 48/121 [01:59<03:17,  2.70s/it]\u001b[A\n",
            " 40%|████      | 49/121 [02:01<02:59,  2.49s/it]\u001b[A\n",
            " 41%|████▏     | 50/121 [02:03<02:45,  2.34s/it]\u001b[A\n",
            " 42%|████▏     | 51/121 [02:05<02:36,  2.23s/it]\u001b[A\n",
            " 43%|████▎     | 52/121 [02:07<02:29,  2.16s/it]\u001b[A\n",
            " 44%|████▍     | 53/121 [02:09<02:24,  2.13s/it]\u001b[A\n",
            " 45%|████▍     | 54/121 [02:12<02:45,  2.46s/it]\u001b[A\n",
            " 45%|████▌     | 55/121 [02:16<02:55,  2.66s/it]\u001b[A\n",
            " 46%|████▋     | 56/121 [02:18<02:52,  2.65s/it]\u001b[A\n",
            " 47%|████▋     | 57/121 [02:20<02:37,  2.46s/it]\u001b[A\n",
            " 48%|████▊     | 58/121 [02:22<02:25,  2.31s/it]\u001b[A\n",
            " 49%|████▉     | 59/121 [02:24<02:16,  2.21s/it]\u001b[A\n",
            " 50%|████▉     | 60/121 [02:26<02:10,  2.14s/it]\u001b[A\n",
            " 50%|█████     | 61/121 [02:29<02:12,  2.21s/it]\u001b[A\n",
            " 51%|█████     | 62/121 [02:32<02:29,  2.53s/it]\u001b[A\n",
            " 52%|█████▏    | 63/121 [02:35<02:35,  2.69s/it]\u001b[A\n",
            " 53%|█████▎    | 64/121 [02:37<02:27,  2.58s/it]\u001b[A\n",
            " 54%|█████▎    | 65/121 [02:39<02:14,  2.40s/it]\u001b[A\n",
            " 55%|█████▍    | 66/121 [02:41<02:04,  2.27s/it]\u001b[A\n",
            " 55%|█████▌    | 67/121 [02:43<01:57,  2.18s/it]\u001b[A\n",
            " 56%|█████▌    | 68/121 [02:45<01:52,  2.12s/it]\u001b[A\n",
            " 57%|█████▋    | 69/121 [02:48<01:57,  2.26s/it]\u001b[A\n",
            " 58%|█████▊    | 70/121 [02:51<02:10,  2.55s/it]\u001b[A\n",
            " 59%|█████▊    | 71/121 [02:54<02:14,  2.70s/it]\u001b[A\n",
            " 60%|█████▉    | 72/121 [02:56<02:03,  2.52s/it]\u001b[A\n",
            " 60%|██████    | 73/121 [02:58<01:53,  2.35s/it]\u001b[A\n",
            " 61%|██████    | 74/121 [03:00<01:51,  2.37s/it]\u001b[A\n",
            " 62%|██████▏   | 75/121 [03:04<02:00,  2.62s/it]\u001b[A\n",
            " 63%|██████▎   | 76/121 [03:07<02:06,  2.82s/it]\u001b[A\n",
            " 64%|██████▎   | 77/121 [03:10<02:12,  3.02s/it]\u001b[A\n",
            " 64%|██████▍   | 78/121 [03:14<02:12,  3.08s/it]\u001b[A\n",
            " 65%|██████▌   | 79/121 [03:16<02:04,  2.97s/it]\u001b[A\n",
            " 66%|██████▌   | 80/121 [03:18<01:49,  2.67s/it]\u001b[A\n",
            " 67%|██████▋   | 81/121 [03:20<01:38,  2.47s/it]\u001b[A\n",
            " 68%|██████▊   | 82/121 [03:22<01:30,  2.32s/it]\u001b[A\n",
            " 69%|██████▊   | 83/121 [03:24<01:24,  2.22s/it]\u001b[A\n",
            " 69%|██████▉   | 84/121 [03:27<01:23,  2.25s/it]\u001b[A\n",
            " 70%|███████   | 85/121 [03:30<01:32,  2.56s/it]\u001b[A\n",
            " 71%|███████   | 86/121 [03:33<01:34,  2.71s/it]\u001b[A\n",
            " 72%|███████▏  | 87/121 [03:35<01:29,  2.62s/it]\u001b[A\n",
            " 73%|███████▎  | 88/121 [03:37<01:20,  2.43s/it]\u001b[A\n",
            " 74%|███████▎  | 89/121 [03:39<01:13,  2.30s/it]\u001b[A\n",
            " 74%|███████▍  | 90/121 [03:41<01:08,  2.20s/it]\u001b[A\n",
            " 75%|███████▌  | 91/121 [03:43<01:03,  2.12s/it]\u001b[A\n",
            " 76%|███████▌  | 92/121 [03:46<01:06,  2.30s/it]\u001b[A\n",
            " 77%|███████▋  | 93/121 [03:49<01:12,  2.59s/it]\u001b[A\n",
            " 78%|███████▊  | 94/121 [03:52<01:13,  2.70s/it]\u001b[A\n",
            " 79%|███████▊  | 95/121 [03:54<01:05,  2.52s/it]\u001b[A\n",
            " 79%|███████▉  | 96/121 [03:56<00:59,  2.36s/it]\u001b[A\n",
            " 80%|████████  | 97/121 [03:58<00:53,  2.24s/it]\u001b[A\n",
            " 81%|████████  | 98/121 [04:00<00:49,  2.16s/it]\u001b[A\n",
            " 82%|████████▏ | 99/121 [04:02<00:46,  2.10s/it]\u001b[A\n",
            " 83%|████████▎ | 100/121 [04:05<00:49,  2.36s/it]\u001b[A\n",
            " 83%|████████▎ | 101/121 [04:08<00:52,  2.60s/it]\u001b[A\n",
            " 84%|████████▍ | 102/121 [04:11<00:50,  2.68s/it]\u001b[A\n",
            " 85%|████████▌ | 103/121 [04:13<00:44,  2.46s/it]\u001b[A\n",
            " 86%|████████▌ | 104/121 [04:15<00:39,  2.31s/it]\u001b[A\n",
            " 87%|████████▋ | 105/121 [04:17<00:35,  2.22s/it]\u001b[A\n",
            " 88%|████████▊ | 106/121 [04:19<00:32,  2.14s/it]\u001b[A\n",
            " 88%|████████▊ | 107/121 [04:21<00:29,  2.11s/it]\u001b[A\n",
            " 89%|████████▉ | 108/121 [04:24<00:31,  2.45s/it]\u001b[A\n",
            " 90%|█████████ | 109/121 [04:27<00:31,  2.64s/it]\u001b[A\n",
            " 91%|█████████ | 110/121 [04:30<00:29,  2.64s/it]\u001b[A\n",
            " 92%|█████████▏| 111/121 [04:32<00:24,  2.45s/it]\u001b[A\n",
            " 93%|█████████▎| 112/121 [04:34<00:20,  2.31s/it]\u001b[A\n",
            " 93%|█████████▎| 113/121 [04:36<00:17,  2.21s/it]\u001b[A\n",
            " 94%|█████████▍| 114/121 [04:38<00:15,  2.14s/it]\u001b[A\n",
            " 95%|█████████▌| 115/121 [04:40<00:13,  2.19s/it]\u001b[A\n",
            " 96%|█████████▌| 116/121 [04:44<00:12,  2.51s/it]\u001b[A\n",
            " 97%|█████████▋| 117/121 [04:47<00:10,  2.67s/it]\u001b[A\n",
            " 98%|█████████▊| 118/121 [04:49<00:07,  2.58s/it]\u001b[A\n",
            " 98%|█████████▊| 119/121 [04:51<00:04,  2.40s/it]\u001b[A\n",
            " 99%|█████████▉| 120/121 [04:53<00:02,  2.28s/it]\u001b[A\n",
            "100%|██████████| 121/121 [04:55<00:00,  2.44s/it]\n",
            " 33%|███▎      | 1/3 [1:10:30<2:21:00, 4230.26s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Validation loss: 0.4377836395393718\n",
            "F1 Score (weighted): 0.8233462030823877\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "Epoch 2:   0%|          | 0/484 [00:00<?, ?it/s]\u001b[A\n",
            "Epoch 2:   0%|          | 0/484 [00:09<?, ?it/s, training_loss=0.136]\u001b[A\n",
            "Epoch 2:   0%|          | 1/484 [00:09<1:15:48,  9.42s/it, training_loss=0.136]\u001b[A\n",
            "Epoch 2:   0%|          | 1/484 [00:16<1:15:48,  9.42s/it, training_loss=0.086]\u001b[A\n",
            "Epoch 2:   0%|          | 2/484 [00:16<1:05:25,  8.14s/it, training_loss=0.086]\u001b[A\n",
            "Epoch 2:   0%|          | 2/484 [00:24<1:05:25,  8.14s/it, training_loss=0.115]\u001b[A\n",
            "Epoch 2:   1%|          | 3/484 [00:24<1:03:04,  7.87s/it, training_loss=0.115]\u001b[A\n",
            "Epoch 2:   1%|          | 3/484 [00:32<1:03:04,  7.87s/it, training_loss=0.180]\u001b[A\n",
            "Epoch 2:   1%|          | 4/484 [00:32<1:04:33,  8.07s/it, training_loss=0.180]\u001b[A\n",
            "Epoch 2:   1%|          | 4/484 [00:39<1:04:33,  8.07s/it, training_loss=0.072]\u001b[A\n",
            "Epoch 2:   1%|          | 5/484 [00:39<1:00:19,  7.56s/it, training_loss=0.072]\u001b[A\n",
            "Epoch 2:   1%|          | 5/484 [00:48<1:00:19,  7.56s/it, training_loss=0.085]\u001b[A\n",
            "Epoch 2:   1%|          | 6/484 [00:48<1:05:52,  8.27s/it, training_loss=0.085]\u001b[A\n",
            "Epoch 2:   1%|          | 6/484 [00:55<1:05:52,  8.27s/it, training_loss=0.079]\u001b[A\n",
            "Epoch 2:   1%|▏         | 7/484 [00:55<1:01:34,  7.74s/it, training_loss=0.079]\u001b[A\n",
            "Epoch 2:   1%|▏         | 7/484 [01:04<1:01:34,  7.74s/it, training_loss=0.136]\u001b[A\n",
            "Epoch 2:   2%|▏         | 8/484 [01:04<1:05:32,  8.26s/it, training_loss=0.136]\u001b[A\n",
            "Epoch 2:   2%|▏         | 8/484 [01:11<1:05:32,  8.26s/it, training_loss=0.165]\u001b[A\n",
            "Epoch 2:   2%|▏         | 9/484 [01:11<1:02:05,  7.84s/it, training_loss=0.165]\u001b[A\n",
            "Epoch 2:   2%|▏         | 9/484 [01:19<1:02:05,  7.84s/it, training_loss=0.212]\u001b[A\n",
            "Epoch 2:   2%|▏         | 10/484 [01:19<1:02:25,  7.90s/it, training_loss=0.212]\u001b[A\n",
            "Epoch 2:   2%|▏         | 10/484 [01:27<1:02:25,  7.90s/it, training_loss=0.088]\u001b[A\n",
            "Epoch 2:   2%|▏         | 11/484 [01:27<1:02:40,  7.95s/it, training_loss=0.088]\u001b[A\n",
            "Epoch 2:   2%|▏         | 11/484 [01:34<1:02:40,  7.95s/it, training_loss=0.087]\u001b[A\n",
            "Epoch 2:   2%|▏         | 12/484 [01:34<59:34,  7.57s/it, training_loss=0.087]  \u001b[A\n",
            "Epoch 2:   2%|▏         | 12/484 [01:44<59:34,  7.57s/it, training_loss=0.100]\u001b[A\n",
            "Epoch 2:   3%|▎         | 13/484 [01:44<1:03:47,  8.13s/it, training_loss=0.100]\u001b[A\n",
            "Epoch 2:   3%|▎         | 13/484 [01:50<1:03:47,  8.13s/it, training_loss=0.061]\u001b[A\n",
            "Epoch 2:   3%|▎         | 14/484 [01:50<1:00:01,  7.66s/it, training_loss=0.061]\u001b[A\n",
            "Epoch 2:   3%|▎         | 14/484 [02:00<1:00:01,  7.66s/it, training_loss=0.070]\u001b[A\n",
            "Epoch 2:   3%|▎         | 15/484 [02:00<1:04:09,  8.21s/it, training_loss=0.070]\u001b[A\n",
            "Epoch 2:   3%|▎         | 15/484 [02:06<1:04:09,  8.21s/it, training_loss=0.119]\u001b[A\n",
            "Epoch 2:   3%|▎         | 16/484 [02:06<1:00:23,  7.74s/it, training_loss=0.119]\u001b[A\n",
            "Epoch 2:   3%|▎         | 16/484 [02:15<1:00:23,  7.74s/it, training_loss=0.164]\u001b[A\n",
            "Epoch 2:   4%|▎         | 17/484 [02:15<1:01:34,  7.91s/it, training_loss=0.164]\u001b[A\n",
            "Epoch 2:   4%|▎         | 17/484 [02:22<1:01:34,  7.91s/it, training_loss=0.187]\u001b[A\n",
            "Epoch 2:   4%|▎         | 18/484 [02:22<1:01:15,  7.89s/it, training_loss=0.187]\u001b[A\n",
            "Epoch 2:   4%|▎         | 18/484 [02:29<1:01:15,  7.89s/it, training_loss=0.234]\u001b[A\n",
            "Epoch 2:   4%|▍         | 19/484 [02:29<58:34,  7.56s/it, training_loss=0.234]  \u001b[A\n",
            "Epoch 2:   4%|▍         | 19/484 [02:38<58:34,  7.56s/it, training_loss=0.110]\u001b[A\n",
            "Epoch 2:   4%|▍         | 20/484 [02:38<1:02:21,  8.06s/it, training_loss=0.110]\u001b[A\n",
            "Epoch 2:   4%|▍         | 20/484 [02:45<1:02:21,  8.06s/it, training_loss=0.045]\u001b[A\n",
            "Epoch 2:   4%|▍         | 21/484 [02:45<58:47,  7.62s/it, training_loss=0.045]  \u001b[A\n",
            "Epoch 2:   4%|▍         | 21/484 [02:55<58:47,  7.62s/it, training_loss=0.224]\u001b[A\n",
            "Epoch 2:   5%|▍         | 22/484 [02:56<1:05:16,  8.48s/it, training_loss=0.224]\u001b[A\n",
            "Epoch 2:   5%|▍         | 22/484 [03:04<1:05:16,  8.48s/it, training_loss=0.203]\u001b[A\n",
            "Epoch 2:   5%|▍         | 23/484 [03:04<1:06:12,  8.62s/it, training_loss=0.203]\u001b[A\n",
            "Epoch 2:   5%|▍         | 23/484 [03:11<1:06:12,  8.62s/it, training_loss=0.047]\u001b[A\n",
            "Epoch 2:   5%|▍         | 24/484 [03:11<1:01:27,  8.02s/it, training_loss=0.047]\u001b[A\n",
            "Epoch 2:   5%|▍         | 24/484 [03:21<1:01:27,  8.02s/it, training_loss=0.036]\u001b[A\n",
            "Epoch 2:   5%|▌         | 25/484 [03:21<1:05:17,  8.53s/it, training_loss=0.036]\u001b[A\n",
            "Epoch 2:   5%|▌         | 25/484 [03:27<1:05:17,  8.53s/it, training_loss=0.099]\u001b[A\n",
            "Epoch 2:   5%|▌         | 26/484 [03:27<1:00:50,  7.97s/it, training_loss=0.099]\u001b[A\n",
            "Epoch 2:   5%|▌         | 26/484 [03:36<1:00:50,  7.97s/it, training_loss=0.020]\u001b[A\n",
            "Epoch 2:   6%|▌         | 27/484 [03:37<1:03:09,  8.29s/it, training_loss=0.020]\u001b[A\n",
            "Epoch 2:   6%|▌         | 27/484 [03:44<1:03:09,  8.29s/it, training_loss=0.117]\u001b[A\n",
            "Epoch 2:   6%|▌         | 28/484 [03:44<1:00:32,  7.97s/it, training_loss=0.117]\u001b[A\n",
            "Epoch 2:   6%|▌         | 28/484 [03:51<1:00:32,  7.97s/it, training_loss=0.141]\u001b[A\n",
            "Epoch 2:   6%|▌         | 29/484 [03:51<59:26,  7.84s/it, training_loss=0.141]  \u001b[A\n",
            "Epoch 2:   6%|▌         | 29/484 [04:00<59:26,  7.84s/it, training_loss=0.193]\u001b[A\n",
            "Epoch 2:   6%|▌         | 30/484 [04:00<1:00:40,  8.02s/it, training_loss=0.193]\u001b[A\n",
            "Epoch 2:   6%|▌         | 30/484 [04:06<1:00:40,  8.02s/it, training_loss=0.268]\u001b[A\n",
            "Epoch 2:   6%|▋         | 31/484 [04:06<57:14,  7.58s/it, training_loss=0.268]  \u001b[A\n",
            "Epoch 2:   6%|▋         | 31/484 [04:16<57:14,  7.58s/it, training_loss=0.091]\u001b[A\n",
            "Epoch 2:   7%|▋         | 32/484 [04:16<1:01:42,  8.19s/it, training_loss=0.091]\u001b[A\n",
            "Epoch 2:   7%|▋         | 32/484 [04:22<1:01:42,  8.19s/it, training_loss=0.098]\u001b[A\n",
            "Epoch 2:   7%|▋         | 33/484 [04:22<57:50,  7.69s/it, training_loss=0.098]  \u001b[A\n",
            "Epoch 2:   7%|▋         | 33/484 [04:31<57:50,  7.69s/it, training_loss=0.062]\u001b[A\n",
            "Epoch 2:   7%|▋         | 34/484 [04:31<1:00:49,  8.11s/it, training_loss=0.062]\u001b[A\n",
            "Epoch 2:   7%|▋         | 34/484 [04:38<1:00:49,  8.11s/it, training_loss=0.041]\u001b[A\n",
            "Epoch 2:   7%|▋         | 35/484 [04:38<58:05,  7.76s/it, training_loss=0.041]  \u001b[A\n",
            "Epoch 2:   7%|▋         | 35/484 [04:46<58:05,  7.76s/it, training_loss=0.032]\u001b[A\n",
            "Epoch 2:   7%|▋         | 36/484 [04:46<57:37,  7.72s/it, training_loss=0.032]\u001b[A\n",
            "Epoch 2:   7%|▋         | 36/484 [04:54<57:37,  7.72s/it, training_loss=0.041]\u001b[A\n",
            "Epoch 2:   8%|▊         | 37/484 [04:54<58:52,  7.90s/it, training_loss=0.041]\u001b[A\n",
            "Epoch 2:   8%|▊         | 37/484 [05:01<58:52,  7.90s/it, training_loss=0.054]\u001b[A\n",
            "Epoch 2:   8%|▊         | 38/484 [05:01<55:58,  7.53s/it, training_loss=0.054]\u001b[A\n",
            "Epoch 2:   8%|▊         | 38/484 [05:11<55:58,  7.53s/it, training_loss=0.125]\u001b[A\n",
            "Epoch 2:   8%|▊         | 39/484 [05:11<1:00:29,  8.16s/it, training_loss=0.125]\u001b[A\n",
            "Epoch 2:   8%|▊         | 39/484 [05:17<1:00:29,  8.16s/it, training_loss=0.150]\u001b[A\n",
            "Epoch 2:   8%|▊         | 40/484 [05:17<57:02,  7.71s/it, training_loss=0.150]  \u001b[A\n",
            "Epoch 2:   8%|▊         | 40/484 [05:27<57:02,  7.71s/it, training_loss=0.062]\u001b[A\n",
            "Epoch 2:   8%|▊         | 41/484 [05:27<1:00:27,  8.19s/it, training_loss=0.062]\u001b[A\n",
            "Epoch 2:   8%|▊         | 41/484 [05:33<1:00:27,  8.19s/it, training_loss=0.319]\u001b[A\n",
            "Epoch 2:   9%|▊         | 42/484 [05:33<57:13,  7.77s/it, training_loss=0.319]  \u001b[A\n",
            "Epoch 2:   9%|▊         | 42/484 [05:41<57:13,  7.77s/it, training_loss=0.161]\u001b[A\n",
            "Epoch 2:   9%|▉         | 43/484 [05:41<57:25,  7.81s/it, training_loss=0.161]\u001b[A\n",
            "Epoch 2:   9%|▉         | 43/484 [05:49<57:25,  7.81s/it, training_loss=0.080]\u001b[A\n",
            "Epoch 2:   9%|▉         | 44/484 [05:49<57:41,  7.87s/it, training_loss=0.080]\u001b[A\n",
            "Epoch 2:   9%|▉         | 44/484 [05:56<57:41,  7.87s/it, training_loss=0.037]\u001b[A\n",
            "Epoch 2:   9%|▉         | 45/484 [05:56<54:56,  7.51s/it, training_loss=0.037]\u001b[A\n",
            "Epoch 2:   9%|▉         | 45/484 [06:05<54:56,  7.51s/it, training_loss=0.032]\u001b[A\n",
            "Epoch 2:  10%|▉         | 46/484 [06:05<59:01,  8.08s/it, training_loss=0.032]\u001b[A\n",
            "Epoch 2:  10%|▉         | 46/484 [06:12<59:01,  8.08s/it, training_loss=0.071]\u001b[A\n",
            "Epoch 2:  10%|▉         | 47/484 [06:12<55:43,  7.65s/it, training_loss=0.071]\u001b[A\n",
            "Epoch 2:  10%|▉         | 47/484 [06:22<55:43,  7.65s/it, training_loss=0.154]\u001b[A\n",
            "Epoch 2:  10%|▉         | 48/484 [06:22<59:49,  8.23s/it, training_loss=0.154]\u001b[A\n",
            "Epoch 2:  10%|▉         | 48/484 [06:28<59:49,  8.23s/it, training_loss=0.060]\u001b[A\n",
            "Epoch 2:  10%|█         | 49/484 [06:28<56:33,  7.80s/it, training_loss=0.060]\u001b[A\n",
            "Epoch 2:  10%|█         | 49/484 [06:37<56:33,  7.80s/it, training_loss=0.075]\u001b[A\n",
            "Epoch 2:  10%|█         | 50/484 [06:37<57:27,  7.94s/it, training_loss=0.075]\u001b[A\n",
            "Epoch 2:  10%|█         | 50/484 [06:44<57:27,  7.94s/it, training_loss=0.039]\u001b[A\n",
            "Epoch 2:  11%|█         | 51/484 [06:44<56:55,  7.89s/it, training_loss=0.039]\u001b[A\n",
            "Epoch 2:  11%|█         | 51/484 [06:51<56:55,  7.89s/it, training_loss=0.068]\u001b[A\n",
            "Epoch 2:  11%|█         | 52/484 [06:51<54:36,  7.59s/it, training_loss=0.068]\u001b[A\n",
            "Epoch 2:  11%|█         | 52/484 [07:01<54:36,  7.59s/it, training_loss=0.064]\u001b[A\n",
            "Epoch 2:  11%|█         | 53/484 [07:01<58:01,  8.08s/it, training_loss=0.064]\u001b[A\n",
            "Epoch 2:  11%|█         | 53/484 [07:07<58:01,  8.08s/it, training_loss=0.016]\u001b[A\n",
            "Epoch 2:  11%|█         | 54/484 [07:07<54:46,  7.64s/it, training_loss=0.016]\u001b[A\n",
            "Epoch 2:  11%|█         | 54/484 [07:17<54:46,  7.64s/it, training_loss=0.166]\u001b[A\n",
            "Epoch 2:  11%|█▏        | 55/484 [07:17<58:53,  8.24s/it, training_loss=0.166]\u001b[A\n",
            "Epoch 2:  11%|█▏        | 55/484 [07:24<58:53,  8.24s/it, training_loss=0.063]\u001b[A\n",
            "Epoch 2:  12%|█▏        | 56/484 [07:24<55:24,  7.77s/it, training_loss=0.063]\u001b[A\n",
            "Epoch 2:  12%|█▏        | 56/484 [07:34<55:24,  7.77s/it, training_loss=0.123]\u001b[A\n",
            "Epoch 2:  12%|█▏        | 57/484 [07:34<1:01:51,  8.69s/it, training_loss=0.123]\u001b[A\n",
            "Epoch 2:  12%|█▏        | 57/484 [07:43<1:01:51,  8.69s/it, training_loss=0.099]\u001b[A\n",
            "Epoch 2:  12%|█▏        | 58/484 [07:43<1:01:33,  8.67s/it, training_loss=0.099]\u001b[A\n",
            "Epoch 2:  12%|█▏        | 58/484 [07:50<1:01:33,  8.67s/it, training_loss=0.032]\u001b[A\n",
            "Epoch 2:  12%|█▏        | 59/484 [07:50<56:55,  8.04s/it, training_loss=0.032]  \u001b[A\n",
            "Epoch 2:  12%|█▏        | 59/484 [07:59<56:55,  8.04s/it, training_loss=0.075]\u001b[A\n",
            "Epoch 2:  12%|█▏        | 60/484 [07:59<1:00:18,  8.53s/it, training_loss=0.075]\u001b[A\n",
            "Epoch 2:  12%|█▏        | 60/484 [08:06<1:00:18,  8.53s/it, training_loss=0.021]\u001b[A\n",
            "Epoch 2:  13%|█▎        | 61/484 [08:06<56:02,  7.95s/it, training_loss=0.021]  \u001b[A\n",
            "Epoch 2:  13%|█▎        | 61/484 [08:15<56:02,  7.95s/it, training_loss=0.230]\u001b[A\n",
            "Epoch 2:  13%|█▎        | 62/484 [08:15<58:14,  8.28s/it, training_loss=0.230]\u001b[A\n",
            "Epoch 2:  13%|█▎        | 62/484 [08:22<58:14,  8.28s/it, training_loss=0.084]\u001b[A\n",
            "Epoch 2:  13%|█▎        | 63/484 [08:22<55:32,  7.92s/it, training_loss=0.084]\u001b[A\n",
            "Epoch 2:  13%|█▎        | 63/484 [08:30<55:32,  7.92s/it, training_loss=0.029]\u001b[A\n",
            "Epoch 2:  13%|█▎        | 64/484 [08:30<54:54,  7.84s/it, training_loss=0.029]\u001b[A\n",
            "Epoch 2:  13%|█▎        | 64/484 [08:38<54:54,  7.84s/it, training_loss=0.061]\u001b[A\n",
            "Epoch 2:  13%|█▎        | 65/484 [08:38<55:38,  7.97s/it, training_loss=0.061]\u001b[A\n",
            "Epoch 2:  13%|█▎        | 65/484 [08:44<55:38,  7.97s/it, training_loss=0.122]\u001b[A\n",
            "Epoch 2:  14%|█▎        | 66/484 [08:44<52:32,  7.54s/it, training_loss=0.122]\u001b[A\n",
            "Epoch 2:  14%|█▎        | 66/484 [08:54<52:32,  7.54s/it, training_loss=0.126]\u001b[A\n",
            "Epoch 2:  14%|█▍        | 67/484 [08:54<56:47,  8.17s/it, training_loss=0.126]\u001b[A\n",
            "Epoch 2:  14%|█▍        | 67/484 [09:01<56:47,  8.17s/it, training_loss=0.174]\u001b[A\n",
            "Epoch 2:  14%|█▍        | 68/484 [09:01<53:23,  7.70s/it, training_loss=0.174]\u001b[A\n",
            "Epoch 2:  14%|█▍        | 68/484 [09:10<53:23,  7.70s/it, training_loss=0.022]\u001b[A\n",
            "Epoch 2:  14%|█▍        | 69/484 [09:10<56:32,  8.17s/it, training_loss=0.022]\u001b[A\n",
            "Epoch 2:  14%|█▍        | 69/484 [09:17<56:32,  8.17s/it, training_loss=0.024]\u001b[A\n",
            "Epoch 2:  14%|█▍        | 70/484 [09:17<53:48,  7.80s/it, training_loss=0.024]\u001b[A\n",
            "Epoch 2:  14%|█▍        | 70/484 [09:25<53:48,  7.80s/it, training_loss=0.015]\u001b[A\n",
            "Epoch 2:  15%|█▍        | 71/484 [09:25<53:52,  7.83s/it, training_loss=0.015]\u001b[A\n",
            "Epoch 2:  15%|█▍        | 71/484 [09:33<53:52,  7.83s/it, training_loss=0.146]\u001b[A\n",
            "Epoch 2:  15%|█▍        | 72/484 [09:33<54:12,  7.89s/it, training_loss=0.146]\u001b[A\n",
            "Epoch 2:  15%|█▍        | 72/484 [09:39<54:12,  7.89s/it, training_loss=0.157]\u001b[A\n",
            "Epoch 2:  15%|█▌        | 73/484 [09:39<51:33,  7.53s/it, training_loss=0.157]\u001b[A\n",
            "Epoch 2:  15%|█▌        | 73/484 [09:49<51:33,  7.53s/it, training_loss=0.031]\u001b[A\n",
            "Epoch 2:  15%|█▌        | 74/484 [09:49<55:21,  8.10s/it, training_loss=0.031]\u001b[A\n",
            "Epoch 2:  15%|█▌        | 74/484 [09:55<55:21,  8.10s/it, training_loss=0.213]\u001b[A\n",
            "Epoch 2:  15%|█▌        | 75/484 [09:55<52:02,  7.64s/it, training_loss=0.213]\u001b[A\n",
            "Epoch 2:  15%|█▌        | 75/484 [10:05<52:02,  7.64s/it, training_loss=0.012]\u001b[A\n",
            "Epoch 2:  16%|█▌        | 76/484 [10:05<55:38,  8.18s/it, training_loss=0.012]\u001b[A\n",
            "Epoch 2:  16%|█▌        | 76/484 [10:12<55:38,  8.18s/it, training_loss=0.038]\u001b[A\n",
            "Epoch 2:  16%|█▌        | 77/484 [10:12<52:24,  7.72s/it, training_loss=0.038]\u001b[A\n",
            "Epoch 2:  16%|█▌        | 77/484 [10:20<52:24,  7.72s/it, training_loss=0.025]\u001b[A\n",
            "Epoch 2:  16%|█▌        | 78/484 [10:20<52:49,  7.81s/it, training_loss=0.025]\u001b[A\n",
            "Epoch 2:  16%|█▌        | 78/484 [10:27<52:49,  7.81s/it, training_loss=0.217]\u001b[A\n",
            "Epoch 2:  16%|█▋        | 79/484 [10:28<52:56,  7.84s/it, training_loss=0.217]\u001b[A\n",
            "Epoch 2:  16%|█▋        | 79/484 [10:34<52:56,  7.84s/it, training_loss=0.022]\u001b[A\n",
            "Epoch 2:  17%|█▋        | 80/484 [10:34<50:29,  7.50s/it, training_loss=0.022]\u001b[A\n",
            "Epoch 2:  17%|█▋        | 80/484 [10:44<50:29,  7.50s/it, training_loss=0.025]\u001b[A\n",
            "Epoch 2:  17%|█▋        | 81/484 [10:44<54:05,  8.05s/it, training_loss=0.025]\u001b[A\n",
            "Epoch 2:  17%|█▋        | 81/484 [10:50<54:05,  8.05s/it, training_loss=0.142]\u001b[A\n",
            "Epoch 2:  17%|█▋        | 82/484 [10:50<50:55,  7.60s/it, training_loss=0.142]\u001b[A\n",
            "Epoch 2:  17%|█▋        | 82/484 [11:00<50:55,  7.60s/it, training_loss=0.068]\u001b[A\n",
            "Epoch 2:  17%|█▋        | 83/484 [11:00<54:39,  8.18s/it, training_loss=0.068]\u001b[A\n",
            "Epoch 2:  17%|█▋        | 83/484 [11:06<54:39,  8.18s/it, training_loss=0.112]\u001b[A\n",
            "Epoch 2:  17%|█▋        | 84/484 [11:06<51:25,  7.71s/it, training_loss=0.112]\u001b[A\n",
            "Epoch 2:  17%|█▋        | 84/484 [11:14<51:25,  7.71s/it, training_loss=0.099]\u001b[A\n",
            "Epoch 2:  18%|█▊        | 85/484 [11:14<52:18,  7.87s/it, training_loss=0.099]\u001b[A\n",
            "Epoch 2:  18%|█▊        | 85/484 [11:22<52:18,  7.87s/it, training_loss=0.031]\u001b[A\n",
            "Epoch 2:  18%|█▊        | 86/484 [11:22<51:59,  7.84s/it, training_loss=0.031]\u001b[A\n",
            "Epoch 2:  18%|█▊        | 86/484 [11:29<51:59,  7.84s/it, training_loss=0.063]\u001b[A\n",
            "Epoch 2:  18%|█▊        | 87/484 [11:29<49:40,  7.51s/it, training_loss=0.063]\u001b[A\n",
            "Epoch 2:  18%|█▊        | 87/484 [11:38<49:40,  7.51s/it, training_loss=0.118]\u001b[A\n",
            "Epoch 2:  18%|█▊        | 88/484 [11:38<53:05,  8.05s/it, training_loss=0.118]\u001b[A\n",
            "Epoch 2:  18%|█▊        | 88/484 [11:45<53:05,  8.05s/it, training_loss=0.087]\u001b[A\n",
            "Epoch 2:  18%|█▊        | 89/484 [11:45<50:05,  7.61s/it, training_loss=0.087]\u001b[A\n",
            "Epoch 2:  18%|█▊        | 89/484 [11:54<50:05,  7.61s/it, training_loss=0.101]\u001b[A\n",
            "Epoch 2:  19%|█▊        | 90/484 [11:54<53:49,  8.20s/it, training_loss=0.101]\u001b[A\n",
            "Epoch 2:  19%|█▊        | 90/484 [12:01<53:49,  8.20s/it, training_loss=0.310]\u001b[A\n",
            "Epoch 2:  19%|█▉        | 91/484 [12:01<50:29,  7.71s/it, training_loss=0.310]\u001b[A\n",
            "Epoch 2:  19%|█▉        | 91/484 [12:10<50:29,  7.71s/it, training_loss=0.082]\u001b[A\n",
            "Epoch 2:  19%|█▉        | 92/484 [12:10<52:29,  8.04s/it, training_loss=0.082]\u001b[A\n",
            "Epoch 2:  19%|█▉        | 92/484 [12:20<52:29,  8.04s/it, training_loss=0.110]\u001b[A\n",
            "Epoch 2:  19%|█▉        | 93/484 [12:20<57:07,  8.77s/it, training_loss=0.110]\u001b[A\n",
            "Epoch 2:  19%|█▉        | 93/484 [12:27<57:07,  8.77s/it, training_loss=0.034]\u001b[A\n",
            "Epoch 2:  19%|█▉        | 94/484 [12:27<52:40,  8.10s/it, training_loss=0.034]\u001b[A\n",
            "Epoch 2:  19%|█▉        | 94/484 [12:36<52:40,  8.10s/it, training_loss=0.064]\u001b[A\n",
            "Epoch 2:  20%|█▉        | 95/484 [12:36<53:52,  8.31s/it, training_loss=0.064]\u001b[A\n",
            "Epoch 2:  20%|█▉        | 95/484 [12:43<53:52,  8.31s/it, training_loss=0.079]\u001b[A\n",
            "Epoch 2:  20%|█▉        | 96/484 [12:43<52:03,  8.05s/it, training_loss=0.079]\u001b[A\n",
            "Epoch 2:  20%|█▉        | 96/484 [12:50<52:03,  8.05s/it, training_loss=0.035]\u001b[A\n",
            "Epoch 2:  20%|██        | 97/484 [12:50<50:21,  7.81s/it, training_loss=0.035]\u001b[A\n",
            "Epoch 2:  20%|██        | 97/484 [12:59<50:21,  7.81s/it, training_loss=0.037]\u001b[A\n",
            "Epoch 2:  20%|██        | 98/484 [12:59<52:04,  8.10s/it, training_loss=0.037]\u001b[A\n",
            "Epoch 2:  20%|██        | 98/484 [13:06<52:04,  8.10s/it, training_loss=0.052]\u001b[A\n",
            "Epoch 2:  20%|██        | 99/484 [13:06<49:03,  7.65s/it, training_loss=0.052]\u001b[A\n",
            "Epoch 2:  20%|██        | 99/484 [13:15<49:03,  7.65s/it, training_loss=0.228]\u001b[A\n",
            "Epoch 2:  21%|██        | 100/484 [13:15<52:51,  8.26s/it, training_loss=0.228]\u001b[A\n",
            "Epoch 2:  21%|██        | 100/484 [13:22<52:51,  8.26s/it, training_loss=0.161]\u001b[A\n",
            "Epoch 2:  21%|██        | 101/484 [13:22<49:39,  7.78s/it, training_loss=0.161]\u001b[A\n",
            "Epoch 2:  21%|██        | 101/484 [13:31<49:39,  7.78s/it, training_loss=0.074]\u001b[A\n",
            "Epoch 2:  21%|██        | 102/484 [13:31<51:57,  8.16s/it, training_loss=0.074]\u001b[A\n",
            "Epoch 2:  21%|██        | 102/484 [13:38<51:57,  8.16s/it, training_loss=0.014]\u001b[A\n",
            "Epoch 2:  21%|██▏       | 103/484 [13:38<49:47,  7.84s/it, training_loss=0.014]\u001b[A\n",
            "Epoch 2:  21%|██▏       | 103/484 [13:46<49:47,  7.84s/it, training_loss=0.009]\u001b[A\n",
            "Epoch 2:  21%|██▏       | 104/484 [13:46<49:11,  7.77s/it, training_loss=0.009]\u001b[A\n",
            "Epoch 2:  21%|██▏       | 104/484 [13:54<49:11,  7.77s/it, training_loss=0.041]\u001b[A\n",
            "Epoch 2:  22%|██▏       | 105/484 [13:54<50:14,  7.95s/it, training_loss=0.041]\u001b[A\n",
            "Epoch 2:  22%|██▏       | 105/484 [14:01<50:14,  7.95s/it, training_loss=0.230]\u001b[A\n",
            "Epoch 2:  22%|██▏       | 106/484 [14:01<47:41,  7.57s/it, training_loss=0.230]\u001b[A\n",
            "Epoch 2:  22%|██▏       | 106/484 [14:10<47:41,  7.57s/it, training_loss=0.022]\u001b[A\n",
            "Epoch 2:  22%|██▏       | 107/484 [14:10<51:28,  8.19s/it, training_loss=0.022]\u001b[A\n",
            "Epoch 2:  22%|██▏       | 107/484 [14:17<51:28,  8.19s/it, training_loss=0.021]\u001b[A\n",
            "Epoch 2:  22%|██▏       | 108/484 [14:17<48:23,  7.72s/it, training_loss=0.021]\u001b[A\n",
            "Epoch 2:  22%|██▏       | 108/484 [14:26<48:23,  7.72s/it, training_loss=0.092]\u001b[A\n",
            "Epoch 2:  23%|██▎       | 109/484 [14:26<51:19,  8.21s/it, training_loss=0.092]\u001b[A\n",
            "Epoch 2:  23%|██▎       | 109/484 [14:33<51:19,  8.21s/it, training_loss=0.051]\u001b[A\n",
            "Epoch 2:  23%|██▎       | 110/484 [14:33<48:40,  7.81s/it, training_loss=0.051]\u001b[A\n",
            "Epoch 2:  23%|██▎       | 110/484 [14:41<48:40,  7.81s/it, training_loss=0.027]\u001b[A\n",
            "Epoch 2:  23%|██▎       | 111/484 [14:41<49:07,  7.90s/it, training_loss=0.027]\u001b[A\n",
            "Epoch 2:  23%|██▎       | 111/484 [14:49<49:07,  7.90s/it, training_loss=0.095]\u001b[A\n",
            "Epoch 2:  23%|██▎       | 112/484 [14:49<49:04,  7.92s/it, training_loss=0.095]\u001b[A\n",
            "Epoch 2:  23%|██▎       | 112/484 [14:56<49:04,  7.92s/it, training_loss=0.215]\u001b[A\n",
            "Epoch 2:  23%|██▎       | 113/484 [14:56<46:45,  7.56s/it, training_loss=0.215]\u001b[A\n",
            "Epoch 2:  23%|██▎       | 113/484 [15:06<46:45,  7.56s/it, training_loss=0.023]\u001b[A\n",
            "Epoch 2:  24%|██▎       | 114/484 [15:06<50:02,  8.11s/it, training_loss=0.023]\u001b[A\n",
            "Epoch 2:  24%|██▎       | 114/484 [15:12<50:02,  8.11s/it, training_loss=0.025]\u001b[A\n",
            "Epoch 2:  24%|██▍       | 115/484 [15:12<47:10,  7.67s/it, training_loss=0.025]\u001b[A\n",
            "Epoch 2:  24%|██▍       | 115/484 [15:22<47:10,  7.67s/it, training_loss=0.137]\u001b[A\n",
            "Epoch 2:  24%|██▍       | 116/484 [15:22<50:34,  8.24s/it, training_loss=0.137]\u001b[A\n",
            "Epoch 2:  24%|██▍       | 116/484 [15:28<50:34,  8.24s/it, training_loss=0.019]\u001b[A\n",
            "Epoch 2:  24%|██▍       | 117/484 [15:28<47:22,  7.74s/it, training_loss=0.019]\u001b[A\n",
            "Epoch 2:  24%|██▍       | 117/484 [15:37<47:22,  7.74s/it, training_loss=0.109]\u001b[A\n",
            "Epoch 2:  24%|██▍       | 118/484 [15:37<48:26,  7.94s/it, training_loss=0.109]\u001b[A\n",
            "Epoch 2:  24%|██▍       | 118/484 [15:44<48:26,  7.94s/it, training_loss=0.212]\u001b[A\n",
            "Epoch 2:  25%|██▍       | 119/484 [15:44<47:57,  7.88s/it, training_loss=0.212]\u001b[A\n",
            "Epoch 2:  25%|██▍       | 119/484 [15:51<47:57,  7.88s/it, training_loss=0.092]\u001b[A\n",
            "Epoch 2:  25%|██▍       | 120/484 [15:51<46:09,  7.61s/it, training_loss=0.092]\u001b[A\n",
            "Epoch 2:  25%|██▍       | 120/484 [16:01<46:09,  7.61s/it, training_loss=0.022]\u001b[A\n",
            "Epoch 2:  25%|██▌       | 121/484 [16:01<49:37,  8.20s/it, training_loss=0.022]\u001b[A\n",
            "Epoch 2:  25%|██▌       | 121/484 [16:08<49:37,  8.20s/it, training_loss=0.018]\u001b[A\n",
            "Epoch 2:  25%|██▌       | 122/484 [16:08<46:29,  7.71s/it, training_loss=0.018]\u001b[A\n",
            "Epoch 2:  25%|██▌       | 122/484 [16:17<46:29,  7.71s/it, training_loss=0.020]\u001b[A\n",
            "Epoch 2:  25%|██▌       | 123/484 [16:17<49:42,  8.26s/it, training_loss=0.020]\u001b[A\n",
            "Epoch 2:  25%|██▌       | 123/484 [16:24<49:42,  8.26s/it, training_loss=0.054]\u001b[A\n",
            "Epoch 2:  26%|██▌       | 124/484 [16:24<46:35,  7.76s/it, training_loss=0.054]\u001b[A\n",
            "Epoch 2:  26%|██▌       | 124/484 [16:32<46:35,  7.76s/it, training_loss=0.062]\u001b[A\n",
            "Epoch 2:  26%|██▌       | 125/484 [16:32<48:00,  8.02s/it, training_loss=0.062]\u001b[A\n",
            "Epoch 2:  26%|██▌       | 125/484 [16:40<48:00,  8.02s/it, training_loss=0.123]\u001b[A\n",
            "Epoch 2:  26%|██▌       | 126/484 [16:40<47:00,  7.88s/it, training_loss=0.123]\u001b[A\n",
            "Epoch 2:  26%|██▌       | 126/484 [16:49<47:00,  7.88s/it, training_loss=0.043]\u001b[A\n",
            "Epoch 2:  26%|██▌       | 127/484 [16:49<48:36,  8.17s/it, training_loss=0.043]\u001b[A\n",
            "Epoch 2:  26%|██▌       | 127/484 [16:59<48:36,  8.17s/it, training_loss=0.011]\u001b[A\n",
            "Epoch 2:  26%|██▋       | 128/484 [16:59<52:42,  8.88s/it, training_loss=0.011]\u001b[A\n",
            "Epoch 2:  26%|██▋       | 128/484 [17:06<52:42,  8.88s/it, training_loss=0.012]\u001b[A\n",
            "Epoch 2:  27%|██▋       | 129/484 [17:06<48:27,  8.19s/it, training_loss=0.012]\u001b[A\n",
            "Epoch 2:  27%|██▋       | 129/484 [17:15<48:27,  8.19s/it, training_loss=0.137]\u001b[A\n",
            "Epoch 2:  27%|██▋       | 130/484 [17:15<49:44,  8.43s/it, training_loss=0.137]\u001b[A\n",
            "Epoch 2:  27%|██▋       | 130/484 [17:22<49:44,  8.43s/it, training_loss=0.029]\u001b[A\n",
            "Epoch 2:  27%|██▋       | 131/484 [17:22<47:33,  8.08s/it, training_loss=0.029]\u001b[A\n",
            "Epoch 2:  27%|██▋       | 131/484 [17:30<47:33,  8.08s/it, training_loss=0.289]\u001b[A\n",
            "Epoch 2:  27%|██▋       | 132/484 [17:30<46:31,  7.93s/it, training_loss=0.289]\u001b[A\n",
            "Epoch 2:  27%|██▋       | 132/484 [17:38<46:31,  7.93s/it, training_loss=0.025]\u001b[A\n",
            "Epoch 2:  27%|██▋       | 133/484 [17:38<47:25,  8.11s/it, training_loss=0.025]\u001b[A\n",
            "Epoch 2:  27%|██▋       | 133/484 [17:45<47:25,  8.11s/it, training_loss=0.082]\u001b[A\n",
            "Epoch 2:  28%|██▊       | 134/484 [17:45<44:46,  7.68s/it, training_loss=0.082]\u001b[A\n",
            "Epoch 2:  28%|██▊       | 134/484 [17:55<44:46,  7.68s/it, training_loss=0.116]\u001b[A\n",
            "Epoch 2:  28%|██▊       | 135/484 [17:55<48:10,  8.28s/it, training_loss=0.116]\u001b[A\n",
            "Epoch 2:  28%|██▊       | 135/484 [18:01<48:10,  8.28s/it, training_loss=0.022]\u001b[A\n",
            "Epoch 2:  28%|██▊       | 136/484 [18:01<45:01,  7.76s/it, training_loss=0.022]\u001b[A\n",
            "Epoch 2:  28%|██▊       | 136/484 [18:10<45:01,  7.76s/it, training_loss=0.181]\u001b[A\n",
            "Epoch 2:  28%|██▊       | 137/484 [18:10<47:26,  8.20s/it, training_loss=0.181]\u001b[A\n",
            "Epoch 2:  28%|██▊       | 137/484 [18:17<47:26,  8.20s/it, training_loss=0.308]\u001b[A\n",
            "Epoch 2:  29%|██▊       | 138/484 [18:17<45:13,  7.84s/it, training_loss=0.308]\u001b[A\n",
            "Epoch 2:  29%|██▊       | 138/484 [18:25<45:13,  7.84s/it, training_loss=0.129]\u001b[A\n",
            "Epoch 2:  29%|██▊       | 139/484 [18:25<45:12,  7.86s/it, training_loss=0.129]\u001b[A\n",
            "Epoch 2:  29%|██▊       | 139/484 [18:33<45:12,  7.86s/it, training_loss=0.044]\u001b[A\n",
            "Epoch 2:  29%|██▉       | 140/484 [18:33<45:26,  7.93s/it, training_loss=0.044]\u001b[A\n",
            "Epoch 2:  29%|██▉       | 140/484 [18:40<45:26,  7.93s/it, training_loss=0.177]\u001b[A\n",
            "Epoch 2:  29%|██▉       | 141/484 [18:40<43:23,  7.59s/it, training_loss=0.177]\u001b[A\n",
            "Epoch 2:  29%|██▉       | 141/484 [18:50<43:23,  7.59s/it, training_loss=0.006]\u001b[A\n",
            "Epoch 2:  29%|██▉       | 142/484 [18:50<46:28,  8.15s/it, training_loss=0.006]\u001b[A\n",
            "Epoch 2:  29%|██▉       | 142/484 [18:56<46:28,  8.15s/it, training_loss=0.013]\u001b[A\n",
            "Epoch 2:  30%|██▉       | 143/484 [18:56<43:43,  7.69s/it, training_loss=0.013]\u001b[A\n",
            "Epoch 2:  30%|██▉       | 143/484 [19:06<43:43,  7.69s/it, training_loss=0.061]\u001b[A\n",
            "Epoch 2:  30%|██▉       | 144/484 [19:06<46:39,  8.23s/it, training_loss=0.061]\u001b[A\n",
            "Epoch 2:  30%|██▉       | 144/484 [19:12<46:39,  8.23s/it, training_loss=0.015]\u001b[A\n",
            "Epoch 2:  30%|██▉       | 145/484 [19:12<43:58,  7.78s/it, training_loss=0.015]\u001b[A\n",
            "Epoch 2:  30%|██▉       | 145/484 [19:21<43:58,  7.78s/it, training_loss=0.204]\u001b[A\n",
            "Epoch 2:  30%|███       | 146/484 [19:21<44:41,  7.93s/it, training_loss=0.204]\u001b[A\n",
            "Epoch 2:  30%|███       | 146/484 [19:29<44:41,  7.93s/it, training_loss=0.074]\u001b[A\n",
            "Epoch 2:  30%|███       | 147/484 [19:29<44:20,  7.90s/it, training_loss=0.074]\u001b[A\n",
            "Epoch 2:  30%|███       | 147/484 [19:35<44:20,  7.90s/it, training_loss=0.112]\u001b[A\n",
            "Epoch 2:  31%|███       | 148/484 [19:35<42:33,  7.60s/it, training_loss=0.112]\u001b[A\n",
            "Epoch 2:  31%|███       | 148/484 [19:45<42:33,  7.60s/it, training_loss=0.130]\u001b[A\n",
            "Epoch 2:  31%|███       | 149/484 [19:45<45:05,  8.08s/it, training_loss=0.130]\u001b[A\n",
            "Epoch 2:  31%|███       | 149/484 [19:51<45:05,  8.08s/it, training_loss=0.076]\u001b[A\n",
            "Epoch 2:  31%|███       | 150/484 [19:51<42:23,  7.61s/it, training_loss=0.076]\u001b[A\n",
            "Epoch 2:  31%|███       | 150/484 [20:01<42:23,  7.61s/it, training_loss=0.322]\u001b[A\n",
            "Epoch 2:  31%|███       | 151/484 [20:02<46:43,  8.42s/it, training_loss=0.322]\u001b[A\n",
            "Epoch 2:  31%|███       | 151/484 [20:08<46:43,  8.42s/it, training_loss=0.034]\u001b[A\n",
            "Epoch 2:  31%|███▏      | 152/484 [20:08<43:37,  7.88s/it, training_loss=0.034]\u001b[A\n",
            "Epoch 2:  31%|███▏      | 152/484 [20:17<43:37,  7.88s/it, training_loss=0.177]\u001b[A\n",
            "Epoch 2:  32%|███▏      | 153/484 [20:17<44:38,  8.09s/it, training_loss=0.177]\u001b[A\n",
            "Epoch 2:  32%|███▏      | 153/484 [20:24<44:38,  8.09s/it, training_loss=0.143]\u001b[A\n",
            "Epoch 2:  32%|███▏      | 154/484 [20:24<43:44,  7.95s/it, training_loss=0.143]\u001b[A\n",
            "Epoch 2:  32%|███▏      | 154/484 [20:31<43:44,  7.95s/it, training_loss=0.033]\u001b[A\n",
            "Epoch 2:  32%|███▏      | 155/484 [20:31<41:59,  7.66s/it, training_loss=0.033]\u001b[A\n",
            "Epoch 2:  32%|███▏      | 155/484 [20:40<41:59,  7.66s/it, training_loss=0.239]\u001b[A\n",
            "Epoch 2:  32%|███▏      | 156/484 [20:40<44:08,  8.07s/it, training_loss=0.239]\u001b[A\n",
            "Epoch 2:  32%|███▏      | 156/484 [20:47<44:08,  8.07s/it, training_loss=0.147]\u001b[A\n",
            "Epoch 2:  32%|███▏      | 157/484 [20:47<41:40,  7.65s/it, training_loss=0.147]\u001b[A\n",
            "Epoch 2:  32%|███▏      | 157/484 [20:57<41:40,  7.65s/it, training_loss=0.274]\u001b[A\n",
            "Epoch 2:  33%|███▎      | 158/484 [20:57<44:52,  8.26s/it, training_loss=0.274]\u001b[A\n",
            "Epoch 2:  33%|███▎      | 158/484 [21:03<44:52,  8.26s/it, training_loss=0.168]\u001b[A\n",
            "Epoch 2:  33%|███▎      | 159/484 [21:03<42:01,  7.76s/it, training_loss=0.168]\u001b[A\n",
            "Epoch 2:  33%|███▎      | 159/484 [21:12<42:01,  7.76s/it, training_loss=0.107]\u001b[A\n",
            "Epoch 2:  33%|███▎      | 160/484 [21:12<43:45,  8.10s/it, training_loss=0.107]\u001b[A\n",
            "Epoch 2:  33%|███▎      | 160/484 [21:20<43:45,  8.10s/it, training_loss=0.257]\u001b[A\n",
            "Epoch 2:  33%|███▎      | 161/484 [21:20<42:21,  7.87s/it, training_loss=0.257]\u001b[A\n",
            "Epoch 2:  33%|███▎      | 161/484 [21:28<42:21,  7.87s/it, training_loss=0.177]\u001b[A\n",
            "Epoch 2:  33%|███▎      | 162/484 [21:28<43:27,  8.10s/it, training_loss=0.177]\u001b[A\n",
            "Epoch 2:  33%|███▎      | 162/484 [21:39<43:27,  8.10s/it, training_loss=0.129]\u001b[A\n",
            "Epoch 2:  34%|███▎      | 163/484 [21:39<47:13,  8.83s/it, training_loss=0.129]\u001b[A\n",
            "Epoch 2:  34%|███▎      | 163/484 [21:45<47:13,  8.83s/it, training_loss=0.087]\u001b[A\n",
            "Epoch 2:  34%|███▍      | 164/484 [21:45<43:29,  8.15s/it, training_loss=0.087]\u001b[A\n",
            "Epoch 2:  34%|███▍      | 164/484 [21:54<43:29,  8.15s/it, training_loss=0.022]\u001b[A\n",
            "Epoch 2:  34%|███▍      | 165/484 [21:54<43:42,  8.22s/it, training_loss=0.022]\u001b[A\n",
            "Epoch 2:  34%|███▍      | 165/484 [22:01<43:42,  8.22s/it, training_loss=0.049]\u001b[A\n",
            "Epoch 2:  34%|███▍      | 166/484 [22:01<42:41,  8.05s/it, training_loss=0.049]\u001b[A\n",
            "Epoch 2:  34%|███▍      | 166/484 [22:14<42:41,  8.05s/it, training_loss=0.480]\u001b[A\n",
            "Epoch 2:  35%|███▍      | 167/484 [22:14<50:08,  9.49s/it, training_loss=0.480]\u001b[A\n",
            "Epoch 2:  35%|███▍      | 167/484 [22:21<50:08,  9.49s/it, training_loss=0.135]\u001b[A\n",
            "Epoch 2:  35%|███▍      | 168/484 [22:21<46:20,  8.80s/it, training_loss=0.135]\u001b[A\n",
            "Epoch 2:  35%|███▍      | 168/484 [22:29<46:20,  8.80s/it, training_loss=0.118]\u001b[A\n",
            "Epoch 2:  35%|███▍      | 169/484 [22:29<44:12,  8.42s/it, training_loss=0.118]\u001b[A\n",
            "Epoch 2:  35%|███▍      | 169/484 [22:37<44:12,  8.42s/it, training_loss=0.204]\u001b[A\n",
            "Epoch 2:  35%|███▌      | 170/484 [22:37<43:57,  8.40s/it, training_loss=0.204]\u001b[A\n",
            "Epoch 2:  35%|███▌      | 170/484 [22:44<43:57,  8.40s/it, training_loss=0.183]\u001b[A\n",
            "Epoch 2:  35%|███▌      | 171/484 [22:44<40:57,  7.85s/it, training_loss=0.183]\u001b[A\n",
            "Epoch 2:  35%|███▌      | 171/484 [22:53<40:57,  7.85s/it, training_loss=0.054]\u001b[A\n",
            "Epoch 2:  36%|███▌      | 172/484 [22:53<43:42,  8.40s/it, training_loss=0.054]\u001b[A\n",
            "Epoch 2:  36%|███▌      | 172/484 [23:00<43:42,  8.40s/it, training_loss=0.355]\u001b[A\n",
            "Epoch 2:  36%|███▌      | 173/484 [23:00<40:46,  7.87s/it, training_loss=0.355]\u001b[A\n",
            "Epoch 2:  36%|███▌      | 173/484 [23:09<40:46,  7.87s/it, training_loss=0.117]\u001b[A\n",
            "Epoch 2:  36%|███▌      | 174/484 [23:09<42:54,  8.30s/it, training_loss=0.117]\u001b[A\n",
            "Epoch 2:  36%|███▌      | 174/484 [23:16<42:54,  8.30s/it, training_loss=0.368]\u001b[A\n",
            "Epoch 2:  36%|███▌      | 175/484 [23:16<40:44,  7.91s/it, training_loss=0.368]\u001b[A\n",
            "Epoch 2:  36%|███▌      | 175/484 [23:24<40:44,  7.91s/it, training_loss=0.023]\u001b[A\n",
            "Epoch 2:  36%|███▋      | 176/484 [23:25<40:52,  7.96s/it, training_loss=0.023]\u001b[A\n",
            "Epoch 2:  36%|███▋      | 176/484 [23:33<40:52,  7.96s/it, training_loss=0.013]\u001b[A\n",
            "Epoch 2:  37%|███▋      | 177/484 [23:33<40:50,  7.98s/it, training_loss=0.013]\u001b[A\n",
            "Epoch 2:  37%|███▋      | 177/484 [23:39<40:50,  7.98s/it, training_loss=0.037]\u001b[A\n",
            "Epoch 2:  37%|███▋      | 178/484 [23:39<38:58,  7.64s/it, training_loss=0.037]\u001b[A\n",
            "Epoch 2:  37%|███▋      | 178/484 [23:49<38:58,  7.64s/it, training_loss=0.033]\u001b[A\n",
            "Epoch 2:  37%|███▋      | 179/484 [23:49<41:32,  8.17s/it, training_loss=0.033]\u001b[A\n",
            "Epoch 2:  37%|███▋      | 179/484 [23:55<41:32,  8.17s/it, training_loss=0.022]\u001b[A\n",
            "Epoch 2:  37%|███▋      | 180/484 [23:55<38:56,  7.69s/it, training_loss=0.022]\u001b[A\n",
            "Epoch 2:  37%|███▋      | 180/484 [24:05<38:56,  7.69s/it, training_loss=0.200]\u001b[A\n",
            "Epoch 2:  37%|███▋      | 181/484 [24:05<41:42,  8.26s/it, training_loss=0.200]\u001b[A\n",
            "Epoch 2:  37%|███▋      | 181/484 [24:12<41:42,  8.26s/it, training_loss=0.157]\u001b[A\n",
            "Epoch 2:  38%|███▊      | 182/484 [24:12<39:10,  7.78s/it, training_loss=0.157]\u001b[A\n",
            "Epoch 2:  38%|███▊      | 182/484 [24:20<39:10,  7.78s/it, training_loss=0.030]\u001b[A\n",
            "Epoch 2:  38%|███▊      | 183/484 [24:20<39:42,  7.91s/it, training_loss=0.030]\u001b[A\n",
            "Epoch 2:  38%|███▊      | 183/484 [24:28<39:42,  7.91s/it, training_loss=0.013]\u001b[A\n",
            "Epoch 2:  38%|███▊      | 184/484 [24:28<39:20,  7.87s/it, training_loss=0.013]\u001b[A\n",
            "Epoch 2:  38%|███▊      | 184/484 [24:34<39:20,  7.87s/it, training_loss=0.039]\u001b[A\n",
            "Epoch 2:  38%|███▊      | 185/484 [24:34<37:34,  7.54s/it, training_loss=0.039]\u001b[A\n",
            "Epoch 2:  38%|███▊      | 185/484 [24:44<37:34,  7.54s/it, training_loss=0.087]\u001b[A\n",
            "Epoch 2:  38%|███▊      | 186/484 [24:44<39:59,  8.05s/it, training_loss=0.087]\u001b[A\n",
            "Epoch 2:  38%|███▊      | 186/484 [24:50<39:59,  8.05s/it, training_loss=0.016]\u001b[A\n",
            "Epoch 2:  39%|███▊      | 187/484 [24:50<37:35,  7.59s/it, training_loss=0.016]\u001b[A\n",
            "Epoch 2:  39%|███▊      | 187/484 [25:00<37:35,  7.59s/it, training_loss=0.120]\u001b[A\n",
            "Epoch 2:  39%|███▉      | 188/484 [25:00<40:13,  8.15s/it, training_loss=0.120]\u001b[A\n",
            "Epoch 2:  39%|███▉      | 188/484 [25:06<40:13,  8.15s/it, training_loss=0.025]\u001b[A\n",
            "Epoch 2:  39%|███▉      | 189/484 [25:06<38:02,  7.74s/it, training_loss=0.025]\u001b[A\n",
            "Epoch 2:  39%|███▉      | 189/484 [25:15<38:02,  7.74s/it, training_loss=0.023]\u001b[A\n",
            "Epoch 2:  39%|███▉      | 190/484 [25:15<38:54,  7.94s/it, training_loss=0.023]\u001b[A\n",
            "Epoch 2:  39%|███▉      | 190/484 [25:23<38:54,  7.94s/it, training_loss=0.145]\u001b[A\n",
            "Epoch 2:  39%|███▉      | 191/484 [25:23<38:31,  7.89s/it, training_loss=0.145]\u001b[A\n",
            "Epoch 2:  39%|███▉      | 191/484 [25:30<38:31,  7.89s/it, training_loss=0.122]\u001b[A\n",
            "Epoch 2:  40%|███▉      | 192/484 [25:30<37:01,  7.61s/it, training_loss=0.122]\u001b[A\n",
            "Epoch 2:  40%|███▉      | 192/484 [25:39<37:01,  7.61s/it, training_loss=0.259]\u001b[A\n",
            "Epoch 2:  40%|███▉      | 193/484 [25:39<39:02,  8.05s/it, training_loss=0.259]\u001b[A\n",
            "Epoch 2:  40%|███▉      | 193/484 [25:45<39:02,  8.05s/it, training_loss=0.024]\u001b[A\n",
            "Epoch 2:  40%|████      | 194/484 [25:45<36:50,  7.62s/it, training_loss=0.024]\u001b[A\n",
            "Epoch 2:  40%|████      | 194/484 [25:55<36:50,  7.62s/it, training_loss=0.035]\u001b[A\n",
            "Epoch 2:  40%|████      | 195/484 [25:55<39:38,  8.23s/it, training_loss=0.035]\u001b[A\n",
            "Epoch 2:  40%|████      | 195/484 [26:01<39:38,  8.23s/it, training_loss=0.126]\u001b[A\n",
            "Epoch 2:  40%|████      | 196/484 [26:01<37:06,  7.73s/it, training_loss=0.126]\u001b[A\n",
            "Epoch 2:  40%|████      | 196/484 [26:12<37:06,  7.73s/it, training_loss=0.290]\u001b[A\n",
            "Epoch 2:  41%|████      | 197/484 [26:12<41:32,  8.69s/it, training_loss=0.290]\u001b[A\n",
            "Epoch 2:  41%|████      | 197/484 [26:21<41:32,  8.69s/it, training_loss=0.165]\u001b[A\n",
            "Epoch 2:  41%|████      | 198/484 [26:21<41:01,  8.61s/it, training_loss=0.165]\u001b[A\n",
            "Epoch 2:  41%|████      | 198/484 [26:27<41:01,  8.61s/it, training_loss=0.122]\u001b[A\n",
            "Epoch 2:  41%|████      | 199/484 [26:27<38:00,  8.00s/it, training_loss=0.122]\u001b[A\n",
            "Epoch 2:  41%|████      | 199/484 [26:37<38:00,  8.00s/it, training_loss=0.020]\u001b[A\n",
            "Epoch 2:  41%|████▏     | 200/484 [26:37<40:11,  8.49s/it, training_loss=0.020]\u001b[A\n",
            "Epoch 2:  41%|████▏     | 200/484 [26:44<40:11,  8.49s/it, training_loss=0.231]\u001b[A\n",
            "Epoch 2:  42%|████▏     | 201/484 [26:44<37:21,  7.92s/it, training_loss=0.231]\u001b[A\n",
            "Epoch 2:  42%|████▏     | 201/484 [26:53<37:21,  7.92s/it, training_loss=0.066]\u001b[A\n",
            "Epoch 2:  42%|████▏     | 202/484 [26:53<39:00,  8.30s/it, training_loss=0.066]\u001b[A\n",
            "Epoch 2:  42%|████▏     | 202/484 [27:00<39:00,  8.30s/it, training_loss=0.031]\u001b[A\n",
            "Epoch 2:  42%|████▏     | 203/484 [27:00<36:54,  7.88s/it, training_loss=0.031]\u001b[A\n",
            "Epoch 2:  42%|████▏     | 203/484 [27:07<36:54,  7.88s/it, training_loss=0.079]\u001b[A\n",
            "Epoch 2:  42%|████▏     | 204/484 [27:07<36:39,  7.85s/it, training_loss=0.079]\u001b[A\n",
            "Epoch 2:  42%|████▏     | 204/484 [27:16<36:39,  7.85s/it, training_loss=0.140]\u001b[A\n",
            "Epoch 2:  42%|████▏     | 205/484 [27:16<36:57,  7.95s/it, training_loss=0.140]\u001b[A\n",
            "Epoch 2:  42%|████▏     | 205/484 [27:22<36:57,  7.95s/it, training_loss=0.062]\u001b[A\n",
            "Epoch 2:  43%|████▎     | 206/484 [27:22<34:56,  7.54s/it, training_loss=0.062]\u001b[A\n",
            "Epoch 2:  43%|████▎     | 206/484 [27:32<34:56,  7.54s/it, training_loss=0.145]\u001b[A\n",
            "Epoch 2:  43%|████▎     | 207/484 [27:32<37:41,  8.16s/it, training_loss=0.145]\u001b[A\n",
            "Epoch 2:  43%|████▎     | 207/484 [27:38<37:41,  8.16s/it, training_loss=0.015]\u001b[A\n",
            "Epoch 2:  43%|████▎     | 208/484 [27:38<35:26,  7.70s/it, training_loss=0.015]\u001b[A\n",
            "Epoch 2:  43%|████▎     | 208/484 [27:48<35:26,  7.70s/it, training_loss=0.010]\u001b[A\n",
            "Epoch 2:  43%|████▎     | 209/484 [27:48<37:26,  8.17s/it, training_loss=0.010]\u001b[A\n",
            "Epoch 2:  43%|████▎     | 209/484 [27:55<37:26,  8.17s/it, training_loss=0.069]\u001b[A\n",
            "Epoch 2:  43%|████▎     | 210/484 [27:55<35:33,  7.79s/it, training_loss=0.069]\u001b[A\n",
            "Epoch 2:  43%|████▎     | 210/484 [28:03<35:33,  7.79s/it, training_loss=0.376]\u001b[A\n",
            "Epoch 2:  44%|████▎     | 211/484 [28:03<35:35,  7.82s/it, training_loss=0.376]\u001b[A\n",
            "Epoch 2:  44%|████▎     | 211/484 [28:11<35:35,  7.82s/it, training_loss=0.010]\u001b[A\n",
            "Epoch 2:  44%|████▍     | 212/484 [28:11<35:46,  7.89s/it, training_loss=0.010]\u001b[A\n",
            "Epoch 2:  44%|████▍     | 212/484 [28:17<35:46,  7.89s/it, training_loss=0.013]\u001b[A\n",
            "Epoch 2:  44%|████▍     | 213/484 [28:17<34:00,  7.53s/it, training_loss=0.013]\u001b[A\n",
            "Epoch 2:  44%|████▍     | 213/484 [28:27<34:00,  7.53s/it, training_loss=0.054]\u001b[A\n",
            "Epoch 2:  44%|████▍     | 214/484 [28:27<36:29,  8.11s/it, training_loss=0.054]\u001b[A\n",
            "Epoch 2:  44%|████▍     | 214/484 [28:33<36:29,  8.11s/it, training_loss=0.061]\u001b[A\n",
            "Epoch 2:  44%|████▍     | 215/484 [28:33<34:14,  7.64s/it, training_loss=0.061]\u001b[A\n",
            "Epoch 2:  44%|████▍     | 215/484 [28:43<34:14,  7.64s/it, training_loss=0.016]\u001b[A\n",
            "Epoch 2:  45%|████▍     | 216/484 [28:43<36:20,  8.14s/it, training_loss=0.016]\u001b[A\n",
            "Epoch 2:  45%|████▍     | 216/484 [28:49<36:20,  8.14s/it, training_loss=0.010]\u001b[A\n",
            "Epoch 2:  45%|████▍     | 217/484 [28:49<34:23,  7.73s/it, training_loss=0.010]\u001b[A\n",
            "Epoch 2:  45%|████▍     | 217/484 [28:57<34:23,  7.73s/it, training_loss=0.192]\u001b[A\n",
            "Epoch 2:  45%|████▌     | 218/484 [28:57<34:33,  7.80s/it, training_loss=0.192]\u001b[A\n",
            "Epoch 2:  45%|████▌     | 218/484 [29:05<34:33,  7.80s/it, training_loss=0.008]\u001b[A\n",
            "Epoch 2:  45%|████▌     | 219/484 [29:05<34:41,  7.85s/it, training_loss=0.008]\u001b[A\n",
            "Epoch 2:  45%|████▌     | 219/484 [29:12<34:41,  7.85s/it, training_loss=0.012]\u001b[A\n",
            "Epoch 2:  45%|████▌     | 220/484 [29:12<33:00,  7.50s/it, training_loss=0.012]\u001b[A\n",
            "Epoch 2:  45%|████▌     | 220/484 [29:21<33:00,  7.50s/it, training_loss=0.065]\u001b[A\n",
            "Epoch 2:  46%|████▌     | 221/484 [29:21<35:25,  8.08s/it, training_loss=0.065]\u001b[A\n",
            "Epoch 2:  46%|████▌     | 221/484 [29:28<35:25,  8.08s/it, training_loss=0.186]\u001b[A\n",
            "Epoch 2:  46%|████▌     | 222/484 [29:28<33:16,  7.62s/it, training_loss=0.186]\u001b[A\n",
            "Epoch 2:  46%|████▌     | 222/484 [29:37<33:16,  7.62s/it, training_loss=0.013]\u001b[A\n",
            "Epoch 2:  46%|████▌     | 223/484 [29:37<35:28,  8.16s/it, training_loss=0.013]\u001b[A\n",
            "Epoch 2:  46%|████▌     | 223/484 [29:44<35:28,  8.16s/it, training_loss=0.021]\u001b[A\n",
            "Epoch 2:  46%|████▋     | 224/484 [29:44<33:32,  7.74s/it, training_loss=0.021]\u001b[A\n",
            "Epoch 2:  46%|████▋     | 224/484 [29:52<33:32,  7.74s/it, training_loss=0.013]\u001b[A\n",
            "Epoch 2:  46%|████▋     | 225/484 [29:52<33:57,  7.87s/it, training_loss=0.013]\u001b[A\n",
            "Epoch 2:  46%|████▋     | 225/484 [30:00<33:57,  7.87s/it, training_loss=0.017]\u001b[A\n",
            "Epoch 2:  47%|████▋     | 226/484 [30:00<33:43,  7.84s/it, training_loss=0.017]\u001b[A\n",
            "Epoch 2:  47%|████▋     | 226/484 [30:07<33:43,  7.84s/it, training_loss=0.015]\u001b[A\n",
            "Epoch 2:  47%|████▋     | 227/484 [30:07<32:08,  7.50s/it, training_loss=0.015]\u001b[A\n",
            "Epoch 2:  47%|████▋     | 227/484 [30:16<32:08,  7.50s/it, training_loss=0.122]\u001b[A\n",
            "Epoch 2:  47%|████▋     | 228/484 [30:16<34:19,  8.05s/it, training_loss=0.122]\u001b[A\n",
            "Epoch 2:  47%|████▋     | 228/484 [30:23<34:19,  8.05s/it, training_loss=0.020]\u001b[A\n",
            "Epoch 2:  47%|████▋     | 229/484 [30:23<32:19,  7.61s/it, training_loss=0.020]\u001b[A\n",
            "Epoch 2:  47%|████▋     | 229/484 [30:32<32:19,  7.61s/it, training_loss=0.052]\u001b[A\n",
            "Epoch 2:  48%|████▊     | 230/484 [30:32<34:42,  8.20s/it, training_loss=0.052]\u001b[A\n",
            "Epoch 2:  48%|████▊     | 230/484 [30:39<34:42,  8.20s/it, training_loss=0.337]\u001b[A\n",
            "Epoch 2:  48%|████▊     | 231/484 [30:39<32:57,  7.82s/it, training_loss=0.337]\u001b[A\n",
            "Epoch 2:  48%|████▊     | 231/484 [30:50<32:57,  7.82s/it, training_loss=0.119]\u001b[A\n",
            "Epoch 2:  48%|████▊     | 232/484 [30:50<37:04,  8.83s/it, training_loss=0.119]\u001b[A\n",
            "Epoch 2:  48%|████▊     | 232/484 [30:58<37:04,  8.83s/it, training_loss=0.390]\u001b[A\n",
            "Epoch 2:  48%|████▊     | 233/484 [30:58<35:36,  8.51s/it, training_loss=0.390]\u001b[A\n",
            "Epoch 2:  48%|████▊     | 233/484 [31:05<35:36,  8.51s/it, training_loss=0.013]\u001b[A\n",
            "Epoch 2:  48%|████▊     | 234/484 [31:05<33:34,  8.06s/it, training_loss=0.013]\u001b[A\n",
            "Epoch 2:  48%|████▊     | 234/484 [31:14<33:34,  8.06s/it, training_loss=0.152]\u001b[A\n",
            "Epoch 2:  49%|████▊     | 235/484 [31:14<34:36,  8.34s/it, training_loss=0.152]\u001b[A\n",
            "Epoch 2:  49%|████▊     | 235/484 [31:21<34:36,  8.34s/it, training_loss=0.102]\u001b[A\n",
            "Epoch 2:  49%|████▉     | 236/484 [31:21<32:20,  7.82s/it, training_loss=0.102]\u001b[A\n",
            "Epoch 2:  49%|████▉     | 236/484 [31:30<32:20,  7.82s/it, training_loss=0.236]\u001b[A\n",
            "Epoch 2:  49%|████▉     | 237/484 [31:30<34:31,  8.38s/it, training_loss=0.236]\u001b[A\n",
            "Epoch 2:  49%|████▉     | 237/484 [31:37<34:31,  8.38s/it, training_loss=0.059]\u001b[A\n",
            "Epoch 2:  49%|████▉     | 238/484 [31:37<32:10,  7.85s/it, training_loss=0.059]\u001b[A\n",
            "Epoch 2:  49%|████▉     | 238/484 [31:46<32:10,  7.85s/it, training_loss=0.013]\u001b[A\n",
            "Epoch 2:  49%|████▉     | 239/484 [31:46<33:13,  8.14s/it, training_loss=0.013]\u001b[A\n",
            "Epoch 2:  49%|████▉     | 239/484 [31:53<33:13,  8.14s/it, training_loss=0.239]\u001b[A\n",
            "Epoch 2:  50%|████▉     | 240/484 [31:53<32:12,  7.92s/it, training_loss=0.239]\u001b[A\n",
            "Epoch 2:  50%|████▉     | 240/484 [32:01<32:12,  7.92s/it, training_loss=0.062]\u001b[A\n",
            "Epoch 2:  50%|████▉     | 241/484 [32:01<31:30,  7.78s/it, training_loss=0.062]\u001b[A\n",
            "Epoch 2:  50%|████▉     | 241/484 [32:09<31:30,  7.78s/it, training_loss=0.063]\u001b[A\n",
            "Epoch 2:  50%|█████     | 242/484 [32:09<32:23,  8.03s/it, training_loss=0.063]\u001b[A\n",
            "Epoch 2:  50%|█████     | 242/484 [32:16<32:23,  8.03s/it, training_loss=0.019]\u001b[A\n",
            "Epoch 2:  50%|█████     | 243/484 [32:16<30:32,  7.61s/it, training_loss=0.019]\u001b[A\n",
            "Epoch 2:  50%|█████     | 243/484 [32:26<30:32,  7.61s/it, training_loss=0.320]\u001b[A\n",
            "Epoch 2:  50%|█████     | 244/484 [32:26<32:55,  8.23s/it, training_loss=0.320]\u001b[A\n",
            "Epoch 2:  50%|█████     | 244/484 [32:32<32:55,  8.23s/it, training_loss=0.068]\u001b[A\n",
            "Epoch 2:  51%|█████     | 245/484 [32:32<30:51,  7.75s/it, training_loss=0.068]\u001b[A\n",
            "Epoch 2:  51%|█████     | 245/484 [32:41<30:51,  7.75s/it, training_loss=0.206]\u001b[A\n",
            "Epoch 2:  51%|█████     | 246/484 [32:41<32:15,  8.13s/it, training_loss=0.206]\u001b[A\n",
            "Epoch 2:  51%|█████     | 246/484 [32:48<32:15,  8.13s/it, training_loss=0.033]\u001b[A\n",
            "Epoch 2:  51%|█████     | 247/484 [32:48<30:54,  7.82s/it, training_loss=0.033]\u001b[A\n",
            "Epoch 2:  51%|█████     | 247/484 [32:56<30:54,  7.82s/it, training_loss=0.013]\u001b[A\n",
            "Epoch 2:  51%|█████     | 248/484 [32:56<30:25,  7.74s/it, training_loss=0.013]\u001b[A\n",
            "Epoch 2:  51%|█████     | 248/484 [33:04<30:25,  7.74s/it, training_loss=0.124]\u001b[A\n",
            "Epoch 2:  51%|█████▏    | 249/484 [33:04<31:08,  7.95s/it, training_loss=0.124]\u001b[A\n",
            "Epoch 2:  51%|█████▏    | 249/484 [33:11<31:08,  7.95s/it, training_loss=0.083]\u001b[A\n",
            "Epoch 2:  52%|█████▏    | 250/484 [33:11<29:22,  7.53s/it, training_loss=0.083]\u001b[A\n",
            "Epoch 2:  52%|█████▏    | 250/484 [33:21<29:22,  7.53s/it, training_loss=0.227]\u001b[A\n",
            "Epoch 2:  52%|█████▏    | 251/484 [33:21<31:42,  8.17s/it, training_loss=0.227]\u001b[A\n",
            "Epoch 2:  52%|█████▏    | 251/484 [33:27<31:42,  8.17s/it, training_loss=0.058]\u001b[A\n",
            "Epoch 2:  52%|█████▏    | 252/484 [33:27<29:48,  7.71s/it, training_loss=0.058]\u001b[A\n",
            "Epoch 2:  52%|█████▏    | 252/484 [33:36<29:48,  7.71s/it, training_loss=0.144]\u001b[A\n",
            "Epoch 2:  52%|█████▏    | 253/484 [33:36<31:24,  8.16s/it, training_loss=0.144]\u001b[A\n",
            "Epoch 2:  52%|█████▏    | 253/484 [33:43<31:24,  8.16s/it, training_loss=0.018]\u001b[A\n",
            "Epoch 2:  52%|█████▏    | 254/484 [33:43<29:53,  7.80s/it, training_loss=0.018]\u001b[A\n",
            "Epoch 2:  52%|█████▏    | 254/484 [33:51<29:53,  7.80s/it, training_loss=0.109]\u001b[A\n",
            "Epoch 2:  53%|█████▎    | 255/484 [33:51<29:55,  7.84s/it, training_loss=0.109]\u001b[A\n",
            "Epoch 2:  53%|█████▎    | 255/484 [33:59<29:55,  7.84s/it, training_loss=0.083]\u001b[A\n",
            "Epoch 2:  53%|█████▎    | 256/484 [33:59<30:04,  7.91s/it, training_loss=0.083]\u001b[A\n",
            "Epoch 2:  53%|█████▎    | 256/484 [34:06<30:04,  7.91s/it, training_loss=0.072]\u001b[A\n",
            "Epoch 2:  53%|█████▎    | 257/484 [34:06<28:31,  7.54s/it, training_loss=0.072]\u001b[A\n",
            "Epoch 2:  53%|█████▎    | 257/484 [34:16<28:31,  7.54s/it, training_loss=0.160]\u001b[A\n",
            "Epoch 2:  53%|█████▎    | 258/484 [34:16<30:33,  8.11s/it, training_loss=0.160]\u001b[A\n",
            "Epoch 2:  53%|█████▎    | 258/484 [34:22<30:33,  8.11s/it, training_loss=0.022]\u001b[A\n",
            "Epoch 2:  54%|█████▎    | 259/484 [34:22<28:44,  7.66s/it, training_loss=0.022]\u001b[A\n",
            "Epoch 2:  54%|█████▎    | 259/484 [34:32<28:44,  7.66s/it, training_loss=0.100]\u001b[A\n",
            "Epoch 2:  54%|█████▎    | 260/484 [34:32<30:35,  8.19s/it, training_loss=0.100]\u001b[A\n",
            "Epoch 2:  54%|█████▎    | 260/484 [34:38<30:35,  8.19s/it, training_loss=0.148]\u001b[A\n",
            "Epoch 2:  54%|█████▍    | 261/484 [34:38<28:52,  7.77s/it, training_loss=0.148]\u001b[A\n",
            "Epoch 2:  54%|█████▍    | 261/484 [34:47<28:52,  7.77s/it, training_loss=0.097]\u001b[A\n",
            "Epoch 2:  54%|█████▍    | 262/484 [34:47<29:12,  7.90s/it, training_loss=0.097]\u001b[A\n",
            "Epoch 2:  54%|█████▍    | 262/484 [34:54<29:12,  7.90s/it, training_loss=0.038]\u001b[A\n",
            "Epoch 2:  54%|█████▍    | 263/484 [34:54<29:01,  7.88s/it, training_loss=0.038]\u001b[A\n",
            "Epoch 2:  54%|█████▍    | 263/484 [35:01<29:01,  7.88s/it, training_loss=0.333]\u001b[A\n",
            "Epoch 2:  55%|█████▍    | 264/484 [35:01<27:38,  7.54s/it, training_loss=0.333]\u001b[A\n",
            "Epoch 2:  55%|█████▍    | 264/484 [35:10<27:38,  7.54s/it, training_loss=0.305]\u001b[A\n",
            "Epoch 2:  55%|█████▍    | 265/484 [35:10<29:30,  8.08s/it, training_loss=0.305]\u001b[A\n",
            "Epoch 2:  55%|█████▍    | 265/484 [35:19<29:30,  8.08s/it, training_loss=0.233]\u001b[A\n",
            "Epoch 2:  55%|█████▍    | 266/484 [35:19<29:41,  8.17s/it, training_loss=0.233]\u001b[A\n",
            "Epoch 2:  55%|█████▍    | 266/484 [35:30<29:41,  8.17s/it, training_loss=0.047]\u001b[A\n",
            "Epoch 2:  55%|█████▌    | 267/484 [35:30<32:35,  9.01s/it, training_loss=0.047]\u001b[A\n",
            "Epoch 2:  55%|█████▌    | 267/484 [35:36<32:35,  9.01s/it, training_loss=0.010]\u001b[A\n",
            "Epoch 2:  55%|█████▌    | 268/484 [35:36<29:52,  8.30s/it, training_loss=0.010]\u001b[A\n",
            "Epoch 2:  55%|█████▌    | 268/484 [35:45<29:52,  8.30s/it, training_loss=0.052]\u001b[A\n",
            "Epoch 2:  56%|█████▌    | 269/484 [35:45<29:45,  8.31s/it, training_loss=0.052]\u001b[A\n",
            "Epoch 2:  56%|█████▌    | 269/484 [35:53<29:45,  8.31s/it, training_loss=0.018]\u001b[A\n",
            "Epoch 2:  56%|█████▌    | 270/484 [35:53<29:00,  8.13s/it, training_loss=0.018]\u001b[A\n",
            "Epoch 2:  56%|█████▌    | 270/484 [35:59<29:00,  8.13s/it, training_loss=0.030]\u001b[A\n",
            "Epoch 2:  56%|█████▌    | 271/484 [35:59<27:22,  7.71s/it, training_loss=0.030]\u001b[A\n",
            "Epoch 2:  56%|█████▌    | 271/484 [36:08<27:22,  7.71s/it, training_loss=0.200]\u001b[A\n",
            "Epoch 2:  56%|█████▌    | 272/484 [36:08<28:50,  8.16s/it, training_loss=0.200]\u001b[A\n",
            "Epoch 2:  56%|█████▌    | 272/484 [36:15<28:50,  8.16s/it, training_loss=0.016]\u001b[A\n",
            "Epoch 2:  56%|█████▋    | 273/484 [36:15<27:04,  7.70s/it, training_loss=0.016]\u001b[A\n",
            "Epoch 2:  56%|█████▋    | 273/484 [36:25<27:04,  7.70s/it, training_loss=0.053]\u001b[A\n",
            "Epoch 2:  57%|█████▋    | 274/484 [36:25<29:01,  8.29s/it, training_loss=0.053]\u001b[A\n",
            "Epoch 2:  57%|█████▋    | 274/484 [36:31<29:01,  8.29s/it, training_loss=0.046]\u001b[A\n",
            "Epoch 2:  57%|█████▋    | 275/484 [36:31<27:06,  7.78s/it, training_loss=0.046]\u001b[A\n",
            "Epoch 2:  57%|█████▋    | 275/484 [36:40<27:06,  7.78s/it, training_loss=0.022]\u001b[A\n",
            "Epoch 2:  57%|█████▋    | 276/484 [36:40<27:48,  8.02s/it, training_loss=0.022]\u001b[A\n",
            "Epoch 2:  57%|█████▋    | 276/484 [36:47<27:48,  8.02s/it, training_loss=0.090]\u001b[A\n",
            "Epoch 2:  57%|█████▋    | 277/484 [36:47<27:11,  7.88s/it, training_loss=0.090]\u001b[A\n",
            "Epoch 2:  57%|█████▋    | 277/484 [36:55<27:11,  7.88s/it, training_loss=0.148]\u001b[A\n",
            "Epoch 2:  57%|█████▋    | 278/484 [36:55<26:10,  7.63s/it, training_loss=0.148]\u001b[A\n",
            "Epoch 2:  57%|█████▋    | 278/484 [37:03<26:10,  7.63s/it, training_loss=0.025]\u001b[A\n",
            "Epoch 2:  58%|█████▊    | 279/484 [37:04<27:27,  8.04s/it, training_loss=0.025]\u001b[A\n",
            "Epoch 2:  58%|█████▊    | 279/484 [37:10<27:27,  8.04s/it, training_loss=0.074]\u001b[A\n",
            "Epoch 2:  58%|█████▊    | 280/484 [37:10<25:50,  7.60s/it, training_loss=0.074]\u001b[A\n",
            "Epoch 2:  58%|█████▊    | 280/484 [37:20<25:50,  7.60s/it, training_loss=0.017]\u001b[A\n",
            "Epoch 2:  58%|█████▊    | 281/484 [37:20<27:46,  8.21s/it, training_loss=0.017]\u001b[A\n",
            "Epoch 2:  58%|█████▊    | 281/484 [37:26<27:46,  8.21s/it, training_loss=0.228]\u001b[A\n",
            "Epoch 2:  58%|█████▊    | 282/484 [37:26<26:01,  7.73s/it, training_loss=0.228]\u001b[A\n",
            "Epoch 2:  58%|█████▊    | 282/484 [37:35<26:01,  7.73s/it, training_loss=0.086]\u001b[A\n",
            "Epoch 2:  58%|█████▊    | 283/484 [37:35<26:57,  8.05s/it, training_loss=0.086]\u001b[A\n",
            "Epoch 2:  58%|█████▊    | 283/484 [37:42<26:57,  8.05s/it, training_loss=0.028]\u001b[A\n",
            "Epoch 2:  59%|█████▊    | 284/484 [37:43<26:10,  7.85s/it, training_loss=0.028]\u001b[A\n",
            "Epoch 2:  59%|█████▊    | 284/484 [37:50<26:10,  7.85s/it, training_loss=0.017]\u001b[A\n",
            "Epoch 2:  59%|█████▉    | 285/484 [37:50<25:27,  7.68s/it, training_loss=0.017]\u001b[A\n",
            "Epoch 2:  59%|█████▉    | 285/484 [37:59<25:27,  7.68s/it, training_loss=0.021]\u001b[A\n",
            "Epoch 2:  59%|█████▉    | 286/484 [37:59<26:25,  8.01s/it, training_loss=0.021]\u001b[A\n",
            "Epoch 2:  59%|█████▉    | 286/484 [38:05<26:25,  8.01s/it, training_loss=0.021]\u001b[A\n",
            "Epoch 2:  59%|█████▉    | 287/484 [38:05<24:54,  7.58s/it, training_loss=0.021]\u001b[A\n",
            "Epoch 2:  59%|█████▉    | 287/484 [38:15<24:54,  7.58s/it, training_loss=0.132]\u001b[A\n",
            "Epoch 2:  60%|█████▉    | 288/484 [38:15<26:51,  8.22s/it, training_loss=0.132]\u001b[A\n",
            "Epoch 2:  60%|█████▉    | 288/484 [38:21<26:51,  8.22s/it, training_loss=0.198]\u001b[A\n",
            "Epoch 2:  60%|█████▉    | 289/484 [38:21<25:04,  7.72s/it, training_loss=0.198]\u001b[A\n",
            "Epoch 2:  60%|█████▉    | 289/484 [38:30<25:04,  7.72s/it, training_loss=0.162]\u001b[A\n",
            "Epoch 2:  60%|█████▉    | 290/484 [38:30<26:08,  8.09s/it, training_loss=0.162]\u001b[A\n",
            "Epoch 2:  60%|█████▉    | 290/484 [38:38<26:08,  8.09s/it, training_loss=0.247]\u001b[A\n",
            "Epoch 2:  60%|██████    | 291/484 [38:38<25:09,  7.82s/it, training_loss=0.247]\u001b[A\n",
            "Epoch 2:  60%|██████    | 291/484 [38:45<25:09,  7.82s/it, training_loss=0.008]\u001b[A\n",
            "Epoch 2:  60%|██████    | 292/484 [38:45<24:48,  7.75s/it, training_loss=0.008]\u001b[A\n",
            "Epoch 2:  60%|██████    | 292/484 [38:54<24:48,  7.75s/it, training_loss=0.118]\u001b[A\n",
            "Epoch 2:  61%|██████    | 293/484 [38:54<25:18,  7.95s/it, training_loss=0.118]\u001b[A\n",
            "Epoch 2:  61%|██████    | 293/484 [39:00<25:18,  7.95s/it, training_loss=0.165]\u001b[A\n",
            "Epoch 2:  61%|██████    | 294/484 [39:00<23:56,  7.56s/it, training_loss=0.165]\u001b[A\n",
            "Epoch 2:  61%|██████    | 294/484 [39:10<23:56,  7.56s/it, training_loss=0.295]\u001b[A\n",
            "Epoch 2:  61%|██████    | 295/484 [39:10<25:54,  8.22s/it, training_loss=0.295]\u001b[A\n",
            "Epoch 2:  61%|██████    | 295/484 [39:17<25:54,  8.22s/it, training_loss=0.269]\u001b[A\n",
            "Epoch 2:  61%|██████    | 296/484 [39:17<24:16,  7.75s/it, training_loss=0.269]\u001b[A\n",
            "Epoch 2:  61%|██████    | 296/484 [39:26<24:16,  7.75s/it, training_loss=0.113]\u001b[A\n",
            "Epoch 2:  61%|██████▏   | 297/484 [39:26<25:39,  8.23s/it, training_loss=0.113]\u001b[A\n",
            "Epoch 2:  61%|██████▏   | 297/484 [39:33<25:39,  8.23s/it, training_loss=0.049]\u001b[A\n",
            "Epoch 2:  62%|██████▏   | 298/484 [39:33<24:10,  7.80s/it, training_loss=0.049]\u001b[A\n",
            "Epoch 2:  62%|██████▏   | 298/484 [39:41<24:10,  7.80s/it, training_loss=0.089]\u001b[A\n",
            "Epoch 2:  62%|██████▏   | 299/484 [39:41<24:13,  7.86s/it, training_loss=0.089]\u001b[A\n",
            "Epoch 2:  62%|██████▏   | 299/484 [39:49<24:13,  7.86s/it, training_loss=0.146]\u001b[A\n",
            "Epoch 2:  62%|██████▏   | 300/484 [39:49<24:15,  7.91s/it, training_loss=0.146]\u001b[A\n",
            "Epoch 2:  62%|██████▏   | 300/484 [39:59<24:15,  7.91s/it, training_loss=0.065]\u001b[A\n",
            "Epoch 2:  62%|██████▏   | 301/484 [39:59<26:39,  8.74s/it, training_loss=0.065]\u001b[A\n",
            "Epoch 2:  62%|██████▏   | 301/484 [40:08<26:39,  8.74s/it, training_loss=0.067]\u001b[A\n",
            "Epoch 2:  62%|██████▏   | 302/484 [40:08<26:17,  8.67s/it, training_loss=0.067]\u001b[A\n",
            "Epoch 2:  62%|██████▏   | 302/484 [40:15<26:17,  8.67s/it, training_loss=0.043]\u001b[A\n",
            "Epoch 2:  63%|██████▎   | 303/484 [40:15<24:14,  8.03s/it, training_loss=0.043]\u001b[A\n",
            "Epoch 2:  63%|██████▎   | 303/484 [40:24<24:14,  8.03s/it, training_loss=0.192]\u001b[A\n",
            "Epoch 2:  63%|██████▎   | 304/484 [40:24<25:37,  8.54s/it, training_loss=0.192]\u001b[A\n",
            "Epoch 2:  63%|██████▎   | 304/484 [40:31<25:37,  8.54s/it, training_loss=0.153]\u001b[A\n",
            "Epoch 2:  63%|██████▎   | 305/484 [40:31<23:44,  7.96s/it, training_loss=0.153]\u001b[A\n",
            "Epoch 2:  63%|██████▎   | 305/484 [40:40<23:44,  7.96s/it, training_loss=0.235]\u001b[A\n",
            "Epoch 2:  63%|██████▎   | 306/484 [40:40<24:44,  8.34s/it, training_loss=0.235]\u001b[A\n",
            "Epoch 2:  63%|██████▎   | 306/484 [40:47<24:44,  8.34s/it, training_loss=0.038]\u001b[A\n",
            "Epoch 2:  63%|██████▎   | 307/484 [40:47<23:24,  7.94s/it, training_loss=0.038]\u001b[A\n",
            "Epoch 2:  63%|██████▎   | 307/484 [40:55<23:24,  7.94s/it, training_loss=0.045]\u001b[A\n",
            "Epoch 2:  64%|██████▎   | 308/484 [40:55<23:04,  7.87s/it, training_loss=0.045]\u001b[A\n",
            "Epoch 2:  64%|██████▎   | 308/484 [41:03<23:04,  7.87s/it, training_loss=0.226]\u001b[A\n",
            "Epoch 2:  64%|██████▍   | 309/484 [41:03<23:18,  7.99s/it, training_loss=0.226]\u001b[A\n",
            "Epoch 2:  64%|██████▍   | 309/484 [41:10<23:18,  7.99s/it, training_loss=0.171]\u001b[A\n",
            "Epoch 2:  64%|██████▍   | 310/484 [41:10<22:00,  7.59s/it, training_loss=0.171]\u001b[A\n",
            "Epoch 2:  64%|██████▍   | 310/484 [41:19<22:00,  7.59s/it, training_loss=0.032]\u001b[A\n",
            "Epoch 2:  64%|██████▍   | 311/484 [41:19<23:37,  8.19s/it, training_loss=0.032]\u001b[A\n",
            "Epoch 2:  64%|██████▍   | 311/484 [41:26<23:37,  8.19s/it, training_loss=0.251]\u001b[A\n",
            "Epoch 2:  64%|██████▍   | 312/484 [41:26<22:07,  7.72s/it, training_loss=0.251]\u001b[A\n",
            "Epoch 2:  64%|██████▍   | 312/484 [41:35<22:07,  7.72s/it, training_loss=0.037]\u001b[A\n",
            "Epoch 2:  65%|██████▍   | 313/484 [41:35<23:24,  8.21s/it, training_loss=0.037]\u001b[A\n",
            "Epoch 2:  65%|██████▍   | 313/484 [41:42<23:24,  8.21s/it, training_loss=0.235]\u001b[A\n",
            "Epoch 2:  65%|██████▍   | 314/484 [41:42<22:07,  7.81s/it, training_loss=0.235]\u001b[A\n",
            "Epoch 2:  65%|██████▍   | 314/484 [41:50<22:07,  7.81s/it, training_loss=0.094]\u001b[A\n",
            "Epoch 2:  65%|██████▌   | 315/484 [41:50<22:10,  7.87s/it, training_loss=0.094]\u001b[A\n",
            "Epoch 2:  65%|██████▌   | 315/484 [41:58<22:10,  7.87s/it, training_loss=0.147]\u001b[A\n",
            "Epoch 2:  65%|██████▌   | 316/484 [41:58<22:09,  7.91s/it, training_loss=0.147]\u001b[A\n",
            "Epoch 2:  65%|██████▌   | 316/484 [42:05<22:09,  7.91s/it, training_loss=0.163]\u001b[A\n",
            "Epoch 2:  65%|██████▌   | 317/484 [42:05<20:57,  7.53s/it, training_loss=0.163]\u001b[A\n",
            "Epoch 2:  65%|██████▌   | 317/484 [42:14<20:57,  7.53s/it, training_loss=0.013]\u001b[A\n",
            "Epoch 2:  66%|██████▌   | 318/484 [42:14<22:24,  8.10s/it, training_loss=0.013]\u001b[A\n",
            "Epoch 2:  66%|██████▌   | 318/484 [42:21<22:24,  8.10s/it, training_loss=0.065]\u001b[A\n",
            "Epoch 2:  66%|██████▌   | 319/484 [42:21<20:58,  7.63s/it, training_loss=0.065]\u001b[A\n",
            "Epoch 2:  66%|██████▌   | 319/484 [42:30<20:58,  7.63s/it, training_loss=0.069]\u001b[A\n",
            "Epoch 2:  66%|██████▌   | 320/484 [42:30<22:17,  8.16s/it, training_loss=0.069]\u001b[A\n",
            "Epoch 2:  66%|██████▌   | 320/484 [42:37<22:17,  8.16s/it, training_loss=0.105]\u001b[A\n",
            "Epoch 2:  66%|██████▋   | 321/484 [42:37<20:58,  7.72s/it, training_loss=0.105]\u001b[A\n",
            "Epoch 2:  66%|██████▋   | 321/484 [42:45<20:58,  7.72s/it, training_loss=0.070]\u001b[A\n",
            "Epoch 2:  67%|██████▋   | 322/484 [42:45<21:14,  7.87s/it, training_loss=0.070]\u001b[A\n",
            "Epoch 2:  67%|██████▋   | 322/484 [42:53<21:14,  7.87s/it, training_loss=0.102]\u001b[A\n",
            "Epoch 2:  67%|██████▋   | 323/484 [42:53<21:06,  7.87s/it, training_loss=0.102]\u001b[A\n",
            "Epoch 2:  67%|██████▋   | 323/484 [43:00<21:06,  7.87s/it, training_loss=0.011]\u001b[A\n",
            "Epoch 2:  67%|██████▋   | 324/484 [43:00<20:06,  7.54s/it, training_loss=0.011]\u001b[A\n",
            "Epoch 2:  67%|██████▋   | 324/484 [43:09<20:06,  7.54s/it, training_loss=0.037]\u001b[A\n",
            "Epoch 2:  67%|██████▋   | 325/484 [43:09<21:23,  8.07s/it, training_loss=0.037]\u001b[A\n",
            "Epoch 2:  67%|██████▋   | 325/484 [43:16<21:23,  8.07s/it, training_loss=0.088]\u001b[A\n",
            "Epoch 2:  67%|██████▋   | 326/484 [43:16<20:08,  7.65s/it, training_loss=0.088]\u001b[A\n",
            "Epoch 2:  67%|██████▋   | 326/484 [43:25<20:08,  7.65s/it, training_loss=0.085]\u001b[A\n",
            "Epoch 2:  68%|██████▊   | 327/484 [43:25<21:35,  8.25s/it, training_loss=0.085]\u001b[A\n",
            "Epoch 2:  68%|██████▊   | 327/484 [43:32<21:35,  8.25s/it, training_loss=0.020]\u001b[A\n",
            "Epoch 2:  68%|██████▊   | 328/484 [43:32<20:09,  7.75s/it, training_loss=0.020]\u001b[A\n",
            "Epoch 2:  68%|██████▊   | 328/484 [43:40<20:09,  7.75s/it, training_loss=0.142]\u001b[A\n",
            "Epoch 2:  68%|██████▊   | 329/484 [43:40<20:38,  7.99s/it, training_loss=0.142]\u001b[A\n",
            "Epoch 2:  68%|██████▊   | 329/484 [43:48<20:38,  7.99s/it, training_loss=0.030]\u001b[A\n",
            "Epoch 2:  68%|██████▊   | 330/484 [43:48<20:11,  7.87s/it, training_loss=0.030]\u001b[A\n",
            "Epoch 2:  68%|██████▊   | 330/484 [43:55<20:11,  7.87s/it, training_loss=0.030]\u001b[A\n",
            "Epoch 2:  68%|██████▊   | 331/484 [43:55<19:24,  7.61s/it, training_loss=0.030]\u001b[A\n",
            "Epoch 2:  68%|██████▊   | 331/484 [44:04<19:24,  7.61s/it, training_loss=0.080]\u001b[A\n",
            "Epoch 2:  69%|██████▊   | 332/484 [44:04<20:23,  8.05s/it, training_loss=0.080]\u001b[A\n",
            "Epoch 2:  69%|██████▊   | 332/484 [44:11<20:23,  8.05s/it, training_loss=0.125]\u001b[A\n",
            "Epoch 2:  69%|██████▉   | 333/484 [44:11<19:09,  7.61s/it, training_loss=0.125]\u001b[A\n",
            "Epoch 2:  69%|██████▉   | 333/484 [44:20<19:09,  7.61s/it, training_loss=0.107]\u001b[A\n",
            "Epoch 2:  69%|██████▉   | 334/484 [44:20<20:35,  8.24s/it, training_loss=0.107]\u001b[A\n",
            "Epoch 2:  69%|██████▉   | 334/484 [44:29<20:35,  8.24s/it, training_loss=0.041]\u001b[A\n",
            "Epoch 2:  69%|██████▉   | 335/484 [44:29<20:54,  8.42s/it, training_loss=0.041]\u001b[A\n",
            "Epoch 2:  69%|██████▉   | 335/484 [44:40<20:54,  8.42s/it, training_loss=0.306]\u001b[A\n",
            "Epoch 2:  69%|██████▉   | 336/484 [44:40<22:18,  9.04s/it, training_loss=0.306]\u001b[A\n",
            "Epoch 2:  69%|██████▉   | 336/484 [44:46<22:18,  9.04s/it, training_loss=0.185]\u001b[A\n",
            "Epoch 2:  70%|██████▉   | 337/484 [44:46<20:20,  8.30s/it, training_loss=0.185]\u001b[A\n",
            "Epoch 2:  70%|██████▉   | 337/484 [44:55<20:20,  8.30s/it, training_loss=0.167]\u001b[A\n",
            "Epoch 2:  70%|██████▉   | 338/484 [44:55<20:41,  8.50s/it, training_loss=0.167]\u001b[A\n",
            "Epoch 2:  70%|██████▉   | 338/484 [45:03<20:41,  8.50s/it, training_loss=0.084]\u001b[A\n",
            "Epoch 2:  70%|███████   | 339/484 [45:03<19:37,  8.12s/it, training_loss=0.084]\u001b[A\n",
            "Epoch 2:  70%|███████   | 339/484 [45:10<19:37,  8.12s/it, training_loss=0.019]\u001b[A\n",
            "Epoch 2:  70%|███████   | 340/484 [45:10<18:59,  7.91s/it, training_loss=0.019]\u001b[A\n",
            "Epoch 2:  70%|███████   | 340/484 [45:19<18:59,  7.91s/it, training_loss=0.084]\u001b[A\n",
            "Epoch 2:  70%|███████   | 341/484 [45:19<19:19,  8.11s/it, training_loss=0.084]\u001b[A\n",
            "Epoch 2:  70%|███████   | 341/484 [45:25<19:19,  8.11s/it, training_loss=0.023]\u001b[A\n",
            "Epoch 2:  71%|███████   | 342/484 [45:25<18:08,  7.66s/it, training_loss=0.023]\u001b[A\n",
            "Epoch 2:  71%|███████   | 342/484 [45:35<18:08,  7.66s/it, training_loss=0.242]\u001b[A\n",
            "Epoch 2:  71%|███████   | 343/484 [45:35<19:27,  8.28s/it, training_loss=0.242]\u001b[A\n",
            "Epoch 2:  71%|███████   | 343/484 [45:42<19:27,  8.28s/it, training_loss=0.009]\u001b[A\n",
            "Epoch 2:  71%|███████   | 344/484 [45:42<18:11,  7.79s/it, training_loss=0.009]\u001b[A\n",
            "Epoch 2:  71%|███████   | 344/484 [45:51<18:11,  7.79s/it, training_loss=0.014]\u001b[A\n",
            "Epoch 2:  71%|███████▏  | 345/484 [45:51<19:03,  8.23s/it, training_loss=0.014]\u001b[A\n",
            "Epoch 2:  71%|███████▏  | 345/484 [45:58<19:03,  8.23s/it, training_loss=0.031]\u001b[A\n",
            "Epoch 2:  71%|███████▏  | 346/484 [45:58<18:05,  7.86s/it, training_loss=0.031]\u001b[A\n",
            "Epoch 2:  71%|███████▏  | 346/484 [46:06<18:05,  7.86s/it, training_loss=0.088]\u001b[A\n",
            "Epoch 2:  72%|███████▏  | 347/484 [46:06<18:00,  7.88s/it, training_loss=0.088]\u001b[A\n",
            "Epoch 2:  72%|███████▏  | 347/484 [46:14<18:00,  7.88s/it, training_loss=0.102]\u001b[A\n",
            "Epoch 2:  72%|███████▏  | 348/484 [46:14<17:58,  7.93s/it, training_loss=0.102]\u001b[A\n",
            "Epoch 2:  72%|███████▏  | 348/484 [46:20<17:58,  7.93s/it, training_loss=0.126]\u001b[A\n",
            "Epoch 2:  72%|███████▏  | 349/484 [46:20<16:59,  7.56s/it, training_loss=0.126]\u001b[A\n",
            "Epoch 2:  72%|███████▏  | 349/484 [46:30<16:59,  7.56s/it, training_loss=0.006]\u001b[A\n",
            "Epoch 2:  72%|███████▏  | 350/484 [46:30<18:09,  8.13s/it, training_loss=0.006]\u001b[A\n",
            "Epoch 2:  72%|███████▏  | 350/484 [46:36<18:09,  8.13s/it, training_loss=0.045]\u001b[A\n",
            "Epoch 2:  73%|███████▎  | 351/484 [46:36<16:57,  7.65s/it, training_loss=0.045]\u001b[A\n",
            "Epoch 2:  73%|███████▎  | 351/484 [46:46<16:57,  7.65s/it, training_loss=0.012]\u001b[A\n",
            "Epoch 2:  73%|███████▎  | 352/484 [46:46<17:59,  8.18s/it, training_loss=0.012]\u001b[A\n",
            "Epoch 2:  73%|███████▎  | 352/484 [46:53<17:59,  8.18s/it, training_loss=0.309]\u001b[A\n",
            "Epoch 2:  73%|███████▎  | 353/484 [46:53<16:57,  7.77s/it, training_loss=0.309]\u001b[A\n",
            "Epoch 2:  73%|███████▎  | 353/484 [47:01<16:57,  7.77s/it, training_loss=0.017]\u001b[A\n",
            "Epoch 2:  73%|███████▎  | 354/484 [47:01<17:02,  7.87s/it, training_loss=0.017]\u001b[A\n",
            "Epoch 2:  73%|███████▎  | 354/484 [47:09<17:02,  7.87s/it, training_loss=0.191]\u001b[A\n",
            "Epoch 2:  73%|███████▎  | 355/484 [47:09<16:59,  7.90s/it, training_loss=0.191]\u001b[A\n",
            "Epoch 2:  73%|███████▎  | 355/484 [47:16<16:59,  7.90s/it, training_loss=0.137]\u001b[A\n",
            "Epoch 2:  74%|███████▎  | 356/484 [47:16<16:07,  7.56s/it, training_loss=0.137]\u001b[A\n",
            "Epoch 2:  74%|███████▎  | 356/484 [47:25<16:07,  7.56s/it, training_loss=0.093]\u001b[A\n",
            "Epoch 2:  74%|███████▍  | 357/484 [47:25<17:08,  8.10s/it, training_loss=0.093]\u001b[A\n",
            "Epoch 2:  74%|███████▍  | 357/484 [47:32<17:08,  8.10s/it, training_loss=0.012]\u001b[A\n",
            "Epoch 2:  74%|███████▍  | 358/484 [47:32<16:05,  7.67s/it, training_loss=0.012]\u001b[A\n",
            "Epoch 2:  74%|███████▍  | 358/484 [47:41<16:05,  7.67s/it, training_loss=0.102]\u001b[A\n",
            "Epoch 2:  74%|███████▍  | 359/484 [47:41<17:11,  8.25s/it, training_loss=0.102]\u001b[A\n",
            "Epoch 2:  74%|███████▍  | 359/484 [47:48<17:11,  8.25s/it, training_loss=0.018]\u001b[A\n",
            "Epoch 2:  74%|███████▍  | 360/484 [47:48<16:00,  7.74s/it, training_loss=0.018]\u001b[A\n",
            "Epoch 2:  74%|███████▍  | 360/484 [47:56<16:00,  7.74s/it, training_loss=0.016]\u001b[A\n",
            "Epoch 2:  75%|███████▍  | 361/484 [47:56<16:19,  7.97s/it, training_loss=0.016]\u001b[A\n",
            "Epoch 2:  75%|███████▍  | 361/484 [48:04<16:19,  7.97s/it, training_loss=0.077]\u001b[A\n",
            "Epoch 2:  75%|███████▍  | 362/484 [48:04<16:00,  7.87s/it, training_loss=0.077]\u001b[A\n",
            "Epoch 2:  75%|███████▍  | 362/484 [48:11<16:00,  7.87s/it, training_loss=0.008]\u001b[A\n",
            "Epoch 2:  75%|███████▌  | 363/484 [48:11<15:20,  7.61s/it, training_loss=0.008]\u001b[A\n",
            "Epoch 2:  75%|███████▌  | 363/484 [48:20<15:20,  7.61s/it, training_loss=0.090]\u001b[A\n",
            "Epoch 2:  75%|███████▌  | 364/484 [48:20<16:03,  8.03s/it, training_loss=0.090]\u001b[A\n",
            "Epoch 2:  75%|███████▌  | 364/484 [48:26<16:03,  8.03s/it, training_loss=0.126]\u001b[A\n",
            "Epoch 2:  75%|███████▌  | 365/484 [48:26<15:03,  7.59s/it, training_loss=0.126]\u001b[A\n",
            "Epoch 2:  75%|███████▌  | 365/484 [48:36<15:03,  7.59s/it, training_loss=0.019]\u001b[A\n",
            "Epoch 2:  76%|███████▌  | 366/484 [48:36<16:10,  8.22s/it, training_loss=0.019]\u001b[A\n",
            "Epoch 2:  76%|███████▌  | 366/484 [48:43<16:10,  8.22s/it, training_loss=0.038]\u001b[A\n",
            "Epoch 2:  76%|███████▌  | 367/484 [48:43<15:06,  7.75s/it, training_loss=0.038]\u001b[A\n",
            "Epoch 2:  76%|███████▌  | 367/484 [48:52<15:06,  7.75s/it, training_loss=0.183]\u001b[A\n",
            "Epoch 2:  76%|███████▌  | 368/484 [48:52<15:39,  8.10s/it, training_loss=0.183]\u001b[A\n",
            "Epoch 2:  76%|███████▌  | 368/484 [49:00<15:39,  8.10s/it, training_loss=0.254]\u001b[A\n",
            "Epoch 2:  76%|███████▌  | 369/484 [49:00<15:56,  8.31s/it, training_loss=0.254]\u001b[A\n",
            "Epoch 2:  76%|███████▌  | 369/484 [49:11<15:56,  8.31s/it, training_loss=0.019]\u001b[A\n",
            "Epoch 2:  76%|███████▋  | 370/484 [49:11<16:59,  8.94s/it, training_loss=0.019]\u001b[A\n",
            "Epoch 2:  76%|███████▋  | 370/484 [49:18<16:59,  8.94s/it, training_loss=0.014]\u001b[A\n",
            "Epoch 2:  77%|███████▋  | 371/484 [49:18<15:48,  8.40s/it, training_loss=0.014]\u001b[A\n",
            "Epoch 2:  77%|███████▋  | 371/484 [49:26<15:48,  8.40s/it, training_loss=0.078]\u001b[A\n",
            "Epoch 2:  77%|███████▋  | 372/484 [49:26<15:15,  8.18s/it, training_loss=0.078]\u001b[A\n",
            "Epoch 2:  77%|███████▋  | 372/484 [49:34<15:15,  8.18s/it, training_loss=0.037]\u001b[A\n",
            "Epoch 2:  77%|███████▋  | 373/484 [49:34<15:13,  8.23s/it, training_loss=0.037]\u001b[A\n",
            "Epoch 2:  77%|███████▋  | 373/484 [49:41<15:13,  8.23s/it, training_loss=0.039]\u001b[A\n",
            "Epoch 2:  77%|███████▋  | 374/484 [49:41<14:13,  7.76s/it, training_loss=0.039]\u001b[A\n",
            "Epoch 2:  77%|███████▋  | 374/484 [49:50<14:13,  7.76s/it, training_loss=0.038]\u001b[A\n",
            "Epoch 2:  77%|███████▋  | 375/484 [49:50<15:09,  8.34s/it, training_loss=0.038]\u001b[A\n",
            "Epoch 2:  77%|███████▋  | 375/484 [49:57<15:09,  8.34s/it, training_loss=0.012]\u001b[A\n",
            "Epoch 2:  78%|███████▊  | 376/484 [49:57<14:06,  7.84s/it, training_loss=0.012]\u001b[A\n",
            "Epoch 2:  78%|███████▊  | 376/484 [50:06<14:06,  7.84s/it, training_loss=0.314]\u001b[A\n",
            "Epoch 2:  78%|███████▊  | 377/484 [50:06<14:47,  8.29s/it, training_loss=0.314]\u001b[A\n",
            "Epoch 2:  78%|███████▊  | 377/484 [50:13<14:47,  8.29s/it, training_loss=0.043]\u001b[A\n",
            "Epoch 2:  78%|███████▊  | 378/484 [50:13<13:52,  7.86s/it, training_loss=0.043]\u001b[A\n",
            "Epoch 2:  78%|███████▊  | 378/484 [50:21<13:52,  7.86s/it, training_loss=0.152]\u001b[A\n",
            "Epoch 2:  78%|███████▊  | 379/484 [50:21<13:49,  7.90s/it, training_loss=0.152]\u001b[A\n",
            "Epoch 2:  78%|███████▊  | 379/484 [50:29<13:49,  7.90s/it, training_loss=0.457]\u001b[A\n",
            "Epoch 2:  79%|███████▊  | 380/484 [50:29<13:44,  7.93s/it, training_loss=0.457]\u001b[A\n",
            "Epoch 2:  79%|███████▊  | 380/484 [50:36<13:44,  7.93s/it, training_loss=0.153]\u001b[A\n",
            "Epoch 2:  79%|███████▊  | 381/484 [50:36<13:00,  7.57s/it, training_loss=0.153]\u001b[A\n",
            "Epoch 2:  79%|███████▊  | 381/484 [50:45<13:00,  7.57s/it, training_loss=0.161]\u001b[A\n",
            "Epoch 2:  79%|███████▉  | 382/484 [50:45<13:48,  8.12s/it, training_loss=0.161]\u001b[A\n",
            "Epoch 2:  79%|███████▉  | 382/484 [50:52<13:48,  8.12s/it, training_loss=0.051]\u001b[A\n",
            "Epoch 2:  79%|███████▉  | 383/484 [50:52<12:54,  7.67s/it, training_loss=0.051]\u001b[A\n",
            "Epoch 2:  79%|███████▉  | 383/484 [51:02<12:54,  7.67s/it, training_loss=0.193]\u001b[A\n",
            "Epoch 2:  79%|███████▉  | 384/484 [51:02<13:43,  8.23s/it, training_loss=0.193]\u001b[A\n",
            "Epoch 2:  79%|███████▉  | 384/484 [51:08<13:43,  8.23s/it, training_loss=0.116]\u001b[A\n",
            "Epoch 2:  80%|███████▉  | 385/484 [51:08<12:49,  7.77s/it, training_loss=0.116]\u001b[A\n",
            "Epoch 2:  80%|███████▉  | 385/484 [51:17<12:49,  7.77s/it, training_loss=0.016]\u001b[A\n",
            "Epoch 2:  80%|███████▉  | 386/484 [51:17<12:56,  7.93s/it, training_loss=0.016]\u001b[A\n",
            "Epoch 2:  80%|███████▉  | 386/484 [51:24<12:56,  7.93s/it, training_loss=0.012]\u001b[A\n",
            "Epoch 2:  80%|███████▉  | 387/484 [51:24<12:43,  7.87s/it, training_loss=0.012]\u001b[A\n",
            "Epoch 2:  80%|███████▉  | 387/484 [51:31<12:43,  7.87s/it, training_loss=0.017]\u001b[A\n",
            "Epoch 2:  80%|████████  | 388/484 [51:31<12:05,  7.56s/it, training_loss=0.017]\u001b[A\n",
            "Epoch 2:  80%|████████  | 388/484 [51:40<12:05,  7.56s/it, training_loss=0.227]\u001b[A\n",
            "Epoch 2:  80%|████████  | 389/484 [51:40<12:45,  8.05s/it, training_loss=0.227]\u001b[A\n",
            "Epoch 2:  80%|████████  | 389/484 [51:47<12:45,  8.05s/it, training_loss=0.049]\u001b[A\n",
            "Epoch 2:  81%|████████  | 390/484 [51:47<11:55,  7.61s/it, training_loss=0.049]\u001b[A\n",
            "Epoch 2:  81%|████████  | 390/484 [51:57<11:55,  7.61s/it, training_loss=0.161]\u001b[A\n",
            "Epoch 2:  81%|████████  | 391/484 [51:57<12:45,  8.23s/it, training_loss=0.161]\u001b[A\n",
            "Epoch 2:  81%|████████  | 391/484 [52:03<12:45,  8.23s/it, training_loss=0.167]\u001b[A\n",
            "Epoch 2:  81%|████████  | 392/484 [52:03<11:54,  7.76s/it, training_loss=0.167]\u001b[A\n",
            "Epoch 2:  81%|████████  | 392/484 [52:12<11:54,  7.76s/it, training_loss=0.024]\u001b[A\n",
            "Epoch 2:  81%|████████  | 393/484 [52:12<12:07,  7.99s/it, training_loss=0.024]\u001b[A\n",
            "Epoch 2:  81%|████████  | 393/484 [52:19<12:07,  7.99s/it, training_loss=0.157]\u001b[A\n",
            "Epoch 2:  81%|████████▏ | 394/484 [52:19<11:47,  7.86s/it, training_loss=0.157]\u001b[A\n",
            "Epoch 2:  81%|████████▏ | 394/484 [52:26<11:47,  7.86s/it, training_loss=0.059]\u001b[A\n",
            "Epoch 2:  82%|████████▏ | 395/484 [52:26<11:14,  7.58s/it, training_loss=0.059]\u001b[A\n",
            "Epoch 2:  82%|████████▏ | 395/484 [52:35<11:14,  7.58s/it, training_loss=0.141]\u001b[A\n",
            "Epoch 2:  82%|████████▏ | 396/484 [52:35<11:44,  8.01s/it, training_loss=0.141]\u001b[A\n",
            "Epoch 2:  82%|████████▏ | 396/484 [52:42<11:44,  8.01s/it, training_loss=0.088]\u001b[A\n",
            "Epoch 2:  82%|████████▏ | 397/484 [52:42<10:58,  7.57s/it, training_loss=0.088]\u001b[A\n",
            "Epoch 2:  82%|████████▏ | 397/484 [52:51<10:58,  7.57s/it, training_loss=0.034]\u001b[A\n",
            "Epoch 2:  82%|████████▏ | 398/484 [52:51<11:43,  8.18s/it, training_loss=0.034]\u001b[A\n",
            "Epoch 2:  82%|████████▏ | 398/484 [52:58<11:43,  8.18s/it, training_loss=0.118]\u001b[A\n",
            "Epoch 2:  82%|████████▏ | 399/484 [52:58<10:54,  7.70s/it, training_loss=0.118]\u001b[A\n",
            "Epoch 2:  82%|████████▏ | 399/484 [53:07<10:54,  7.70s/it, training_loss=0.162]\u001b[A\n",
            "Epoch 2:  83%|████████▎ | 400/484 [53:07<11:12,  8.01s/it, training_loss=0.162]\u001b[A\n",
            "Epoch 2:  83%|████████▎ | 400/484 [53:14<11:12,  8.01s/it, training_loss=0.042]\u001b[A\n",
            "Epoch 2:  83%|████████▎ | 401/484 [53:14<10:50,  7.84s/it, training_loss=0.042]\u001b[A\n",
            "Epoch 2:  83%|████████▎ | 401/484 [53:21<10:50,  7.84s/it, training_loss=0.135]\u001b[A\n",
            "Epoch 2:  83%|████████▎ | 402/484 [53:21<10:26,  7.64s/it, training_loss=0.135]\u001b[A\n",
            "Epoch 2:  83%|████████▎ | 402/484 [53:30<10:26,  7.64s/it, training_loss=0.051]\u001b[A\n",
            "Epoch 2:  83%|████████▎ | 403/484 [53:30<10:47,  7.99s/it, training_loss=0.051]\u001b[A\n",
            "Epoch 2:  83%|████████▎ | 403/484 [53:40<10:47,  7.99s/it, training_loss=0.015]\u001b[A\n",
            "Epoch 2:  83%|████████▎ | 404/484 [53:40<11:30,  8.63s/it, training_loss=0.015]\u001b[A\n",
            "Epoch 2:  83%|████████▎ | 404/484 [53:49<11:30,  8.63s/it, training_loss=0.043]\u001b[A\n",
            "Epoch 2:  84%|████████▎ | 405/484 [53:49<11:34,  8.79s/it, training_loss=0.043]\u001b[A\n",
            "Epoch 2:  84%|████████▎ | 405/484 [53:56<11:34,  8.79s/it, training_loss=0.137]\u001b[A\n",
            "Epoch 2:  84%|████████▍ | 406/484 [53:56<10:34,  8.14s/it, training_loss=0.137]\u001b[A\n",
            "Epoch 2:  84%|████████▍ | 406/484 [54:06<10:34,  8.14s/it, training_loss=0.113]\u001b[A\n",
            "Epoch 2:  84%|████████▍ | 407/484 [54:06<11:02,  8.60s/it, training_loss=0.113]\u001b[A\n",
            "Epoch 2:  84%|████████▍ | 407/484 [54:12<11:02,  8.60s/it, training_loss=0.120]\u001b[A\n",
            "Epoch 2:  84%|████████▍ | 408/484 [54:12<10:08,  8.00s/it, training_loss=0.120]\u001b[A\n",
            "Epoch 2:  84%|████████▍ | 408/484 [54:21<10:08,  8.00s/it, training_loss=0.012]\u001b[A\n",
            "Epoch 2:  85%|████████▍ | 409/484 [54:21<10:20,  8.27s/it, training_loss=0.012]\u001b[A\n",
            "Epoch 2:  85%|████████▍ | 409/484 [54:29<10:20,  8.27s/it, training_loss=0.015]\u001b[A\n",
            "Epoch 2:  85%|████████▍ | 410/484 [54:29<09:52,  8.00s/it, training_loss=0.015]\u001b[A\n",
            "Epoch 2:  85%|████████▍ | 410/484 [54:36<09:52,  8.00s/it, training_loss=0.081]\u001b[A\n",
            "Epoch 2:  85%|████████▍ | 411/484 [54:36<09:31,  7.84s/it, training_loss=0.081]\u001b[A\n",
            "Epoch 2:  85%|████████▍ | 411/484 [54:45<09:31,  7.84s/it, training_loss=0.028]\u001b[A\n",
            "Epoch 2:  85%|████████▌ | 412/484 [54:45<09:40,  8.06s/it, training_loss=0.028]\u001b[A\n",
            "Epoch 2:  85%|████████▌ | 412/484 [54:51<09:40,  8.06s/it, training_loss=0.030]\u001b[A\n",
            "Epoch 2:  85%|████████▌ | 413/484 [54:51<09:00,  7.61s/it, training_loss=0.030]\u001b[A\n",
            "Epoch 2:  85%|████████▌ | 413/484 [55:01<09:00,  7.61s/it, training_loss=0.200]\u001b[A\n",
            "Epoch 2:  86%|████████▌ | 414/484 [55:01<09:36,  8.24s/it, training_loss=0.200]\u001b[A\n",
            "Epoch 2:  86%|████████▌ | 414/484 [55:08<09:36,  8.24s/it, training_loss=0.067]\u001b[A\n",
            "Epoch 2:  86%|████████▌ | 415/484 [55:08<08:55,  7.75s/it, training_loss=0.067]\u001b[A\n",
            "Epoch 2:  86%|████████▌ | 415/484 [55:17<08:55,  7.75s/it, training_loss=0.014]\u001b[A\n",
            "Epoch 2:  86%|████████▌ | 416/484 [55:17<09:15,  8.16s/it, training_loss=0.014]\u001b[A\n",
            "Epoch 2:  86%|████████▌ | 416/484 [55:24<09:15,  8.16s/it, training_loss=0.111]\u001b[A\n",
            "Epoch 2:  86%|████████▌ | 417/484 [55:24<08:45,  7.84s/it, training_loss=0.111]\u001b[A\n",
            "Epoch 2:  86%|████████▌ | 417/484 [55:31<08:45,  7.84s/it, training_loss=0.177]\u001b[A\n",
            "Epoch 2:  86%|████████▋ | 418/484 [55:31<08:34,  7.79s/it, training_loss=0.177]\u001b[A\n",
            "Epoch 2:  86%|████████▋ | 418/484 [55:40<08:34,  7.79s/it, training_loss=0.128]\u001b[A\n",
            "Epoch 2:  87%|████████▋ | 419/484 [55:40<08:37,  7.96s/it, training_loss=0.128]\u001b[A\n",
            "Epoch 2:  87%|████████▋ | 419/484 [55:46<08:37,  7.96s/it, training_loss=0.235]\u001b[A\n",
            "Epoch 2:  87%|████████▋ | 420/484 [55:46<08:04,  7.57s/it, training_loss=0.235]\u001b[A\n",
            "Epoch 2:  87%|████████▋ | 420/484 [55:56<08:04,  7.57s/it, training_loss=0.018]\u001b[A\n",
            "Epoch 2:  87%|████████▋ | 421/484 [55:56<08:36,  8.19s/it, training_loss=0.018]\u001b[A\n",
            "Epoch 2:  87%|████████▋ | 421/484 [56:03<08:36,  8.19s/it, training_loss=0.179]\u001b[A\n",
            "Epoch 2:  87%|████████▋ | 422/484 [56:03<07:57,  7.70s/it, training_loss=0.179]\u001b[A\n",
            "Epoch 2:  87%|████████▋ | 422/484 [56:12<07:57,  7.70s/it, training_loss=0.009]\u001b[A\n",
            "Epoch 2:  87%|████████▋ | 423/484 [56:12<08:19,  8.19s/it, training_loss=0.009]\u001b[A\n",
            "Epoch 2:  87%|████████▋ | 423/484 [56:19<08:19,  8.19s/it, training_loss=0.204]\u001b[A\n",
            "Epoch 2:  88%|████████▊ | 424/484 [56:19<07:47,  7.78s/it, training_loss=0.204]\u001b[A\n",
            "Epoch 2:  88%|████████▊ | 424/484 [56:27<07:47,  7.78s/it, training_loss=0.215]\u001b[A\n",
            "Epoch 2:  88%|████████▊ | 425/484 [56:27<07:43,  7.86s/it, training_loss=0.215]\u001b[A\n",
            "Epoch 2:  88%|████████▊ | 425/484 [56:35<07:43,  7.86s/it, training_loss=0.049]\u001b[A\n",
            "Epoch 2:  88%|████████▊ | 426/484 [56:35<07:43,  7.98s/it, training_loss=0.049]\u001b[A\n",
            "Epoch 2:  88%|████████▊ | 426/484 [56:42<07:43,  7.98s/it, training_loss=0.011]\u001b[A\n",
            "Epoch 2:  88%|████████▊ | 427/484 [56:42<07:13,  7.61s/it, training_loss=0.011]\u001b[A\n",
            "Epoch 2:  88%|████████▊ | 427/484 [56:51<07:13,  7.61s/it, training_loss=0.047]\u001b[A\n",
            "Epoch 2:  88%|████████▊ | 428/484 [56:51<07:36,  8.16s/it, training_loss=0.047]\u001b[A\n",
            "Epoch 2:  88%|████████▊ | 428/484 [56:58<07:36,  8.16s/it, training_loss=0.180]\u001b[A\n",
            "Epoch 2:  89%|████████▊ | 429/484 [56:58<07:03,  7.70s/it, training_loss=0.180]\u001b[A\n",
            "Epoch 2:  89%|████████▊ | 429/484 [57:07<07:03,  7.70s/it, training_loss=0.162]\u001b[A\n",
            "Epoch 2:  89%|████████▉ | 430/484 [57:07<07:25,  8.26s/it, training_loss=0.162]\u001b[A\n",
            "Epoch 2:  89%|████████▉ | 430/484 [57:14<07:25,  8.26s/it, training_loss=0.009]\u001b[A\n",
            "Epoch 2:  89%|████████▉ | 431/484 [57:14<06:52,  7.79s/it, training_loss=0.009]\u001b[A\n",
            "Epoch 2:  89%|████████▉ | 431/484 [57:23<06:52,  7.79s/it, training_loss=0.016]\u001b[A\n",
            "Epoch 2:  89%|████████▉ | 432/484 [57:23<06:54,  7.97s/it, training_loss=0.016]\u001b[A\n",
            "Epoch 2:  89%|████████▉ | 432/484 [57:30<06:54,  7.97s/it, training_loss=0.105]\u001b[A\n",
            "Epoch 2:  89%|████████▉ | 433/484 [57:30<06:42,  7.90s/it, training_loss=0.105]\u001b[A\n",
            "Epoch 2:  89%|████████▉ | 433/484 [57:37<06:42,  7.90s/it, training_loss=0.045]\u001b[A\n",
            "Epoch 2:  90%|████████▉ | 434/484 [57:37<06:20,  7.60s/it, training_loss=0.045]\u001b[A\n",
            "Epoch 2:  90%|████████▉ | 434/484 [57:46<06:20,  7.60s/it, training_loss=0.037]\u001b[A\n",
            "Epoch 2:  90%|████████▉ | 435/484 [57:46<06:35,  8.07s/it, training_loss=0.037]\u001b[A\n",
            "Epoch 2:  90%|████████▉ | 435/484 [57:53<06:35,  8.07s/it, training_loss=0.204]\u001b[A\n",
            "Epoch 2:  90%|█████████ | 436/484 [57:53<06:05,  7.62s/it, training_loss=0.204]\u001b[A\n",
            "Epoch 2:  90%|█████████ | 436/484 [58:03<06:05,  7.62s/it, training_loss=0.183]\u001b[A\n",
            "Epoch 2:  90%|█████████ | 437/484 [58:03<06:27,  8.24s/it, training_loss=0.183]\u001b[A\n",
            "Epoch 2:  90%|█████████ | 437/484 [58:09<06:27,  8.24s/it, training_loss=0.142]\u001b[A\n",
            "Epoch 2:  90%|█████████ | 438/484 [58:09<06:00,  7.83s/it, training_loss=0.142]\u001b[A\n",
            "Epoch 2:  90%|█████████ | 438/484 [58:20<06:00,  7.83s/it, training_loss=0.014]\u001b[A\n",
            "Epoch 2:  91%|█████████ | 439/484 [58:20<06:34,  8.76s/it, training_loss=0.014]\u001b[A\n",
            "Epoch 2:  91%|█████████ | 439/484 [58:28<06:34,  8.76s/it, training_loss=0.153]\u001b[A\n",
            "Epoch 2:  91%|█████████ | 440/484 [58:28<06:16,  8.55s/it, training_loss=0.153]\u001b[A\n",
            "Epoch 2:  91%|█████████ | 440/484 [58:35<06:16,  8.55s/it, training_loss=0.191]\u001b[A\n",
            "Epoch 2:  91%|█████████ | 441/484 [58:35<05:44,  8.01s/it, training_loss=0.191]\u001b[A\n",
            "Epoch 2:  91%|█████████ | 441/484 [58:45<05:44,  8.01s/it, training_loss=0.282]\u001b[A\n",
            "Epoch 2:  91%|█████████▏| 442/484 [58:45<05:53,  8.41s/it, training_loss=0.282]\u001b[A\n",
            "Epoch 2:  91%|█████████▏| 442/484 [58:51<05:53,  8.41s/it, training_loss=0.122]\u001b[A\n",
            "Epoch 2:  92%|█████████▏| 443/484 [58:51<05:22,  7.86s/it, training_loss=0.122]\u001b[A\n",
            "Epoch 2:  92%|█████████▏| 443/484 [59:01<05:22,  7.86s/it, training_loss=0.061]\u001b[A\n",
            "Epoch 2:  92%|█████████▏| 444/484 [59:01<05:35,  8.38s/it, training_loss=0.061]\u001b[A\n",
            "Epoch 2:  92%|█████████▏| 444/484 [59:07<05:35,  8.38s/it, training_loss=0.010]\u001b[A\n",
            "Epoch 2:  92%|█████████▏| 445/484 [59:07<05:07,  7.87s/it, training_loss=0.010]\u001b[A\n",
            "Epoch 2:  92%|█████████▏| 445/484 [59:16<05:07,  7.87s/it, training_loss=0.063]\u001b[A\n",
            "Epoch 2:  92%|█████████▏| 446/484 [59:16<05:05,  8.05s/it, training_loss=0.063]\u001b[A\n",
            "Epoch 2:  92%|█████████▏| 446/484 [59:24<05:05,  8.05s/it, training_loss=0.112]\u001b[A\n",
            "Epoch 2:  92%|█████████▏| 447/484 [59:24<04:53,  7.93s/it, training_loss=0.112]\u001b[A\n",
            "Epoch 2:  92%|█████████▏| 447/484 [59:31<04:53,  7.93s/it, training_loss=0.236]\u001b[A\n",
            "Epoch 2:  93%|█████████▎| 448/484 [59:31<04:35,  7.65s/it, training_loss=0.236]\u001b[A\n",
            "Epoch 2:  93%|█████████▎| 448/484 [59:40<04:35,  7.65s/it, training_loss=0.075]\u001b[A\n",
            "Epoch 2:  93%|█████████▎| 449/484 [59:40<04:42,  8.06s/it, training_loss=0.075]\u001b[A\n",
            "Epoch 2:  93%|█████████▎| 449/484 [59:46<04:42,  8.06s/it, training_loss=0.137]\u001b[A\n",
            "Epoch 2:  93%|█████████▎| 450/484 [59:46<04:19,  7.62s/it, training_loss=0.137]\u001b[A\n",
            "Epoch 2:  93%|█████████▎| 450/484 [59:56<04:19,  7.62s/it, training_loss=0.269]\u001b[A\n",
            "Epoch 2:  93%|█████████▎| 451/484 [59:56<04:31,  8.23s/it, training_loss=0.269]\u001b[A\n",
            "Epoch 2:  93%|█████████▎| 451/484 [1:00:02<04:31,  8.23s/it, training_loss=0.197]\u001b[A\n",
            "Epoch 2:  93%|█████████▎| 452/484 [1:00:02<04:07,  7.73s/it, training_loss=0.197]\u001b[A\n",
            "Epoch 2:  93%|█████████▎| 452/484 [1:00:11<04:07,  7.73s/it, training_loss=0.127]\u001b[A\n",
            "Epoch 2:  94%|█████████▎| 453/484 [1:00:11<04:08,  8.01s/it, training_loss=0.127]\u001b[A\n",
            "Epoch 2:  94%|█████████▎| 453/484 [1:00:18<04:08,  8.01s/it, training_loss=0.023]\u001b[A\n",
            "Epoch 2:  94%|█████████▍| 454/484 [1:00:18<03:55,  7.84s/it, training_loss=0.023]\u001b[A\n",
            "Epoch 2:  94%|█████████▍| 454/484 [1:00:26<03:55,  7.84s/it, training_loss=0.060]\u001b[A\n",
            "Epoch 2:  94%|█████████▍| 455/484 [1:00:26<03:41,  7.63s/it, training_loss=0.060]\u001b[A\n",
            "Epoch 2:  94%|█████████▍| 455/484 [1:00:34<03:41,  7.63s/it, training_loss=0.146]\u001b[A\n",
            "Epoch 2:  94%|█████████▍| 456/484 [1:00:34<03:43,  7.99s/it, training_loss=0.146]\u001b[A\n",
            "Epoch 2:  94%|█████████▍| 456/484 [1:00:41<03:43,  7.99s/it, training_loss=0.017]\u001b[A\n",
            "Epoch 2:  94%|█████████▍| 457/484 [1:00:41<03:24,  7.58s/it, training_loss=0.017]\u001b[A\n",
            "Epoch 2:  94%|█████████▍| 457/484 [1:00:51<03:24,  7.58s/it, training_loss=0.191]\u001b[A\n",
            "Epoch 2:  95%|█████████▍| 458/484 [1:00:51<03:33,  8.22s/it, training_loss=0.191]\u001b[A\n",
            "Epoch 2:  95%|█████████▍| 458/484 [1:00:57<03:33,  8.22s/it, training_loss=0.220]\u001b[A\n",
            "Epoch 2:  95%|█████████▍| 459/484 [1:00:57<03:13,  7.74s/it, training_loss=0.220]\u001b[A\n",
            "Epoch 2:  95%|█████████▍| 459/484 [1:01:06<03:13,  7.74s/it, training_loss=0.044]\u001b[A\n",
            "Epoch 2:  95%|█████████▌| 460/484 [1:01:06<03:15,  8.13s/it, training_loss=0.044]\u001b[A\n",
            "Epoch 2:  95%|█████████▌| 460/484 [1:01:14<03:15,  8.13s/it, training_loss=0.023]\u001b[A\n",
            "Epoch 2:  95%|█████████▌| 461/484 [1:01:14<03:00,  7.86s/it, training_loss=0.023]\u001b[A\n",
            "Epoch 2:  95%|█████████▌| 461/484 [1:01:21<03:00,  7.86s/it, training_loss=0.134]\u001b[A\n",
            "Epoch 2:  95%|█████████▌| 462/484 [1:01:21<02:51,  7.78s/it, training_loss=0.134]\u001b[A\n",
            "Epoch 2:  95%|█████████▌| 462/484 [1:01:30<02:51,  7.78s/it, training_loss=0.014]\u001b[A\n",
            "Epoch 2:  96%|█████████▌| 463/484 [1:01:30<02:47,  7.99s/it, training_loss=0.014]\u001b[A\n",
            "Epoch 2:  96%|█████████▌| 463/484 [1:01:36<02:47,  7.99s/it, training_loss=0.199]\u001b[A\n",
            "Epoch 2:  96%|█████████▌| 464/484 [1:01:36<02:31,  7.60s/it, training_loss=0.199]\u001b[A\n",
            "Epoch 2:  96%|█████████▌| 464/484 [1:01:46<02:31,  7.60s/it, training_loss=0.075]\u001b[A\n",
            "Epoch 2:  96%|█████████▌| 465/484 [1:01:46<02:36,  8.22s/it, training_loss=0.075]\u001b[A\n",
            "Epoch 2:  96%|█████████▌| 465/484 [1:01:53<02:36,  8.22s/it, training_loss=0.143]\u001b[A\n",
            "Epoch 2:  96%|█████████▋| 466/484 [1:01:53<02:18,  7.72s/it, training_loss=0.143]\u001b[A\n",
            "Epoch 2:  96%|█████████▋| 466/484 [1:02:02<02:18,  7.72s/it, training_loss=0.010]\u001b[A\n",
            "Epoch 2:  96%|█████████▋| 467/484 [1:02:02<02:18,  8.16s/it, training_loss=0.010]\u001b[A\n",
            "Epoch 2:  96%|█████████▋| 467/484 [1:02:09<02:18,  8.16s/it, training_loss=0.018]\u001b[A\n",
            "Epoch 2:  97%|█████████▋| 468/484 [1:02:09<02:04,  7.80s/it, training_loss=0.018]\u001b[A\n",
            "Epoch 2:  97%|█████████▋| 468/484 [1:02:17<02:04,  7.80s/it, training_loss=0.004]\u001b[A\n",
            "Epoch 2:  97%|█████████▋| 469/484 [1:02:17<01:56,  7.78s/it, training_loss=0.004]\u001b[A\n",
            "Epoch 2:  97%|█████████▋| 469/484 [1:02:25<01:56,  7.78s/it, training_loss=0.074]\u001b[A\n",
            "Epoch 2:  97%|█████████▋| 470/484 [1:02:25<01:50,  7.90s/it, training_loss=0.074]\u001b[A\n",
            "Epoch 2:  97%|█████████▋| 470/484 [1:02:31<01:50,  7.90s/it, training_loss=0.063]\u001b[A\n",
            "Epoch 2:  97%|█████████▋| 471/484 [1:02:31<01:37,  7.53s/it, training_loss=0.063]\u001b[A\n",
            "Epoch 2:  97%|█████████▋| 471/484 [1:02:41<01:37,  7.53s/it, training_loss=0.012]\u001b[A\n",
            "Epoch 2:  98%|█████████▊| 472/484 [1:02:41<01:37,  8.13s/it, training_loss=0.012]\u001b[A\n",
            "Epoch 2:  98%|█████████▊| 472/484 [1:02:47<01:37,  8.13s/it, training_loss=0.025]\u001b[A\n",
            "Epoch 2:  98%|█████████▊| 473/484 [1:02:47<01:24,  7.67s/it, training_loss=0.025]\u001b[A\n",
            "Epoch 2:  98%|█████████▊| 473/484 [1:02:59<01:24,  7.67s/it, training_loss=0.082]\u001b[A\n",
            "Epoch 2:  98%|█████████▊| 474/484 [1:02:59<01:26,  8.69s/it, training_loss=0.082]\u001b[A\n",
            "Epoch 2:  98%|█████████▊| 474/484 [1:03:07<01:26,  8.69s/it, training_loss=0.231]\u001b[A\n",
            "Epoch 2:  98%|█████████▊| 475/484 [1:03:07<01:17,  8.61s/it, training_loss=0.231]\u001b[A\n",
            "Epoch 2:  98%|█████████▊| 475/484 [1:03:14<01:17,  8.61s/it, training_loss=0.385]\u001b[A\n",
            "Epoch 2:  98%|█████████▊| 476/484 [1:03:14<01:04,  8.05s/it, training_loss=0.385]\u001b[A\n",
            "Epoch 2:  98%|█████████▊| 476/484 [1:03:23<01:04,  8.05s/it, training_loss=0.010]\u001b[A\n",
            "Epoch 2:  99%|█████████▊| 477/484 [1:03:23<00:59,  8.52s/it, training_loss=0.010]\u001b[A\n",
            "Epoch 2:  99%|█████████▊| 477/484 [1:03:30<00:59,  8.52s/it, training_loss=0.217]\u001b[A\n",
            "Epoch 2:  99%|█████████▉| 478/484 [1:03:30<00:47,  7.95s/it, training_loss=0.217]\u001b[A\n",
            "Epoch 2:  99%|█████████▉| 478/484 [1:03:39<00:47,  7.95s/it, training_loss=0.387]\u001b[A\n",
            "Epoch 2:  99%|█████████▉| 479/484 [1:03:39<00:42,  8.41s/it, training_loss=0.387]\u001b[A\n",
            "Epoch 2:  99%|█████████▉| 479/484 [1:03:46<00:42,  8.41s/it, training_loss=0.022]\u001b[A\n",
            "Epoch 2:  99%|█████████▉| 480/484 [1:03:46<00:31,  7.93s/it, training_loss=0.022]\u001b[A\n",
            "Epoch 2:  99%|█████████▉| 480/484 [1:03:54<00:31,  7.93s/it, training_loss=0.059]\u001b[A\n",
            "Epoch 2:  99%|█████████▉| 481/484 [1:03:54<00:23,  7.99s/it, training_loss=0.059]\u001b[A\n",
            "Epoch 2:  99%|█████████▉| 481/484 [1:04:02<00:23,  7.99s/it, training_loss=0.277]\u001b[A\n",
            "Epoch 2: 100%|█████████▉| 482/484 [1:04:02<00:15,  7.96s/it, training_loss=0.277]\u001b[A\n",
            "Epoch 2: 100%|█████████▉| 482/484 [1:04:09<00:15,  7.96s/it, training_loss=0.178]\u001b[A\n",
            "Epoch 2: 100%|█████████▉| 483/484 [1:04:09<00:07,  7.62s/it, training_loss=0.178]\u001b[A\n",
            "Epoch 2: 100%|█████████▉| 483/484 [1:04:17<00:07,  7.62s/it, training_loss=0.011]\u001b[A\n",
            "Epoch 2: 100%|██████████| 484/484 [1:04:17<00:00,  7.69s/it, training_loss=0.011]\u001b[A\n",
            " 33%|███▎      | 1/3 [2:14:50<2:21:00, 4230.26s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            " Epoch {epoch}\n",
            "Training loss: {loss_train_avg}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "  0%|          | 0/121 [00:00<?, ?it/s]\u001b[A\n",
            "  1%|          | 1/121 [00:01<03:57,  1.98s/it]\u001b[A\n",
            "  2%|▏         | 2/121 [00:03<03:54,  1.97s/it]\u001b[A\n",
            "  2%|▏         | 3/121 [00:05<03:54,  1.99s/it]\u001b[A\n",
            "  3%|▎         | 4/121 [00:08<04:22,  2.24s/it]\u001b[A\n",
            "  4%|▍         | 5/121 [00:12<05:44,  2.97s/it]\u001b[A\n",
            "  5%|▍         | 6/121 [00:16<05:57,  3.11s/it]\u001b[A\n",
            "  6%|▌         | 7/121 [00:18<05:11,  2.74s/it]\u001b[A\n",
            "  7%|▋         | 8/121 [00:20<04:40,  2.49s/it]\u001b[A\n",
            "  7%|▋         | 9/121 [00:22<04:20,  2.33s/it]\u001b[A\n",
            "  8%|▊         | 10/121 [00:24<04:06,  2.22s/it]\u001b[A\n",
            "  9%|▉         | 11/121 [00:26<03:55,  2.14s/it]\u001b[A\n",
            " 10%|▉         | 12/121 [00:29<04:27,  2.46s/it]\u001b[A\n",
            " 11%|█         | 13/121 [00:32<04:51,  2.70s/it]\u001b[A\n",
            " 12%|█▏        | 14/121 [00:35<04:52,  2.74s/it]\u001b[A\n",
            " 12%|█▏        | 15/121 [00:37<04:31,  2.56s/it]\u001b[A\n",
            " 13%|█▎        | 16/121 [00:39<04:18,  2.46s/it]\u001b[A\n",
            " 14%|█▍        | 17/121 [00:42<04:26,  2.56s/it]\u001b[A\n",
            " 15%|█▍        | 18/121 [00:44<04:20,  2.53s/it]\u001b[A\n",
            " 16%|█▌        | 19/121 [00:50<05:40,  3.34s/it]\u001b[A\n",
            " 17%|█▋        | 20/121 [00:53<05:36,  3.33s/it]\u001b[A\n",
            " 17%|█▋        | 21/121 [00:56<05:24,  3.24s/it]\u001b[A\n",
            " 18%|█▊        | 22/121 [00:58<04:47,  2.90s/it]\u001b[A\n",
            " 19%|█▉        | 23/121 [01:00<04:21,  2.66s/it]\u001b[A\n",
            " 20%|█▉        | 24/121 [01:02<04:03,  2.51s/it]\u001b[A\n",
            " 21%|██        | 25/121 [01:05<03:58,  2.48s/it]\u001b[A\n",
            " 21%|██▏       | 26/121 [01:08<04:07,  2.61s/it]\u001b[A\n",
            " 22%|██▏       | 27/121 [01:11<04:22,  2.80s/it]\u001b[A\n",
            " 23%|██▎       | 28/121 [01:14<04:27,  2.88s/it]\u001b[A\n",
            " 24%|██▍       | 29/121 [01:16<04:00,  2.62s/it]\u001b[A\n",
            " 25%|██▍       | 30/121 [01:18<03:40,  2.43s/it]\u001b[A\n",
            " 26%|██▌       | 31/121 [01:20<03:25,  2.28s/it]\u001b[A\n",
            " 26%|██▋       | 32/121 [01:22<03:16,  2.20s/it]\u001b[A\n",
            " 27%|██▋       | 33/121 [01:24<03:07,  2.13s/it]\u001b[A\n",
            " 28%|██▊       | 34/121 [01:27<03:31,  2.43s/it]\u001b[A\n",
            " 29%|██▉       | 35/121 [01:30<03:46,  2.63s/it]\u001b[A\n",
            " 30%|██▉       | 36/121 [01:33<03:47,  2.68s/it]\u001b[A\n",
            " 31%|███       | 37/121 [01:35<03:27,  2.47s/it]\u001b[A\n",
            " 31%|███▏      | 38/121 [01:37<03:12,  2.32s/it]\u001b[A\n",
            " 32%|███▏      | 39/121 [01:39<03:02,  2.22s/it]\u001b[A\n",
            " 33%|███▎      | 40/121 [01:41<02:54,  2.15s/it]\u001b[A\n",
            " 34%|███▍      | 41/121 [01:43<02:53,  2.17s/it]\u001b[A\n",
            " 35%|███▍      | 42/121 [01:46<03:17,  2.50s/it]\u001b[A\n",
            " 36%|███▌      | 43/121 [01:49<03:28,  2.68s/it]\u001b[A\n",
            " 36%|███▋      | 44/121 [01:52<03:21,  2.61s/it]\u001b[A\n",
            " 37%|███▋      | 45/121 [01:54<03:04,  2.42s/it]\u001b[A\n",
            " 38%|███▊      | 46/121 [01:56<02:51,  2.28s/it]\u001b[A\n",
            " 39%|███▉      | 47/121 [01:58<02:41,  2.19s/it]\u001b[A\n",
            " 40%|███▉      | 48/121 [02:00<02:34,  2.12s/it]\u001b[A\n",
            " 40%|████      | 49/121 [02:02<02:43,  2.27s/it]\u001b[A\n",
            " 41%|████▏     | 50/121 [02:06<03:01,  2.56s/it]\u001b[A\n",
            " 42%|████▏     | 51/121 [02:09<03:07,  2.68s/it]\u001b[A\n",
            " 43%|████▎     | 52/121 [02:11<02:54,  2.53s/it]\u001b[A\n",
            " 44%|████▍     | 53/121 [02:13<02:40,  2.36s/it]\u001b[A\n",
            " 45%|████▍     | 54/121 [02:15<02:30,  2.24s/it]\u001b[A\n",
            " 45%|████▌     | 55/121 [02:17<02:22,  2.16s/it]\u001b[A\n",
            " 46%|████▋     | 56/121 [02:19<02:16,  2.10s/it]\u001b[A\n",
            " 47%|████▋     | 57/121 [02:22<02:29,  2.33s/it]\u001b[A\n",
            " 48%|████▊     | 58/121 [02:25<02:44,  2.61s/it]\u001b[A\n",
            " 49%|████▉     | 59/121 [02:28<02:48,  2.72s/it]\u001b[A\n",
            " 50%|████▉     | 60/121 [02:30<02:32,  2.50s/it]\u001b[A\n",
            " 50%|█████     | 61/121 [02:32<02:20,  2.34s/it]\u001b[A\n",
            " 51%|█████     | 62/121 [02:34<02:11,  2.23s/it]\u001b[A\n",
            " 52%|█████▏    | 63/121 [02:36<02:04,  2.15s/it]\u001b[A\n",
            " 53%|█████▎    | 64/121 [02:38<01:59,  2.10s/it]\u001b[A\n",
            " 54%|█████▎    | 65/121 [02:41<02:16,  2.45s/it]\u001b[A\n",
            " 55%|█████▍    | 66/121 [02:44<02:26,  2.66s/it]\u001b[A\n",
            " 55%|█████▌    | 67/121 [02:47<02:23,  2.65s/it]\u001b[A\n",
            " 56%|█████▌    | 68/121 [02:49<02:09,  2.45s/it]\u001b[A\n",
            " 57%|█████▋    | 69/121 [02:51<02:00,  2.32s/it]\u001b[A\n",
            " 58%|█████▊    | 70/121 [02:53<01:53,  2.22s/it]\u001b[A\n",
            " 59%|█████▊    | 71/121 [02:55<01:47,  2.15s/it]\u001b[A\n",
            " 60%|█████▉    | 72/121 [02:57<01:49,  2.23s/it]\u001b[A\n",
            " 60%|██████    | 73/121 [03:00<02:01,  2.53s/it]\u001b[A\n",
            " 61%|██████    | 74/121 [03:03<02:06,  2.68s/it]\u001b[A\n",
            " 62%|██████▏   | 75/121 [03:06<01:58,  2.58s/it]\u001b[A\n",
            " 63%|██████▎   | 76/121 [03:08<01:48,  2.40s/it]\u001b[A\n",
            " 64%|██████▎   | 77/121 [03:10<01:40,  2.27s/it]\u001b[A\n",
            " 64%|██████▍   | 78/121 [03:12<01:33,  2.18s/it]\u001b[A\n",
            " 65%|██████▌   | 79/121 [03:14<01:29,  2.12s/it]\u001b[A\n",
            " 66%|██████▌   | 80/121 [03:16<01:34,  2.31s/it]\u001b[A\n",
            " 67%|██████▋   | 81/121 [03:20<01:43,  2.60s/it]\u001b[A\n",
            " 68%|██████▊   | 82/121 [03:23<01:53,  2.92s/it]\u001b[A\n",
            " 69%|██████▊   | 83/121 [03:27<01:58,  3.13s/it]\u001b[A\n",
            " 69%|██████▉   | 84/121 [03:30<01:54,  3.10s/it]\u001b[A\n",
            " 70%|███████   | 85/121 [03:32<01:39,  2.77s/it]\u001b[A\n",
            " 71%|███████   | 86/121 [03:34<01:28,  2.53s/it]\u001b[A\n",
            " 72%|███████▏  | 87/121 [03:36<01:20,  2.36s/it]\u001b[A\n",
            " 73%|███████▎  | 88/121 [03:39<01:21,  2.47s/it]\u001b[A\n",
            " 74%|███████▎  | 89/121 [03:42<01:26,  2.69s/it]\u001b[A\n",
            " 74%|███████▍  | 90/121 [03:45<01:26,  2.80s/it]\u001b[A\n",
            " 75%|███████▌  | 91/121 [03:47<01:17,  2.58s/it]\u001b[A\n",
            " 76%|███████▌  | 92/121 [03:49<01:09,  2.40s/it]\u001b[A\n",
            " 77%|███████▋  | 93/121 [03:51<01:03,  2.27s/it]\u001b[A\n",
            " 78%|███████▊  | 94/121 [03:53<00:58,  2.18s/it]\u001b[A\n",
            " 79%|███████▊  | 95/121 [03:55<00:55,  2.12s/it]\u001b[A\n",
            " 79%|███████▉  | 96/121 [03:58<01:00,  2.41s/it]\u001b[A\n",
            " 80%|████████  | 97/121 [04:01<01:03,  2.64s/it]\u001b[A\n",
            " 81%|████████  | 98/121 [04:04<01:01,  2.68s/it]\u001b[A\n",
            " 82%|████████▏ | 99/121 [04:06<00:54,  2.46s/it]\u001b[A\n",
            " 83%|████████▎ | 100/121 [04:08<00:48,  2.32s/it]\u001b[A\n",
            " 83%|████████▎ | 101/121 [04:10<00:44,  2.22s/it]\u001b[A\n",
            " 84%|████████▍ | 102/121 [04:12<00:40,  2.15s/it]\u001b[A\n",
            " 85%|████████▌ | 103/121 [04:14<00:38,  2.15s/it]\u001b[A\n",
            " 86%|████████▌ | 104/121 [04:17<00:42,  2.49s/it]\u001b[A\n",
            " 87%|████████▋ | 105/121 [04:20<00:43,  2.69s/it]\u001b[A\n",
            " 88%|████████▊ | 106/121 [04:23<00:39,  2.62s/it]\u001b[A\n",
            " 88%|████████▊ | 107/121 [04:25<00:33,  2.42s/it]\u001b[A\n",
            " 89%|████████▉ | 108/121 [04:27<00:29,  2.28s/it]\u001b[A\n",
            " 90%|█████████ | 109/121 [04:29<00:26,  2.19s/it]\u001b[A\n",
            " 91%|█████████ | 110/121 [04:31<00:23,  2.12s/it]\u001b[A\n",
            " 92%|█████████▏| 111/121 [04:33<00:22,  2.24s/it]\u001b[A\n",
            " 93%|█████████▎| 112/121 [04:36<00:22,  2.55s/it]\u001b[A\n",
            " 93%|█████████▎| 113/121 [04:39<00:21,  2.69s/it]\u001b[A\n",
            " 94%|█████████▍| 114/121 [04:42<00:17,  2.55s/it]\u001b[A\n",
            " 95%|█████████▌| 115/121 [04:44<00:14,  2.38s/it]\u001b[A\n",
            " 96%|█████████▌| 116/121 [04:46<00:11,  2.25s/it]\u001b[A\n",
            " 97%|█████████▋| 117/121 [04:48<00:08,  2.17s/it]\u001b[A\n",
            " 98%|█████████▊| 118/121 [04:50<00:06,  2.12s/it]\u001b[A\n",
            " 98%|█████████▊| 119/121 [04:52<00:04,  2.36s/it]\u001b[A\n",
            " 99%|█████████▉| 120/121 [04:56<00:02,  2.61s/it]\u001b[A\n",
            "100%|██████████| 121/121 [04:59<00:00,  2.47s/it]\n",
            " 67%|██████▋   | 2/3 [2:19:49<1:09:48, 4188.36s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Validation loss: 0.4858403139832345\n",
            "F1 Score (weighted): 0.8390961072277918\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "Epoch 3:   0%|          | 0/484 [00:00<?, ?it/s]\u001b[A\n",
            "Epoch 3:   0%|          | 0/484 [00:07<?, ?it/s, training_loss=0.172]\u001b[A\n",
            "Epoch 3:   0%|          | 1/484 [00:07<58:14,  7.24s/it, training_loss=0.172]\u001b[A\n",
            "Epoch 3:   0%|          | 1/484 [00:16<58:14,  7.24s/it, training_loss=0.183]\u001b[A\n",
            "Epoch 3:   0%|          | 2/484 [00:16<1:06:18,  8.25s/it, training_loss=0.183]\u001b[A\n",
            "Epoch 3:   0%|          | 2/484 [00:23<1:06:18,  8.25s/it, training_loss=0.005]\u001b[A\n",
            "Epoch 3:   1%|          | 3/484 [00:23<1:02:25,  7.79s/it, training_loss=0.005]\u001b[A\n",
            "Epoch 3:   1%|          | 3/484 [00:31<1:02:25,  7.79s/it, training_loss=0.012]\u001b[A\n",
            "Epoch 3:   1%|          | 4/484 [00:31<1:01:46,  7.72s/it, training_loss=0.012]\u001b[A\n",
            "Epoch 3:   1%|          | 4/484 [00:39<1:01:46,  7.72s/it, training_loss=0.106]\u001b[A\n",
            "Epoch 3:   1%|          | 5/484 [00:39<1:03:53,  8.00s/it, training_loss=0.106]\u001b[A\n",
            "Epoch 3:   1%|          | 5/484 [00:46<1:03:53,  8.00s/it, training_loss=0.077]\u001b[A\n",
            "Epoch 3:   1%|          | 6/484 [00:46<1:00:02,  7.54s/it, training_loss=0.077]\u001b[A\n",
            "Epoch 3:   1%|          | 6/484 [00:55<1:00:02,  7.54s/it, training_loss=0.094]\u001b[A\n",
            "Epoch 3:   1%|▏         | 7/484 [00:55<1:05:42,  8.26s/it, training_loss=0.094]\u001b[A\n",
            "Epoch 3:   1%|▏         | 7/484 [01:02<1:05:42,  8.26s/it, training_loss=0.008]\u001b[A\n",
            "Epoch 3:   2%|▏         | 8/484 [01:02<1:01:25,  7.74s/it, training_loss=0.008]\u001b[A\n",
            "Epoch 3:   2%|▏         | 8/484 [01:11<1:01:25,  7.74s/it, training_loss=0.250]\u001b[A\n",
            "Epoch 3:   2%|▏         | 9/484 [01:11<1:04:59,  8.21s/it, training_loss=0.250]\u001b[A\n",
            "Epoch 3:   2%|▏         | 9/484 [01:18<1:04:59,  8.21s/it, training_loss=0.020]\u001b[A\n",
            "Epoch 3:   2%|▏         | 10/484 [01:18<1:01:41,  7.81s/it, training_loss=0.020]\u001b[A\n",
            "Epoch 3:   2%|▏         | 10/484 [01:26<1:01:41,  7.81s/it, training_loss=0.008]\u001b[A\n",
            "Epoch 3:   2%|▏         | 11/484 [01:26<1:01:55,  7.85s/it, training_loss=0.008]\u001b[A\n",
            "Epoch 3:   2%|▏         | 11/484 [01:34<1:01:55,  7.85s/it, training_loss=0.132]\u001b[A\n",
            "Epoch 3:   2%|▏         | 12/484 [01:34<1:02:19,  7.92s/it, training_loss=0.132]\u001b[A\n",
            "Epoch 3:   2%|▏         | 12/484 [01:41<1:02:19,  7.92s/it, training_loss=0.009]\u001b[A\n",
            "Epoch 3:   3%|▎         | 13/484 [01:41<59:31,  7.58s/it, training_loss=0.009]  \u001b[A\n",
            "Epoch 3:   3%|▎         | 13/484 [01:51<59:31,  7.58s/it, training_loss=0.011]\u001b[A\n",
            "Epoch 3:   3%|▎         | 14/484 [01:51<1:03:58,  8.17s/it, training_loss=0.011]\u001b[A\n",
            "Epoch 3:   3%|▎         | 14/484 [01:57<1:03:58,  8.17s/it, training_loss=0.006]\u001b[A\n",
            "Epoch 3:   3%|▎         | 15/484 [01:57<1:00:13,  7.70s/it, training_loss=0.006]\u001b[A\n",
            "Epoch 3:   3%|▎         | 15/484 [02:07<1:00:13,  7.70s/it, training_loss=0.140]\u001b[A\n",
            "Epoch 3:   3%|▎         | 16/484 [02:07<1:04:25,  8.26s/it, training_loss=0.140]\u001b[A\n",
            "Epoch 3:   3%|▎         | 16/484 [02:13<1:04:25,  8.26s/it, training_loss=0.048]\u001b[A\n",
            "Epoch 3:   4%|▎         | 17/484 [02:13<1:00:27,  7.77s/it, training_loss=0.048]\u001b[A\n",
            "Epoch 3:   4%|▎         | 17/484 [02:22<1:00:27,  7.77s/it, training_loss=0.187]\u001b[A\n",
            "Epoch 3:   4%|▎         | 18/484 [02:22<1:01:42,  7.95s/it, training_loss=0.187]\u001b[A\n",
            "Epoch 3:   4%|▎         | 18/484 [02:30<1:01:42,  7.95s/it, training_loss=0.041]\u001b[A\n",
            "Epoch 3:   4%|▍         | 19/484 [02:30<1:01:09,  7.89s/it, training_loss=0.041]\u001b[A\n",
            "Epoch 3:   4%|▍         | 19/484 [02:36<1:01:09,  7.89s/it, training_loss=0.123]\u001b[A\n",
            "Epoch 3:   4%|▍         | 20/484 [02:36<58:34,  7.57s/it, training_loss=0.123]  \u001b[A\n",
            "Epoch 3:   4%|▍         | 20/484 [02:46<58:34,  7.57s/it, training_loss=0.005]\u001b[A\n",
            "Epoch 3:   4%|▍         | 21/484 [02:46<1:02:10,  8.06s/it, training_loss=0.005]\u001b[A\n",
            "Epoch 3:   4%|▍         | 21/484 [02:52<1:02:10,  8.06s/it, training_loss=0.012]\u001b[A\n",
            "Epoch 3:   5%|▍         | 22/484 [02:52<59:17,  7.70s/it, training_loss=0.012]  \u001b[A\n",
            "Epoch 3:   5%|▍         | 22/484 [03:04<59:17,  7.70s/it, training_loss=0.017]\u001b[A\n",
            "Epoch 3:   5%|▍         | 23/484 [03:04<1:07:40,  8.81s/it, training_loss=0.017]\u001b[A\n",
            "Epoch 3:   5%|▍         | 23/484 [03:11<1:07:40,  8.81s/it, training_loss=0.023]\u001b[A\n",
            "Epoch 3:   5%|▍         | 24/484 [03:11<1:04:49,  8.46s/it, training_loss=0.023]\u001b[A\n",
            "Epoch 3:   5%|▍         | 24/484 [03:19<1:04:49,  8.46s/it, training_loss=0.030]\u001b[A\n",
            "Epoch 3:   5%|▌         | 25/484 [03:19<1:01:34,  8.05s/it, training_loss=0.030]\u001b[A\n",
            "Epoch 3:   5%|▌         | 25/484 [03:27<1:01:34,  8.05s/it, training_loss=0.013]\u001b[A\n",
            "Epoch 3:   5%|▌         | 26/484 [03:27<1:03:26,  8.31s/it, training_loss=0.013]\u001b[A\n",
            "Epoch 3:   5%|▌         | 26/484 [03:34<1:03:26,  8.31s/it, training_loss=0.173]\u001b[A\n",
            "Epoch 3:   6%|▌         | 27/484 [03:34<59:28,  7.81s/it, training_loss=0.173]  \u001b[A\n",
            "Epoch 3:   6%|▌         | 27/484 [03:44<59:28,  7.81s/it, training_loss=0.013]\u001b[A\n",
            "Epoch 3:   6%|▌         | 28/484 [03:44<1:03:38,  8.37s/it, training_loss=0.013]\u001b[A\n",
            "Epoch 3:   6%|▌         | 28/484 [03:50<1:03:38,  8.37s/it, training_loss=0.015]\u001b[A\n",
            "Epoch 3:   6%|▌         | 29/484 [03:50<59:22,  7.83s/it, training_loss=0.015]  \u001b[A\n",
            "Epoch 3:   6%|▌         | 29/484 [03:59<59:22,  7.83s/it, training_loss=0.006]\u001b[A\n",
            "Epoch 3:   6%|▌         | 30/484 [03:59<1:01:58,  8.19s/it, training_loss=0.006]\u001b[A\n",
            "Epoch 3:   6%|▌         | 30/484 [04:07<1:01:58,  8.19s/it, training_loss=0.045]\u001b[A\n",
            "Epoch 3:   6%|▋         | 31/484 [04:07<59:39,  7.90s/it, training_loss=0.045]  \u001b[A\n",
            "Epoch 3:   6%|▋         | 31/484 [04:14<59:39,  7.90s/it, training_loss=0.053]\u001b[A\n",
            "Epoch 3:   7%|▋         | 32/484 [04:14<58:42,  7.79s/it, training_loss=0.053]\u001b[A\n",
            "Epoch 3:   7%|▋         | 32/484 [04:23<58:42,  7.79s/it, training_loss=0.023]\u001b[A\n",
            "Epoch 3:   7%|▋         | 33/484 [04:23<1:00:01,  7.98s/it, training_loss=0.023]\u001b[A\n",
            "Epoch 3:   7%|▋         | 33/484 [04:29<1:00:01,  7.98s/it, training_loss=0.275]\u001b[A\n",
            "Epoch 3:   7%|▋         | 34/484 [04:29<56:54,  7.59s/it, training_loss=0.275]  \u001b[A\n",
            "Epoch 3:   7%|▋         | 34/484 [04:39<56:54,  7.59s/it, training_loss=0.048]\u001b[A\n",
            "Epoch 3:   7%|▋         | 35/484 [04:39<1:01:32,  8.22s/it, training_loss=0.048]\u001b[A\n",
            "Epoch 3:   7%|▋         | 35/484 [04:45<1:01:32,  8.22s/it, training_loss=0.030]\u001b[A\n",
            "Epoch 3:   7%|▋         | 36/484 [04:46<57:41,  7.73s/it, training_loss=0.030]  \u001b[A\n",
            "Epoch 3:   7%|▋         | 36/484 [04:55<57:41,  7.73s/it, training_loss=0.006]\u001b[A\n",
            "Epoch 3:   8%|▊         | 37/484 [04:55<1:00:50,  8.17s/it, training_loss=0.006]\u001b[A\n",
            "Epoch 3:   8%|▊         | 37/484 [05:02<1:00:50,  8.17s/it, training_loss=0.095]\u001b[A\n",
            "Epoch 3:   8%|▊         | 38/484 [05:02<58:02,  7.81s/it, training_loss=0.095]  \u001b[A\n",
            "Epoch 3:   8%|▊         | 38/484 [05:10<58:02,  7.81s/it, training_loss=0.011]\u001b[A\n",
            "Epoch 3:   8%|▊         | 39/484 [05:10<58:00,  7.82s/it, training_loss=0.011]\u001b[A\n",
            "Epoch 3:   8%|▊         | 39/484 [05:18<58:00,  7.82s/it, training_loss=0.009]\u001b[A\n",
            "Epoch 3:   8%|▊         | 40/484 [05:18<58:34,  7.92s/it, training_loss=0.009]\u001b[A\n",
            "Epoch 3:   8%|▊         | 40/484 [05:24<58:34,  7.92s/it, training_loss=0.005]\u001b[A\n",
            "Epoch 3:   8%|▊         | 41/484 [05:24<55:40,  7.54s/it, training_loss=0.005]\u001b[A\n",
            "Epoch 3:   8%|▊         | 41/484 [05:34<55:40,  7.54s/it, training_loss=0.023]\u001b[A\n",
            "Epoch 3:   9%|▊         | 42/484 [05:34<1:00:01,  8.15s/it, training_loss=0.023]\u001b[A\n",
            "Epoch 3:   9%|▊         | 42/484 [05:41<1:00:01,  8.15s/it, training_loss=0.094]\u001b[A\n",
            "Epoch 3:   9%|▉         | 43/484 [05:41<56:37,  7.70s/it, training_loss=0.094]  \u001b[A\n",
            "Epoch 3:   9%|▉         | 43/484 [05:50<56:37,  7.70s/it, training_loss=0.147]\u001b[A\n",
            "Epoch 3:   9%|▉         | 44/484 [05:50<1:00:29,  8.25s/it, training_loss=0.147]\u001b[A\n",
            "Epoch 3:   9%|▉         | 44/484 [05:57<1:00:29,  8.25s/it, training_loss=0.167]\u001b[A\n",
            "Epoch 3:   9%|▉         | 45/484 [05:57<57:02,  7.80s/it, training_loss=0.167]  \u001b[A\n",
            "Epoch 3:   9%|▉         | 45/484 [06:05<57:02,  7.80s/it, training_loss=0.094]\u001b[A\n",
            "Epoch 3:  10%|▉         | 46/484 [06:05<57:57,  7.94s/it, training_loss=0.094]\u001b[A\n",
            "Epoch 3:  10%|▉         | 46/484 [06:13<57:57,  7.94s/it, training_loss=0.006]\u001b[A\n",
            "Epoch 3:  10%|▉         | 47/484 [06:13<57:43,  7.93s/it, training_loss=0.006]\u001b[A\n",
            "Epoch 3:  10%|▉         | 47/484 [06:20<57:43,  7.93s/it, training_loss=0.014]\u001b[A\n",
            "Epoch 3:  10%|▉         | 48/484 [06:20<55:01,  7.57s/it, training_loss=0.014]\u001b[A\n",
            "Epoch 3:  10%|▉         | 48/484 [06:29<55:01,  7.57s/it, training_loss=0.034]\u001b[A\n",
            "Epoch 3:  10%|█         | 49/484 [06:29<58:43,  8.10s/it, training_loss=0.034]\u001b[A\n",
            "Epoch 3:  10%|█         | 49/484 [06:36<58:43,  8.10s/it, training_loss=0.070]\u001b[A\n",
            "Epoch 3:  10%|█         | 50/484 [06:36<55:26,  7.67s/it, training_loss=0.070]\u001b[A\n",
            "Epoch 3:  10%|█         | 50/484 [06:45<55:26,  7.67s/it, training_loss=0.199]\u001b[A\n",
            "Epoch 3:  11%|█         | 51/484 [06:45<59:31,  8.25s/it, training_loss=0.199]\u001b[A\n",
            "Epoch 3:  11%|█         | 51/484 [06:52<59:31,  8.25s/it, training_loss=0.007]\u001b[A\n",
            "Epoch 3:  11%|█         | 52/484 [06:52<55:47,  7.75s/it, training_loss=0.007]\u001b[A\n",
            "Epoch 3:  11%|█         | 52/484 [07:00<55:47,  7.75s/it, training_loss=0.081]\u001b[A\n",
            "Epoch 3:  11%|█         | 53/484 [07:00<57:15,  7.97s/it, training_loss=0.081]\u001b[A\n",
            "Epoch 3:  11%|█         | 53/484 [07:08<57:15,  7.97s/it, training_loss=0.007]\u001b[A\n",
            "Epoch 3:  11%|█         | 54/484 [07:08<56:27,  7.88s/it, training_loss=0.007]\u001b[A\n",
            "Epoch 3:  11%|█         | 54/484 [07:15<56:27,  7.88s/it, training_loss=0.009]\u001b[A\n",
            "Epoch 3:  11%|█▏        | 55/484 [07:15<54:16,  7.59s/it, training_loss=0.009]\u001b[A\n",
            "Epoch 3:  11%|█▏        | 55/484 [07:25<54:16,  7.59s/it, training_loss=0.062]\u001b[A\n",
            "Epoch 3:  12%|█▏        | 56/484 [07:25<59:40,  8.37s/it, training_loss=0.062]\u001b[A\n",
            "Epoch 3:  12%|█▏        | 56/484 [07:34<59:40,  8.37s/it, training_loss=0.064]\u001b[A\n",
            "Epoch 3:  12%|█▏        | 57/484 [07:34<1:01:14,  8.61s/it, training_loss=0.064]\u001b[A\n",
            "Epoch 3:  12%|█▏        | 57/484 [07:43<1:01:14,  8.61s/it, training_loss=0.008]\u001b[A\n",
            "Epoch 3:  12%|█▏        | 58/484 [07:43<1:01:01,  8.60s/it, training_loss=0.008]\u001b[A\n",
            "Epoch 3:  12%|█▏        | 58/484 [07:50<1:01:01,  8.60s/it, training_loss=0.012]\u001b[A\n",
            "Epoch 3:  12%|█▏        | 59/484 [07:50<56:45,  8.01s/it, training_loss=0.012]  \u001b[A\n",
            "Epoch 3:  12%|█▏        | 59/484 [07:59<56:45,  8.01s/it, training_loss=0.050]\u001b[A\n",
            "Epoch 3:  12%|█▏        | 60/484 [07:59<1:00:17,  8.53s/it, training_loss=0.050]\u001b[A\n",
            "Epoch 3:  12%|█▏        | 60/484 [08:06<1:00:17,  8.53s/it, training_loss=0.010]\u001b[A\n",
            "Epoch 3:  13%|█▎        | 61/484 [08:06<55:58,  7.94s/it, training_loss=0.010]  \u001b[A\n",
            "Epoch 3:  13%|█▎        | 61/484 [08:15<55:58,  7.94s/it, training_loss=0.077]\u001b[A\n",
            "Epoch 3:  13%|█▎        | 62/484 [08:15<58:27,  8.31s/it, training_loss=0.077]\u001b[A\n",
            "Epoch 3:  13%|█▎        | 62/484 [08:22<58:27,  8.31s/it, training_loss=0.178]\u001b[A\n",
            "Epoch 3:  13%|█▎        | 63/484 [08:22<55:21,  7.89s/it, training_loss=0.178]\u001b[A\n",
            "Epoch 3:  13%|█▎        | 63/484 [08:30<55:21,  7.89s/it, training_loss=0.006]\u001b[A\n",
            "Epoch 3:  13%|█▎        | 64/484 [08:30<55:03,  7.87s/it, training_loss=0.006]\u001b[A\n",
            "Epoch 3:  13%|█▎        | 64/484 [08:38<55:03,  7.87s/it, training_loss=0.225]\u001b[A\n",
            "Epoch 3:  13%|█▎        | 65/484 [08:38<55:26,  7.94s/it, training_loss=0.225]\u001b[A\n",
            "Epoch 3:  13%|█▎        | 65/484 [08:44<55:26,  7.94s/it, training_loss=0.179]\u001b[A\n",
            "Epoch 3:  14%|█▎        | 66/484 [08:44<52:28,  7.53s/it, training_loss=0.179]\u001b[A\n",
            "Epoch 3:  14%|█▎        | 66/484 [08:54<52:28,  7.53s/it, training_loss=0.049]\u001b[A\n",
            "Epoch 3:  14%|█▍        | 67/484 [08:54<56:35,  8.14s/it, training_loss=0.049]\u001b[A\n",
            "Epoch 3:  14%|█▍        | 67/484 [09:01<56:35,  8.14s/it, training_loss=0.048]\u001b[A\n",
            "Epoch 3:  14%|█▍        | 68/484 [09:01<53:08,  7.66s/it, training_loss=0.048]\u001b[A\n",
            "Epoch 3:  14%|█▍        | 68/484 [09:10<53:08,  7.66s/it, training_loss=0.281]\u001b[A\n",
            "Epoch 3:  14%|█▍        | 69/484 [09:10<56:26,  8.16s/it, training_loss=0.281]\u001b[A\n",
            "Epoch 3:  14%|█▍        | 69/484 [09:17<56:26,  8.16s/it, training_loss=0.012]\u001b[A\n",
            "Epoch 3:  14%|█▍        | 70/484 [09:17<53:37,  7.77s/it, training_loss=0.012]\u001b[A\n",
            "Epoch 3:  14%|█▍        | 70/484 [09:25<53:37,  7.77s/it, training_loss=0.026]\u001b[A\n",
            "Epoch 3:  15%|█▍        | 71/484 [09:25<53:42,  7.80s/it, training_loss=0.026]\u001b[A\n",
            "Epoch 3:  15%|█▍        | 71/484 [09:33<53:42,  7.80s/it, training_loss=0.105]\u001b[A\n",
            "Epoch 3:  15%|█▍        | 72/484 [09:33<54:09,  7.89s/it, training_loss=0.105]\u001b[A\n",
            "Epoch 3:  15%|█▍        | 72/484 [09:39<54:09,  7.89s/it, training_loss=0.220]\u001b[A\n",
            "Epoch 3:  15%|█▌        | 73/484 [09:39<51:41,  7.55s/it, training_loss=0.220]\u001b[A\n",
            "Epoch 3:  15%|█▌        | 73/484 [09:49<51:41,  7.55s/it, training_loss=0.007]\u001b[A\n",
            "Epoch 3:  15%|█▌        | 74/484 [09:49<55:39,  8.15s/it, training_loss=0.007]\u001b[A\n",
            "Epoch 3:  15%|█▌        | 74/484 [09:56<55:39,  8.15s/it, training_loss=0.030]\u001b[A\n",
            "Epoch 3:  15%|█▌        | 75/484 [09:56<52:24,  7.69s/it, training_loss=0.030]\u001b[A\n",
            "Epoch 3:  15%|█▌        | 75/484 [10:05<52:24,  7.69s/it, training_loss=0.137]\u001b[A\n",
            "Epoch 3:  16%|█▌        | 76/484 [10:05<55:52,  8.22s/it, training_loss=0.137]\u001b[A\n",
            "Epoch 3:  16%|█▌        | 76/484 [10:12<55:52,  8.22s/it, training_loss=0.010]\u001b[A\n",
            "Epoch 3:  16%|█▌        | 77/484 [10:12<52:43,  7.77s/it, training_loss=0.010]\u001b[A\n",
            "Epoch 3:  16%|█▌        | 77/484 [10:20<52:43,  7.77s/it, training_loss=0.019]\u001b[A\n",
            "Epoch 3:  16%|█▌        | 78/484 [10:20<53:22,  7.89s/it, training_loss=0.019]\u001b[A\n",
            "Epoch 3:  16%|█▌        | 78/484 [10:28<53:22,  7.89s/it, training_loss=0.180]\u001b[A\n",
            "Epoch 3:  16%|█▋        | 79/484 [10:28<53:16,  7.89s/it, training_loss=0.180]\u001b[A\n",
            "Epoch 3:  16%|█▋        | 79/484 [10:35<53:16,  7.89s/it, training_loss=0.154]\u001b[A\n",
            "Epoch 3:  17%|█▋        | 80/484 [10:35<51:03,  7.58s/it, training_loss=0.154]\u001b[A\n",
            "Epoch 3:  17%|█▋        | 80/484 [10:44<51:03,  7.58s/it, training_loss=0.166]\u001b[A\n",
            "Epoch 3:  17%|█▋        | 81/484 [10:44<54:13,  8.07s/it, training_loss=0.166]\u001b[A\n",
            "Epoch 3:  17%|█▋        | 81/484 [10:50<54:13,  8.07s/it, training_loss=0.187]\u001b[A\n",
            "Epoch 3:  17%|█▋        | 82/484 [10:51<51:04,  7.62s/it, training_loss=0.187]\u001b[A\n",
            "Epoch 3:  17%|█▋        | 82/484 [11:00<51:04,  7.62s/it, training_loss=0.012]\u001b[A\n",
            "Epoch 3:  17%|█▋        | 83/484 [11:00<54:56,  8.22s/it, training_loss=0.012]\u001b[A\n",
            "Epoch 3:  17%|█▋        | 83/484 [11:07<54:56,  8.22s/it, training_loss=0.009]\u001b[A\n",
            "Epoch 3:  17%|█▋        | 84/484 [11:07<51:37,  7.74s/it, training_loss=0.009]\u001b[A\n",
            "Epoch 3:  17%|█▋        | 84/484 [11:15<51:37,  7.74s/it, training_loss=0.133]\u001b[A\n",
            "Epoch 3:  18%|█▊        | 85/484 [11:15<53:02,  7.98s/it, training_loss=0.133]\u001b[A\n",
            "Epoch 3:  18%|█▊        | 85/484 [11:23<53:02,  7.98s/it, training_loss=0.030]\u001b[A\n",
            "Epoch 3:  18%|█▊        | 86/484 [11:23<52:19,  7.89s/it, training_loss=0.030]\u001b[A\n",
            "Epoch 3:  18%|█▊        | 86/484 [11:30<52:19,  7.89s/it, training_loss=0.036]\u001b[A\n",
            "Epoch 3:  18%|█▊        | 87/484 [11:30<50:21,  7.61s/it, training_loss=0.036]\u001b[A\n",
            "Epoch 3:  18%|█▊        | 87/484 [11:39<50:21,  7.61s/it, training_loss=0.052]\u001b[A\n",
            "Epoch 3:  18%|█▊        | 88/484 [11:39<53:15,  8.07s/it, training_loss=0.052]\u001b[A\n",
            "Epoch 3:  18%|█▊        | 88/484 [11:46<53:15,  8.07s/it, training_loss=0.059]\u001b[A\n",
            "Epoch 3:  18%|█▊        | 89/484 [11:46<51:39,  7.85s/it, training_loss=0.059]\u001b[A\n",
            "Epoch 3:  18%|█▊        | 89/484 [11:57<51:39,  7.85s/it, training_loss=0.006]\u001b[A\n",
            "Epoch 3:  19%|█▊        | 90/484 [11:57<56:48,  8.65s/it, training_loss=0.006]\u001b[A\n",
            "Epoch 3:  19%|█▊        | 90/484 [12:06<56:48,  8.65s/it, training_loss=0.135]\u001b[A\n",
            "Epoch 3:  19%|█▉        | 91/484 [12:06<57:42,  8.81s/it, training_loss=0.135]\u001b[A\n",
            "Epoch 3:  19%|█▉        | 91/484 [12:17<57:42,  8.81s/it, training_loss=0.007]\u001b[A\n",
            "Epoch 3:  19%|█▉        | 92/484 [12:17<1:01:03,  9.34s/it, training_loss=0.007]\u001b[A\n",
            "Epoch 3:  19%|█▉        | 92/484 [12:23<1:01:03,  9.34s/it, training_loss=0.022]\u001b[A\n",
            "Epoch 3:  19%|█▉        | 93/484 [12:23<55:34,  8.53s/it, training_loss=0.022]  \u001b[A\n",
            "Epoch 3:  19%|█▉        | 93/484 [12:33<55:34,  8.53s/it, training_loss=0.081]\u001b[A\n",
            "Epoch 3:  19%|█▉        | 94/484 [12:33<56:53,  8.75s/it, training_loss=0.081]\u001b[A\n",
            "Epoch 3:  19%|█▉        | 94/484 [12:39<56:53,  8.75s/it, training_loss=0.085]\u001b[A\n",
            "Epoch 3:  20%|█▉        | 95/484 [12:39<53:03,  8.18s/it, training_loss=0.085]\u001b[A\n",
            "Epoch 3:  20%|█▉        | 95/484 [12:47<53:03,  8.18s/it, training_loss=0.092]\u001b[A\n",
            "Epoch 3:  20%|█▉        | 96/484 [12:47<52:32,  8.13s/it, training_loss=0.092]\u001b[A\n",
            "Epoch 3:  20%|█▉        | 96/484 [12:55<52:32,  8.13s/it, training_loss=0.213]\u001b[A\n",
            "Epoch 3:  20%|██        | 97/484 [12:55<52:08,  8.08s/it, training_loss=0.213]\u001b[A\n",
            "Epoch 3:  20%|██        | 97/484 [13:02<52:08,  8.08s/it, training_loss=0.014]\u001b[A\n",
            "Epoch 3:  20%|██        | 98/484 [13:02<49:21,  7.67s/it, training_loss=0.014]\u001b[A\n",
            "Epoch 3:  20%|██        | 98/484 [13:12<49:21,  7.67s/it, training_loss=0.011]\u001b[A\n",
            "Epoch 3:  20%|██        | 99/484 [13:12<52:41,  8.21s/it, training_loss=0.011]\u001b[A\n",
            "Epoch 3:  20%|██        | 99/484 [13:18<52:41,  8.21s/it, training_loss=0.262]\u001b[A\n",
            "Epoch 3:  21%|██        | 100/484 [13:18<49:28,  7.73s/it, training_loss=0.262]\u001b[A\n",
            "Epoch 3:  21%|██        | 100/484 [13:28<49:28,  7.73s/it, training_loss=0.006]\u001b[A\n",
            "Epoch 3:  21%|██        | 101/484 [13:28<52:39,  8.25s/it, training_loss=0.006]\u001b[A\n",
            "Epoch 3:  21%|██        | 101/484 [13:34<52:39,  8.25s/it, training_loss=0.178]\u001b[A\n",
            "Epoch 3:  21%|██        | 102/484 [13:34<49:39,  7.80s/it, training_loss=0.178]\u001b[A\n",
            "Epoch 3:  21%|██        | 102/484 [13:43<49:39,  7.80s/it, training_loss=0.125]\u001b[A\n",
            "Epoch 3:  21%|██▏       | 103/484 [13:43<50:21,  7.93s/it, training_loss=0.125]\u001b[A\n",
            "Epoch 3:  21%|██▏       | 103/484 [13:51<50:21,  7.93s/it, training_loss=0.171]\u001b[A\n",
            "Epoch 3:  21%|██▏       | 104/484 [13:51<50:06,  7.91s/it, training_loss=0.171]\u001b[A\n",
            "Epoch 3:  21%|██▏       | 104/484 [13:57<50:06,  7.91s/it, training_loss=0.041]\u001b[A\n",
            "Epoch 3:  22%|██▏       | 105/484 [13:57<48:00,  7.60s/it, training_loss=0.041]\u001b[A\n",
            "Epoch 3:  22%|██▏       | 105/484 [14:07<48:00,  7.60s/it, training_loss=0.014]\u001b[A\n",
            "Epoch 3:  22%|██▏       | 106/484 [14:07<50:59,  8.09s/it, training_loss=0.014]\u001b[A\n",
            "Epoch 3:  22%|██▏       | 106/484 [14:13<50:59,  8.09s/it, training_loss=0.004]\u001b[A\n",
            "Epoch 3:  22%|██▏       | 107/484 [14:13<48:04,  7.65s/it, training_loss=0.004]\u001b[A\n",
            "Epoch 3:  22%|██▏       | 107/484 [14:23<48:04,  7.65s/it, training_loss=0.006]\u001b[A\n",
            "Epoch 3:  22%|██▏       | 108/484 [14:23<51:47,  8.26s/it, training_loss=0.006]\u001b[A\n",
            "Epoch 3:  22%|██▏       | 108/484 [14:30<51:47,  8.26s/it, training_loss=0.045]\u001b[A\n",
            "Epoch 3:  23%|██▎       | 109/484 [14:30<48:30,  7.76s/it, training_loss=0.045]\u001b[A\n",
            "Epoch 3:  23%|██▎       | 109/484 [14:38<48:30,  7.76s/it, training_loss=0.005]\u001b[A\n",
            "Epoch 3:  23%|██▎       | 110/484 [14:38<50:10,  8.05s/it, training_loss=0.005]\u001b[A\n",
            "Epoch 3:  23%|██▎       | 110/484 [14:46<50:10,  8.05s/it, training_loss=0.237]\u001b[A\n",
            "Epoch 3:  23%|██▎       | 111/484 [14:46<48:58,  7.88s/it, training_loss=0.237]\u001b[A\n",
            "Epoch 3:  23%|██▎       | 111/484 [14:53<48:58,  7.88s/it, training_loss=0.199]\u001b[A\n",
            "Epoch 3:  23%|██▎       | 112/484 [14:53<47:46,  7.71s/it, training_loss=0.199]\u001b[A\n",
            "Epoch 3:  23%|██▎       | 112/484 [15:02<47:46,  7.71s/it, training_loss=0.011]\u001b[A\n",
            "Epoch 3:  23%|██▎       | 113/484 [15:02<49:40,  8.03s/it, training_loss=0.011]\u001b[A\n",
            "Epoch 3:  23%|██▎       | 113/484 [15:08<49:40,  8.03s/it, training_loss=0.041]\u001b[A\n",
            "Epoch 3:  24%|██▎       | 114/484 [15:08<46:53,  7.60s/it, training_loss=0.041]\u001b[A\n",
            "Epoch 3:  24%|██▎       | 114/484 [15:18<46:53,  7.60s/it, training_loss=0.007]\u001b[A\n",
            "Epoch 3:  24%|██▍       | 115/484 [15:18<50:36,  8.23s/it, training_loss=0.007]\u001b[A\n",
            "Epoch 3:  24%|██▍       | 115/484 [15:25<50:36,  8.23s/it, training_loss=0.089]\u001b[A\n",
            "Epoch 3:  24%|██▍       | 116/484 [15:25<47:26,  7.73s/it, training_loss=0.089]\u001b[A\n",
            "Epoch 3:  24%|██▍       | 116/484 [15:34<47:26,  7.73s/it, training_loss=0.028]\u001b[A\n",
            "Epoch 3:  24%|██▍       | 117/484 [15:34<49:37,  8.11s/it, training_loss=0.028]\u001b[A\n",
            "Epoch 3:  24%|██▍       | 117/484 [15:41<49:37,  8.11s/it, training_loss=0.056]\u001b[A\n",
            "Epoch 3:  24%|██▍       | 118/484 [15:41<47:55,  7.86s/it, training_loss=0.056]\u001b[A\n",
            "Epoch 3:  24%|██▍       | 118/484 [15:49<47:55,  7.86s/it, training_loss=0.004]\u001b[A\n",
            "Epoch 3:  25%|██▍       | 119/484 [15:49<47:36,  7.82s/it, training_loss=0.004]\u001b[A\n",
            "Epoch 3:  25%|██▍       | 119/484 [15:57<47:36,  7.82s/it, training_loss=0.004]\u001b[A\n",
            "Epoch 3:  25%|██▍       | 120/484 [15:57<48:23,  7.98s/it, training_loss=0.004]\u001b[A\n",
            "Epoch 3:  25%|██▍       | 120/484 [16:04<48:23,  7.98s/it, training_loss=0.026]\u001b[A\n",
            "Epoch 3:  25%|██▌       | 121/484 [16:04<45:51,  7.58s/it, training_loss=0.026]\u001b[A\n",
            "Epoch 3:  25%|██▌       | 121/484 [16:13<45:51,  7.58s/it, training_loss=0.087]\u001b[A\n",
            "Epoch 3:  25%|██▌       | 122/484 [16:13<49:28,  8.20s/it, training_loss=0.087]\u001b[A\n",
            "Epoch 3:  25%|██▌       | 122/484 [16:20<49:28,  8.20s/it, training_loss=0.009]\u001b[A\n",
            "Epoch 3:  25%|██▌       | 123/484 [16:20<46:26,  7.72s/it, training_loss=0.009]\u001b[A\n",
            "Epoch 3:  25%|██▌       | 123/484 [16:30<46:26,  7.72s/it, training_loss=0.038]\u001b[A\n",
            "Epoch 3:  26%|██▌       | 124/484 [16:30<50:11,  8.36s/it, training_loss=0.038]\u001b[A\n",
            "Epoch 3:  26%|██▌       | 124/484 [16:39<50:11,  8.36s/it, training_loss=0.309]\u001b[A\n",
            "Epoch 3:  26%|██▌       | 125/484 [16:39<52:10,  8.72s/it, training_loss=0.309]\u001b[A\n",
            "Epoch 3:  26%|██▌       | 125/484 [16:46<52:10,  8.72s/it, training_loss=0.007]\u001b[A\n",
            "Epoch 3:  26%|██▌       | 126/484 [16:46<48:12,  8.08s/it, training_loss=0.007]\u001b[A\n",
            "Epoch 3:  26%|██▌       | 126/484 [16:55<48:12,  8.08s/it, training_loss=0.083]\u001b[A\n",
            "Epoch 3:  26%|██▌       | 127/484 [16:55<50:39,  8.51s/it, training_loss=0.083]\u001b[A\n",
            "Epoch 3:  26%|██▌       | 127/484 [17:02<50:39,  8.51s/it, training_loss=0.197]\u001b[A\n",
            "Epoch 3:  26%|██▋       | 128/484 [17:02<47:13,  7.96s/it, training_loss=0.197]\u001b[A\n",
            "Epoch 3:  26%|██▋       | 128/484 [17:10<47:13,  7.96s/it, training_loss=0.028]\u001b[A\n",
            "Epoch 3:  27%|██▋       | 129/484 [17:10<47:31,  8.03s/it, training_loss=0.028]\u001b[A\n",
            "Epoch 3:  27%|██▋       | 129/484 [17:18<47:31,  8.03s/it, training_loss=0.006]\u001b[A\n",
            "Epoch 3:  27%|██▋       | 130/484 [17:18<47:06,  7.98s/it, training_loss=0.006]\u001b[A\n",
            "Epoch 3:  27%|██▋       | 130/484 [17:25<47:06,  7.98s/it, training_loss=0.011]\u001b[A\n",
            "Epoch 3:  27%|██▋       | 131/484 [17:25<44:52,  7.63s/it, training_loss=0.011]\u001b[A\n",
            "Epoch 3:  27%|██▋       | 131/484 [17:34<44:52,  7.63s/it, training_loss=0.179]\u001b[A\n",
            "Epoch 3:  27%|██▋       | 132/484 [17:34<47:33,  8.11s/it, training_loss=0.179]\u001b[A\n",
            "Epoch 3:  27%|██▋       | 132/484 [17:41<47:33,  8.11s/it, training_loss=0.006]\u001b[A\n",
            "Epoch 3:  27%|██▋       | 133/484 [17:41<44:50,  7.66s/it, training_loss=0.006]\u001b[A\n",
            "Epoch 3:  27%|██▋       | 133/484 [17:51<44:50,  7.66s/it, training_loss=0.030]\u001b[A\n",
            "Epoch 3:  28%|██▊       | 134/484 [17:51<48:16,  8.28s/it, training_loss=0.030]\u001b[A\n",
            "Epoch 3:  28%|██▊       | 134/484 [17:57<48:16,  8.28s/it, training_loss=0.010]\u001b[A\n",
            "Epoch 3:  28%|██▊       | 135/484 [17:57<45:21,  7.80s/it, training_loss=0.010]\u001b[A\n",
            "Epoch 3:  28%|██▊       | 135/484 [18:06<45:21,  7.80s/it, training_loss=0.005]\u001b[A\n",
            "Epoch 3:  28%|██▊       | 136/484 [18:06<46:40,  8.05s/it, training_loss=0.005]\u001b[A\n",
            "Epoch 3:  28%|██▊       | 136/484 [18:13<46:40,  8.05s/it, training_loss=0.196]\u001b[A\n",
            "Epoch 3:  28%|██▊       | 137/484 [18:13<45:44,  7.91s/it, training_loss=0.196]\u001b[A\n",
            "Epoch 3:  28%|██▊       | 137/484 [18:21<45:44,  7.91s/it, training_loss=0.189]\u001b[A\n",
            "Epoch 3:  29%|██▊       | 138/484 [18:21<44:18,  7.68s/it, training_loss=0.189]\u001b[A\n",
            "Epoch 3:  29%|██▊       | 138/484 [18:30<44:18,  7.68s/it, training_loss=0.092]\u001b[A\n",
            "Epoch 3:  29%|██▊       | 139/484 [18:30<46:27,  8.08s/it, training_loss=0.092]\u001b[A\n",
            "Epoch 3:  29%|██▊       | 139/484 [18:36<46:27,  8.08s/it, training_loss=0.004]\u001b[A\n",
            "Epoch 3:  29%|██▉       | 140/484 [18:36<43:54,  7.66s/it, training_loss=0.004]\u001b[A\n",
            "Epoch 3:  29%|██▉       | 140/484 [18:46<43:54,  7.66s/it, training_loss=0.016]\u001b[A\n",
            "Epoch 3:  29%|██▉       | 141/484 [18:46<47:21,  8.28s/it, training_loss=0.016]\u001b[A\n",
            "Epoch 3:  29%|██▉       | 141/484 [18:53<47:21,  8.28s/it, training_loss=0.010]\u001b[A\n",
            "Epoch 3:  29%|██▉       | 142/484 [18:53<44:21,  7.78s/it, training_loss=0.010]\u001b[A\n",
            "Epoch 3:  29%|██▉       | 142/484 [19:02<44:21,  7.78s/it, training_loss=0.009]\u001b[A\n",
            "Epoch 3:  30%|██▉       | 143/484 [19:02<46:14,  8.14s/it, training_loss=0.009]\u001b[A\n",
            "Epoch 3:  30%|██▉       | 143/484 [19:09<46:14,  8.14s/it, training_loss=0.005]\u001b[A\n",
            "Epoch 3:  30%|██▉       | 144/484 [19:09<44:28,  7.85s/it, training_loss=0.005]\u001b[A\n",
            "Epoch 3:  30%|██▉       | 144/484 [19:16<44:28,  7.85s/it, training_loss=0.019]\u001b[A\n",
            "Epoch 3:  30%|██▉       | 145/484 [19:16<43:42,  7.74s/it, training_loss=0.019]\u001b[A\n",
            "Epoch 3:  30%|██▉       | 145/484 [19:25<43:42,  7.74s/it, training_loss=0.013]\u001b[A\n",
            "Epoch 3:  30%|███       | 146/484 [19:25<44:52,  7.96s/it, training_loss=0.013]\u001b[A\n",
            "Epoch 3:  30%|███       | 146/484 [19:31<44:52,  7.96s/it, training_loss=0.005]\u001b[A\n",
            "Epoch 3:  30%|███       | 147/484 [19:31<42:22,  7.55s/it, training_loss=0.005]\u001b[A\n",
            "Epoch 3:  30%|███       | 147/484 [19:41<42:22,  7.55s/it, training_loss=0.026]\u001b[A\n",
            "Epoch 3:  31%|███       | 148/484 [19:41<45:54,  8.20s/it, training_loss=0.026]\u001b[A\n",
            "Epoch 3:  31%|███       | 148/484 [19:48<45:54,  8.20s/it, training_loss=0.051]\u001b[A\n",
            "Epoch 3:  31%|███       | 149/484 [19:48<43:11,  7.74s/it, training_loss=0.051]\u001b[A\n",
            "Epoch 3:  31%|███       | 149/484 [19:57<43:11,  7.74s/it, training_loss=0.012]\u001b[A\n",
            "Epoch 3:  31%|███       | 150/484 [19:57<45:29,  8.17s/it, training_loss=0.012]\u001b[A\n",
            "Epoch 3:  31%|███       | 150/484 [20:04<45:29,  8.17s/it, training_loss=0.004]\u001b[A\n",
            "Epoch 3:  31%|███       | 151/484 [20:04<43:26,  7.83s/it, training_loss=0.004]\u001b[A\n",
            "Epoch 3:  31%|███       | 151/484 [20:12<43:26,  7.83s/it, training_loss=0.006]\u001b[A\n",
            "Epoch 3:  31%|███▏      | 152/484 [20:12<43:21,  7.84s/it, training_loss=0.006]\u001b[A\n",
            "Epoch 3:  31%|███▏      | 152/484 [20:20<43:21,  7.84s/it, training_loss=0.033]\u001b[A\n",
            "Epoch 3:  32%|███▏      | 153/484 [20:20<43:46,  7.93s/it, training_loss=0.033]\u001b[A\n",
            "Epoch 3:  32%|███▏      | 153/484 [20:27<43:46,  7.93s/it, training_loss=0.185]\u001b[A\n",
            "Epoch 3:  32%|███▏      | 154/484 [20:27<41:37,  7.57s/it, training_loss=0.185]\u001b[A\n",
            "Epoch 3:  32%|███▏      | 154/484 [20:36<41:37,  7.57s/it, training_loss=0.098]\u001b[A\n",
            "Epoch 3:  32%|███▏      | 155/484 [20:36<44:47,  8.17s/it, training_loss=0.098]\u001b[A\n",
            "Epoch 3:  32%|███▏      | 155/484 [20:43<44:47,  8.17s/it, training_loss=0.029]\u001b[A\n",
            "Epoch 3:  32%|███▏      | 156/484 [20:43<42:07,  7.71s/it, training_loss=0.029]\u001b[A\n",
            "Epoch 3:  32%|███▏      | 156/484 [20:52<42:07,  7.71s/it, training_loss=0.011]\u001b[A\n",
            "Epoch 3:  32%|███▏      | 157/484 [20:52<44:54,  8.24s/it, training_loss=0.011]\u001b[A\n",
            "Epoch 3:  32%|███▏      | 157/484 [21:02<44:54,  8.24s/it, training_loss=0.049]\u001b[A\n",
            "Epoch 3:  33%|███▎      | 158/484 [21:02<47:20,  8.71s/it, training_loss=0.049]\u001b[A\n",
            "Epoch 3:  33%|███▎      | 158/484 [21:12<47:20,  8.71s/it, training_loss=0.089]\u001b[A\n",
            "Epoch 3:  33%|███▎      | 159/484 [21:12<48:30,  8.96s/it, training_loss=0.089]\u001b[A\n",
            "Epoch 3:  33%|███▎      | 159/484 [21:18<48:30,  8.96s/it, training_loss=0.218]\u001b[A\n",
            "Epoch 3:  33%|███▎      | 160/484 [21:18<44:32,  8.25s/it, training_loss=0.218]\u001b[A\n",
            "Epoch 3:  33%|███▎      | 160/484 [21:27<44:32,  8.25s/it, training_loss=0.197]\u001b[A\n",
            "Epoch 3:  33%|███▎      | 161/484 [21:27<44:32,  8.27s/it, training_loss=0.197]\u001b[A\n",
            "Epoch 3:  33%|███▎      | 161/484 [21:34<44:32,  8.27s/it, training_loss=0.198]\u001b[A\n",
            "Epoch 3:  33%|███▎      | 162/484 [21:34<43:28,  8.10s/it, training_loss=0.198]\u001b[A\n",
            "Epoch 3:  33%|███▎      | 162/484 [21:41<43:28,  8.10s/it, training_loss=0.087]\u001b[A\n",
            "Epoch 3:  34%|███▎      | 163/484 [21:41<41:21,  7.73s/it, training_loss=0.087]\u001b[A\n",
            "Epoch 3:  34%|███▎      | 163/484 [21:50<41:21,  7.73s/it, training_loss=0.012]\u001b[A\n",
            "Epoch 3:  34%|███▍      | 164/484 [21:50<43:29,  8.16s/it, training_loss=0.012]\u001b[A\n",
            "Epoch 3:  34%|███▍      | 164/484 [21:57<43:29,  8.16s/it, training_loss=0.135]\u001b[A\n",
            "Epoch 3:  34%|███▍      | 165/484 [21:57<40:57,  7.70s/it, training_loss=0.135]\u001b[A\n",
            "Epoch 3:  34%|███▍      | 165/484 [22:07<40:57,  7.70s/it, training_loss=0.005]\u001b[A\n",
            "Epoch 3:  34%|███▍      | 166/484 [22:07<43:54,  8.28s/it, training_loss=0.005]\u001b[A\n",
            "Epoch 3:  34%|███▍      | 166/484 [22:13<43:54,  8.28s/it, training_loss=0.010]\u001b[A\n",
            "Epoch 3:  35%|███▍      | 167/484 [22:13<41:06,  7.78s/it, training_loss=0.010]\u001b[A\n",
            "Epoch 3:  35%|███▍      | 167/484 [22:22<41:06,  7.78s/it, training_loss=0.216]\u001b[A\n",
            "Epoch 3:  35%|███▍      | 168/484 [22:22<42:21,  8.04s/it, training_loss=0.216]\u001b[A\n",
            "Epoch 3:  35%|███▍      | 168/484 [22:29<42:21,  8.04s/it, training_loss=0.075]\u001b[A\n",
            "Epoch 3:  35%|███▍      | 169/484 [22:29<41:24,  7.89s/it, training_loss=0.075]\u001b[A\n",
            "Epoch 3:  35%|███▍      | 169/484 [22:37<41:24,  7.89s/it, training_loss=0.005]\u001b[A\n",
            "Epoch 3:  35%|███▌      | 170/484 [22:37<40:05,  7.66s/it, training_loss=0.005]\u001b[A\n",
            "Epoch 3:  35%|███▌      | 170/484 [22:45<40:05,  7.66s/it, training_loss=0.005]\u001b[A\n",
            "Epoch 3:  35%|███▌      | 171/484 [22:45<41:48,  8.01s/it, training_loss=0.005]\u001b[A\n",
            "Epoch 3:  35%|███▌      | 171/484 [22:52<41:48,  8.01s/it, training_loss=0.189]\u001b[A\n",
            "Epoch 3:  36%|███▌      | 172/484 [22:52<39:33,  7.61s/it, training_loss=0.189]\u001b[A\n",
            "Epoch 3:  36%|███▌      | 172/484 [23:02<39:33,  7.61s/it, training_loss=0.006]\u001b[A\n",
            "Epoch 3:  36%|███▌      | 173/484 [23:02<42:40,  8.23s/it, training_loss=0.006]\u001b[A\n",
            "Epoch 3:  36%|███▌      | 173/484 [23:08<42:40,  8.23s/it, training_loss=0.010]\u001b[A\n",
            "Epoch 3:  36%|███▌      | 174/484 [23:08<39:59,  7.74s/it, training_loss=0.010]\u001b[A\n",
            "Epoch 3:  36%|███▌      | 174/484 [23:17<39:59,  7.74s/it, training_loss=0.343]\u001b[A\n",
            "Epoch 3:  36%|███▌      | 175/484 [23:17<41:27,  8.05s/it, training_loss=0.343]\u001b[A\n",
            "Epoch 3:  36%|███▌      | 175/484 [23:24<41:27,  8.05s/it, training_loss=0.036]\u001b[A\n",
            "Epoch 3:  36%|███▋      | 176/484 [23:24<40:09,  7.82s/it, training_loss=0.036]\u001b[A\n",
            "Epoch 3:  36%|███▋      | 176/484 [23:32<40:09,  7.82s/it, training_loss=0.015]\u001b[A\n",
            "Epoch 3:  37%|███▋      | 177/484 [23:32<39:16,  7.68s/it, training_loss=0.015]\u001b[A\n",
            "Epoch 3:  37%|███▋      | 177/484 [23:40<39:16,  7.68s/it, training_loss=0.019]\u001b[A\n",
            "Epoch 3:  37%|███▋      | 178/484 [23:40<40:37,  7.97s/it, training_loss=0.019]\u001b[A\n",
            "Epoch 3:  37%|███▋      | 178/484 [23:47<40:37,  7.97s/it, training_loss=0.047]\u001b[A\n",
            "Epoch 3:  37%|███▋      | 179/484 [23:47<38:28,  7.57s/it, training_loss=0.047]\u001b[A\n",
            "Epoch 3:  37%|███▋      | 179/484 [23:57<38:28,  7.57s/it, training_loss=0.196]\u001b[A\n",
            "Epoch 3:  37%|███▋      | 180/484 [23:57<41:38,  8.22s/it, training_loss=0.196]\u001b[A\n",
            "Epoch 3:  37%|███▋      | 180/484 [24:03<41:38,  8.22s/it, training_loss=0.015]\u001b[A\n",
            "Epoch 3:  37%|███▋      | 181/484 [24:03<39:05,  7.74s/it, training_loss=0.015]\u001b[A\n",
            "Epoch 3:  37%|███▋      | 181/484 [24:13<39:05,  7.74s/it, training_loss=0.011]\u001b[A\n",
            "Epoch 3:  38%|███▊      | 182/484 [24:13<41:06,  8.17s/it, training_loss=0.011]\u001b[A\n",
            "Epoch 3:  38%|███▊      | 182/484 [24:20<41:06,  8.17s/it, training_loss=0.015]\u001b[A\n",
            "Epoch 3:  38%|███▊      | 183/484 [24:20<39:19,  7.84s/it, training_loss=0.015]\u001b[A\n",
            "Epoch 3:  38%|███▊      | 183/484 [24:27<39:19,  7.84s/it, training_loss=0.018]\u001b[A\n",
            "Epoch 3:  38%|███▊      | 184/484 [24:27<39:07,  7.82s/it, training_loss=0.018]\u001b[A\n",
            "Epoch 3:  38%|███▊      | 184/484 [24:36<39:07,  7.82s/it, training_loss=0.003]\u001b[A\n",
            "Epoch 3:  38%|███▊      | 185/484 [24:36<39:31,  7.93s/it, training_loss=0.003]\u001b[A\n",
            "Epoch 3:  38%|███▊      | 185/484 [24:42<39:31,  7.93s/it, training_loss=0.010]\u001b[A\n",
            "Epoch 3:  38%|███▊      | 186/484 [24:42<37:29,  7.55s/it, training_loss=0.010]\u001b[A\n",
            "Epoch 3:  38%|███▊      | 186/484 [24:52<37:29,  7.55s/it, training_loss=0.009]\u001b[A\n",
            "Epoch 3:  39%|███▊      | 187/484 [24:52<40:21,  8.15s/it, training_loss=0.009]\u001b[A\n",
            "Epoch 3:  39%|███▊      | 187/484 [24:58<40:21,  8.15s/it, training_loss=0.219]\u001b[A\n",
            "Epoch 3:  39%|███▉      | 188/484 [24:58<37:52,  7.68s/it, training_loss=0.219]\u001b[A\n",
            "Epoch 3:  39%|███▉      | 188/484 [25:08<37:52,  7.68s/it, training_loss=0.020]\u001b[A\n",
            "Epoch 3:  39%|███▉      | 189/484 [25:08<40:01,  8.14s/it, training_loss=0.020]\u001b[A\n",
            "Epoch 3:  39%|███▉      | 189/484 [25:14<40:01,  8.14s/it, training_loss=0.012]\u001b[A\n",
            "Epoch 3:  39%|███▉      | 190/484 [25:14<38:00,  7.76s/it, training_loss=0.012]\u001b[A\n",
            "Epoch 3:  39%|███▉      | 190/484 [25:23<38:00,  7.76s/it, training_loss=0.073]\u001b[A\n",
            "Epoch 3:  39%|███▉      | 191/484 [25:23<38:24,  7.87s/it, training_loss=0.073]\u001b[A\n",
            "Epoch 3:  39%|███▉      | 191/484 [25:33<38:24,  7.87s/it, training_loss=0.005]\u001b[A\n",
            "Epoch 3:  40%|███▉      | 192/484 [25:33<42:33,  8.75s/it, training_loss=0.005]\u001b[A\n",
            "Epoch 3:  40%|███▉      | 192/484 [25:40<42:33,  8.75s/it, training_loss=0.369]\u001b[A\n",
            "Epoch 3:  40%|███▉      | 193/484 [25:40<39:38,  8.17s/it, training_loss=0.369]\u001b[A\n",
            "Epoch 3:  40%|███▉      | 193/484 [25:48<39:38,  8.17s/it, training_loss=0.005]\u001b[A\n",
            "Epoch 3:  40%|████      | 194/484 [25:48<39:36,  8.20s/it, training_loss=0.005]\u001b[A\n",
            "Epoch 3:  40%|████      | 194/484 [25:56<39:36,  8.20s/it, training_loss=0.055]\u001b[A\n",
            "Epoch 3:  40%|████      | 195/484 [25:56<38:57,  8.09s/it, training_loss=0.055]\u001b[A\n",
            "Epoch 3:  40%|████      | 195/484 [26:03<38:57,  8.09s/it, training_loss=0.094]\u001b[A\n",
            "Epoch 3:  40%|████      | 196/484 [26:03<37:01,  7.71s/it, training_loss=0.094]\u001b[A\n",
            "Epoch 3:  40%|████      | 196/484 [26:12<37:01,  7.71s/it, training_loss=0.024]\u001b[A\n",
            "Epoch 3:  41%|████      | 197/484 [26:12<38:59,  8.15s/it, training_loss=0.024]\u001b[A\n",
            "Epoch 3:  41%|████      | 197/484 [26:19<38:59,  8.15s/it, training_loss=0.004]\u001b[A\n",
            "Epoch 3:  41%|████      | 198/484 [26:19<36:35,  7.68s/it, training_loss=0.004]\u001b[A\n",
            "Epoch 3:  41%|████      | 198/484 [26:28<36:35,  7.68s/it, training_loss=0.232]\u001b[A\n",
            "Epoch 3:  41%|████      | 199/484 [26:28<39:13,  8.26s/it, training_loss=0.232]\u001b[A\n",
            "Epoch 3:  41%|████      | 199/484 [26:35<39:13,  8.26s/it, training_loss=0.043]\u001b[A\n",
            "Epoch 3:  41%|████▏     | 200/484 [26:35<36:44,  7.76s/it, training_loss=0.043]\u001b[A\n",
            "Epoch 3:  41%|████▏     | 200/484 [26:43<36:44,  7.76s/it, training_loss=0.009]\u001b[A\n",
            "Epoch 3:  42%|████▏     | 201/484 [26:43<37:31,  7.95s/it, training_loss=0.009]\u001b[A\n",
            "Epoch 3:  42%|████▏     | 201/484 [26:51<37:31,  7.95s/it, training_loss=0.033]\u001b[A\n",
            "Epoch 3:  42%|████▏     | 202/484 [26:51<36:59,  7.87s/it, training_loss=0.033]\u001b[A\n",
            "Epoch 3:  42%|████▏     | 202/484 [26:58<36:59,  7.87s/it, training_loss=0.089]\u001b[A\n",
            "Epoch 3:  42%|████▏     | 203/484 [26:58<35:36,  7.60s/it, training_loss=0.089]\u001b[A\n",
            "Epoch 3:  42%|████▏     | 203/484 [27:07<35:36,  7.60s/it, training_loss=0.104]\u001b[A\n",
            "Epoch 3:  42%|████▏     | 204/484 [27:07<37:27,  8.03s/it, training_loss=0.104]\u001b[A\n",
            "Epoch 3:  42%|████▏     | 204/484 [27:14<37:27,  8.03s/it, training_loss=0.019]\u001b[A\n",
            "Epoch 3:  42%|████▏     | 205/484 [27:14<35:20,  7.60s/it, training_loss=0.019]\u001b[A\n",
            "Epoch 3:  42%|████▏     | 205/484 [27:23<35:20,  7.60s/it, training_loss=0.036]\u001b[A\n",
            "Epoch 3:  43%|████▎     | 206/484 [27:23<38:04,  8.22s/it, training_loss=0.036]\u001b[A\n",
            "Epoch 3:  43%|████▎     | 206/484 [27:30<38:04,  8.22s/it, training_loss=0.009]\u001b[A\n",
            "Epoch 3:  43%|████▎     | 207/484 [27:30<35:40,  7.73s/it, training_loss=0.009]\u001b[A\n",
            "Epoch 3:  43%|████▎     | 207/484 [27:39<35:40,  7.73s/it, training_loss=0.161]\u001b[A\n",
            "Epoch 3:  43%|████▎     | 208/484 [27:39<37:56,  8.25s/it, training_loss=0.161]\u001b[A\n",
            "Epoch 3:  43%|████▎     | 208/484 [27:47<37:56,  8.25s/it, training_loss=0.013]\u001b[A\n",
            "Epoch 3:  43%|████▎     | 209/484 [27:47<36:27,  7.95s/it, training_loss=0.013]\u001b[A\n",
            "Epoch 3:  43%|████▎     | 209/484 [27:54<36:27,  7.95s/it, training_loss=0.010]\u001b[A\n",
            "Epoch 3:  43%|████▎     | 210/484 [27:54<35:50,  7.85s/it, training_loss=0.010]\u001b[A\n",
            "Epoch 3:  43%|████▎     | 210/484 [28:03<35:50,  7.85s/it, training_loss=0.086]\u001b[A\n",
            "Epoch 3:  44%|████▎     | 211/484 [28:03<36:58,  8.13s/it, training_loss=0.086]\u001b[A\n",
            "Epoch 3:  44%|████▎     | 211/484 [28:10<36:58,  8.13s/it, training_loss=0.219]\u001b[A\n",
            "Epoch 3:  44%|████▍     | 212/484 [28:10<34:44,  7.66s/it, training_loss=0.219]\u001b[A\n",
            "Epoch 3:  44%|████▍     | 212/484 [28:19<34:44,  7.66s/it, training_loss=0.033]\u001b[A\n",
            "Epoch 3:  44%|████▍     | 213/484 [28:19<37:20,  8.27s/it, training_loss=0.033]\u001b[A\n",
            "Epoch 3:  44%|████▍     | 213/484 [28:26<37:20,  8.27s/it, training_loss=0.090]\u001b[A\n",
            "Epoch 3:  44%|████▍     | 214/484 [28:26<35:02,  7.79s/it, training_loss=0.090]\u001b[A\n",
            "Epoch 3:  44%|████▍     | 214/484 [28:35<35:02,  7.79s/it, training_loss=0.010]\u001b[A\n",
            "Epoch 3:  44%|████▍     | 215/484 [28:35<37:04,  8.27s/it, training_loss=0.010]\u001b[A\n",
            "Epoch 3:  44%|████▍     | 215/484 [28:42<37:04,  8.27s/it, training_loss=0.144]\u001b[A\n",
            "Epoch 3:  45%|████▍     | 216/484 [28:42<34:56,  7.82s/it, training_loss=0.144]\u001b[A\n",
            "Epoch 3:  45%|████▍     | 216/484 [28:50<34:56,  7.82s/it, training_loss=0.009]\u001b[A\n",
            "Epoch 3:  45%|████▍     | 217/484 [28:50<34:58,  7.86s/it, training_loss=0.009]\u001b[A\n",
            "Epoch 3:  45%|████▍     | 217/484 [28:58<34:58,  7.86s/it, training_loss=0.004]\u001b[A\n",
            "Epoch 3:  45%|████▌     | 218/484 [28:58<34:58,  7.89s/it, training_loss=0.004]\u001b[A\n",
            "Epoch 3:  45%|████▌     | 218/484 [29:05<34:58,  7.89s/it, training_loss=0.094]\u001b[A\n",
            "Epoch 3:  45%|████▌     | 219/484 [29:05<33:10,  7.51s/it, training_loss=0.094]\u001b[A\n",
            "Epoch 3:  45%|████▌     | 219/484 [29:14<33:10,  7.51s/it, training_loss=0.218]\u001b[A\n",
            "Epoch 3:  45%|████▌     | 220/484 [29:14<35:41,  8.11s/it, training_loss=0.218]\u001b[A\n",
            "Epoch 3:  45%|████▌     | 220/484 [29:21<35:41,  8.11s/it, training_loss=0.031]\u001b[A\n",
            "Epoch 3:  46%|████▌     | 221/484 [29:21<33:32,  7.65s/it, training_loss=0.031]\u001b[A\n",
            "Epoch 3:  46%|████▌     | 221/484 [29:30<33:32,  7.65s/it, training_loss=0.005]\u001b[A\n",
            "Epoch 3:  46%|████▌     | 222/484 [29:30<35:38,  8.16s/it, training_loss=0.005]\u001b[A\n",
            "Epoch 3:  46%|████▌     | 222/484 [29:37<35:38,  8.16s/it, training_loss=0.047]\u001b[A\n",
            "Epoch 3:  46%|████▌     | 223/484 [29:37<33:40,  7.74s/it, training_loss=0.047]\u001b[A\n",
            "Epoch 3:  46%|████▌     | 223/484 [29:45<33:40,  7.74s/it, training_loss=0.004]\u001b[A\n",
            "Epoch 3:  46%|████▋     | 224/484 [29:45<33:58,  7.84s/it, training_loss=0.004]\u001b[A\n",
            "Epoch 3:  46%|████▋     | 224/484 [29:56<33:58,  7.84s/it, training_loss=0.005]\u001b[A\n",
            "Epoch 3:  46%|████▋     | 225/484 [29:56<37:55,  8.79s/it, training_loss=0.005]\u001b[A\n",
            "Epoch 3:  46%|████▋     | 225/484 [30:03<37:55,  8.79s/it, training_loss=0.008]\u001b[A\n",
            "Epoch 3:  47%|████▋     | 226/484 [30:03<35:11,  8.18s/it, training_loss=0.008]\u001b[A\n",
            "Epoch 3:  47%|████▋     | 226/484 [30:12<35:11,  8.18s/it, training_loss=0.084]\u001b[A\n",
            "Epoch 3:  47%|████▋     | 227/484 [30:12<35:58,  8.40s/it, training_loss=0.084]\u001b[A\n",
            "Epoch 3:  47%|████▋     | 227/484 [30:19<35:58,  8.40s/it, training_loss=0.003]\u001b[A\n",
            "Epoch 3:  47%|████▋     | 228/484 [30:19<34:25,  8.07s/it, training_loss=0.003]\u001b[A\n",
            "Epoch 3:  47%|████▋     | 228/484 [30:26<34:25,  8.07s/it, training_loss=0.004]\u001b[A\n",
            "Epoch 3:  47%|████▋     | 229/484 [30:26<33:30,  7.89s/it, training_loss=0.004]\u001b[A\n",
            "Epoch 3:  47%|████▋     | 229/484 [30:35<33:30,  7.89s/it, training_loss=0.014]\u001b[A\n",
            "Epoch 3:  48%|████▊     | 230/484 [30:35<34:11,  8.08s/it, training_loss=0.014]\u001b[A\n",
            "Epoch 3:  48%|████▊     | 230/484 [30:42<34:11,  8.08s/it, training_loss=0.037]\u001b[A\n",
            "Epoch 3:  48%|████▊     | 231/484 [30:42<32:11,  7.63s/it, training_loss=0.037]\u001b[A\n",
            "Epoch 3:  48%|████▊     | 231/484 [30:51<32:11,  7.63s/it, training_loss=0.008]\u001b[A\n",
            "Epoch 3:  48%|████▊     | 232/484 [30:51<34:35,  8.24s/it, training_loss=0.008]\u001b[A\n",
            "Epoch 3:  48%|████▊     | 232/484 [30:58<34:35,  8.24s/it, training_loss=0.053]\u001b[A\n",
            "Epoch 3:  48%|████▊     | 233/484 [30:58<32:22,  7.74s/it, training_loss=0.053]\u001b[A\n",
            "Epoch 3:  48%|████▊     | 233/484 [31:07<32:22,  7.74s/it, training_loss=0.084]\u001b[A\n",
            "Epoch 3:  48%|████▊     | 234/484 [31:07<33:55,  8.14s/it, training_loss=0.084]\u001b[A\n",
            "Epoch 3:  48%|████▊     | 234/484 [31:14<33:55,  8.14s/it, training_loss=0.146]\u001b[A\n",
            "Epoch 3:  49%|████▊     | 235/484 [31:14<32:26,  7.82s/it, training_loss=0.146]\u001b[A\n",
            "Epoch 3:  49%|████▊     | 235/484 [31:22<32:26,  7.82s/it, training_loss=0.326]\u001b[A\n",
            "Epoch 3:  49%|████▉     | 236/484 [31:22<32:10,  7.78s/it, training_loss=0.326]\u001b[A\n",
            "Epoch 3:  49%|████▉     | 236/484 [31:30<32:10,  7.78s/it, training_loss=0.083]\u001b[A\n",
            "Epoch 3:  49%|████▉     | 237/484 [31:30<32:32,  7.91s/it, training_loss=0.083]\u001b[A\n",
            "Epoch 3:  49%|████▉     | 237/484 [31:36<32:32,  7.91s/it, training_loss=0.202]\u001b[A\n",
            "Epoch 3:  49%|████▉     | 238/484 [31:36<30:45,  7.50s/it, training_loss=0.202]\u001b[A\n",
            "Epoch 3:  49%|████▉     | 238/484 [31:46<30:45,  7.50s/it, training_loss=0.004]\u001b[A\n",
            "Epoch 3:  49%|████▉     | 239/484 [31:46<33:16,  8.15s/it, training_loss=0.004]\u001b[A\n",
            "Epoch 3:  49%|████▉     | 239/484 [31:53<33:16,  8.15s/it, training_loss=0.312]\u001b[A\n",
            "Epoch 3:  50%|████▉     | 240/484 [31:53<31:13,  7.68s/it, training_loss=0.312]\u001b[A\n",
            "Epoch 3:  50%|████▉     | 240/484 [32:02<31:13,  7.68s/it, training_loss=0.010]\u001b[A\n",
            "Epoch 3:  50%|████▉     | 241/484 [32:02<33:24,  8.25s/it, training_loss=0.010]\u001b[A\n",
            "Epoch 3:  50%|████▉     | 241/484 [32:09<33:24,  8.25s/it, training_loss=0.009]\u001b[A\n",
            "Epoch 3:  50%|█████     | 242/484 [32:09<31:35,  7.83s/it, training_loss=0.009]\u001b[A\n",
            "Epoch 3:  50%|█████     | 242/484 [32:17<31:35,  7.83s/it, training_loss=0.019]\u001b[A\n",
            "Epoch 3:  50%|█████     | 243/484 [32:17<31:47,  7.91s/it, training_loss=0.019]\u001b[A\n",
            "Epoch 3:  50%|█████     | 243/484 [32:25<31:47,  7.91s/it, training_loss=0.008]\u001b[A\n",
            "Epoch 3:  50%|█████     | 244/484 [32:25<31:44,  7.93s/it, training_loss=0.008]\u001b[A\n",
            "Epoch 3:  50%|█████     | 244/484 [32:32<31:44,  7.93s/it, training_loss=0.023]\u001b[A\n",
            "Epoch 3:  51%|█████     | 245/484 [32:32<30:09,  7.57s/it, training_loss=0.023]\u001b[A\n",
            "Epoch 3:  51%|█████     | 245/484 [32:41<30:09,  7.57s/it, training_loss=0.023]\u001b[A\n",
            "Epoch 3:  51%|█████     | 246/484 [32:41<32:08,  8.10s/it, training_loss=0.023]\u001b[A\n",
            "Epoch 3:  51%|█████     | 246/484 [32:48<32:08,  8.10s/it, training_loss=0.011]\u001b[A\n",
            "Epoch 3:  51%|█████     | 247/484 [32:48<30:10,  7.64s/it, training_loss=0.011]\u001b[A\n",
            "Epoch 3:  51%|█████     | 247/484 [32:57<30:10,  7.64s/it, training_loss=0.010]\u001b[A\n",
            "Epoch 3:  51%|█████     | 248/484 [32:57<32:13,  8.19s/it, training_loss=0.010]\u001b[A\n",
            "Epoch 3:  51%|█████     | 248/484 [33:04<32:13,  8.19s/it, training_loss=0.118]\u001b[A\n",
            "Epoch 3:  51%|█████▏    | 249/484 [33:04<30:18,  7.74s/it, training_loss=0.118]\u001b[A\n",
            "Epoch 3:  51%|█████▏    | 249/484 [33:12<30:18,  7.74s/it, training_loss=0.192]\u001b[A\n",
            "Epoch 3:  52%|█████▏    | 250/484 [33:12<30:41,  7.87s/it, training_loss=0.192]\u001b[A\n",
            "Epoch 3:  52%|█████▏    | 250/484 [33:20<30:41,  7.87s/it, training_loss=0.009]\u001b[A\n",
            "Epoch 3:  52%|█████▏    | 251/484 [33:20<30:28,  7.85s/it, training_loss=0.009]\u001b[A\n",
            "Epoch 3:  52%|█████▏    | 251/484 [33:27<30:28,  7.85s/it, training_loss=0.030]\u001b[A\n",
            "Epoch 3:  52%|█████▏    | 252/484 [33:27<29:04,  7.52s/it, training_loss=0.030]\u001b[A\n",
            "Epoch 3:  52%|█████▏    | 252/484 [33:36<29:04,  7.52s/it, training_loss=0.166]\u001b[A\n",
            "Epoch 3:  52%|█████▏    | 253/484 [33:36<31:01,  8.06s/it, training_loss=0.166]\u001b[A\n",
            "Epoch 3:  52%|█████▏    | 253/484 [33:43<31:01,  8.06s/it, training_loss=0.227]\u001b[A\n",
            "Epoch 3:  52%|█████▏    | 254/484 [33:43<29:16,  7.64s/it, training_loss=0.227]\u001b[A\n",
            "Epoch 3:  52%|█████▏    | 254/484 [33:52<29:16,  7.64s/it, training_loss=0.006]\u001b[A\n",
            "Epoch 3:  53%|█████▎    | 255/484 [33:52<31:25,  8.24s/it, training_loss=0.006]\u001b[A\n",
            "Epoch 3:  53%|█████▎    | 255/484 [33:59<31:25,  8.24s/it, training_loss=0.006]\u001b[A\n",
            "Epoch 3:  53%|█████▎    | 256/484 [33:59<29:26,  7.75s/it, training_loss=0.006]\u001b[A\n",
            "Epoch 3:  53%|█████▎    | 256/484 [34:08<29:26,  7.75s/it, training_loss=0.273]\u001b[A\n",
            "Epoch 3:  53%|█████▎    | 257/484 [34:08<30:22,  8.03s/it, training_loss=0.273]\u001b[A\n",
            "Epoch 3:  53%|█████▎    | 257/484 [34:18<30:22,  8.03s/it, training_loss=0.254]\u001b[A\n",
            "Epoch 3:  53%|█████▎    | 258/484 [34:18<32:41,  8.68s/it, training_loss=0.254]\u001b[A\n",
            "Epoch 3:  53%|█████▎    | 258/484 [34:27<32:41,  8.68s/it, training_loss=0.007]\u001b[A\n",
            "Epoch 3:  54%|█████▎    | 259/484 [34:27<33:24,  8.91s/it, training_loss=0.007]\u001b[A\n",
            "Epoch 3:  54%|█████▎    | 259/484 [34:34<33:24,  8.91s/it, training_loss=0.008]\u001b[A\n",
            "Epoch 3:  54%|█████▎    | 260/484 [34:34<31:15,  8.37s/it, training_loss=0.008]\u001b[A\n",
            "Epoch 3:  54%|█████▎    | 260/484 [34:42<31:15,  8.37s/it, training_loss=0.003]\u001b[A\n",
            "Epoch 3:  54%|█████▍    | 261/484 [34:42<30:18,  8.15s/it, training_loss=0.003]\u001b[A\n",
            "Epoch 3:  54%|█████▍    | 261/484 [34:50<30:18,  8.15s/it, training_loss=0.013]\u001b[A\n",
            "Epoch 3:  54%|█████▍    | 262/484 [34:50<30:23,  8.21s/it, training_loss=0.013]\u001b[A\n",
            "Epoch 3:  54%|█████▍    | 262/484 [34:57<30:23,  8.21s/it, training_loss=0.026]\u001b[A\n",
            "Epoch 3:  54%|█████▍    | 263/484 [34:57<28:25,  7.72s/it, training_loss=0.026]\u001b[A\n",
            "Epoch 3:  54%|█████▍    | 263/484 [35:07<28:25,  7.72s/it, training_loss=0.063]\u001b[A\n",
            "Epoch 3:  55%|█████▍    | 264/484 [35:07<30:29,  8.32s/it, training_loss=0.063]\u001b[A\n",
            "Epoch 3:  55%|█████▍    | 264/484 [35:13<30:29,  8.32s/it, training_loss=0.036]\u001b[A\n",
            "Epoch 3:  55%|█████▍    | 265/484 [35:13<28:27,  7.80s/it, training_loss=0.036]\u001b[A\n",
            "Epoch 3:  55%|█████▍    | 265/484 [35:22<28:27,  7.80s/it, training_loss=0.014]\u001b[A\n",
            "Epoch 3:  55%|█████▍    | 266/484 [35:22<29:56,  8.24s/it, training_loss=0.014]\u001b[A\n",
            "Epoch 3:  55%|█████▍    | 266/484 [35:29<29:56,  8.24s/it, training_loss=0.003]\u001b[A\n",
            "Epoch 3:  55%|█████▌    | 267/484 [35:29<28:23,  7.85s/it, training_loss=0.003]\u001b[A\n",
            "Epoch 3:  55%|█████▌    | 267/484 [35:37<28:23,  7.85s/it, training_loss=0.197]\u001b[A\n",
            "Epoch 3:  55%|█████▌    | 268/484 [35:37<28:20,  7.87s/it, training_loss=0.197]\u001b[A\n",
            "Epoch 3:  55%|█████▌    | 268/484 [35:45<28:20,  7.87s/it, training_loss=0.012]\u001b[A\n",
            "Epoch 3:  56%|█████▌    | 269/484 [35:45<28:27,  7.94s/it, training_loss=0.012]\u001b[A\n",
            "Epoch 3:  56%|█████▌    | 269/484 [35:52<28:27,  7.94s/it, training_loss=0.067]\u001b[A\n",
            "Epoch 3:  56%|█████▌    | 270/484 [35:52<27:03,  7.58s/it, training_loss=0.067]\u001b[A\n",
            "Epoch 3:  56%|█████▌    | 270/484 [36:02<27:03,  7.58s/it, training_loss=0.071]\u001b[A\n",
            "Epoch 3:  56%|█████▌    | 271/484 [36:02<29:40,  8.36s/it, training_loss=0.071]\u001b[A\n",
            "Epoch 3:  56%|█████▌    | 271/484 [36:09<29:40,  8.36s/it, training_loss=0.005]\u001b[A\n",
            "Epoch 3:  56%|█████▌    | 272/484 [36:09<27:40,  7.83s/it, training_loss=0.005]\u001b[A\n",
            "Epoch 3:  56%|█████▌    | 272/484 [36:19<27:40,  7.83s/it, training_loss=0.011]\u001b[A\n",
            "Epoch 3:  56%|█████▋    | 273/484 [36:19<29:32,  8.40s/it, training_loss=0.011]\u001b[A\n",
            "Epoch 3:  56%|█████▋    | 273/484 [36:25<29:32,  8.40s/it, training_loss=0.007]\u001b[A\n",
            "Epoch 3:  57%|█████▋    | 274/484 [36:25<27:31,  7.86s/it, training_loss=0.007]\u001b[A\n",
            "Epoch 3:  57%|█████▋    | 274/484 [36:34<27:31,  7.86s/it, training_loss=0.052]\u001b[A\n",
            "Epoch 3:  57%|█████▋    | 275/484 [36:34<28:22,  8.14s/it, training_loss=0.052]\u001b[A\n",
            "Epoch 3:  57%|█████▋    | 275/484 [36:41<28:22,  8.14s/it, training_loss=0.167]\u001b[A\n",
            "Epoch 3:  57%|█████▋    | 276/484 [36:41<27:24,  7.91s/it, training_loss=0.167]\u001b[A\n",
            "Epoch 3:  57%|█████▋    | 276/484 [36:49<27:24,  7.91s/it, training_loss=0.256]\u001b[A\n",
            "Epoch 3:  57%|█████▋    | 277/484 [36:49<26:44,  7.75s/it, training_loss=0.256]\u001b[A\n",
            "Epoch 3:  57%|█████▋    | 277/484 [36:57<26:44,  7.75s/it, training_loss=0.004]\u001b[A\n",
            "Epoch 3:  57%|█████▋    | 278/484 [36:57<27:26,  7.99s/it, training_loss=0.004]\u001b[A\n",
            "Epoch 3:  57%|█████▋    | 278/484 [37:04<27:26,  7.99s/it, training_loss=0.198]\u001b[A\n",
            "Epoch 3:  58%|█████▊    | 279/484 [37:04<25:50,  7.56s/it, training_loss=0.198]\u001b[A\n",
            "Epoch 3:  58%|█████▊    | 279/484 [37:14<25:50,  7.56s/it, training_loss=0.151]\u001b[A\n",
            "Epoch 3:  58%|█████▊    | 280/484 [37:14<27:50,  8.19s/it, training_loss=0.151]\u001b[A\n",
            "Epoch 3:  58%|█████▊    | 280/484 [37:20<27:50,  8.19s/it, training_loss=0.092]\u001b[A\n",
            "Epoch 3:  58%|█████▊    | 281/484 [37:20<26:04,  7.71s/it, training_loss=0.092]\u001b[A\n",
            "Epoch 3:  58%|█████▊    | 281/484 [37:29<26:04,  7.71s/it, training_loss=0.265]\u001b[A\n",
            "Epoch 3:  58%|█████▊    | 282/484 [37:29<27:16,  8.10s/it, training_loss=0.265]\u001b[A\n",
            "Epoch 3:  58%|█████▊    | 282/484 [37:36<27:16,  8.10s/it, training_loss=0.109]\u001b[A\n",
            "Epoch 3:  58%|█████▊    | 283/484 [37:36<26:07,  7.80s/it, training_loss=0.109]\u001b[A\n",
            "Epoch 3:  58%|█████▊    | 283/484 [37:44<26:07,  7.80s/it, training_loss=0.184]\u001b[A\n",
            "Epoch 3:  59%|█████▊    | 284/484 [37:44<25:45,  7.73s/it, training_loss=0.184]\u001b[A\n",
            "Epoch 3:  59%|█████▊    | 284/484 [37:52<25:45,  7.73s/it, training_loss=0.038]\u001b[A\n",
            "Epoch 3:  59%|█████▉    | 285/484 [37:52<26:20,  7.94s/it, training_loss=0.038]\u001b[A\n",
            "Epoch 3:  59%|█████▉    | 285/484 [37:59<26:20,  7.94s/it, training_loss=0.202]\u001b[A\n",
            "Epoch 3:  59%|█████▉    | 286/484 [37:59<24:49,  7.52s/it, training_loss=0.202]\u001b[A\n",
            "Epoch 3:  59%|█████▉    | 286/484 [38:08<24:49,  7.52s/it, training_loss=0.007]\u001b[A\n",
            "Epoch 3:  59%|█████▉    | 287/484 [38:08<26:48,  8.16s/it, training_loss=0.007]\u001b[A\n",
            "Epoch 3:  59%|█████▉    | 287/484 [38:15<26:48,  8.16s/it, training_loss=0.152]\u001b[A\n",
            "Epoch 3:  60%|█████▉    | 288/484 [38:15<25:04,  7.68s/it, training_loss=0.152]\u001b[A\n",
            "Epoch 3:  60%|█████▉    | 288/484 [38:24<25:04,  7.68s/it, training_loss=0.345]\u001b[A\n",
            "Epoch 3:  60%|█████▉    | 289/484 [38:24<26:21,  8.11s/it, training_loss=0.345]\u001b[A\n",
            "Epoch 3:  60%|█████▉    | 289/484 [38:31<26:21,  8.11s/it, training_loss=0.014]\u001b[A\n",
            "Epoch 3:  60%|█████▉    | 290/484 [38:31<25:10,  7.79s/it, training_loss=0.014]\u001b[A\n",
            "Epoch 3:  60%|█████▉    | 290/484 [38:39<25:10,  7.79s/it, training_loss=0.005]\u001b[A\n",
            "Epoch 3:  60%|██████    | 291/484 [38:39<24:59,  7.77s/it, training_loss=0.005]\u001b[A\n",
            "Epoch 3:  60%|██████    | 291/484 [38:47<24:59,  7.77s/it, training_loss=0.009]\u001b[A\n",
            "Epoch 3:  60%|██████    | 292/484 [38:47<25:16,  7.90s/it, training_loss=0.009]\u001b[A\n",
            "Epoch 3:  60%|██████    | 292/484 [38:54<25:16,  7.90s/it, training_loss=0.003]\u001b[A\n",
            "Epoch 3:  61%|██████    | 293/484 [38:54<23:54,  7.51s/it, training_loss=0.003]\u001b[A\n",
            "Epoch 3:  61%|██████    | 293/484 [39:03<23:54,  7.51s/it, training_loss=0.126]\u001b[A\n",
            "Epoch 3:  61%|██████    | 294/484 [39:03<25:47,  8.14s/it, training_loss=0.126]\u001b[A\n",
            "Epoch 3:  61%|██████    | 294/484 [39:10<25:47,  8.14s/it, training_loss=0.225]\u001b[A\n",
            "Epoch 3:  61%|██████    | 295/484 [39:10<24:06,  7.65s/it, training_loss=0.225]\u001b[A\n",
            "Epoch 3:  61%|██████    | 295/484 [39:19<24:06,  7.65s/it, training_loss=0.050]\u001b[A\n",
            "Epoch 3:  61%|██████    | 296/484 [39:19<25:25,  8.11s/it, training_loss=0.050]\u001b[A\n",
            "Epoch 3:  61%|██████    | 296/484 [39:26<25:25,  8.11s/it, training_loss=0.187]\u001b[A\n",
            "Epoch 3:  61%|██████▏   | 297/484 [39:26<24:10,  7.76s/it, training_loss=0.187]\u001b[A\n",
            "Epoch 3:  61%|██████▏   | 297/484 [39:34<24:10,  7.76s/it, training_loss=0.032]\u001b[A\n",
            "Epoch 3:  62%|██████▏   | 298/484 [39:34<24:05,  7.77s/it, training_loss=0.032]\u001b[A\n",
            "Epoch 3:  62%|██████▏   | 298/484 [39:42<24:05,  7.77s/it, training_loss=0.015]\u001b[A\n",
            "Epoch 3:  62%|██████▏   | 299/484 [39:42<24:13,  7.86s/it, training_loss=0.015]\u001b[A\n",
            "Epoch 3:  62%|██████▏   | 299/484 [39:49<24:13,  7.86s/it, training_loss=0.004]\u001b[A\n",
            "Epoch 3:  62%|██████▏   | 300/484 [39:49<23:02,  7.51s/it, training_loss=0.004]\u001b[A\n",
            "Epoch 3:  62%|██████▏   | 300/484 [39:58<23:02,  7.51s/it, training_loss=0.044]\u001b[A\n",
            "Epoch 3:  62%|██████▏   | 301/484 [39:58<24:46,  8.12s/it, training_loss=0.044]\u001b[A\n",
            "Epoch 3:  62%|██████▏   | 301/484 [40:05<24:46,  8.12s/it, training_loss=0.163]\u001b[A\n",
            "Epoch 3:  62%|██████▏   | 302/484 [40:05<23:11,  7.65s/it, training_loss=0.163]\u001b[A\n",
            "Epoch 3:  62%|██████▏   | 302/484 [40:14<23:11,  7.65s/it, training_loss=0.007]\u001b[A\n",
            "Epoch 3:  63%|██████▎   | 303/484 [40:14<24:38,  8.17s/it, training_loss=0.007]\u001b[A\n",
            "Epoch 3:  63%|██████▎   | 303/484 [40:21<24:38,  8.17s/it, training_loss=0.167]\u001b[A\n",
            "Epoch 3:  63%|██████▎   | 304/484 [40:21<23:15,  7.76s/it, training_loss=0.167]\u001b[A\n",
            "Epoch 3:  63%|██████▎   | 304/484 [40:29<23:15,  7.76s/it, training_loss=0.301]\u001b[A\n",
            "Epoch 3:  63%|██████▎   | 305/484 [40:29<23:27,  7.86s/it, training_loss=0.301]\u001b[A\n",
            "Epoch 3:  63%|██████▎   | 305/484 [40:37<23:27,  7.86s/it, training_loss=0.255]\u001b[A\n",
            "Epoch 3:  63%|██████▎   | 306/484 [40:37<23:20,  7.87s/it, training_loss=0.255]\u001b[A\n",
            "Epoch 3:  63%|██████▎   | 306/484 [40:43<23:20,  7.87s/it, training_loss=0.007]\u001b[A\n",
            "Epoch 3:  63%|██████▎   | 307/484 [40:43<22:09,  7.51s/it, training_loss=0.007]\u001b[A\n",
            "Epoch 3:  63%|██████▎   | 307/484 [40:53<22:09,  7.51s/it, training_loss=0.210]\u001b[A\n",
            "Epoch 3:  64%|██████▎   | 308/484 [40:53<23:39,  8.07s/it, training_loss=0.210]\u001b[A\n",
            "Epoch 3:  64%|██████▎   | 308/484 [40:59<23:39,  8.07s/it, training_loss=0.060]\u001b[A\n",
            "Epoch 3:  64%|██████▍   | 309/484 [40:59<22:11,  7.61s/it, training_loss=0.060]\u001b[A\n",
            "Epoch 3:  64%|██████▍   | 309/484 [41:09<22:11,  7.61s/it, training_loss=0.244]\u001b[A\n",
            "Epoch 3:  64%|██████▍   | 310/484 [41:09<23:37,  8.15s/it, training_loss=0.244]\u001b[A\n",
            "Epoch 3:  64%|██████▍   | 310/484 [41:15<23:37,  8.15s/it, training_loss=0.276]\u001b[A\n",
            "Epoch 3:  64%|██████▍   | 311/484 [41:15<22:12,  7.70s/it, training_loss=0.276]\u001b[A\n",
            "Epoch 3:  64%|██████▍   | 311/484 [41:23<22:12,  7.70s/it, training_loss=0.049]\u001b[A\n",
            "Epoch 3:  64%|██████▍   | 312/484 [41:23<22:22,  7.80s/it, training_loss=0.049]\u001b[A\n",
            "Epoch 3:  64%|██████▍   | 312/484 [41:31<22:22,  7.80s/it, training_loss=0.170]\u001b[A\n",
            "Epoch 3:  65%|██████▍   | 313/484 [41:31<22:17,  7.82s/it, training_loss=0.170]\u001b[A\n",
            "Epoch 3:  65%|██████▍   | 313/484 [41:38<22:17,  7.82s/it, training_loss=0.066]\u001b[A\n",
            "Epoch 3:  65%|██████▍   | 314/484 [41:38<21:09,  7.47s/it, training_loss=0.066]\u001b[A\n",
            "Epoch 3:  65%|██████▍   | 314/484 [41:47<21:09,  7.47s/it, training_loss=0.005]\u001b[A\n",
            "Epoch 3:  65%|██████▌   | 315/484 [41:47<22:39,  8.05s/it, training_loss=0.005]\u001b[A\n",
            "Epoch 3:  65%|██████▌   | 315/484 [41:54<22:39,  8.05s/it, training_loss=0.047]\u001b[A\n",
            "Epoch 3:  65%|██████▌   | 316/484 [41:54<21:18,  7.61s/it, training_loss=0.047]\u001b[A\n",
            "Epoch 3:  65%|██████▌   | 316/484 [42:03<21:18,  7.61s/it, training_loss=0.038]\u001b[A\n",
            "Epoch 3:  65%|██████▌   | 317/484 [42:03<22:42,  8.16s/it, training_loss=0.038]\u001b[A\n",
            "Epoch 3:  65%|██████▌   | 317/484 [42:10<22:42,  8.16s/it, training_loss=0.066]\u001b[A\n",
            "Epoch 3:  66%|██████▌   | 318/484 [42:10<21:21,  7.72s/it, training_loss=0.066]\u001b[A\n",
            "Epoch 3:  66%|██████▌   | 318/484 [42:18<21:21,  7.72s/it, training_loss=0.005]\u001b[A\n",
            "Epoch 3:  66%|██████▌   | 319/484 [42:18<21:36,  7.86s/it, training_loss=0.005]\u001b[A\n",
            "Epoch 3:  66%|██████▌   | 319/484 [42:26<21:36,  7.86s/it, training_loss=0.007]\u001b[A\n",
            "Epoch 3:  66%|██████▌   | 320/484 [42:26<21:27,  7.85s/it, training_loss=0.007]\u001b[A\n",
            "Epoch 3:  66%|██████▌   | 320/484 [42:33<21:27,  7.85s/it, training_loss=0.012]\u001b[A\n",
            "Epoch 3:  66%|██████▋   | 321/484 [42:33<20:31,  7.56s/it, training_loss=0.012]\u001b[A\n",
            "Epoch 3:  66%|██████▋   | 321/484 [42:42<20:31,  7.56s/it, training_loss=0.005]\u001b[A\n",
            "Epoch 3:  67%|██████▋   | 322/484 [42:42<21:40,  8.03s/it, training_loss=0.005]\u001b[A\n",
            "Epoch 3:  67%|██████▋   | 322/484 [42:49<21:40,  8.03s/it, training_loss=0.163]\u001b[A\n",
            "Epoch 3:  67%|██████▋   | 323/484 [42:49<20:20,  7.58s/it, training_loss=0.163]\u001b[A\n",
            "Epoch 3:  67%|██████▋   | 323/484 [42:59<20:20,  7.58s/it, training_loss=0.005]\u001b[A\n",
            "Epoch 3:  67%|██████▋   | 324/484 [42:59<22:40,  8.50s/it, training_loss=0.005]\u001b[A\n",
            "Epoch 3:  67%|██████▋   | 324/484 [43:06<22:40,  8.50s/it, training_loss=0.283]\u001b[A\n",
            "Epoch 3:  67%|██████▋   | 325/484 [43:06<21:26,  8.09s/it, training_loss=0.283]\u001b[A\n",
            "Epoch 3:  67%|██████▋   | 325/484 [43:15<21:26,  8.09s/it, training_loss=0.115]\u001b[A\n",
            "Epoch 3:  67%|██████▋   | 326/484 [43:15<21:50,  8.29s/it, training_loss=0.115]\u001b[A\n",
            "Epoch 3:  67%|██████▋   | 326/484 [43:22<21:50,  8.29s/it, training_loss=0.009]\u001b[A\n",
            "Epoch 3:  68%|██████▊   | 327/484 [43:22<20:52,  7.98s/it, training_loss=0.009]\u001b[A\n",
            "Epoch 3:  68%|██████▊   | 327/484 [43:30<20:52,  7.98s/it, training_loss=0.009]\u001b[A\n",
            "Epoch 3:  68%|██████▊   | 328/484 [43:30<20:12,  7.77s/it, training_loss=0.009]\u001b[A\n",
            "Epoch 3:  68%|██████▊   | 328/484 [43:41<20:12,  7.77s/it, training_loss=0.007]\u001b[A\n",
            "Epoch 3:  68%|██████▊   | 329/484 [43:41<22:57,  8.89s/it, training_loss=0.007]\u001b[A\n",
            "Epoch 3:  68%|██████▊   | 329/484 [43:48<22:57,  8.89s/it, training_loss=0.010]\u001b[A\n",
            "Epoch 3:  68%|██████▊   | 330/484 [43:48<21:20,  8.31s/it, training_loss=0.010]\u001b[A\n",
            "Epoch 3:  68%|██████▊   | 330/484 [43:58<21:20,  8.31s/it, training_loss=0.009]\u001b[A\n",
            "Epoch 3:  68%|██████▊   | 331/484 [43:58<22:17,  8.74s/it, training_loss=0.009]\u001b[A\n",
            "Epoch 3:  68%|██████▊   | 331/484 [44:05<22:17,  8.74s/it, training_loss=0.475]\u001b[A\n",
            "Epoch 3:  69%|██████▊   | 332/484 [44:05<20:30,  8.09s/it, training_loss=0.475]\u001b[A\n",
            "Epoch 3:  69%|██████▊   | 332/484 [44:14<20:30,  8.09s/it, training_loss=0.164]\u001b[A\n",
            "Epoch 3:  69%|██████▉   | 333/484 [44:14<21:03,  8.37s/it, training_loss=0.164]\u001b[A\n",
            "Epoch 3:  69%|██████▉   | 333/484 [44:21<21:03,  8.37s/it, training_loss=0.005]\u001b[A\n",
            "Epoch 3:  69%|██████▉   | 334/484 [44:21<20:01,  8.01s/it, training_loss=0.005]\u001b[A\n",
            "Epoch 3:  69%|██████▉   | 334/484 [44:28<20:01,  8.01s/it, training_loss=0.007]\u001b[A\n",
            "Epoch 3:  69%|██████▉   | 335/484 [44:28<19:34,  7.88s/it, training_loss=0.007]\u001b[A\n",
            "Epoch 3:  69%|██████▉   | 335/484 [44:37<19:34,  7.88s/it, training_loss=0.122]\u001b[A\n",
            "Epoch 3:  69%|██████▉   | 336/484 [44:37<19:50,  8.04s/it, training_loss=0.122]\u001b[A\n",
            "Epoch 3:  69%|██████▉   | 336/484 [44:43<19:50,  8.04s/it, training_loss=0.008]\u001b[A\n",
            "Epoch 3:  70%|██████▉   | 337/484 [44:43<18:36,  7.60s/it, training_loss=0.008]\u001b[A\n",
            "Epoch 3:  70%|██████▉   | 337/484 [44:53<18:36,  7.60s/it, training_loss=0.040]\u001b[A\n",
            "Epoch 3:  70%|██████▉   | 338/484 [44:53<19:59,  8.22s/it, training_loss=0.040]\u001b[A\n",
            "Epoch 3:  70%|██████▉   | 338/484 [45:00<19:59,  8.22s/it, training_loss=0.017]\u001b[A\n",
            "Epoch 3:  70%|███████   | 339/484 [45:00<18:41,  7.73s/it, training_loss=0.017]\u001b[A\n",
            "Epoch 3:  70%|███████   | 339/484 [45:09<18:41,  7.73s/it, training_loss=0.061]\u001b[A\n",
            "Epoch 3:  70%|███████   | 340/484 [45:09<19:35,  8.16s/it, training_loss=0.061]\u001b[A\n",
            "Epoch 3:  70%|███████   | 340/484 [45:16<19:35,  8.16s/it, training_loss=0.026]\u001b[A\n",
            "Epoch 3:  70%|███████   | 341/484 [45:16<18:37,  7.82s/it, training_loss=0.026]\u001b[A\n",
            "Epoch 3:  70%|███████   | 341/484 [45:24<18:37,  7.82s/it, training_loss=0.115]\u001b[A\n",
            "Epoch 3:  71%|███████   | 342/484 [45:24<18:32,  7.84s/it, training_loss=0.115]\u001b[A\n",
            "Epoch 3:  71%|███████   | 342/484 [45:32<18:32,  7.84s/it, training_loss=0.241]\u001b[A\n",
            "Epoch 3:  71%|███████   | 343/484 [45:32<18:38,  7.93s/it, training_loss=0.241]\u001b[A\n",
            "Epoch 3:  71%|███████   | 343/484 [45:38<18:38,  7.93s/it, training_loss=0.009]\u001b[A\n",
            "Epoch 3:  71%|███████   | 344/484 [45:38<17:38,  7.56s/it, training_loss=0.009]\u001b[A\n",
            "Epoch 3:  71%|███████   | 344/484 [45:48<17:38,  7.56s/it, training_loss=0.003]\u001b[A\n",
            "Epoch 3:  71%|███████▏  | 345/484 [45:48<18:55,  8.17s/it, training_loss=0.003]\u001b[A\n",
            "Epoch 3:  71%|███████▏  | 345/484 [45:55<18:55,  8.17s/it, training_loss=0.013]\u001b[A\n",
            "Epoch 3:  71%|███████▏  | 346/484 [45:55<17:43,  7.70s/it, training_loss=0.013]\u001b[A\n",
            "Epoch 3:  71%|███████▏  | 346/484 [46:04<17:43,  7.70s/it, training_loss=0.030]\u001b[A\n",
            "Epoch 3:  72%|███████▏  | 347/484 [46:04<18:46,  8.22s/it, training_loss=0.030]\u001b[A\n",
            "Epoch 3:  72%|███████▏  | 347/484 [46:11<18:46,  8.22s/it, training_loss=0.018]\u001b[A\n",
            "Epoch 3:  72%|███████▏  | 348/484 [46:11<17:41,  7.81s/it, training_loss=0.018]\u001b[A\n",
            "Epoch 3:  72%|███████▏  | 348/484 [46:19<17:41,  7.81s/it, training_loss=0.057]\u001b[A\n",
            "Epoch 3:  72%|███████▏  | 349/484 [46:19<17:47,  7.90s/it, training_loss=0.057]\u001b[A\n",
            "Epoch 3:  72%|███████▏  | 349/484 [46:27<17:47,  7.90s/it, training_loss=0.058]\u001b[A\n",
            "Epoch 3:  72%|███████▏  | 350/484 [46:27<17:37,  7.90s/it, training_loss=0.058]\u001b[A\n",
            "Epoch 3:  72%|███████▏  | 350/484 [46:34<17:37,  7.90s/it, training_loss=0.030]\u001b[A\n",
            "Epoch 3:  73%|███████▎  | 351/484 [46:34<16:44,  7.56s/it, training_loss=0.030]\u001b[A\n",
            "Epoch 3:  73%|███████▎  | 351/484 [46:43<16:44,  7.56s/it, training_loss=0.081]\u001b[A\n",
            "Epoch 3:  73%|███████▎  | 352/484 [46:43<17:45,  8.07s/it, training_loss=0.081]\u001b[A\n",
            "Epoch 3:  73%|███████▎  | 352/484 [46:50<17:45,  8.07s/it, training_loss=0.021]\u001b[A\n",
            "Epoch 3:  73%|███████▎  | 353/484 [46:50<16:37,  7.61s/it, training_loss=0.021]\u001b[A\n",
            "Epoch 3:  73%|███████▎  | 353/484 [46:59<16:37,  7.61s/it, training_loss=0.004]\u001b[A\n",
            "Epoch 3:  73%|███████▎  | 354/484 [46:59<17:46,  8.20s/it, training_loss=0.004]\u001b[A\n",
            "Epoch 3:  73%|███████▎  | 354/484 [47:06<17:46,  8.20s/it, training_loss=0.133]\u001b[A\n",
            "Epoch 3:  73%|███████▎  | 355/484 [47:06<16:34,  7.71s/it, training_loss=0.133]\u001b[A\n",
            "Epoch 3:  73%|███████▎  | 355/484 [47:14<16:34,  7.71s/it, training_loss=0.002]\u001b[A\n",
            "Epoch 3:  74%|███████▎  | 356/484 [47:14<16:53,  7.92s/it, training_loss=0.002]\u001b[A\n",
            "Epoch 3:  74%|███████▎  | 356/484 [47:22<16:53,  7.92s/it, training_loss=0.013]\u001b[A\n",
            "Epoch 3:  74%|███████▍  | 357/484 [47:22<16:35,  7.84s/it, training_loss=0.013]\u001b[A\n",
            "Epoch 3:  74%|███████▍  | 357/484 [47:28<16:35,  7.84s/it, training_loss=0.164]\u001b[A\n",
            "Epoch 3:  74%|███████▍  | 358/484 [47:28<15:47,  7.52s/it, training_loss=0.164]\u001b[A\n",
            "Epoch 3:  74%|███████▍  | 358/484 [47:38<15:47,  7.52s/it, training_loss=0.055]\u001b[A\n",
            "Epoch 3:  74%|███████▍  | 359/484 [47:38<16:41,  8.01s/it, training_loss=0.055]\u001b[A\n",
            "Epoch 3:  74%|███████▍  | 359/484 [47:44<16:41,  8.01s/it, training_loss=0.017]\u001b[A\n",
            "Epoch 3:  74%|███████▍  | 360/484 [47:44<15:43,  7.61s/it, training_loss=0.017]\u001b[A\n",
            "Epoch 3:  74%|███████▍  | 360/484 [47:54<15:43,  7.61s/it, training_loss=0.150]\u001b[A\n",
            "Epoch 3:  75%|███████▍  | 361/484 [47:54<16:52,  8.23s/it, training_loss=0.150]\u001b[A\n",
            "Epoch 3:  75%|███████▍  | 361/484 [48:01<16:52,  8.23s/it, training_loss=0.148]\u001b[A\n",
            "Epoch 3:  75%|███████▍  | 362/484 [48:01<15:47,  7.77s/it, training_loss=0.148]\u001b[A\n",
            "Epoch 3:  75%|███████▍  | 362/484 [48:10<15:47,  7.77s/it, training_loss=0.260]\u001b[A\n",
            "Epoch 3:  75%|███████▌  | 363/484 [48:10<16:19,  8.09s/it, training_loss=0.260]\u001b[A\n",
            "Epoch 3:  75%|███████▌  | 363/484 [48:17<16:19,  8.09s/it, training_loss=0.005]\u001b[A\n",
            "Epoch 3:  75%|███████▌  | 364/484 [48:17<16:05,  8.05s/it, training_loss=0.005]\u001b[A\n",
            "Epoch 3:  75%|███████▌  | 364/484 [48:25<16:05,  8.05s/it, training_loss=0.005]\u001b[A\n",
            "Epoch 3:  75%|███████▌  | 365/484 [48:25<15:42,  7.92s/it, training_loss=0.005]\u001b[A\n",
            "Epoch 3:  75%|███████▌  | 365/484 [48:34<15:42,  7.92s/it, training_loss=0.004]\u001b[A\n",
            "Epoch 3:  76%|███████▌  | 366/484 [48:34<15:53,  8.08s/it, training_loss=0.004]\u001b[A\n",
            "Epoch 3:  76%|███████▌  | 366/484 [48:40<15:53,  8.08s/it, training_loss=0.015]\u001b[A\n",
            "Epoch 3:  76%|███████▌  | 367/484 [48:40<14:54,  7.65s/it, training_loss=0.015]\u001b[A\n",
            "Epoch 3:  76%|███████▌  | 367/484 [48:50<14:54,  7.65s/it, training_loss=0.230]\u001b[A\n",
            "Epoch 3:  76%|███████▌  | 368/484 [48:50<15:59,  8.27s/it, training_loss=0.230]\u001b[A\n",
            "Epoch 3:  76%|███████▌  | 368/484 [48:57<15:59,  8.27s/it, training_loss=0.174]\u001b[A\n",
            "Epoch 3:  76%|███████▌  | 369/484 [48:57<14:53,  7.77s/it, training_loss=0.174]\u001b[A\n",
            "Epoch 3:  76%|███████▌  | 369/484 [49:06<14:53,  7.77s/it, training_loss=0.081]\u001b[A\n",
            "Epoch 3:  76%|███████▋  | 370/484 [49:06<15:35,  8.21s/it, training_loss=0.081]\u001b[A\n",
            "Epoch 3:  76%|███████▋  | 370/484 [49:14<15:35,  8.21s/it, training_loss=0.011]\u001b[A\n",
            "Epoch 3:  77%|███████▋  | 371/484 [49:14<15:24,  8.18s/it, training_loss=0.011]\u001b[A\n",
            "Epoch 3:  77%|███████▋  | 371/484 [49:24<15:24,  8.18s/it, training_loss=0.286]\u001b[A\n",
            "Epoch 3:  77%|███████▋  | 372/484 [49:24<16:37,  8.90s/it, training_loss=0.286]\u001b[A\n",
            "Epoch 3:  77%|███████▋  | 372/484 [49:32<16:37,  8.90s/it, training_loss=0.005]\u001b[A\n",
            "Epoch 3:  77%|███████▋  | 373/484 [49:32<15:33,  8.41s/it, training_loss=0.005]\u001b[A\n",
            "Epoch 3:  77%|███████▋  | 373/484 [49:39<15:33,  8.41s/it, training_loss=0.003]\u001b[A\n",
            "Epoch 3:  77%|███████▋  | 374/484 [49:39<14:50,  8.10s/it, training_loss=0.003]\u001b[A\n",
            "Epoch 3:  77%|███████▋  | 374/484 [49:48<14:50,  8.10s/it, training_loss=0.157]\u001b[A\n",
            "Epoch 3:  77%|███████▋  | 375/484 [49:48<15:04,  8.29s/it, training_loss=0.157]\u001b[A\n",
            "Epoch 3:  77%|███████▋  | 375/484 [49:54<15:04,  8.29s/it, training_loss=0.015]\u001b[A\n",
            "Epoch 3:  78%|███████▊  | 376/484 [49:54<14:01,  7.79s/it, training_loss=0.015]\u001b[A\n",
            "Epoch 3:  78%|███████▊  | 376/484 [50:04<14:01,  7.79s/it, training_loss=0.332]\u001b[A\n",
            "Epoch 3:  78%|███████▊  | 377/484 [50:04<14:55,  8.37s/it, training_loss=0.332]\u001b[A\n",
            "Epoch 3:  78%|███████▊  | 377/484 [50:11<14:55,  8.37s/it, training_loss=0.085]\u001b[A\n",
            "Epoch 3:  78%|███████▊  | 378/484 [50:11<13:51,  7.84s/it, training_loss=0.085]\u001b[A\n",
            "Epoch 3:  78%|███████▊  | 378/484 [50:20<13:51,  7.84s/it, training_loss=0.130]\u001b[A\n",
            "Epoch 3:  78%|███████▊  | 379/484 [50:20<14:19,  8.19s/it, training_loss=0.130]\u001b[A\n",
            "Epoch 3:  78%|███████▊  | 379/484 [50:27<14:19,  8.19s/it, training_loss=0.014]\u001b[A\n",
            "Epoch 3:  79%|███████▊  | 380/484 [50:27<13:40,  7.89s/it, training_loss=0.014]\u001b[A\n",
            "Epoch 3:  79%|███████▊  | 380/484 [50:35<13:40,  7.89s/it, training_loss=0.192]\u001b[A\n",
            "Epoch 3:  79%|███████▊  | 381/484 [50:35<13:26,  7.83s/it, training_loss=0.192]\u001b[A\n",
            "Epoch 3:  79%|███████▊  | 381/484 [50:43<13:26,  7.83s/it, training_loss=0.057]\u001b[A\n",
            "Epoch 3:  79%|███████▉  | 382/484 [50:43<13:33,  7.98s/it, training_loss=0.057]\u001b[A\n",
            "Epoch 3:  79%|███████▉  | 382/484 [50:50<13:33,  7.98s/it, training_loss=0.004]\u001b[A\n",
            "Epoch 3:  79%|███████▉  | 383/484 [50:50<12:42,  7.55s/it, training_loss=0.004]\u001b[A\n",
            "Epoch 3:  79%|███████▉  | 383/484 [50:59<12:42,  7.55s/it, training_loss=0.042]\u001b[A\n",
            "Epoch 3:  79%|███████▉  | 384/484 [50:59<13:38,  8.19s/it, training_loss=0.042]\u001b[A\n",
            "Epoch 3:  79%|███████▉  | 384/484 [51:06<13:38,  8.19s/it, training_loss=0.006]\u001b[A\n",
            "Epoch 3:  80%|███████▉  | 385/484 [51:06<12:42,  7.70s/it, training_loss=0.006]\u001b[A\n",
            "Epoch 3:  80%|███████▉  | 385/484 [51:15<12:42,  7.70s/it, training_loss=0.056]\u001b[A\n",
            "Epoch 3:  80%|███████▉  | 386/484 [51:15<13:16,  8.13s/it, training_loss=0.056]\u001b[A\n",
            "Epoch 3:  80%|███████▉  | 386/484 [51:22<13:16,  8.13s/it, training_loss=0.203]\u001b[A\n",
            "Epoch 3:  80%|███████▉  | 387/484 [51:22<12:34,  7.78s/it, training_loss=0.203]\u001b[A\n",
            "Epoch 3:  80%|███████▉  | 387/484 [51:30<12:34,  7.78s/it, training_loss=0.004]\u001b[A\n",
            "Epoch 3:  80%|████████  | 388/484 [51:30<12:26,  7.78s/it, training_loss=0.004]\u001b[A\n",
            "Epoch 3:  80%|████████  | 388/484 [51:38<12:26,  7.78s/it, training_loss=0.015]\u001b[A\n",
            "Epoch 3:  80%|████████  | 389/484 [51:38<12:29,  7.89s/it, training_loss=0.015]\u001b[A\n",
            "Epoch 3:  80%|████████  | 389/484 [51:44<12:29,  7.89s/it, training_loss=0.003]\u001b[A\n",
            "Epoch 3:  81%|████████  | 390/484 [51:44<11:46,  7.51s/it, training_loss=0.003]\u001b[A\n",
            "Epoch 3:  81%|████████  | 390/484 [51:54<11:46,  7.51s/it, training_loss=0.004]\u001b[A\n",
            "Epoch 3:  81%|████████  | 391/484 [51:54<12:38,  8.16s/it, training_loss=0.004]\u001b[A\n",
            "Epoch 3:  81%|████████  | 391/484 [52:01<12:38,  8.16s/it, training_loss=0.143]\u001b[A\n",
            "Epoch 3:  81%|████████  | 392/484 [52:01<11:48,  7.70s/it, training_loss=0.143]\u001b[A\n",
            "Epoch 3:  81%|████████  | 392/484 [52:10<11:48,  7.70s/it, training_loss=0.167]\u001b[A\n",
            "Epoch 3:  81%|████████  | 393/484 [52:10<12:26,  8.21s/it, training_loss=0.167]\u001b[A\n",
            "Epoch 3:  81%|████████  | 393/484 [52:17<12:26,  8.21s/it, training_loss=0.108]\u001b[A\n",
            "Epoch 3:  81%|████████▏ | 394/484 [52:17<11:41,  7.80s/it, training_loss=0.108]\u001b[A\n",
            "Epoch 3:  81%|████████▏ | 394/484 [52:25<11:41,  7.80s/it, training_loss=0.012]\u001b[A\n",
            "Epoch 3:  82%|████████▏ | 395/484 [52:25<11:40,  7.87s/it, training_loss=0.012]\u001b[A\n",
            "Epoch 3:  82%|████████▏ | 395/484 [52:33<11:40,  7.87s/it, training_loss=0.017]\u001b[A\n",
            "Epoch 3:  82%|████████▏ | 396/484 [52:33<11:36,  7.92s/it, training_loss=0.017]\u001b[A\n",
            "Epoch 3:  82%|████████▏ | 396/484 [52:40<11:36,  7.92s/it, training_loss=0.092]\u001b[A\n",
            "Epoch 3:  82%|████████▏ | 397/484 [52:40<10:59,  7.58s/it, training_loss=0.092]\u001b[A\n",
            "Epoch 3:  82%|████████▏ | 397/484 [52:49<10:59,  7.58s/it, training_loss=0.067]\u001b[A\n",
            "Epoch 3:  82%|████████▏ | 398/484 [52:49<11:38,  8.12s/it, training_loss=0.067]\u001b[A\n",
            "Epoch 3:  82%|████████▏ | 398/484 [52:56<11:38,  8.12s/it, training_loss=0.005]\u001b[A\n",
            "Epoch 3:  82%|████████▏ | 399/484 [52:56<10:51,  7.66s/it, training_loss=0.005]\u001b[A\n",
            "Epoch 3:  82%|████████▏ | 399/484 [53:05<10:51,  7.66s/it, training_loss=0.004]\u001b[A\n",
            "Epoch 3:  83%|████████▎ | 400/484 [53:05<11:30,  8.23s/it, training_loss=0.004]\u001b[A\n",
            "Epoch 3:  83%|████████▎ | 400/484 [53:12<11:30,  8.23s/it, training_loss=0.112]\u001b[A\n",
            "Epoch 3:  83%|████████▎ | 401/484 [53:12<10:43,  7.75s/it, training_loss=0.112]\u001b[A\n",
            "Epoch 3:  83%|████████▎ | 401/484 [53:20<10:43,  7.75s/it, training_loss=0.206]\u001b[A\n",
            "Epoch 3:  83%|████████▎ | 402/484 [53:20<10:48,  7.91s/it, training_loss=0.206]\u001b[A\n",
            "Epoch 3:  83%|████████▎ | 402/484 [53:28<10:48,  7.91s/it, training_loss=0.006]\u001b[A\n",
            "Epoch 3:  83%|████████▎ | 403/484 [53:28<10:38,  7.88s/it, training_loss=0.006]\u001b[A\n",
            "Epoch 3:  83%|████████▎ | 403/484 [53:37<10:38,  7.88s/it, training_loss=0.013]\u001b[A\n",
            "Epoch 3:  83%|████████▎ | 404/484 [53:37<10:55,  8.19s/it, training_loss=0.013]\u001b[A\n",
            "Epoch 3:  83%|████████▎ | 404/484 [53:47<10:55,  8.19s/it, training_loss=0.012]\u001b[A\n",
            "Epoch 3:  84%|████████▎ | 405/484 [53:47<11:40,  8.87s/it, training_loss=0.012]\u001b[A\n",
            "Epoch 3:  84%|████████▎ | 405/484 [53:54<11:40,  8.87s/it, training_loss=0.145]\u001b[A\n",
            "Epoch 3:  84%|████████▍ | 406/484 [53:54<10:39,  8.20s/it, training_loss=0.145]\u001b[A\n",
            "Epoch 3:  84%|████████▍ | 406/484 [54:03<10:39,  8.20s/it, training_loss=0.032]\u001b[A\n",
            "Epoch 3:  84%|████████▍ | 407/484 [54:03<10:51,  8.46s/it, training_loss=0.032]\u001b[A\n",
            "Epoch 3:  84%|████████▍ | 407/484 [54:10<10:51,  8.46s/it, training_loss=0.102]\u001b[A\n",
            "Epoch 3:  84%|████████▍ | 408/484 [54:10<10:13,  8.07s/it, training_loss=0.102]\u001b[A\n",
            "Epoch 3:  84%|████████▍ | 408/484 [54:18<10:13,  8.07s/it, training_loss=0.002]\u001b[A\n",
            "Epoch 3:  85%|████████▍ | 409/484 [54:18<09:55,  7.94s/it, training_loss=0.002]\u001b[A\n",
            "Epoch 3:  85%|████████▍ | 409/484 [54:26<09:55,  7.94s/it, training_loss=0.013]\u001b[A\n",
            "Epoch 3:  85%|████████▍ | 410/484 [54:26<09:57,  8.08s/it, training_loss=0.013]\u001b[A\n",
            "Epoch 3:  85%|████████▍ | 410/484 [54:33<09:57,  8.08s/it, training_loss=0.007]\u001b[A\n",
            "Epoch 3:  85%|████████▍ | 411/484 [54:33<09:17,  7.63s/it, training_loss=0.007]\u001b[A\n",
            "Epoch 3:  85%|████████▍ | 411/484 [54:43<09:17,  7.63s/it, training_loss=0.005]\u001b[A\n",
            "Epoch 3:  85%|████████▌ | 412/484 [54:43<09:54,  8.25s/it, training_loss=0.005]\u001b[A\n",
            "Epoch 3:  85%|████████▌ | 412/484 [54:49<09:54,  8.25s/it, training_loss=0.006]\u001b[A\n",
            "Epoch 3:  85%|████████▌ | 413/484 [54:49<09:11,  7.77s/it, training_loss=0.006]\u001b[A\n",
            "Epoch 3:  85%|████████▌ | 413/484 [54:59<09:11,  7.77s/it, training_loss=0.005]\u001b[A\n",
            "Epoch 3:  86%|████████▌ | 414/484 [54:59<09:36,  8.24s/it, training_loss=0.005]\u001b[A\n",
            "Epoch 3:  86%|████████▌ | 414/484 [55:05<09:36,  8.24s/it, training_loss=0.003]\u001b[A\n",
            "Epoch 3:  86%|████████▌ | 415/484 [55:06<09:01,  7.84s/it, training_loss=0.003]\u001b[A\n",
            "Epoch 3:  86%|████████▌ | 415/484 [55:13<09:01,  7.84s/it, training_loss=0.074]\u001b[A\n",
            "Epoch 3:  86%|████████▌ | 416/484 [55:13<08:55,  7.87s/it, training_loss=0.074]\u001b[A\n",
            "Epoch 3:  86%|████████▌ | 416/484 [55:21<08:55,  7.87s/it, training_loss=0.007]\u001b[A\n",
            "Epoch 3:  86%|████████▌ | 417/484 [55:21<08:50,  7.92s/it, training_loss=0.007]\u001b[A\n",
            "Epoch 3:  86%|████████▌ | 417/484 [55:28<08:50,  7.92s/it, training_loss=0.083]\u001b[A\n",
            "Epoch 3:  86%|████████▋ | 418/484 [55:28<08:19,  7.56s/it, training_loss=0.083]\u001b[A\n",
            "Epoch 3:  86%|████████▋ | 418/484 [55:38<08:19,  7.56s/it, training_loss=0.003]\u001b[A\n",
            "Epoch 3:  87%|████████▋ | 419/484 [55:38<08:48,  8.14s/it, training_loss=0.003]\u001b[A\n",
            "Epoch 3:  87%|████████▋ | 419/484 [55:44<08:48,  8.14s/it, training_loss=0.117]\u001b[A\n",
            "Epoch 3:  87%|████████▋ | 420/484 [55:44<08:09,  7.65s/it, training_loss=0.117]\u001b[A\n",
            "Epoch 3:  87%|████████▋ | 420/484 [55:54<08:09,  7.65s/it, training_loss=0.177]\u001b[A\n",
            "Epoch 3:  87%|████████▋ | 421/484 [55:54<08:34,  8.17s/it, training_loss=0.177]\u001b[A\n",
            "Epoch 3:  87%|████████▋ | 421/484 [56:00<08:34,  8.17s/it, training_loss=0.010]\u001b[A\n",
            "Epoch 3:  87%|████████▋ | 422/484 [56:00<08:02,  7.79s/it, training_loss=0.010]\u001b[A\n",
            "Epoch 3:  87%|████████▋ | 422/484 [56:09<08:02,  7.79s/it, training_loss=0.261]\u001b[A\n",
            "Epoch 3:  87%|████████▋ | 423/484 [56:09<08:02,  7.91s/it, training_loss=0.261]\u001b[A\n",
            "Epoch 3:  87%|████████▋ | 423/484 [56:17<08:02,  7.91s/it, training_loss=0.029]\u001b[A\n",
            "Epoch 3:  88%|████████▊ | 424/484 [56:17<07:54,  7.90s/it, training_loss=0.029]\u001b[A\n",
            "Epoch 3:  88%|████████▊ | 424/484 [56:23<07:54,  7.90s/it, training_loss=0.009]\u001b[A\n",
            "Epoch 3:  88%|████████▊ | 425/484 [56:23<07:27,  7.59s/it, training_loss=0.009]\u001b[A\n",
            "Epoch 3:  88%|████████▊ | 425/484 [56:33<07:27,  7.59s/it, training_loss=0.004]\u001b[A\n",
            "Epoch 3:  88%|████████▊ | 426/484 [56:33<07:50,  8.11s/it, training_loss=0.004]\u001b[A\n",
            "Epoch 3:  88%|████████▊ | 426/484 [56:39<07:50,  8.11s/it, training_loss=0.004]\u001b[A\n",
            "Epoch 3:  88%|████████▊ | 427/484 [56:39<07:16,  7.65s/it, training_loss=0.004]\u001b[A\n",
            "Epoch 3:  88%|████████▊ | 427/484 [56:49<07:16,  7.65s/it, training_loss=0.018]\u001b[A\n",
            "Epoch 3:  88%|████████▊ | 428/484 [56:49<07:41,  8.23s/it, training_loss=0.018]\u001b[A\n",
            "Epoch 3:  88%|████████▊ | 428/484 [56:55<07:41,  8.23s/it, training_loss=0.005]\u001b[A\n",
            "Epoch 3:  89%|████████▊ | 429/484 [56:55<07:05,  7.73s/it, training_loss=0.005]\u001b[A\n",
            "Epoch 3:  89%|████████▊ | 429/484 [57:04<07:05,  7.73s/it, training_loss=0.105]\u001b[A\n",
            "Epoch 3:  89%|████████▉ | 430/484 [57:04<07:07,  7.91s/it, training_loss=0.105]\u001b[A\n",
            "Epoch 3:  89%|████████▉ | 430/484 [57:12<07:07,  7.91s/it, training_loss=0.007]\u001b[A\n",
            "Epoch 3:  89%|████████▉ | 431/484 [57:12<06:56,  7.86s/it, training_loss=0.007]\u001b[A\n",
            "Epoch 3:  89%|████████▉ | 431/484 [57:18<06:56,  7.86s/it, training_loss=0.031]\u001b[A\n",
            "Epoch 3:  89%|████████▉ | 432/484 [57:18<06:33,  7.57s/it, training_loss=0.031]\u001b[A\n",
            "Epoch 3:  89%|████████▉ | 432/484 [57:28<06:33,  7.57s/it, training_loss=0.016]\u001b[A\n",
            "Epoch 3:  89%|████████▉ | 433/484 [57:28<06:51,  8.06s/it, training_loss=0.016]\u001b[A\n",
            "Epoch 3:  89%|████████▉ | 433/484 [57:34<06:51,  8.06s/it, training_loss=0.186]\u001b[A\n",
            "Epoch 3:  90%|████████▉ | 434/484 [57:34<06:21,  7.63s/it, training_loss=0.186]\u001b[A\n",
            "Epoch 3:  90%|████████▉ | 434/484 [57:44<06:21,  7.63s/it, training_loss=0.019]\u001b[A\n",
            "Epoch 3:  90%|████████▉ | 435/484 [57:44<06:42,  8.21s/it, training_loss=0.019]\u001b[A\n",
            "Epoch 3:  90%|████████▉ | 435/484 [57:50<06:42,  8.21s/it, training_loss=0.004]\u001b[A\n",
            "Epoch 3:  90%|█████████ | 436/484 [57:50<06:11,  7.75s/it, training_loss=0.004]\u001b[A\n",
            "Epoch 3:  90%|█████████ | 436/484 [57:59<06:11,  7.75s/it, training_loss=0.017]\u001b[A\n",
            "Epoch 3:  90%|█████████ | 437/484 [57:59<06:16,  8.01s/it, training_loss=0.017]\u001b[A\n",
            "Epoch 3:  90%|█████████ | 437/484 [58:07<06:16,  8.01s/it, training_loss=0.005]\u001b[A\n",
            "Epoch 3:  90%|█████████ | 438/484 [58:07<06:01,  7.86s/it, training_loss=0.005]\u001b[A\n",
            "Epoch 3:  90%|█████████ | 438/484 [58:14<06:01,  7.86s/it, training_loss=0.020]\u001b[A\n",
            "Epoch 3:  91%|█████████ | 439/484 [58:14<05:43,  7.63s/it, training_loss=0.020]\u001b[A\n",
            "Epoch 3:  91%|█████████ | 439/484 [58:23<05:43,  7.63s/it, training_loss=0.006]\u001b[A\n",
            "Epoch 3:  91%|█████████ | 440/484 [58:23<05:57,  8.11s/it, training_loss=0.006]\u001b[A\n",
            "Epoch 3:  91%|█████████ | 440/484 [58:30<05:57,  8.11s/it, training_loss=0.010]\u001b[A\n",
            "Epoch 3:  91%|█████████ | 441/484 [58:30<05:32,  7.74s/it, training_loss=0.010]\u001b[A\n",
            "Epoch 3:  91%|█████████ | 441/484 [58:41<05:32,  7.74s/it, training_loss=0.233]\u001b[A\n",
            "Epoch 3:  91%|█████████▏| 442/484 [58:41<06:06,  8.73s/it, training_loss=0.233]\u001b[A\n",
            "Epoch 3:  91%|█████████▏| 442/484 [58:49<06:06,  8.73s/it, training_loss=0.200]\u001b[A\n",
            "Epoch 3:  92%|█████████▏| 443/484 [58:49<05:47,  8.48s/it, training_loss=0.200]\u001b[A\n",
            "Epoch 3:  92%|█████████▏| 443/484 [58:56<05:47,  8.48s/it, training_loss=0.013]\u001b[A\n",
            "Epoch 3:  92%|█████████▏| 444/484 [58:56<05:18,  7.96s/it, training_loss=0.013]\u001b[A\n",
            "Epoch 3:  92%|█████████▏| 444/484 [59:05<05:18,  7.96s/it, training_loss=0.007]\u001b[A\n",
            "Epoch 3:  92%|█████████▏| 445/484 [59:05<05:26,  8.37s/it, training_loss=0.007]\u001b[A\n",
            "Epoch 3:  92%|█████████▏| 445/484 [59:11<05:26,  8.37s/it, training_loss=0.004]\u001b[A\n",
            "Epoch 3:  92%|█████████▏| 446/484 [59:11<04:57,  7.83s/it, training_loss=0.004]\u001b[A\n",
            "Epoch 3:  92%|█████████▏| 446/484 [59:21<04:57,  7.83s/it, training_loss=0.010]\u001b[A\n",
            "Epoch 3:  92%|█████████▏| 447/484 [59:21<05:07,  8.32s/it, training_loss=0.010]\u001b[A\n",
            "Epoch 3:  92%|█████████▏| 447/484 [59:28<05:07,  8.32s/it, training_loss=0.127]\u001b[A\n",
            "Epoch 3:  93%|█████████▎| 448/484 [59:28<04:41,  7.83s/it, training_loss=0.127]\u001b[A\n",
            "Epoch 3:  93%|█████████▎| 448/484 [59:36<04:41,  7.83s/it, training_loss=0.006]\u001b[A\n",
            "Epoch 3:  93%|█████████▎| 449/484 [59:36<04:38,  7.96s/it, training_loss=0.006]\u001b[A\n",
            "Epoch 3:  93%|█████████▎| 449/484 [59:44<04:38,  7.96s/it, training_loss=0.081]\u001b[A\n",
            "Epoch 3:  93%|█████████▎| 450/484 [59:44<04:28,  7.90s/it, training_loss=0.081]\u001b[A\n",
            "Epoch 3:  93%|█████████▎| 450/484 [59:50<04:28,  7.90s/it, training_loss=0.003]\u001b[A\n",
            "Epoch 3:  93%|█████████▎| 451/484 [59:50<04:09,  7.56s/it, training_loss=0.003]\u001b[A\n",
            "Epoch 3:  93%|█████████▎| 451/484 [1:00:00<04:09,  7.56s/it, training_loss=0.006]\u001b[A\n",
            "Epoch 3:  93%|█████████▎| 452/484 [1:00:00<04:18,  8.09s/it, training_loss=0.006]\u001b[A\n",
            "Epoch 3:  93%|█████████▎| 452/484 [1:00:06<04:18,  8.09s/it, training_loss=0.003]\u001b[A\n",
            "Epoch 3:  94%|█████████▎| 453/484 [1:00:06<03:56,  7.64s/it, training_loss=0.003]\u001b[A\n",
            "Epoch 3:  94%|█████████▎| 453/484 [1:00:16<03:56,  7.64s/it, training_loss=0.008]\u001b[A\n",
            "Epoch 3:  94%|█████████▍| 454/484 [1:00:16<04:07,  8.25s/it, training_loss=0.008]\u001b[A\n",
            "Epoch 3:  94%|█████████▍| 454/484 [1:00:23<04:07,  8.25s/it, training_loss=0.006]\u001b[A\n",
            "Epoch 3:  94%|█████████▍| 455/484 [1:00:23<03:49,  7.92s/it, training_loss=0.006]\u001b[A\n",
            "Epoch 3:  94%|█████████▍| 455/484 [1:00:32<03:49,  7.92s/it, training_loss=0.072]\u001b[A\n",
            "Epoch 3:  94%|█████████▍| 456/484 [1:00:32<03:49,  8.19s/it, training_loss=0.072]\u001b[A\n",
            "Epoch 3:  94%|█████████▍| 456/484 [1:00:39<03:49,  8.19s/it, training_loss=0.116]\u001b[A\n",
            "Epoch 3:  94%|█████████▍| 457/484 [1:00:39<03:34,  7.95s/it, training_loss=0.116]\u001b[A\n",
            "Epoch 3:  94%|█████████▍| 457/484 [1:00:47<03:34,  7.95s/it, training_loss=0.228]\u001b[A\n",
            "Epoch 3:  95%|█████████▍| 458/484 [1:00:47<03:21,  7.77s/it, training_loss=0.228]\u001b[A\n",
            "Epoch 3:  95%|█████████▍| 458/484 [1:00:55<03:21,  7.77s/it, training_loss=0.028]\u001b[A\n",
            "Epoch 3:  95%|█████████▍| 459/484 [1:00:55<03:20,  8.03s/it, training_loss=0.028]\u001b[A\n",
            "Epoch 3:  95%|█████████▍| 459/484 [1:01:02<03:20,  8.03s/it, training_loss=0.121]\u001b[A\n",
            "Epoch 3:  95%|█████████▌| 460/484 [1:01:02<03:02,  7.59s/it, training_loss=0.121]\u001b[A\n",
            "Epoch 3:  95%|█████████▌| 460/484 [1:01:12<03:02,  7.59s/it, training_loss=0.009]\u001b[A\n",
            "Epoch 3:  95%|█████████▌| 461/484 [1:01:12<03:08,  8.21s/it, training_loss=0.009]\u001b[A\n",
            "Epoch 3:  95%|█████████▌| 461/484 [1:01:18<03:08,  8.21s/it, training_loss=0.007]\u001b[A\n",
            "Epoch 3:  95%|█████████▌| 462/484 [1:01:18<02:49,  7.71s/it, training_loss=0.007]\u001b[A\n",
            "Epoch 3:  95%|█████████▌| 462/484 [1:01:27<02:49,  7.71s/it, training_loss=0.098]\u001b[A\n",
            "Epoch 3:  96%|█████████▌| 463/484 [1:01:27<02:49,  8.07s/it, training_loss=0.098]\u001b[A\n",
            "Epoch 3:  96%|█████████▌| 463/484 [1:01:34<02:49,  8.07s/it, training_loss=0.011]\u001b[A\n",
            "Epoch 3:  96%|█████████▌| 464/484 [1:01:34<02:35,  7.80s/it, training_loss=0.011]\u001b[A\n",
            "Epoch 3:  96%|█████████▌| 464/484 [1:01:41<02:35,  7.80s/it, training_loss=0.183]\u001b[A\n",
            "Epoch 3:  96%|█████████▌| 465/484 [1:01:41<02:25,  7.66s/it, training_loss=0.183]\u001b[A\n",
            "Epoch 3:  96%|█████████▌| 465/484 [1:01:50<02:25,  7.66s/it, training_loss=0.159]\u001b[A\n",
            "Epoch 3:  96%|█████████▋| 466/484 [1:01:50<02:23,  7.95s/it, training_loss=0.159]\u001b[A\n",
            "Epoch 3:  96%|█████████▋| 466/484 [1:01:57<02:23,  7.95s/it, training_loss=0.210]\u001b[A\n",
            "Epoch 3:  96%|█████████▋| 467/484 [1:01:57<02:08,  7.55s/it, training_loss=0.210]\u001b[A\n",
            "Epoch 3:  96%|█████████▋| 467/484 [1:02:06<02:08,  7.55s/it, training_loss=0.004]\u001b[A\n",
            "Epoch 3:  97%|█████████▋| 468/484 [1:02:06<02:11,  8.20s/it, training_loss=0.004]\u001b[A\n",
            "Epoch 3:  97%|█████████▋| 468/484 [1:02:13<02:11,  8.20s/it, training_loss=0.006]\u001b[A\n",
            "Epoch 3:  97%|█████████▋| 469/484 [1:02:13<01:55,  7.73s/it, training_loss=0.006]\u001b[A\n",
            "Epoch 3:  97%|█████████▋| 469/484 [1:02:22<01:55,  7.73s/it, training_loss=0.004]\u001b[A\n",
            "Epoch 3:  97%|█████████▋| 470/484 [1:02:22<01:53,  8.13s/it, training_loss=0.004]\u001b[A\n",
            "Epoch 3:  97%|█████████▋| 470/484 [1:02:29<01:53,  8.13s/it, training_loss=0.004]\u001b[A\n",
            "Epoch 3:  97%|█████████▋| 471/484 [1:02:29<01:42,  7.85s/it, training_loss=0.004]\u001b[A\n",
            "Epoch 3:  97%|█████████▋| 471/484 [1:02:37<01:42,  7.85s/it, training_loss=0.024]\u001b[A\n",
            "Epoch 3:  98%|█████████▊| 472/484 [1:02:37<01:33,  7.81s/it, training_loss=0.024]\u001b[A\n",
            "Epoch 3:  98%|█████████▊| 472/484 [1:02:46<01:33,  7.81s/it, training_loss=0.005]\u001b[A\n",
            "Epoch 3:  98%|█████████▊| 473/484 [1:02:46<01:28,  8.07s/it, training_loss=0.005]\u001b[A\n",
            "Epoch 3:  98%|█████████▊| 473/484 [1:02:56<01:28,  8.07s/it, training_loss=0.199]\u001b[A\n",
            "Epoch 3:  98%|█████████▊| 474/484 [1:02:56<01:27,  8.73s/it, training_loss=0.199]\u001b[A\n",
            "Epoch 3:  98%|█████████▊| 474/484 [1:03:04<01:27,  8.73s/it, training_loss=0.007]\u001b[A\n",
            "Epoch 3:  98%|█████████▊| 475/484 [1:03:04<01:16,  8.53s/it, training_loss=0.007]\u001b[A\n",
            "Epoch 3:  98%|█████████▊| 475/484 [1:03:11<01:16,  8.53s/it, training_loss=0.101]\u001b[A\n",
            "Epoch 3:  98%|█████████▊| 476/484 [1:03:11<01:03,  7.97s/it, training_loss=0.101]\u001b[A\n",
            "Epoch 3:  98%|█████████▊| 476/484 [1:03:20<01:03,  7.97s/it, training_loss=0.040]\u001b[A\n",
            "Epoch 3:  99%|█████████▊| 477/484 [1:03:20<00:59,  8.44s/it, training_loss=0.040]\u001b[A\n",
            "Epoch 3:  99%|█████████▊| 477/484 [1:03:27<00:59,  8.44s/it, training_loss=0.005]\u001b[A\n",
            "Epoch 3:  99%|█████████▉| 478/484 [1:03:27<00:47,  7.88s/it, training_loss=0.005]\u001b[A\n",
            "Epoch 3:  99%|█████████▉| 478/484 [1:03:36<00:47,  7.88s/it, training_loss=0.009]\u001b[A\n",
            "Epoch 3:  99%|█████████▉| 479/484 [1:03:36<00:41,  8.35s/it, training_loss=0.009]\u001b[A\n",
            "Epoch 3:  99%|█████████▉| 479/484 [1:03:43<00:41,  8.35s/it, training_loss=0.005]\u001b[A\n",
            "Epoch 3:  99%|█████████▉| 480/484 [1:03:43<00:31,  7.89s/it, training_loss=0.005]\u001b[A\n",
            "Epoch 3:  99%|█████████▉| 480/484 [1:03:51<00:31,  7.89s/it, training_loss=0.003]\u001b[A\n",
            "Epoch 3:  99%|█████████▉| 481/484 [1:03:51<00:23,  7.92s/it, training_loss=0.003]\u001b[A\n",
            "Epoch 3:  99%|█████████▉| 481/484 [1:03:59<00:23,  7.92s/it, training_loss=0.175]\u001b[A\n",
            "Epoch 3: 100%|█████████▉| 482/484 [1:03:59<00:15,  7.95s/it, training_loss=0.175]\u001b[A\n",
            "Epoch 3: 100%|█████████▉| 482/484 [1:04:06<00:15,  7.95s/it, training_loss=0.074]\u001b[A\n",
            "Epoch 3: 100%|█████████▉| 483/484 [1:04:06<00:07,  7.58s/it, training_loss=0.074]\u001b[A\n",
            "Epoch 3: 100%|█████████▉| 483/484 [1:04:14<00:07,  7.58s/it, training_loss=0.151]\u001b[A\n",
            "Epoch 3: 100%|██████████| 484/484 [1:04:14<00:00,  7.74s/it, training_loss=0.151]\u001b[A\n",
            " 67%|██████▋   | 2/3 [3:24:06<1:09:48, 4188.36s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            " Epoch {epoch}\n",
            "Training loss: {loss_train_avg}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "  0%|          | 0/121 [00:00<?, ?it/s]\u001b[A\n",
            "  1%|          | 1/121 [00:02<04:02,  2.02s/it]\u001b[A\n",
            "  2%|▏         | 2/121 [00:03<03:57,  1.99s/it]\u001b[A\n",
            "  2%|▏         | 3/121 [00:05<03:54,  1.98s/it]\u001b[A\n",
            "  3%|▎         | 4/121 [00:08<04:39,  2.39s/it]\u001b[A\n",
            "  4%|▍         | 5/121 [00:13<05:47,  3.00s/it]\u001b[A\n",
            "  5%|▍         | 6/121 [00:16<05:48,  3.03s/it]\u001b[A\n",
            "  6%|▌         | 7/121 [00:18<05:06,  2.69s/it]\u001b[A\n",
            "  7%|▋         | 8/121 [00:20<04:38,  2.46s/it]\u001b[A\n",
            "  7%|▋         | 9/121 [00:22<04:18,  2.31s/it]\u001b[A\n",
            "  8%|▊         | 10/121 [00:24<04:04,  2.20s/it]\u001b[A\n",
            "  9%|▉         | 11/121 [00:25<03:53,  2.12s/it]\u001b[A\n",
            " 10%|▉         | 12/121 [00:29<04:21,  2.40s/it]\u001b[A\n",
            " 11%|█         | 13/121 [00:32<04:44,  2.63s/it]\u001b[A\n",
            " 12%|█▏        | 14/121 [00:35<05:05,  2.85s/it]\u001b[A\n",
            " 12%|█▏        | 15/121 [00:37<04:44,  2.68s/it]\u001b[A\n",
            " 13%|█▎        | 16/121 [00:40<04:55,  2.82s/it]\u001b[A\n",
            " 14%|█▍        | 17/121 [00:43<04:47,  2.77s/it]\u001b[A\n",
            " 15%|█▍        | 18/121 [00:45<04:31,  2.64s/it]\u001b[A\n",
            " 16%|█▌        | 19/121 [00:49<04:45,  2.80s/it]\u001b[A\n",
            " 17%|█▋        | 20/121 [00:52<04:50,  2.87s/it]\u001b[A\n",
            " 17%|█▋        | 21/121 [00:54<04:32,  2.73s/it]\u001b[A\n",
            " 18%|█▊        | 22/121 [00:56<04:06,  2.49s/it]\u001b[A\n",
            " 19%|█▉        | 23/121 [00:58<03:48,  2.33s/it]\u001b[A\n",
            " 20%|█▉        | 24/121 [01:00<03:35,  2.22s/it]\u001b[A\n",
            " 21%|██        | 25/121 [01:02<03:25,  2.14s/it]\u001b[A\n",
            " 21%|██▏       | 26/121 [01:04<03:33,  2.25s/it]\u001b[A\n",
            " 22%|██▏       | 27/121 [01:08<03:58,  2.54s/it]\u001b[A\n",
            " 23%|██▎       | 28/121 [01:11<04:09,  2.68s/it]\u001b[A\n",
            " 24%|██▍       | 29/121 [01:13<03:54,  2.55s/it]\u001b[A\n",
            " 25%|██▍       | 30/121 [01:15<03:36,  2.38s/it]\u001b[A\n",
            " 26%|██▌       | 31/121 [01:17<03:21,  2.24s/it]\u001b[A\n",
            " 26%|██▋       | 32/121 [01:19<03:11,  2.15s/it]\u001b[A\n",
            " 27%|██▋       | 33/121 [01:21<03:04,  2.09s/it]\u001b[A\n",
            " 28%|██▊       | 34/121 [01:23<03:17,  2.27s/it]\u001b[A\n",
            " 29%|██▉       | 35/121 [01:27<03:38,  2.54s/it]\u001b[A\n",
            " 30%|██▉       | 36/121 [01:30<03:47,  2.67s/it]\u001b[A\n",
            " 31%|███       | 37/121 [01:32<03:30,  2.50s/it]\u001b[A\n",
            " 31%|███▏      | 38/121 [01:34<03:13,  2.33s/it]\u001b[A\n",
            " 32%|███▏      | 39/121 [01:36<03:02,  2.23s/it]\u001b[A\n",
            " 33%|███▎      | 40/121 [01:38<02:54,  2.15s/it]\u001b[A\n",
            " 34%|███▍      | 41/121 [01:39<02:47,  2.10s/it]\u001b[A\n",
            " 35%|███▍      | 42/121 [01:42<03:05,  2.35s/it]\u001b[A\n",
            " 36%|███▌      | 43/121 [01:46<03:22,  2.60s/it]\u001b[A\n",
            " 36%|███▋      | 44/121 [01:48<03:27,  2.69s/it]\u001b[A\n",
            " 37%|███▋      | 45/121 [01:50<03:08,  2.47s/it]\u001b[A\n",
            " 38%|███▊      | 46/121 [01:52<02:54,  2.32s/it]\u001b[A\n",
            " 39%|███▉      | 47/121 [01:54<02:43,  2.22s/it]\u001b[A\n",
            " 40%|███▉      | 48/121 [01:56<02:36,  2.15s/it]\u001b[A\n",
            " 40%|████      | 49/121 [01:58<02:31,  2.10s/it]\u001b[A\n",
            " 41%|████▏     | 50/121 [02:02<02:52,  2.43s/it]\u001b[A\n",
            " 42%|████▏     | 51/121 [02:05<03:05,  2.64s/it]\u001b[A\n",
            " 43%|████▎     | 52/121 [02:07<03:02,  2.65s/it]\u001b[A\n",
            " 44%|████▍     | 53/121 [02:09<02:46,  2.45s/it]\u001b[A\n",
            " 45%|████▍     | 54/121 [02:11<02:35,  2.32s/it]\u001b[A\n",
            " 45%|████▌     | 55/121 [02:13<02:26,  2.21s/it]\u001b[A\n",
            " 46%|████▋     | 56/121 [02:15<02:19,  2.15s/it]\u001b[A\n",
            " 47%|████▋     | 57/121 [02:18<02:20,  2.19s/it]\u001b[A\n",
            " 48%|████▊     | 58/121 [02:21<02:38,  2.52s/it]\u001b[A\n",
            " 49%|████▉     | 59/121 [02:24<02:45,  2.67s/it]\u001b[A\n",
            " 50%|████▉     | 60/121 [02:26<02:37,  2.58s/it]\u001b[A\n",
            " 50%|█████     | 61/121 [02:28<02:23,  2.40s/it]\u001b[A\n",
            " 51%|█████     | 62/121 [02:30<02:13,  2.27s/it]\u001b[A\n",
            " 52%|█████▏    | 63/121 [02:32<02:06,  2.18s/it]\u001b[A\n",
            " 53%|█████▎    | 64/121 [02:34<02:00,  2.12s/it]\u001b[A\n",
            " 54%|█████▎    | 65/121 [02:37<02:07,  2.28s/it]\u001b[A\n",
            " 55%|█████▍    | 66/121 [02:40<02:21,  2.57s/it]\u001b[A\n",
            " 55%|█████▌    | 67/121 [02:43<02:27,  2.73s/it]\u001b[A\n",
            " 56%|█████▌    | 68/121 [02:46<02:33,  2.89s/it]\u001b[A\n",
            " 57%|█████▋    | 69/121 [02:50<02:34,  2.97s/it]\u001b[A\n",
            " 58%|█████▊    | 70/121 [02:52<02:26,  2.87s/it]\u001b[A\n",
            " 59%|█████▊    | 71/121 [02:54<02:11,  2.63s/it]\u001b[A\n",
            " 60%|█████▉    | 72/121 [02:58<02:18,  2.83s/it]\u001b[A\n",
            " 60%|██████    | 73/121 [03:01<02:19,  2.91s/it]\u001b[A\n",
            " 61%|██████    | 74/121 [03:03<02:12,  2.81s/it]\u001b[A\n",
            " 62%|██████▏   | 75/121 [03:05<01:57,  2.56s/it]\u001b[A\n",
            " 63%|██████▎   | 76/121 [03:07<01:47,  2.39s/it]\u001b[A\n",
            " 64%|██████▎   | 77/121 [03:09<01:39,  2.27s/it]\u001b[A\n",
            " 64%|██████▍   | 78/121 [03:11<01:34,  2.19s/it]\u001b[A\n",
            " 65%|██████▌   | 79/121 [03:14<01:35,  2.27s/it]\u001b[A\n",
            " 66%|██████▌   | 80/121 [03:17<01:44,  2.56s/it]\u001b[A\n",
            " 67%|██████▋   | 81/121 [03:20<01:48,  2.70s/it]\u001b[A\n",
            " 68%|██████▊   | 82/121 [03:22<01:40,  2.59s/it]\u001b[A\n",
            " 69%|██████▊   | 83/121 [03:24<01:31,  2.40s/it]\u001b[A\n",
            " 69%|██████▉   | 84/121 [03:26<01:24,  2.28s/it]\u001b[A\n",
            " 70%|███████   | 85/121 [03:28<01:18,  2.19s/it]\u001b[A\n",
            " 71%|███████   | 86/121 [03:30<01:14,  2.14s/it]\u001b[A\n",
            " 72%|███████▏  | 87/121 [03:33<01:19,  2.33s/it]\u001b[A\n",
            " 73%|███████▎  | 88/121 [03:36<01:25,  2.60s/it]\u001b[A\n",
            " 74%|███████▎  | 89/121 [03:39<01:27,  2.72s/it]\u001b[A\n",
            " 74%|███████▍  | 90/121 [03:41<01:18,  2.52s/it]\u001b[A\n",
            " 75%|███████▌  | 91/121 [03:43<01:10,  2.36s/it]\u001b[A\n",
            " 76%|███████▌  | 92/121 [03:45<01:05,  2.24s/it]\u001b[A\n",
            " 77%|███████▋  | 93/121 [03:47<01:00,  2.17s/it]\u001b[A\n",
            " 78%|███████▊  | 94/121 [03:49<00:57,  2.12s/it]\u001b[A\n",
            " 79%|███████▊  | 95/121 [03:52<01:02,  2.42s/it]\u001b[A\n",
            " 79%|███████▉  | 96/121 [03:56<01:06,  2.65s/it]\u001b[A\n",
            " 80%|████████  | 97/121 [03:58<01:04,  2.69s/it]\u001b[A\n",
            " 81%|████████  | 98/121 [04:00<00:57,  2.48s/it]\u001b[A\n",
            " 82%|████████▏ | 99/121 [04:02<00:51,  2.35s/it]\u001b[A\n",
            " 83%|████████▎ | 100/121 [04:04<00:47,  2.24s/it]\u001b[A\n",
            " 83%|████████▎ | 101/121 [04:06<00:43,  2.17s/it]\u001b[A\n",
            " 84%|████████▍ | 102/121 [04:09<00:41,  2.19s/it]\u001b[A\n",
            " 85%|████████▌ | 103/121 [04:12<00:45,  2.51s/it]\u001b[A\n",
            " 86%|████████▌ | 104/121 [04:15<00:45,  2.68s/it]\u001b[A\n",
            " 87%|████████▋ | 105/121 [04:17<00:42,  2.63s/it]\u001b[A\n",
            " 88%|████████▊ | 106/121 [04:19<00:36,  2.43s/it]\u001b[A\n",
            " 88%|████████▊ | 107/121 [04:21<00:32,  2.29s/it]\u001b[A\n",
            " 89%|████████▉ | 108/121 [04:23<00:28,  2.20s/it]\u001b[A\n",
            " 90%|█████████ | 109/121 [04:25<00:25,  2.13s/it]\u001b[A\n",
            " 91%|█████████ | 110/121 [04:28<00:24,  2.24s/it]\u001b[A\n",
            " 92%|█████████▏| 111/121 [04:31<00:25,  2.55s/it]\u001b[A\n",
            " 93%|█████████▎| 112/121 [04:34<00:24,  2.68s/it]\u001b[A\n",
            " 93%|█████████▎| 113/121 [04:36<00:20,  2.55s/it]\u001b[A\n",
            " 94%|█████████▍| 114/121 [04:38<00:16,  2.38s/it]\u001b[A\n",
            " 95%|█████████▌| 115/121 [04:40<00:13,  2.25s/it]\u001b[A\n",
            " 96%|█████████▌| 116/121 [04:42<00:10,  2.16s/it]\u001b[A\n",
            " 97%|█████████▋| 117/121 [04:44<00:08,  2.10s/it]\u001b[A\n",
            " 98%|█████████▊| 118/121 [04:47<00:06,  2.31s/it]\u001b[A\n",
            " 98%|█████████▊| 119/121 [04:50<00:05,  2.57s/it]\u001b[A\n",
            " 99%|█████████▉| 120/121 [04:53<00:02,  2.70s/it]\u001b[A\n",
            "100%|██████████| 121/121 [04:55<00:00,  2.44s/it]\n",
            "100%|██████████| 3/3 [3:29:02<00:00, 4180.69s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Validation loss: 0.5151993139369859\n",
            "F1 Score (weighted): 0.8548481511857235\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "_, predictions, true_vals = evaluate(dataloader_val)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tPQEu0MvcrLJ",
        "outputId": "225f5bfc-9391-4057-8ce2-45aac7d3bdef"
      },
      "execution_count": 58,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 121/121 [04:52<00:00,  2.41s/it]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "true_vals.shape\n",
        "accuracy_per_class(predictions, true_vals)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-6l2MScTcro0",
        "outputId": "4b18e5fe-50c8-4c3a-b4ac-825792a00763"
      },
      "execution_count": 59,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy:104/120\n",
            " -> 0.8666666666666667\n",
            "Accuracy:503/575\n",
            " -> 0.8747826086956522\n",
            "Accuracy:220/273\n",
            " -> 0.8058608058608059\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "path = F\"/content/gdrive/MyDrive/NLP/BERT_ft_epoch3.model\"\n",
        "model.load_state_dict(torch.load(path))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zcm5wY4-i-Dy",
        "outputId": "4c5cd136-e4a3-4ec6-abb7-1e2f6d2344a7"
      },
      "execution_count": 60,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<All keys matched successfully>"
            ]
          },
          "metadata": {},
          "execution_count": 60
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import TextClassificationPipeline\n",
        "\n",
        "pipe = TextClassificationPipeline(model=model, tokenizer=tokenizer, return_all_scores=True)"
      ],
      "metadata": {
        "id": "kozbV9TAi-GP",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f76dc30c-6d4f-4065-fd45-960e1bab96c0"
      },
      "execution_count": 61,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/pipelines/text_classification.py:104: UserWarning: `return_all_scores` is now deprecated,  if want a similar funcionality use `top_k=None` instead of `return_all_scores=True` or `top_k=1` instead of `return_all_scores=False`.\n",
            "  warnings.warn(\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# preprocess the sentence\n",
        "sentence = \"The Emirates Financial Market Index increased during yesterday’s session by 1.44% to close at 12.2663 points, and the market value increased by 50.5 billion dirhams to reach 67.386 billion dirhams. 0.85 billion shares, with a total value of 1.32 billion dirhams, through 14,654 transactions.\"\n",
        "input_ids = torch.tensor(tokenizer.encode(sentence, add_special_tokens=True)).unsqueeze(0)\n",
        "attention_mask = torch.tensor([1] * input_ids.shape[1]).unsqueeze(0)\n",
        "\n",
        "# get the predicted sentiment label\n",
        "with torch.no_grad():\n",
        "    outputs = model(input_ids=input_ids, attention_mask=attention_mask)\n",
        "    _, predicted_label = torch.max(outputs[0], dim=1)\n"
      ],
      "metadata": {
        "id": "7pyHwdyKi-LH"
      },
      "execution_count": 62,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "predicted_label"
      ],
      "metadata": {
        "id": "8HgSqUXVi-Nt",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "29273a22-ef22-441f-8c6d-dba939438345"
      },
      "execution_count": 63,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([2])"
            ]
          },
          "metadata": {},
          "execution_count": 63
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# End\n"
      ],
      "metadata": {
        "id": "-vfxcPDmttis"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model.summary()\n"
      ],
      "metadata": {
        "id": "qp_4qBVmoC5x",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 287
        },
        "outputId": "53006c3a-ccc6-4b83-deef-658bbc804395"
      },
      "execution_count": 64,
      "outputs": [
        {
          "output_type": "error",
          "ename": "AttributeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-64-5f15418b3570>\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msummary\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__getattr__\u001b[0;34m(self, name)\u001b[0m\n\u001b[1;32m   1612\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mname\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mmodules\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1613\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mmodules\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1614\u001b[0;31m         raise AttributeError(\"'{}' object has no attribute '{}'\".format(\n\u001b[0m\u001b[1;32m   1615\u001b[0m             type(self).__name__, name))\n\u001b[1;32m   1616\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mAttributeError\u001b[0m: 'BertForSequenceClassification' object has no attribute 'summary'"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from simpletransformers.classification import ClassificationModel\n",
        "\n",
        "\n",
        "# Create a TransformerModel\n",
        "model = ClassificationModel('bert', 'bert-base-cased', num_labels=3, args={'reprocess_input_data': True, 'overwrite_output_dir': True},use_cuda=False)"
      ],
      "metadata": {
        "id": "qnq13_yW_TX1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 0,1,2 : positive,negative\n",
        "def making_label(st):\n",
        "    if(st=='positive'):\n",
        "        return 0\n",
        "    elif(st=='neutral'):\n",
        "        return 2\n",
        "    else:\n",
        "        return 1\n",
        "    \n",
        "train['label'] = train['Sentiment'].apply(making_label)\n",
        "test['label'] = test['Sentiment'].apply(making_label)\n",
        "print(train.shape)"
      ],
      "metadata": {
        "id": "nS7bRBKb_WG7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_df = pd.DataFrame({\n",
        "    'text': train['Sentence'][:1500].replace(r'\\n', ' ', regex=True),\n",
        "    'label': train['label'][:1500]\n",
        "})\n",
        "\n",
        "eval_df = pd.DataFrame({\n",
        "    'text': test['Sentence'][-400:].replace(r'\\n', ' ', regex=True),\n",
        "    'label': test['label'][-400:]\n",
        "})"
      ],
      "metadata": {
        "id": "jF-ruRta_4C1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.train_model(train_df)"
      ],
      "metadata": {
        "id": "mdvEoYNO_-cG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "result, model_outputs, wrong_predictions = model.eval_model(eval_df)"
      ],
      "metadata": {
        "id": "f8eKnc76AEOs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "lst = []\n",
        "for arr in model_outputs:\n",
        "    lst.append(np.argmax(arr))"
      ],
      "metadata": {
        "id": "fOmt_agRzMyH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "true = eval_df['label'].tolist()\n",
        "predicted = lst"
      ],
      "metadata": {
        "id": "o5Er_aNnzaZu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import sklearn\n",
        "sklearn.metrics.accuracy_score(true,predicted)"
      ],
      "metadata": {
        "id": "nojvATamza0V"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "predictions, raw_outputs = model.predict(\"Almost all the region's markets reversed in yesterday's session trading from the trend they were in the previous session in light of the dominance of buying operations in the markets throughout the trading period almost with the encouragement of some dealers to take financial positions on selected shares for the purpose of investment or speculation after the prices became more attractive and in Under the return of relative stability to the regional and global climate. Where only the Jordanian market declined under pressure from the services stocks, as it declined by 0.27%, to close its general index at the level of 2350.91 points. The Kuwaiti market bounced back to recover most of the losses of the previous session, supported by almost all sectors, amid a decline in liquidity, as it rose by 0.66%, to close at 6914.40 points. The Saudi stock market maintained its upward trend, with the support of the main sectors and stocks in the market, as it rose by 0.36%, to close at 43.6332 points. Buying forces returned to control the Qatari Stock Exchange to recoup most of the losses of the previous session, rising by 0.59% to close at 81158.87 points. With the rebound of heavy stocks in the Bahraini market from the levels of the previous session, the Bahraini market recovered all the losses, to close its index at 1438.87 points, with a gain of 0.83%. The Omani market continued its rise, supported by a number of its best stocks, as it rose by 0.31%, to close at 6602.95 points.\")"
      ],
      "metadata": {
        "id": "rIbPgdUW0XIu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "np.average(predictions)"
      ],
      "metadata": {
        "id": "YGz_1jQX1Fa6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Uploading the MarianMTModel Translator"
      ],
      "metadata": {
        "id": "XGq5DTV-EMVn"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import MarianTokenizer, MarianMTModel\n",
        "mname = \"marefa-nlp/marefa-mt-en-ar\"\n",
        "tokenizer = MarianTokenizer.from_pretrained(mname)\n",
        "model = MarianMTModel.from_pretrained(mname)"
      ],
      "metadata": {
        "id": "kaVnG-iuyugI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Translating the dataset"
      ],
      "metadata": {
        "id": "9jYWLnnxEo0F"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# English Text\n",
        "input = \"With the new production plant the company would increase its capacity to meet the expected increase in demand and would improve the use of raw materials and therefore increase the production profitability.\"\n",
        "\n",
        "translated_tokens = model.generate(**tokenizer.prepare_seq2seq_batch([input], return_tensors=\"pt\"))\n",
        "translated_text = [tokenizer.decode(t, skip_special_tokens=True) for t in translated_tokens]\n",
        "\n",
        "# translated Arabic Text\n",
        "print(translated_text)\n"
      ],
      "metadata": {
        "id": "aGfkclBC0wxq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Directory containing the text files to merge\n",
        "dir_path = 'gdrive/My Drive/Finance/'\n",
        "\n",
        "# List of all the text files in the directory\n",
        "files = os.listdir(dir_path)\n",
        "print(files)\n",
        "\n",
        "# Open the CSV file for writing\n",
        "with open('merged_file.csv', 'w', newline='') as csvfile:\n",
        "    writer = csv.writer(csvfile)\n",
        "\n",
        "    # Write the header row to the CSV file\n",
        "    writer.writerow(['filename', 'content'])\n",
        "\n",
        "    # Iterate through all the text files in the directory\n",
        "    for file in files:\n",
        "        if file.endswith('.txt'):\n",
        "            # Open the text file for reading\n",
        "            with open(os.path.join(dir_path, file), 'r') as f:\n",
        "                content = f.read()\n",
        "                \n",
        "            # Write the filename and content to the CSV file\n",
        "            writer.writerow([file, content])\n",
        "\n",
        "# Close the CSV file\n",
        "csvfile.close()"
      ],
      "metadata": {
        "id": "OepVekXDBQ14"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df = pd.read_csv(\"merged_file.csv\")\n",
        "print(df.describe)"
      ],
      "metadata": {
        "id": "vG2Mz3dbDeis"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}