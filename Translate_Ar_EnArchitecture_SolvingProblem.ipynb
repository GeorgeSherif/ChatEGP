{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/GeorgeSherif/NLP-ChatEGP/blob/main/Translate_Ar_EnArchitecture_SolvingProblem.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OAw4nlDbEZUQ"
      },
      "source": [
        "# **Installing & Importing the Necessary Libraries and Mounting the drive**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SDVJd_TDyswW"
      },
      "outputs": [],
      "source": [
        "!pip3 install transformers sentencepiece nltk protobuf torch pygal simpletransformers torchvision sacremoses\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "9UP_-BDdA37e",
        "outputId": "623e37ea-5a81-4520-8184-aa878870d5a5",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/gdrive; to attempt to forcibly remount, call drive.mount(\"/content/gdrive\", force_remount=True).\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "from IPython.display import display # Allows the use of display() for DataFrames\n",
        "drive.mount('/content/gdrive')\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "8eiG5KriE7bY"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from nltk.corpus import stopwords\n",
        "import os\n",
        "import warnings\n",
        "import csv\n",
        "from textblob import TextBlob\n",
        "import re\n",
        "from nltk.stem.isri import ISRIStemmer\n",
        "import nltk\n",
        "nltk.download('stopwords')\n",
        "nltk.download('punkt')\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt \n",
        "import plotly.express as px\n",
        "import plotly.graph_objects as go\n",
        "import pygal as py\n",
        "import matplotlib\n",
        "plt.rcParams[\"figure.figsize\"] = (8,5)\n",
        "matplotlib.rc('xtick', labelsize=7) \n",
        "matplotlib.rc('ytick', labelsize=7) \n",
        "from textblob import TextBlob\n",
        "\n",
        "import torch\n",
        "import torchvision\n",
        "\n",
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "\n",
        "warnings.filterwarnings(\"ignore\", category=FutureWarning)\n",
        "%matplotlib inline "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "Ah5YDfy94Jqg"
      },
      "outputs": [],
      "source": [
        "if torch.cuda.is_available():\n",
        "    device = torch.device('cuda')\n",
        "else:\n",
        "    device = torch.device('cpu')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "haDPqEitD7k7"
      },
      "source": [
        "# **Approach 1: Evaluate the English Model (BERT)**\n",
        "\n",
        "\n",
        "*   English Train Data\n",
        "*   Arabic Test Data\n",
        "*   Train with the English Dataset\n",
        "*   Translate the Arabic Dataset\n",
        "*   Evaluate Model\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PcdWNYwxG7b8"
      },
      "source": [
        "### Load the English Dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 184,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GHd4hXPPG6Rn",
        "outputId": "26e1adba-acfe-44a4-8c4b-d49333d5eeeb"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2879\n"
          ]
        }
      ],
      "source": [
        "df = pd.read_csv('/content/gdrive/MyDrive/NLP/English Dataset.csv' ,engine=\"python\", encoding = \"ISO-8859-1\")\n",
        "#df = pd.read_csv('/content/gdrive/MyDrive/NLP/preprocessed.csv' ,engine=\"python\", encoding = \"ISO-8859-1\")\n",
        "print((df['Sentiment'] == 'neutral').sum())\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "num_entries_to_remove_positive = (df['Sentiment'] == 'positive').sum() - (df['Sentiment'] == 'negative').sum()\n",
        "num_entries_to_remove_neutral = (df['Sentiment'] == 'neutral').sum() - (df['Sentiment'] == 'negative').sum()\n",
        "print(num_entries_to_remove_neutral)\n",
        "\n",
        "\n",
        "indices_to_remove = df[df['Sentiment'] == 'positive'].sample(num_entries_to_remove_positive).index\n",
        "dfPositive = df[df['Sentiment'] == 'positive'].drop(indices_to_remove)\n",
        "\n",
        "indices_to_remove = df[df['Sentiment'] == 'neutral'].sample(num_entries_to_remove_neutral).index\n",
        "dfNeutral = df[df['Sentiment'] == 'neutral'].drop(indices_to_remove)\n",
        "\n",
        "indices_to_remove = df[df['Sentiment'] == 'negative'].sample(0).index\n",
        "dfNegative = df[df['Sentiment'] == 'negative'].drop(indices_to_remove)\n",
        "\n",
        "print(dfNegative)"
      ],
      "metadata": {
        "id": "mvni0Nfgo1e8",
        "outputId": "04ba584b-225d-47be-ebd0-6b15a92347c5",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 185,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2275\n",
            "     Sentiment                                           Sentence\n",
            "2     negative  The international electronic industry company ...\n",
            "415   negative  A tinyurl link takes users to a scamming site ...\n",
            "421   negative  Compared with the FTSE 100 index , which rose ...\n",
            "423   negative  Compared with the FTSE 100 index , which rose ...\n",
            "500   negative  One of the challenges in the oil production in...\n",
            "...        ...                                                ...\n",
            "4840  negative  HELSINKI Thomson Financial - Shares in Cargote...\n",
            "4841  negative  LONDON MarketWatch -- Share prices ended lower...\n",
            "4843  negative  Operating profit fell to EUR 35.4 mn from EUR ...\n",
            "4844  negative  Net sales of the Paper segment decreased to EU...\n",
            "4845  negative  Sales in Finland decreased by 10.5 % in Januar...\n",
            "\n",
            "[604 rows x 2 columns]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "dfNew = pd.concat((dfNegative, dfNeutral, dfPositive), axis = 0)\n",
        "dfNew\n",
        "df = dfNew"
      ],
      "metadata": {
        "id": "ceiz6xnyqKde"
      },
      "execution_count": 186,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df['Sentiment'] = df['Sentiment'].replace(['negative','neutral','positive'],[0,1,2])\n",
        "df"
      ],
      "metadata": {
        "id": "mEEYIAVdptnR",
        "outputId": "b3c1502d-aee3-4bba-b834-7faf6da159aa",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 423
        }
      },
      "execution_count": 187,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "      Sentiment                                           Sentence\n",
              "2             0  The international electronic industry company ...\n",
              "415           0  A tinyurl link takes users to a scamming site ...\n",
              "421           0  Compared with the FTSE 100 index , which rose ...\n",
              "423           0  Compared with the FTSE 100 index , which rose ...\n",
              "500           0  One of the challenges in the oil production in...\n",
              "...         ...                                                ...\n",
              "4534          2  To ensure low operational cost for radio netwo...\n",
              "4536          2  Key shareholders of Finnish IT services provid...\n",
              "4773          2  According to the company , its operating profi...\n",
              "4786          2  Danske Bank A-S DANSKE DC jumped 3.7 percent t...\n",
              "4822          2  The 2015 target for net sales has been set at ...\n",
              "\n",
              "[1812 rows x 2 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-e7916abd-1529-4fed-a12f-6b8eff5d376e\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Sentiment</th>\n",
              "      <th>Sentence</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0</td>\n",
              "      <td>The international electronic industry company ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>415</th>\n",
              "      <td>0</td>\n",
              "      <td>A tinyurl link takes users to a scamming site ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>421</th>\n",
              "      <td>0</td>\n",
              "      <td>Compared with the FTSE 100 index , which rose ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>423</th>\n",
              "      <td>0</td>\n",
              "      <td>Compared with the FTSE 100 index , which rose ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>500</th>\n",
              "      <td>0</td>\n",
              "      <td>One of the challenges in the oil production in...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4534</th>\n",
              "      <td>2</td>\n",
              "      <td>To ensure low operational cost for radio netwo...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4536</th>\n",
              "      <td>2</td>\n",
              "      <td>Key shareholders of Finnish IT services provid...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4773</th>\n",
              "      <td>2</td>\n",
              "      <td>According to the company , its operating profi...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4786</th>\n",
              "      <td>2</td>\n",
              "      <td>Danske Bank A-S DANSKE DC jumped 3.7 percent t...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4822</th>\n",
              "      <td>2</td>\n",
              "      <td>The 2015 target for net sales has been set at ...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>1812 rows × 2 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-e7916abd-1529-4fed-a12f-6b8eff5d376e')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-e7916abd-1529-4fed-a12f-6b8eff5d376e button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-e7916abd-1529-4fed-a12f-6b8eff5d376e');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 187
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 188,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 478
        },
        "id": "r5E8aFGXG6Zl",
        "outputId": "b6e4df9e-374b-496c-cacf-f854a48ba9d9"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<Axes: xlabel='count', ylabel='Sentiment'>"
            ]
          },
          "metadata": {},
          "execution_count": 188
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 800x500 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ],
      "source": [
        "sns.countplot(y=\"Sentiment\",data=df)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 189,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 423
        },
        "id": "yIn3Q46wlVV6",
        "outputId": "51c7cf05-a4d4-4e8d-fae7-2f982fb4676c"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "      Sentiment                                           Sentence\n",
              "2             0  The international electronic industry company ...\n",
              "415           0  A tinyurl link takes users to a scamming site ...\n",
              "421           0  Compared with the FTSE 100 index , which rose ...\n",
              "423           0  Compared with the FTSE 100 index , which rose ...\n",
              "500           0  One of the challenges in the oil production in...\n",
              "...         ...                                                ...\n",
              "4534          2  To ensure low operational cost for radio netwo...\n",
              "4536          2  Key shareholders of Finnish IT services provid...\n",
              "4773          2  According to the company , its operating profi...\n",
              "4786          2  Danske Bank A-S DANSKE DC jumped 3.7 percent t...\n",
              "4822          2  The 2015 target for net sales has been set at ...\n",
              "\n",
              "[1812 rows x 2 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-3467758e-b750-4b03-ba7d-796513dd44ae\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Sentiment</th>\n",
              "      <th>Sentence</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0</td>\n",
              "      <td>The international electronic industry company ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>415</th>\n",
              "      <td>0</td>\n",
              "      <td>A tinyurl link takes users to a scamming site ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>421</th>\n",
              "      <td>0</td>\n",
              "      <td>Compared with the FTSE 100 index , which rose ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>423</th>\n",
              "      <td>0</td>\n",
              "      <td>Compared with the FTSE 100 index , which rose ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>500</th>\n",
              "      <td>0</td>\n",
              "      <td>One of the challenges in the oil production in...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4534</th>\n",
              "      <td>2</td>\n",
              "      <td>To ensure low operational cost for radio netwo...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4536</th>\n",
              "      <td>2</td>\n",
              "      <td>Key shareholders of Finnish IT services provid...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4773</th>\n",
              "      <td>2</td>\n",
              "      <td>According to the company , its operating profi...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4786</th>\n",
              "      <td>2</td>\n",
              "      <td>Danske Bank A-S DANSKE DC jumped 3.7 percent t...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4822</th>\n",
              "      <td>2</td>\n",
              "      <td>The 2015 target for net sales has been set at ...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>1812 rows × 2 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-3467758e-b750-4b03-ba7d-796513dd44ae')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-3467758e-b750-4b03-ba7d-796513dd44ae button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-3467758e-b750-4b03-ba7d-796513dd44ae');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 189
        }
      ],
      "source": [
        "df.drop_duplicates(subset=['Sentence'],keep='first',inplace=True)\n",
        "df"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WUgy1Tc6XqT3"
      },
      "source": [
        "### Determinig the sentiment using TextBlob Polarity"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 190,
      "metadata": {
        "id": "-3ssMm1PG6bz"
      },
      "outputs": [],
      "source": [
        "def preprocess(ReviewText):\n",
        "    ReviewText = ReviewText.str.replace(\"(<br/>)\", \"\")\n",
        "    ReviewText = ReviewText.str.replace('(<a).*(>).*(</a>)', '')\n",
        "    ReviewText = ReviewText.str.replace('(&amp)', '')\n",
        "    ReviewText = ReviewText.str.replace('(&gt)', '')\n",
        "    ReviewText = ReviewText.str.replace('(&lt)', '')\n",
        "    ReviewText = ReviewText.str.replace('(\\xa0)', '')\n",
        "    ReviewText = ReviewText.str.replace(',', '')\n",
        "    ReviewText = ReviewText.str.replace('--', '')    \n",
        "    ReviewText = ReviewText.str.replace('`', '')    \n",
        "\n",
        "    return ReviewText\n",
        "df['Review Text'] = preprocess(df['Sentence'])\n",
        "\n",
        "df['polarity'] = df['Sentence'].map(lambda text: TextBlob(text).sentiment.polarity)\n",
        "df['sentence_len'] = df['Review Text'].astype(str).apply(len)\n",
        "df['word_count'] = df['Sentence'].apply(lambda x: len(str(x).split()))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 191,
      "metadata": {
        "id": "l6UVSjnUrJZ7"
      },
      "outputs": [],
      "source": [
        "df = df.drop([\"sentence_len\", \"Sentence\",\"word_count\",\"polarity\" ] , axis =1)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "u_LkJij6lsOf"
      },
      "source": [
        "### Sentiment Analysis using BERT"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 192,
      "metadata": {
        "id": "7fS-iD5jlygM"
      },
      "outputs": [],
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "X_features = df[\"Review Text\"]\n",
        "Y_features = df[\"Sentiment\"]\n",
        "X_train, X_val, y_train, y_val = train_test_split(df.index.values, df.Sentiment.values, test_size=0.2, random_state=42, shuffle=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 193,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NFqRzcKbntvM",
        "outputId": "fe81b6dd-d5c8-4bf7-c459-1a606bb37990"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertForSequenceClassification: ['cls.predictions.decoder.weight', 'cls.predictions.transform.dense.bias', 'cls.seq_relationship.weight', 'cls.predictions.transform.LayerNorm.weight', 'cls.seq_relationship.bias', 'cls.predictions.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.LayerNorm.bias']\n",
            "- This IS expected if you are initializing BertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing BertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        }
      ],
      "source": [
        "from transformers import BertTokenizer,BertForSequenceClassification\n",
        "\n",
        "tokenizer = BertTokenizer.from_pretrained(\"bert-base-uncased\")\n",
        "model = BertForSequenceClassification.from_pretrained('bert-base-uncased',\n",
        "                                                      num_labels = 3,\n",
        "                                                      id2label={0: 'negative', 1: 'neutral', 2: 'positive'},\n",
        "                                                      output_attentions = False,\n",
        "                                                      output_hidden_states = False).to(device)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 194,
      "metadata": {
        "id": "XvfkG7kv0MX1",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1c0be51d-3505-4fb5-c9df-70bfdcf0a0ee"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array(['The international electronic industry company Elcoteq has laid off tens of employees from its Tallinn facility ; contrary to earlier layoffs the company contracted the ranks of its office workers  the daily Postimees reported .',\n",
              "       'A tinyurl link takes users to a scamming site promising that users can earn thousands of dollars by becoming a Google ( NASDAQ : GOOG ) Cash advertiser .',\n",
              "       'Compared with the FTSE 100 index  which rose 36.7 points ( or 0.6 % ) on the day  this was a relative price change of -0.2 % .',\n",
              "       ...,\n",
              "       'According to the company  its operating profit  excluding non-recurring items  in the fourth quarter of 2009 was significantly better than expected  and also better than the figures for the fourth quarter of 2008 .',\n",
              "       'Danske Bank A-S DANSKE DC jumped 3.7 percent to 133.4 kroner  rebounding from yesterday s 3.5 percent slide .',\n",
              "       'The 2015 target for net sales has been set at EUR 1bn and the target for return on investment at over 20 % .'],\n",
              "      dtype=object)"
            ]
          },
          "metadata": {},
          "execution_count": 194
        }
      ],
      "source": [
        "df['data_type'] = ['not_set'] * df.shape[0]\n",
        "\n",
        "df.loc[X_train, 'data_type'] = 'train'\n",
        "df.loc[X_val, 'data_type'] = 'val'\n",
        "\n",
        "#groupby count\n",
        "df.groupby([ 'Sentiment', 'data_type']).count()\n",
        "df = df.rename(columns={'Review Text': 'Sentence'})\n",
        "df[df.data_type == 'train'].Sentence.values\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 205,
      "metadata": {
        "id": "_t00AHGuvgAo"
      },
      "outputs": [],
      "source": [
        "#encode train set\n",
        "encoded_data_train = tokenizer.batch_encode_plus(df[df.data_type == 'train'].Sentence.values,\n",
        "                                                add_special_tokens = True,\n",
        "                                                return_attention_mask = True,\n",
        "                                                pad_to_max_length = True,\n",
        "                                                max_length = 100,\n",
        "                                                return_tensors = 'pt')\n",
        "                                                \n",
        "#encode validation set\n",
        "encoded_data_val = tokenizer.batch_encode_plus( df[df.data_type == 'val'].Sentence.values,\n",
        "                                                add_special_tokens = True,\n",
        "                                                return_attention_mask = True,\n",
        "                                                pad_to_max_length = True,\n",
        "                                                max_length = 100,\n",
        "                                                return_tensors = 'pt')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 206,
      "metadata": {
        "id": "-J5twuCRxA7O"
      },
      "outputs": [],
      "source": [
        "#train set\n",
        "input_ids_train = encoded_data_train['input_ids']\n",
        "attention_masks_train = encoded_data_train['attention_mask']\n",
        "labels_train = torch.tensor(df[df.data_type == 'train'].Sentiment.values)\n",
        "\n",
        "#validation set\n",
        "input_ids_val = encoded_data_val['input_ids']\n",
        "attention_masks_val = encoded_data_val['attention_mask']\n",
        "labels_val = torch.tensor(df[df.data_type == 'val'].Sentiment.values)\n",
        "     "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 207,
      "metadata": {
        "id": "joRW8_E34QX3"
      },
      "outputs": [],
      "source": [
        "from torch.utils.data import TensorDataset\n",
        "\n",
        "#train set\n",
        "dataset_train = TensorDataset(input_ids_train, \n",
        "                              attention_masks_train,\n",
        "                              labels_train)\n",
        "\n",
        "#validation set\n",
        "dataset_val = TensorDataset(input_ids_val, \n",
        "                             attention_masks_val, \n",
        "                             labels_val)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 208,
      "metadata": {
        "id": "kue1cFIC4QaZ"
      },
      "outputs": [],
      "source": [
        "from torch.utils.data import DataLoader, RandomSampler, SequentialSampler\n",
        "\n",
        "batch_size = 8\n",
        "\n",
        "#train set\n",
        "dataloader_train = DataLoader(dataset_train,\n",
        "                              sampler = RandomSampler(dataset_train),\n",
        "                              batch_size = batch_size)\n",
        "\n",
        "#validation set\n",
        "dataloader_val = DataLoader(dataset_val,\n",
        "                              sampler = RandomSampler(dataset_val),\n",
        "                              batch_size = batch_size) #since we don't have to do backpropagation for this step"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 209,
      "metadata": {
        "id": "nfrQRiNf4Qc1"
      },
      "outputs": [],
      "source": [
        "from transformers import AdamW, get_linear_schedule_with_warmup\n",
        "\n",
        "optimizer = AdamW(model.parameters(),\n",
        "                 lr = 1e-5,\n",
        "                 eps = 1e-7) #2e-5 > 5e-5\n",
        "                 \n",
        "epochs = 8\n",
        "\n",
        "scheduler = get_linear_schedule_with_warmup(optimizer,\n",
        "                                           num_warmup_steps = 0,\n",
        "                                           num_training_steps =len(dataloader_train)*epochs)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 210,
      "metadata": {
        "id": "_hTFuvA04Xg_"
      },
      "outputs": [],
      "source": [
        "def evaluate(dataloader_val):\n",
        "\n",
        "    #evaluation mode \n",
        "    model.eval()\n",
        "    \n",
        "    #tracking variables\n",
        "    loss_val_total = 0\n",
        "    predictions, true_vals = [], []\n",
        "    \n",
        "    for batch in tqdm(dataloader_val):\n",
        "        \n",
        "        #load into GPU\n",
        "        batch = tuple(b.to(device) for b in batch)\n",
        "        \n",
        "        #define inputs\n",
        "        inputs = {'input_ids':      batch[0],\n",
        "                  'attention_mask': batch[1],\n",
        "                  'labels':         batch[2]}\n",
        "\n",
        "        #compute logits\n",
        "        with torch.no_grad():        \n",
        "            outputs = model(**inputs)\n",
        "        \n",
        "        #compute loss\n",
        "        loss = outputs[0]\n",
        "        logits = outputs[1]\n",
        "        loss_val_total += loss.item()\n",
        "\n",
        "        #compute accuracy\n",
        "        logits = logits.detach().cpu().numpy()\n",
        "        label_ids = inputs['labels'].cpu().numpy()\n",
        "        predictions.append(logits)\n",
        "        true_vals.append(label_ids)\n",
        "    \n",
        "    #compute average loss\n",
        "    loss_val_avg = loss_val_total/len(dataloader_val) \n",
        "    \n",
        "    predictions = np.concatenate(predictions, axis=0)\n",
        "    true_vals = np.concatenate(true_vals, axis=0)\n",
        "            \n",
        "    return loss_val_avg, predictions, true_vals"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 201,
      "metadata": {
        "id": "sIzdaLGr4ara"
      },
      "outputs": [],
      "source": [
        "from sklearn.metrics import f1_score\n",
        "\n",
        "def f1_score_func(preds, labels):\n",
        "    preds_flat = np.argmax(preds, axis = 1).flatten()\n",
        "    labels_flat = labels.flatten()\n",
        "    return f1_score(labels_flat, preds_flat, average = 'weighted')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 202,
      "metadata": {
        "id": "Z9CCDzC14dMH"
      },
      "outputs": [],
      "source": [
        "#accuracy score\n",
        "def accuracy_per_class(preds, labels):\n",
        "    #label_dict_inverse = {v: k for k, v in label_dict.items()}\n",
        "    \n",
        "    #make prediction\n",
        "    preds_flat = np.argmax(preds, axis=1).flatten()\n",
        "    labels_flat = labels.flatten()\n",
        "    \n",
        "    for label in np.unique(labels_flat):\n",
        "        y_preds = preds_flat[labels_flat==label]\n",
        "        y_true = labels_flat[labels_flat==label]\n",
        "        #print(f'Class: {label_dict_inverse[label]}')\n",
        "        print(f'Accuracy:{len(y_preds[y_preds==label])}/{len(y_true)}\\n -> {len(y_preds[y_preds==label]) / len(y_true)}')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 203,
      "metadata": {
        "id": "OehAW6vX4e7B"
      },
      "outputs": [],
      "source": [
        "import random\n",
        "\n",
        "seed_val = 17\n",
        "random.seed(seed_val)\n",
        "np.random.seed(seed_val)\n",
        "torch.manual_seed(seed_val)\n",
        "torch.cuda.manual_seed_all(seed_val)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 211,
      "metadata": {
        "id": "d5EMKCDo4hmk",
        "outputId": "5c998eae-e170-41e0-c3fe-95d5cf3ba260",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "  0%|          | 0/3 [00:00<?, ?it/s]\n",
            "Epoch 1:   0%|          | 0/182 [00:00<?, ?it/s]\u001b[A\n",
            "Epoch 1:   0%|          | 0/182 [00:19<?, ?it/s, training_loss=0.342]\u001b[A\n",
            "Epoch 1:   1%|          | 1/182 [00:19<58:57, 19.54s/it, training_loss=0.342]\u001b[A\n",
            "Epoch 1:   1%|          | 1/182 [00:32<58:57, 19.54s/it, training_loss=0.410]\u001b[A\n",
            "Epoch 1:   1%|          | 2/182 [00:32<46:50, 15.61s/it, training_loss=0.410]\u001b[A\n",
            "Epoch 1:   1%|          | 2/182 [00:42<46:50, 15.61s/it, training_loss=0.363]\u001b[A\n",
            "Epoch 1:   2%|▏         | 3/182 [00:42<39:19, 13.18s/it, training_loss=0.363]\u001b[A\n",
            "Epoch 1:   2%|▏         | 3/182 [00:55<39:19, 13.18s/it, training_loss=0.384]\u001b[A\n",
            "Epoch 1:   2%|▏         | 4/182 [00:55<39:07, 13.19s/it, training_loss=0.384]\u001b[A\n",
            "Epoch 1:   2%|▏         | 4/182 [01:08<39:07, 13.19s/it, training_loss=0.417]\u001b[A\n",
            "Epoch 1:   3%|▎         | 5/182 [01:08<38:29, 13.05s/it, training_loss=0.417]\u001b[A\n",
            "Epoch 1:   3%|▎         | 5/182 [01:19<38:29, 13.05s/it, training_loss=0.372]\u001b[A\n",
            "Epoch 1:   3%|▎         | 6/182 [01:19<35:38, 12.15s/it, training_loss=0.372]\u001b[A\n",
            "Epoch 1:   3%|▎         | 6/182 [01:32<35:38, 12.15s/it, training_loss=0.388]\u001b[A\n",
            "Epoch 1:   4%|▍         | 7/182 [01:32<36:27, 12.50s/it, training_loss=0.388]\u001b[A\n",
            "Epoch 1:   4%|▍         | 7/182 [01:47<36:27, 12.50s/it, training_loss=0.364]\u001b[A\n",
            "Epoch 1:   4%|▍         | 8/182 [01:47<38:26, 13.26s/it, training_loss=0.364]\u001b[A\n",
            "Epoch 1:   4%|▍         | 8/182 [01:57<38:26, 13.26s/it, training_loss=0.415]\u001b[A\n",
            "Epoch 1:   5%|▍         | 9/182 [01:57<35:34, 12.34s/it, training_loss=0.415]\u001b[A\n",
            "Epoch 1:   5%|▍         | 9/182 [02:10<35:34, 12.34s/it, training_loss=0.379]\u001b[A\n",
            "Epoch 1:   5%|▌         | 10/182 [02:10<35:44, 12.47s/it, training_loss=0.379]\u001b[A\n",
            "Epoch 1:   5%|▌         | 10/182 [02:24<35:44, 12.47s/it, training_loss=0.354]\u001b[A\n",
            "Epoch 1:   6%|▌         | 11/182 [02:24<36:50, 12.93s/it, training_loss=0.354]\u001b[A\n",
            "Epoch 1:   6%|▌         | 11/182 [02:34<36:50, 12.93s/it, training_loss=0.341]\u001b[A\n",
            "Epoch 1:   7%|▋         | 12/182 [02:34<34:18, 12.11s/it, training_loss=0.341]\u001b[A\n",
            "Epoch 1:   7%|▋         | 12/182 [02:47<34:18, 12.11s/it, training_loss=0.396]\u001b[A\n",
            "Epoch 1:   7%|▋         | 13/182 [02:47<34:34, 12.28s/it, training_loss=0.396]\u001b[A\n",
            "Epoch 1:   7%|▋         | 13/182 [03:01<34:34, 12.28s/it, training_loss=0.358]\u001b[A\n",
            "Epoch 1:   8%|▊         | 14/182 [03:01<36:06, 12.90s/it, training_loss=0.358]\u001b[A\n",
            "Epoch 1:   8%|▊         | 14/182 [03:11<36:06, 12.90s/it, training_loss=0.360]\u001b[A\n",
            "Epoch 1:   8%|▊         | 15/182 [03:11<33:44, 12.12s/it, training_loss=0.360]\u001b[A\n",
            "Epoch 1:   8%|▊         | 15/182 [03:24<33:44, 12.12s/it, training_loss=0.328]\u001b[A\n",
            "Epoch 1:   9%|▉         | 16/182 [03:24<33:52, 12.24s/it, training_loss=0.328]\u001b[A\n",
            "Epoch 1:   9%|▉         | 16/182 [03:38<33:52, 12.24s/it, training_loss=0.392]\u001b[A\n",
            "Epoch 1:   9%|▉         | 17/182 [03:38<35:16, 12.83s/it, training_loss=0.392]\u001b[A\n",
            "Epoch 1:   9%|▉         | 17/182 [03:48<35:16, 12.83s/it, training_loss=0.337]\u001b[A\n",
            "Epoch 1:  10%|▉         | 18/182 [03:48<33:05, 12.11s/it, training_loss=0.337]\u001b[A\n",
            "Epoch 1:  10%|▉         | 18/182 [04:01<33:05, 12.11s/it, training_loss=0.372]\u001b[A\n",
            "Epoch 1:  10%|█         | 19/182 [04:01<33:13, 12.23s/it, training_loss=0.372]\u001b[A\n",
            "Epoch 1:  10%|█         | 19/182 [04:14<33:13, 12.23s/it, training_loss=0.338]\u001b[A\n",
            "Epoch 1:  11%|█         | 20/182 [04:14<33:50, 12.53s/it, training_loss=0.338]\u001b[A\n",
            "Epoch 1:  11%|█         | 20/182 [04:24<33:50, 12.53s/it, training_loss=0.352]\u001b[A\n",
            "Epoch 1:  12%|█▏        | 21/182 [04:24<31:46, 11.84s/it, training_loss=0.352]\u001b[A\n",
            "Epoch 1:  12%|█▏        | 21/182 [04:37<31:46, 11.84s/it, training_loss=0.355]\u001b[A\n",
            "Epoch 1:  12%|█▏        | 22/182 [04:37<32:26, 12.17s/it, training_loss=0.355]\u001b[A\n",
            "Epoch 1:  12%|█▏        | 22/182 [04:51<32:26, 12.17s/it, training_loss=0.371]\u001b[A\n",
            "Epoch 1:  13%|█▎        | 23/182 [04:51<33:03, 12.47s/it, training_loss=0.371]\u001b[A\n",
            "Epoch 1:  13%|█▎        | 23/182 [05:01<33:03, 12.47s/it, training_loss=0.384]\u001b[A\n",
            "Epoch 1:  13%|█▎        | 24/182 [05:01<30:56, 11.75s/it, training_loss=0.384]\u001b[A\n",
            "Epoch 1:  13%|█▎        | 24/182 [05:14<30:56, 11.75s/it, training_loss=0.376]\u001b[A\n",
            "Epoch 1:  14%|█▎        | 25/182 [05:14<31:50, 12.17s/it, training_loss=0.376]\u001b[A\n",
            "Epoch 1:  14%|█▎        | 25/182 [05:27<31:50, 12.17s/it, training_loss=0.367]\u001b[A\n",
            "Epoch 1:  14%|█▍        | 26/182 [05:27<32:15, 12.41s/it, training_loss=0.367]\u001b[A\n",
            "Epoch 1:  14%|█▍        | 26/182 [05:37<32:15, 12.41s/it, training_loss=0.365]\u001b[A\n",
            "Epoch 1:  15%|█▍        | 27/182 [05:37<30:20, 11.75s/it, training_loss=0.365]\u001b[A\n",
            "Epoch 1:  15%|█▍        | 27/182 [05:50<30:20, 11.75s/it, training_loss=0.360]\u001b[A\n",
            "Epoch 1:  15%|█▌        | 28/182 [05:50<31:17, 12.19s/it, training_loss=0.360]\u001b[A\n",
            "Epoch 1:  15%|█▌        | 28/182 [06:03<31:17, 12.19s/it, training_loss=0.331]\u001b[A\n",
            "Epoch 1:  16%|█▌        | 29/182 [06:03<31:26, 12.33s/it, training_loss=0.331]\u001b[A\n",
            "Epoch 1:  16%|█▌        | 29/182 [06:13<31:26, 12.33s/it, training_loss=0.356]\u001b[A\n",
            "Epoch 1:  16%|█▋        | 30/182 [06:13<29:52, 11.79s/it, training_loss=0.356]\u001b[A\n",
            "Epoch 1:  16%|█▋        | 30/182 [06:29<29:52, 11.79s/it, training_loss=0.368]\u001b[A\n",
            "Epoch 1:  17%|█▋        | 31/182 [06:29<32:25, 12.89s/it, training_loss=0.368]\u001b[A\n",
            "Epoch 1:  17%|█▋        | 31/182 [06:41<32:25, 12.89s/it, training_loss=0.362]\u001b[A\n",
            "Epoch 1:  18%|█▊        | 32/182 [06:41<31:54, 12.76s/it, training_loss=0.362]\u001b[A\n",
            "Epoch 1:  18%|█▊        | 32/182 [06:52<31:54, 12.76s/it, training_loss=0.374]\u001b[A\n",
            "Epoch 1:  18%|█▊        | 33/182 [06:52<30:17, 12.20s/it, training_loss=0.374]\u001b[A\n",
            "Epoch 1:  18%|█▊        | 33/182 [07:05<30:17, 12.20s/it, training_loss=0.357]\u001b[A\n",
            "Epoch 1:  19%|█▊        | 34/182 [07:05<30:52, 12.52s/it, training_loss=0.357]\u001b[A\n",
            "Epoch 1:  19%|█▊        | 34/182 [07:17<30:52, 12.52s/it, training_loss=0.340]\u001b[A\n",
            "Epoch 1:  19%|█▉        | 35/182 [07:17<30:11, 12.32s/it, training_loss=0.340]\u001b[A\n",
            "Epoch 1:  19%|█▉        | 35/182 [07:28<30:11, 12.32s/it, training_loss=0.337]\u001b[A\n",
            "Epoch 1:  20%|█▉        | 36/182 [07:29<29:11, 12.00s/it, training_loss=0.337]\u001b[A\n",
            "Epoch 1:  20%|█▉        | 36/182 [07:42<29:11, 12.00s/it, training_loss=0.337]\u001b[A\n",
            "Epoch 1:  20%|██        | 37/182 [07:42<29:56, 12.39s/it, training_loss=0.337]\u001b[A\n",
            "Epoch 1:  20%|██        | 37/182 [07:53<29:56, 12.39s/it, training_loss=0.351]\u001b[A\n",
            "Epoch 1:  21%|██        | 38/182 [07:53<29:11, 12.16s/it, training_loss=0.351]\u001b[A\n",
            "Epoch 1:  21%|██        | 38/182 [08:05<29:11, 12.16s/it, training_loss=0.332]\u001b[A\n",
            "Epoch 1:  21%|██▏       | 39/182 [08:05<28:30, 11.96s/it, training_loss=0.332]\u001b[A\n",
            "Epoch 1:  21%|██▏       | 39/182 [08:18<28:30, 11.96s/it, training_loss=0.331]\u001b[A\n",
            "Epoch 1:  22%|██▏       | 40/182 [08:18<29:13, 12.35s/it, training_loss=0.331]\u001b[A\n",
            "Epoch 1:  22%|██▏       | 40/182 [08:29<29:13, 12.35s/it, training_loss=0.344]\u001b[A\n",
            "Epoch 1:  23%|██▎       | 41/182 [08:29<28:15, 12.02s/it, training_loss=0.344]\u001b[A\n",
            "Epoch 1:  23%|██▎       | 41/182 [08:41<28:15, 12.02s/it, training_loss=0.331]\u001b[A\n",
            "Epoch 1:  23%|██▎       | 42/182 [08:41<27:50, 11.93s/it, training_loss=0.331]\u001b[A\n",
            "Epoch 1:  23%|██▎       | 42/182 [08:54<27:50, 11.93s/it, training_loss=0.343]\u001b[A\n",
            "Epoch 1:  24%|██▎       | 43/182 [08:54<28:36, 12.35s/it, training_loss=0.343]\u001b[A\n",
            "Epoch 1:  24%|██▎       | 43/182 [09:07<28:36, 12.35s/it, training_loss=0.336]\u001b[A\n",
            "Epoch 1:  24%|██▍       | 44/182 [09:07<28:11, 12.26s/it, training_loss=0.336]\u001b[A\n",
            "Epoch 1:  24%|██▍       | 44/182 [09:18<28:11, 12.26s/it, training_loss=0.346]\u001b[A\n",
            "Epoch 1:  25%|██▍       | 45/182 [09:18<27:33, 12.07s/it, training_loss=0.346]\u001b[A\n",
            "Epoch 1:  25%|██▍       | 45/182 [09:32<27:33, 12.07s/it, training_loss=0.343]\u001b[A\n",
            "Epoch 1:  25%|██▌       | 46/182 [09:32<28:15, 12.47s/it, training_loss=0.343]\u001b[A\n",
            "Epoch 1:  25%|██▌       | 46/182 [09:43<28:15, 12.47s/it, training_loss=0.358]\u001b[A\n",
            "Epoch 1:  26%|██▌       | 47/182 [09:43<27:12, 12.09s/it, training_loss=0.358]\u001b[A\n",
            "Epoch 1:  26%|██▌       | 47/182 [09:55<27:12, 12.09s/it, training_loss=0.342]\u001b[A\n",
            "Epoch 1:  26%|██▋       | 48/182 [09:55<26:51, 12.03s/it, training_loss=0.342]\u001b[A\n",
            "Epoch 1:  26%|██▋       | 48/182 [10:08<26:51, 12.03s/it, training_loss=0.401]\u001b[A\n",
            "Epoch 1:  27%|██▋       | 49/182 [10:08<27:30, 12.41s/it, training_loss=0.401]\u001b[A\n",
            "Epoch 1:  27%|██▋       | 49/182 [10:19<27:30, 12.41s/it, training_loss=0.407]\u001b[A\n",
            "Epoch 1:  27%|██▋       | 50/182 [10:19<26:25, 12.01s/it, training_loss=0.407]\u001b[A\n",
            "Epoch 1:  27%|██▋       | 50/182 [10:31<26:25, 12.01s/it, training_loss=0.351]\u001b[A\n",
            "Epoch 1:  28%|██▊       | 51/182 [10:31<26:13, 12.01s/it, training_loss=0.351]\u001b[A\n",
            "Epoch 1:  28%|██▊       | 51/182 [10:44<26:13, 12.01s/it, training_loss=0.334]\u001b[A\n",
            "Epoch 1:  29%|██▊       | 52/182 [10:44<26:49, 12.38s/it, training_loss=0.334]\u001b[A\n",
            "Epoch 1:  29%|██▊       | 52/182 [10:55<26:49, 12.38s/it, training_loss=0.355]\u001b[A\n",
            "Epoch 1:  29%|██▉       | 53/182 [10:55<25:27, 11.84s/it, training_loss=0.355]\u001b[A\n",
            "Epoch 1:  29%|██▉       | 53/182 [11:07<25:27, 11.84s/it, training_loss=0.343]\u001b[A\n",
            "Epoch 1:  30%|██▉       | 54/182 [11:07<25:33, 11.98s/it, training_loss=0.343]\u001b[A\n",
            "Epoch 1:  30%|██▉       | 54/182 [11:20<25:33, 11.98s/it, training_loss=0.361]\u001b[A\n",
            "Epoch 1:  30%|███       | 55/182 [11:20<26:10, 12.37s/it, training_loss=0.361]\u001b[A\n",
            "Epoch 1:  30%|███       | 55/182 [11:31<26:10, 12.37s/it, training_loss=0.376]\u001b[A\n",
            "Epoch 1:  31%|███       | 56/182 [11:31<24:39, 11.74s/it, training_loss=0.376]\u001b[A\n",
            "Epoch 1:  31%|███       | 56/182 [11:43<24:39, 11.74s/it, training_loss=0.304]\u001b[A\n",
            "Epoch 1:  31%|███▏      | 57/182 [11:43<25:05, 12.05s/it, training_loss=0.304]\u001b[A\n",
            "Epoch 1:  31%|███▏      | 57/182 [11:57<25:05, 12.05s/it, training_loss=0.374]\u001b[A\n",
            "Epoch 1:  32%|███▏      | 58/182 [11:57<25:37, 12.40s/it, training_loss=0.374]\u001b[A\n",
            "Epoch 1:  32%|███▏      | 58/182 [12:07<25:37, 12.40s/it, training_loss=0.345]\u001b[A\n",
            "Epoch 1:  32%|███▏      | 59/182 [12:07<24:02, 11.73s/it, training_loss=0.345]\u001b[A\n",
            "Epoch 1:  32%|███▏      | 59/182 [12:20<24:02, 11.73s/it, training_loss=0.351]\u001b[A\n",
            "Epoch 1:  33%|███▎      | 60/182 [12:20<24:33, 12.08s/it, training_loss=0.351]\u001b[A\n",
            "Epoch 1:  33%|███▎      | 60/182 [12:33<24:33, 12.08s/it, training_loss=0.325]\u001b[A\n",
            "Epoch 1:  34%|███▎      | 61/182 [12:33<24:58, 12.39s/it, training_loss=0.325]\u001b[A\n",
            "Epoch 1:  34%|███▎      | 61/182 [12:43<24:58, 12.39s/it, training_loss=0.324]\u001b[A\n",
            "Epoch 1:  34%|███▍      | 62/182 [12:43<23:25, 11.71s/it, training_loss=0.324]\u001b[A\n",
            "Epoch 1:  34%|███▍      | 62/182 [12:56<23:25, 11.71s/it, training_loss=0.331]\u001b[A\n",
            "Epoch 1:  35%|███▍      | 63/182 [12:56<24:06, 12.15s/it, training_loss=0.331]\u001b[A\n",
            "Epoch 1:  35%|███▍      | 63/182 [13:09<24:06, 12.15s/it, training_loss=0.363]\u001b[A\n",
            "Epoch 1:  35%|███▌      | 64/182 [13:09<24:16, 12.35s/it, training_loss=0.363]\u001b[A\n",
            "Epoch 1:  35%|███▌      | 64/182 [13:19<24:16, 12.35s/it, training_loss=0.343]\u001b[A\n",
            "Epoch 1:  36%|███▌      | 65/182 [13:19<22:56, 11.77s/it, training_loss=0.343]\u001b[A\n",
            "Epoch 1:  36%|███▌      | 65/182 [13:33<22:56, 11.77s/it, training_loss=0.336]\u001b[A\n",
            "Epoch 1:  36%|███▋      | 66/182 [13:33<23:36, 12.21s/it, training_loss=0.336]\u001b[A\n",
            "Epoch 1:  36%|███▋      | 66/182 [13:45<23:36, 12.21s/it, training_loss=0.375]\u001b[A\n",
            "Epoch 1:  37%|███▋      | 67/182 [13:45<23:38, 12.33s/it, training_loss=0.375]\u001b[A\n",
            "Epoch 1:  37%|███▋      | 67/182 [13:56<23:38, 12.33s/it, training_loss=0.342]\u001b[A\n",
            "Epoch 1:  37%|███▋      | 68/182 [13:56<22:31, 11.85s/it, training_loss=0.342]\u001b[A\n",
            "Epoch 1:  37%|███▋      | 68/182 [14:09<22:31, 11.85s/it, training_loss=0.345]\u001b[A\n",
            "Epoch 1:  38%|███▊      | 69/182 [14:09<23:12, 12.32s/it, training_loss=0.345]\u001b[A\n",
            "Epoch 1:  38%|███▊      | 69/182 [14:22<23:12, 12.32s/it, training_loss=0.329]\u001b[A\n",
            "Epoch 1:  38%|███▊      | 70/182 [14:22<23:03, 12.35s/it, training_loss=0.329]\u001b[A\n",
            "Epoch 1:  38%|███▊      | 70/182 [14:33<23:03, 12.35s/it, training_loss=0.346]\u001b[A\n",
            "Epoch 1:  39%|███▉      | 71/182 [14:33<21:59, 11.89s/it, training_loss=0.346]\u001b[A\n",
            "Epoch 1:  39%|███▉      | 71/182 [14:46<21:59, 11.89s/it, training_loss=0.304]\u001b[A\n",
            "Epoch 1:  40%|███▉      | 72/182 [14:46<22:34, 12.31s/it, training_loss=0.304]\u001b[A\n",
            "Epoch 1:  40%|███▉      | 72/182 [14:58<22:34, 12.31s/it, training_loss=0.341]\u001b[A\n",
            "Epoch 1:  40%|████      | 73/182 [14:58<22:21, 12.30s/it, training_loss=0.341]\u001b[A\n",
            "Epoch 1:  40%|████      | 73/182 [15:09<22:21, 12.30s/it, training_loss=0.280]\u001b[A\n",
            "Epoch 1:  41%|████      | 74/182 [15:09<21:28, 11.93s/it, training_loss=0.280]\u001b[A\n",
            "Epoch 1:  41%|████      | 74/182 [15:23<21:28, 11.93s/it, training_loss=0.305]\u001b[A\n",
            "Epoch 1:  41%|████      | 75/182 [15:23<21:59, 12.33s/it, training_loss=0.305]\u001b[A\n",
            "Epoch 1:  41%|████      | 75/182 [15:35<21:59, 12.33s/it, training_loss=0.306]\u001b[A\n",
            "Epoch 1:  42%|████▏     | 76/182 [15:35<21:44, 12.31s/it, training_loss=0.306]\u001b[A\n",
            "Epoch 1:  42%|████▏     | 76/182 [15:46<21:44, 12.31s/it, training_loss=0.303]\u001b[A\n",
            "Epoch 1:  42%|████▏     | 77/182 [15:46<20:55, 11.96s/it, training_loss=0.303]\u001b[A\n",
            "Epoch 1:  42%|████▏     | 77/182 [15:59<20:55, 11.96s/it, training_loss=0.357]\u001b[A\n",
            "Epoch 1:  43%|████▎     | 78/182 [15:59<21:23, 12.34s/it, training_loss=0.357]\u001b[A\n",
            "Epoch 1:  43%|████▎     | 78/182 [16:11<21:23, 12.34s/it, training_loss=0.304]\u001b[A\n",
            "Epoch 1:  43%|████▎     | 79/182 [16:11<20:56, 12.20s/it, training_loss=0.304]\u001b[A\n",
            "Epoch 1:  43%|████▎     | 79/182 [16:22<20:56, 12.20s/it, training_loss=0.353]\u001b[A\n",
            "Epoch 1:  44%|████▍     | 80/182 [16:22<20:15, 11.91s/it, training_loss=0.353]\u001b[A\n",
            "Epoch 1:  44%|████▍     | 80/182 [16:35<20:15, 11.91s/it, training_loss=0.335]\u001b[A\n",
            "Epoch 1:  45%|████▍     | 81/182 [16:35<20:42, 12.30s/it, training_loss=0.335]\u001b[A\n",
            "Epoch 1:  45%|████▍     | 81/182 [16:47<20:42, 12.30s/it, training_loss=0.304]\u001b[A\n",
            "Epoch 1:  45%|████▌     | 82/182 [16:47<20:06, 12.07s/it, training_loss=0.304]\u001b[A\n",
            "Epoch 1:  45%|████▌     | 82/182 [16:59<20:06, 12.07s/it, training_loss=0.371]\u001b[A\n",
            "Epoch 1:  46%|████▌     | 83/182 [16:59<19:39, 11.91s/it, training_loss=0.371]\u001b[A\n",
            "Epoch 1:  46%|████▌     | 83/182 [17:12<19:39, 11.91s/it, training_loss=0.336]\u001b[A\n",
            "Epoch 1:  46%|████▌     | 84/182 [17:12<20:08, 12.33s/it, training_loss=0.336]\u001b[A\n",
            "Epoch 1:  46%|████▌     | 84/182 [17:23<20:08, 12.33s/it, training_loss=0.354]\u001b[A\n",
            "Epoch 1:  47%|████▋     | 85/182 [17:23<19:20, 11.97s/it, training_loss=0.354]\u001b[A\n",
            "Epoch 1:  47%|████▋     | 85/182 [17:35<19:20, 11.97s/it, training_loss=0.302]\u001b[A\n",
            "Epoch 1:  47%|████▋     | 86/182 [17:35<19:06, 11.95s/it, training_loss=0.302]\u001b[A\n",
            "Epoch 1:  47%|████▋     | 86/182 [17:48<19:06, 11.95s/it, training_loss=0.320]\u001b[A\n",
            "Epoch 1:  48%|████▊     | 87/182 [17:48<19:33, 12.35s/it, training_loss=0.320]\u001b[A\n",
            "Epoch 1:  48%|████▊     | 87/182 [17:59<19:33, 12.35s/it, training_loss=0.280]\u001b[A\n",
            "Epoch 1:  48%|████▊     | 88/182 [17:59<18:38, 11.90s/it, training_loss=0.280]\u001b[A\n",
            "Epoch 1:  48%|████▊     | 88/182 [18:11<18:38, 11.90s/it, training_loss=0.327]\u001b[A\n",
            "Epoch 1:  49%|████▉     | 89/182 [18:11<18:32, 11.97s/it, training_loss=0.327]\u001b[A\n",
            "Epoch 1:  49%|████▉     | 89/182 [18:25<18:32, 11.97s/it, training_loss=0.304]\u001b[A\n",
            "Epoch 1:  49%|████▉     | 90/182 [18:25<19:08, 12.48s/it, training_loss=0.304]\u001b[A\n",
            "Epoch 1:  49%|████▉     | 90/182 [18:35<19:08, 12.48s/it, training_loss=0.319]\u001b[A\n",
            "Epoch 1:  50%|█████     | 91/182 [18:35<18:04, 11.92s/it, training_loss=0.319]\u001b[A\n",
            "Epoch 1:  50%|█████     | 91/182 [18:48<18:04, 11.92s/it, training_loss=0.337]\u001b[A\n",
            "Epoch 1:  51%|█████     | 92/182 [18:48<18:04, 12.05s/it, training_loss=0.337]\u001b[A\n",
            "Epoch 1:  51%|█████     | 92/182 [19:01<18:04, 12.05s/it, training_loss=0.325]\u001b[A\n",
            "Epoch 1:  51%|█████     | 93/182 [19:01<18:24, 12.41s/it, training_loss=0.325]\u001b[A\n",
            "Epoch 1:  51%|█████     | 93/182 [19:11<18:24, 12.41s/it, training_loss=0.315]\u001b[A\n",
            "Epoch 1:  52%|█████▏    | 94/182 [19:11<17:16, 11.77s/it, training_loss=0.315]\u001b[A\n",
            "Epoch 1:  52%|█████▏    | 94/182 [19:24<17:16, 11.77s/it, training_loss=0.275]\u001b[A\n",
            "Epoch 1:  52%|█████▏    | 95/182 [19:24<17:27, 12.04s/it, training_loss=0.275]\u001b[A\n",
            "Epoch 1:  52%|█████▏    | 95/182 [19:37<17:27, 12.04s/it, training_loss=0.301]\u001b[A\n",
            "Epoch 1:  53%|█████▎    | 96/182 [19:37<17:46, 12.40s/it, training_loss=0.301]\u001b[A\n",
            "Epoch 1:  53%|█████▎    | 96/182 [19:47<17:46, 12.40s/it, training_loss=0.349]\u001b[A\n",
            "Epoch 1:  53%|█████▎    | 97/182 [19:47<16:38, 11.75s/it, training_loss=0.349]\u001b[A\n",
            "Epoch 1:  53%|█████▎    | 97/182 [20:00<16:38, 11.75s/it, training_loss=0.316]\u001b[A\n",
            "Epoch 1:  54%|█████▍    | 98/182 [20:00<16:56, 12.10s/it, training_loss=0.316]\u001b[A\n",
            "Epoch 1:  54%|█████▍    | 98/182 [20:14<16:56, 12.10s/it, training_loss=0.306]\u001b[A\n",
            "Epoch 1:  54%|█████▍    | 99/182 [20:14<17:11, 12.43s/it, training_loss=0.306]\u001b[A\n",
            "Epoch 1:  54%|█████▍    | 99/182 [20:24<17:11, 12.43s/it, training_loss=0.300]\u001b[A\n",
            "Epoch 1:  55%|█████▍    | 100/182 [20:24<16:00, 11.71s/it, training_loss=0.300]\u001b[A\n",
            "Epoch 1:  55%|█████▍    | 100/182 [20:37<16:00, 11.71s/it, training_loss=0.292]\u001b[A\n",
            "Epoch 1:  55%|█████▌    | 101/182 [20:37<16:26, 12.18s/it, training_loss=0.292]\u001b[A\n",
            "Epoch 1:  55%|█████▌    | 101/182 [20:50<16:26, 12.18s/it, training_loss=0.335]\u001b[A\n",
            "Epoch 1:  56%|█████▌    | 102/182 [20:50<16:30, 12.38s/it, training_loss=0.335]\u001b[A\n",
            "Epoch 1:  56%|█████▌    | 102/182 [21:00<16:30, 12.38s/it, training_loss=0.351]\u001b[A\n",
            "Epoch 1:  57%|█████▋    | 103/182 [21:00<15:29, 11.77s/it, training_loss=0.351]\u001b[A\n",
            "Epoch 1:  57%|█████▋    | 103/182 [21:13<15:29, 11.77s/it, training_loss=0.304]\u001b[A\n",
            "Epoch 1:  57%|█████▋    | 104/182 [21:13<15:51, 12.20s/it, training_loss=0.304]\u001b[A\n",
            "Epoch 1:  57%|█████▋    | 104/182 [21:26<15:51, 12.20s/it, training_loss=0.289]\u001b[A\n",
            "Epoch 1:  58%|█████▊    | 105/182 [21:26<15:48, 12.31s/it, training_loss=0.289]\u001b[A\n",
            "Epoch 1:  58%|█████▊    | 105/182 [21:37<15:48, 12.31s/it, training_loss=0.295]\u001b[A\n",
            "Epoch 1:  58%|█████▊    | 106/182 [21:37<14:57, 11.81s/it, training_loss=0.295]\u001b[A\n",
            "Epoch 1:  58%|█████▊    | 106/182 [21:50<14:57, 11.81s/it, training_loss=0.264]\u001b[A\n",
            "Epoch 1:  59%|█████▉    | 107/182 [21:50<15:18, 12.25s/it, training_loss=0.264]\u001b[A\n",
            "Epoch 1:  59%|█████▉    | 107/182 [22:02<15:18, 12.25s/it, training_loss=0.334]\u001b[A\n",
            "Epoch 1:  59%|█████▉    | 108/182 [22:02<15:08, 12.28s/it, training_loss=0.334]\u001b[A\n",
            "Epoch 1:  59%|█████▉    | 108/182 [22:13<15:08, 12.28s/it, training_loss=0.277]\u001b[A\n",
            "Epoch 1:  60%|█████▉    | 109/182 [22:13<14:24, 11.84s/it, training_loss=0.277]\u001b[A\n",
            "Epoch 1:  60%|█████▉    | 109/182 [22:26<14:24, 11.84s/it, training_loss=0.274]\u001b[A\n",
            "Epoch 1:  60%|██████    | 110/182 [22:26<14:40, 12.23s/it, training_loss=0.274]\u001b[A\n",
            "Epoch 1:  60%|██████    | 110/182 [22:38<14:40, 12.23s/it, training_loss=0.272]\u001b[A\n",
            "Epoch 1:  61%|██████    | 111/182 [22:38<14:24, 12.18s/it, training_loss=0.272]\u001b[A\n",
            "Epoch 1:  61%|██████    | 111/182 [22:49<14:24, 12.18s/it, training_loss=0.302]\u001b[A\n",
            "Epoch 1:  62%|██████▏   | 112/182 [22:49<13:48, 11.84s/it, training_loss=0.302]\u001b[A\n",
            "Epoch 1:  62%|██████▏   | 112/182 [23:02<13:48, 11.84s/it, training_loss=0.251]\u001b[A\n",
            "Epoch 1:  62%|██████▏   | 113/182 [23:02<14:05, 12.25s/it, training_loss=0.251]\u001b[A\n",
            "Epoch 1:  62%|██████▏   | 113/182 [23:14<14:05, 12.25s/it, training_loss=0.332]\u001b[A\n",
            "Epoch 1:  63%|██████▎   | 114/182 [23:14<13:42, 12.10s/it, training_loss=0.332]\u001b[A\n",
            "Epoch 1:  63%|██████▎   | 114/182 [23:26<13:42, 12.10s/it, training_loss=0.326]\u001b[A\n",
            "Epoch 1:  63%|██████▎   | 115/182 [23:26<13:17, 11.90s/it, training_loss=0.326]\u001b[A\n",
            "Epoch 1:  63%|██████▎   | 115/182 [23:39<13:17, 11.90s/it, training_loss=0.272]\u001b[A\n",
            "Epoch 1:  64%|██████▎   | 116/182 [23:39<13:34, 12.34s/it, training_loss=0.272]\u001b[A\n",
            "Epoch 1:  64%|██████▎   | 116/182 [23:50<13:34, 12.34s/it, training_loss=0.228]\u001b[A\n",
            "Epoch 1:  64%|██████▍   | 117/182 [23:50<13:04, 12.08s/it, training_loss=0.228]\u001b[A\n",
            "Epoch 1:  64%|██████▍   | 117/182 [24:02<13:04, 12.08s/it, training_loss=0.268]\u001b[A\n",
            "Epoch 1:  65%|██████▍   | 118/182 [24:02<12:44, 11.94s/it, training_loss=0.268]\u001b[A\n",
            "Epoch 1:  65%|██████▍   | 118/182 [24:15<12:44, 11.94s/it, training_loss=0.314]\u001b[A\n",
            "Epoch 1:  65%|██████▌   | 119/182 [24:15<12:57, 12.34s/it, training_loss=0.314]\u001b[A\n",
            "Epoch 1:  65%|██████▌   | 119/182 [24:26<12:57, 12.34s/it, training_loss=0.301]\u001b[A\n",
            "Epoch 1:  66%|██████▌   | 120/182 [24:26<12:22, 11.97s/it, training_loss=0.301]\u001b[A\n",
            "Epoch 1:  66%|██████▌   | 120/182 [24:38<12:22, 11.97s/it, training_loss=0.320]\u001b[A\n",
            "Epoch 1:  66%|██████▋   | 121/182 [24:38<12:08, 11.94s/it, training_loss=0.320]\u001b[A\n",
            "Epoch 1:  66%|██████▋   | 121/182 [24:52<12:08, 11.94s/it, training_loss=0.229]\u001b[A\n",
            "Epoch 1:  67%|██████▋   | 122/182 [24:52<12:20, 12.34s/it, training_loss=0.229]\u001b[A\n",
            "Epoch 1:  67%|██████▋   | 122/182 [25:02<12:20, 12.34s/it, training_loss=0.283]\u001b[A\n",
            "Epoch 1:  68%|██████▊   | 123/182 [25:02<11:40, 11.87s/it, training_loss=0.283]\u001b[A\n",
            "Epoch 1:  68%|██████▊   | 123/182 [25:15<11:40, 11.87s/it, training_loss=0.291]\u001b[A\n",
            "Epoch 1:  68%|██████▊   | 124/182 [25:15<11:35, 11.99s/it, training_loss=0.291]\u001b[A\n",
            "Epoch 1:  68%|██████▊   | 124/182 [25:31<11:35, 11.99s/it, training_loss=0.280]\u001b[A\n",
            "Epoch 1:  69%|██████▊   | 125/182 [25:31<12:44, 13.40s/it, training_loss=0.280]\u001b[A\n",
            "Epoch 1:  69%|██████▊   | 125/182 [25:54<12:44, 13.40s/it, training_loss=0.239]\u001b[A\n",
            "Epoch 1:  69%|██████▉   | 126/182 [25:54<14:59, 16.06s/it, training_loss=0.239]\u001b[A\n",
            "Epoch 1:  69%|██████▉   | 126/182 [26:07<14:59, 16.06s/it, training_loss=0.361]\u001b[A\n",
            "Epoch 1:  70%|██████▉   | 127/182 [26:07<13:58, 15.25s/it, training_loss=0.361]\u001b[A\n",
            "Epoch 1:  70%|██████▉   | 127/182 [26:17<13:58, 15.25s/it, training_loss=0.297]\u001b[A\n",
            "Epoch 1:  70%|███████   | 128/182 [26:17<12:22, 13.75s/it, training_loss=0.297]\u001b[A\n",
            "Epoch 1:  70%|███████   | 128/182 [26:30<12:22, 13.75s/it, training_loss=0.225]\u001b[A\n",
            "Epoch 1:  71%|███████   | 129/182 [26:30<11:51, 13.42s/it, training_loss=0.225]\u001b[A\n",
            "Epoch 1:  71%|███████   | 129/182 [26:43<11:51, 13.42s/it, training_loss=0.306]\u001b[A\n",
            "Epoch 1:  71%|███████▏  | 130/182 [26:43<11:34, 13.35s/it, training_loss=0.306]\u001b[A\n",
            "Epoch 1:  71%|███████▏  | 130/182 [26:53<11:34, 13.35s/it, training_loss=0.382]\u001b[A\n",
            "Epoch 1:  72%|███████▏  | 131/182 [26:53<10:31, 12.39s/it, training_loss=0.382]\u001b[A\n",
            "Epoch 1:  72%|███████▏  | 131/182 [27:06<10:31, 12.39s/it, training_loss=0.369]\u001b[A\n",
            "Epoch 1:  73%|███████▎  | 132/182 [27:06<10:29, 12.58s/it, training_loss=0.369]\u001b[A\n",
            "Epoch 1:  73%|███████▎  | 132/182 [27:19<10:29, 12.58s/it, training_loss=0.355]\u001b[A\n",
            "Epoch 1:  73%|███████▎  | 133/182 [27:19<10:23, 12.72s/it, training_loss=0.355]\u001b[A\n",
            "Epoch 1:  73%|███████▎  | 133/182 [27:29<10:23, 12.72s/it, training_loss=0.255]\u001b[A\n",
            "Epoch 1:  74%|███████▎  | 134/182 [27:29<09:33, 11.96s/it, training_loss=0.255]\u001b[A\n",
            "Epoch 1:  74%|███████▎  | 134/182 [27:43<09:33, 11.96s/it, training_loss=0.219]\u001b[A\n",
            "Epoch 1:  74%|███████▍  | 135/182 [27:43<09:39, 12.33s/it, training_loss=0.219]\u001b[A\n",
            "Epoch 1:  74%|███████▍  | 135/182 [27:55<09:39, 12.33s/it, training_loss=0.329]\u001b[A\n",
            "Epoch 1:  75%|███████▍  | 136/182 [27:55<09:34, 12.48s/it, training_loss=0.329]\u001b[A\n",
            "Epoch 1:  75%|███████▍  | 136/182 [28:06<09:34, 12.48s/it, training_loss=0.236]\u001b[A\n",
            "Epoch 1:  75%|███████▌  | 137/182 [28:06<08:53, 11.86s/it, training_loss=0.236]\u001b[A\n",
            "Epoch 1:  75%|███████▌  | 137/182 [28:19<08:53, 11.86s/it, training_loss=0.201]\u001b[A\n",
            "Epoch 1:  76%|███████▌  | 138/182 [28:19<08:58, 12.25s/it, training_loss=0.201]\u001b[A\n",
            "Epoch 1:  76%|███████▌  | 138/182 [28:32<08:58, 12.25s/it, training_loss=0.326]\u001b[A\n",
            "Epoch 1:  76%|███████▋  | 139/182 [28:32<08:50, 12.33s/it, training_loss=0.326]\u001b[A\n",
            "Epoch 1:  76%|███████▋  | 139/182 [28:42<08:50, 12.33s/it, training_loss=0.253]\u001b[A\n",
            "Epoch 1:  77%|███████▋  | 140/182 [28:42<08:16, 11.81s/it, training_loss=0.253]\u001b[A\n",
            "Epoch 1:  77%|███████▋  | 140/182 [28:55<08:16, 11.81s/it, training_loss=0.305]\u001b[A\n",
            "Epoch 1:  77%|███████▋  | 141/182 [28:55<08:20, 12.22s/it, training_loss=0.305]\u001b[A\n",
            "Epoch 1:  77%|███████▋  | 141/182 [29:08<08:20, 12.22s/it, training_loss=0.330]\u001b[A\n",
            "Epoch 1:  78%|███████▊  | 142/182 [29:08<08:08, 12.22s/it, training_loss=0.330]\u001b[A\n",
            "Epoch 1:  78%|███████▊  | 142/182 [29:18<08:08, 12.22s/it, training_loss=0.447]\u001b[A\n",
            "Epoch 1:  79%|███████▊  | 143/182 [29:18<07:40, 11.82s/it, training_loss=0.447]\u001b[A\n",
            "Epoch 1:  79%|███████▊  | 143/182 [29:32<07:40, 11.82s/it, training_loss=0.228]\u001b[A\n",
            "Epoch 1:  79%|███████▉  | 144/182 [29:32<07:45, 12.25s/it, training_loss=0.228]\u001b[A\n",
            "Epoch 1:  79%|███████▉  | 144/182 [29:44<07:45, 12.25s/it, training_loss=0.310]\u001b[A\n",
            "Epoch 1:  80%|███████▉  | 145/182 [29:44<07:31, 12.21s/it, training_loss=0.310]\u001b[A\n",
            "Epoch 1:  80%|███████▉  | 145/182 [29:55<07:31, 12.21s/it, training_loss=0.296]\u001b[A\n",
            "Epoch 1:  80%|████████  | 146/182 [29:55<07:08, 11.90s/it, training_loss=0.296]\u001b[A\n",
            "Epoch 1:  80%|████████  | 146/182 [30:08<07:08, 11.90s/it, training_loss=0.287]\u001b[A\n",
            "Epoch 1:  81%|████████  | 147/182 [30:08<07:10, 12.31s/it, training_loss=0.287]\u001b[A\n",
            "Epoch 1:  81%|████████  | 147/182 [30:20<07:10, 12.31s/it, training_loss=0.286]\u001b[A\n",
            "Epoch 1:  81%|████████▏ | 148/182 [30:20<06:53, 12.15s/it, training_loss=0.286]\u001b[A\n",
            "Epoch 1:  81%|████████▏ | 148/182 [30:31<06:53, 12.15s/it, training_loss=0.212]\u001b[A\n",
            "Epoch 1:  82%|████████▏ | 149/182 [30:31<06:32, 11.89s/it, training_loss=0.212]\u001b[A\n",
            "Epoch 1:  82%|████████▏ | 149/182 [30:44<06:32, 11.89s/it, training_loss=0.256]\u001b[A\n",
            "Epoch 1:  82%|████████▏ | 150/182 [30:44<06:33, 12.29s/it, training_loss=0.256]\u001b[A\n",
            "Epoch 1:  82%|████████▏ | 150/182 [30:56<06:33, 12.29s/it, training_loss=0.296]\u001b[A\n",
            "Epoch 1:  83%|████████▎ | 151/182 [30:56<06:10, 11.96s/it, training_loss=0.296]\u001b[A\n",
            "Epoch 1:  83%|████████▎ | 151/182 [31:07<06:10, 11.96s/it, training_loss=0.241]\u001b[A\n",
            "Epoch 1:  84%|████████▎ | 152/182 [31:07<05:56, 11.87s/it, training_loss=0.241]\u001b[A\n",
            "Epoch 1:  84%|████████▎ | 152/182 [31:21<05:56, 11.87s/it, training_loss=0.257]\u001b[A\n",
            "Epoch 1:  84%|████████▍ | 153/182 [31:21<05:56, 12.28s/it, training_loss=0.257]\u001b[A\n",
            "Epoch 1:  84%|████████▍ | 153/182 [31:31<05:56, 12.28s/it, training_loss=0.358]\u001b[A\n",
            "Epoch 1:  85%|████████▍ | 154/182 [31:31<05:32, 11.87s/it, training_loss=0.358]\u001b[A\n",
            "Epoch 1:  85%|████████▍ | 154/182 [31:44<05:32, 11.87s/it, training_loss=0.220]\u001b[A\n",
            "Epoch 1:  85%|████████▌ | 155/182 [31:44<05:22, 11.94s/it, training_loss=0.220]\u001b[A\n",
            "Epoch 1:  85%|████████▌ | 155/182 [31:57<05:22, 11.94s/it, training_loss=0.252]\u001b[A\n",
            "Epoch 1:  86%|████████▌ | 156/182 [31:57<05:21, 12.35s/it, training_loss=0.252]\u001b[A\n",
            "Epoch 1:  86%|████████▌ | 156/182 [32:08<05:21, 12.35s/it, training_loss=0.248]\u001b[A\n",
            "Epoch 1:  86%|████████▋ | 157/182 [32:08<04:56, 11.85s/it, training_loss=0.248]\u001b[A\n",
            "Epoch 1:  86%|████████▋ | 157/182 [32:20<04:56, 11.85s/it, training_loss=0.243]\u001b[A\n",
            "Epoch 1:  87%|████████▋ | 158/182 [32:20<04:47, 11.98s/it, training_loss=0.243]\u001b[A\n",
            "Epoch 1:  87%|████████▋ | 158/182 [32:33<04:47, 11.98s/it, training_loss=0.229]\u001b[A\n",
            "Epoch 1:  87%|████████▋ | 159/182 [32:33<04:44, 12.38s/it, training_loss=0.229]\u001b[A\n",
            "Epoch 1:  87%|████████▋ | 159/182 [32:43<04:44, 12.38s/it, training_loss=0.235]\u001b[A\n",
            "Epoch 1:  88%|████████▊ | 160/182 [32:43<04:17, 11.72s/it, training_loss=0.235]\u001b[A\n",
            "Epoch 1:  88%|████████▊ | 160/182 [32:56<04:17, 11.72s/it, training_loss=0.282]\u001b[A\n",
            "Epoch 1:  88%|████████▊ | 161/182 [32:56<04:12, 12.01s/it, training_loss=0.282]\u001b[A\n",
            "Epoch 1:  88%|████████▊ | 161/182 [33:09<04:12, 12.01s/it, training_loss=0.254]\u001b[A\n",
            "Epoch 1:  89%|████████▉ | 162/182 [33:09<04:06, 12.31s/it, training_loss=0.254]\u001b[A\n",
            "Epoch 1:  89%|████████▉ | 162/182 [33:19<04:06, 12.31s/it, training_loss=0.226]\u001b[A\n",
            "Epoch 1:  90%|████████▉ | 163/182 [33:19<03:41, 11.65s/it, training_loss=0.226]\u001b[A\n",
            "Epoch 1:  90%|████████▉ | 163/182 [33:32<03:41, 11.65s/it, training_loss=0.238]\u001b[A\n",
            "Epoch 1:  90%|█████████ | 164/182 [33:32<03:38, 12.11s/it, training_loss=0.238]\u001b[A\n",
            "Epoch 1:  90%|█████████ | 164/182 [33:45<03:38, 12.11s/it, training_loss=0.240]\u001b[A\n",
            "Epoch 1:  91%|█████████ | 165/182 [33:45<03:29, 12.35s/it, training_loss=0.240]\u001b[A\n",
            "Epoch 1:  91%|█████████ | 165/182 [33:56<03:29, 12.35s/it, training_loss=0.198]\u001b[A\n",
            "Epoch 1:  91%|█████████ | 166/182 [33:56<03:07, 11.74s/it, training_loss=0.198]\u001b[A\n",
            "Epoch 1:  91%|█████████ | 166/182 [34:09<03:07, 11.74s/it, training_loss=0.291]\u001b[A\n",
            "Epoch 1:  92%|█████████▏| 167/182 [34:09<03:02, 12.19s/it, training_loss=0.291]\u001b[A\n",
            "Epoch 1:  92%|█████████▏| 167/182 [34:21<03:02, 12.19s/it, training_loss=0.257]\u001b[A\n",
            "Epoch 1:  92%|█████████▏| 168/182 [34:21<02:52, 12.30s/it, training_loss=0.257]\u001b[A\n",
            "Epoch 1:  92%|█████████▏| 168/182 [34:32<02:52, 12.30s/it, training_loss=0.243]\u001b[A\n",
            "Epoch 1:  93%|█████████▎| 169/182 [34:32<02:33, 11.78s/it, training_loss=0.243]\u001b[A\n",
            "Epoch 1:  93%|█████████▎| 169/182 [34:45<02:33, 11.78s/it, training_loss=0.240]\u001b[A\n",
            "Epoch 1:  93%|█████████▎| 170/182 [34:45<02:26, 12.20s/it, training_loss=0.240]\u001b[A\n",
            "Epoch 1:  93%|█████████▎| 170/182 [34:57<02:26, 12.20s/it, training_loss=0.179]\u001b[A\n",
            "Epoch 1:  94%|█████████▍| 171/182 [34:57<02:14, 12.19s/it, training_loss=0.179]\u001b[A\n",
            "Epoch 1:  94%|█████████▍| 171/182 [35:08<02:14, 12.19s/it, training_loss=0.269]\u001b[A\n",
            "Epoch 1:  95%|█████████▍| 172/182 [35:08<01:58, 11.82s/it, training_loss=0.269]\u001b[A\n",
            "Epoch 1:  95%|█████████▍| 172/182 [35:21<01:58, 11.82s/it, training_loss=0.214]\u001b[A\n",
            "Epoch 1:  95%|█████████▌| 173/182 [35:21<01:50, 12.25s/it, training_loss=0.214]\u001b[A\n",
            "Epoch 1:  95%|█████████▌| 173/182 [35:33<01:50, 12.25s/it, training_loss=0.225]\u001b[A\n",
            "Epoch 1:  96%|█████████▌| 174/182 [35:33<01:37, 12.16s/it, training_loss=0.225]\u001b[A\n",
            "Epoch 1:  96%|█████████▌| 174/182 [35:45<01:37, 12.16s/it, training_loss=0.244]\u001b[A\n",
            "Epoch 1:  96%|█████████▌| 175/182 [35:45<01:23, 11.86s/it, training_loss=0.244]\u001b[A\n",
            "Epoch 1:  96%|█████████▌| 175/182 [35:58<01:23, 11.86s/it, training_loss=0.137]\u001b[A\n",
            "Epoch 1:  97%|█████████▋| 176/182 [35:58<01:13, 12.29s/it, training_loss=0.137]\u001b[A\n",
            "Epoch 1:  97%|█████████▋| 176/182 [36:09<01:13, 12.29s/it, training_loss=0.197]\u001b[A\n",
            "Epoch 1:  97%|█████████▋| 177/182 [36:09<01:00, 12.07s/it, training_loss=0.197]\u001b[A\n",
            "Epoch 1:  97%|█████████▋| 177/182 [36:21<01:00, 12.07s/it, training_loss=0.267]\u001b[A\n",
            "Epoch 1:  98%|█████████▊| 178/182 [36:21<00:47, 11.87s/it, training_loss=0.267]\u001b[A\n",
            "Epoch 1:  98%|█████████▊| 178/182 [36:34<00:47, 11.87s/it, training_loss=0.270]\u001b[A\n",
            "Epoch 1:  98%|█████████▊| 179/182 [36:34<00:36, 12.27s/it, training_loss=0.270]\u001b[A\n",
            "Epoch 1:  98%|█████████▊| 179/182 [36:45<00:36, 12.27s/it, training_loss=0.242]\u001b[A\n",
            "Epoch 1:  99%|█████████▉| 180/182 [36:45<00:23, 11.90s/it, training_loss=0.242]\u001b[A\n",
            "Epoch 1:  99%|█████████▉| 180/182 [36:57<00:23, 11.90s/it, training_loss=0.246]\u001b[A\n",
            "Epoch 1:  99%|█████████▉| 181/182 [36:57<00:11, 11.89s/it, training_loss=0.246]\u001b[A\n",
            "Epoch 1:  99%|█████████▉| 181/182 [36:59<00:11, 11.89s/it, training_loss=0.226]\u001b[A\n",
            "Epoch 1: 100%|██████████| 182/182 [36:59<00:00,  8.94s/it, training_loss=0.226]\u001b[A\n",
            "  0%|          | 0/3 [37:06<?, ?it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            " Epoch {epoch}\n",
            "Training loss: {loss_train_avg}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "  0%|          | 0/46 [00:00<?, ?it/s]\u001b[A\n",
            "  2%|▏         | 1/46 [00:03<02:29,  3.32s/it]\u001b[A\n",
            "  4%|▍         | 2/46 [00:06<02:23,  3.27s/it]\u001b[A\n",
            "  7%|▋         | 3/46 [00:09<02:23,  3.34s/it]\u001b[A\n",
            "  9%|▊         | 4/46 [00:16<03:16,  4.68s/it]\u001b[A\n",
            " 11%|█         | 5/46 [00:21<03:18,  4.84s/it]\u001b[A\n",
            " 13%|█▎        | 6/46 [00:26<03:11,  4.79s/it]\u001b[A\n",
            " 15%|█▌        | 7/46 [00:29<02:46,  4.26s/it]\u001b[A\n",
            " 17%|█▋        | 8/46 [00:34<02:47,  4.42s/it]\u001b[A\n",
            " 20%|█▉        | 9/46 [00:39<02:47,  4.54s/it]\u001b[A\n",
            " 22%|██▏       | 10/46 [00:42<02:28,  4.12s/it]\u001b[A\n",
            " 24%|██▍       | 11/46 [00:45<02:13,  3.83s/it]\u001b[A\n",
            " 26%|██▌       | 12/46 [00:48<02:03,  3.62s/it]\u001b[A\n",
            " 28%|██▊       | 13/46 [00:53<02:13,  4.03s/it]\u001b[A\n",
            " 30%|███       | 14/46 [00:58<02:14,  4.19s/it]\u001b[A\n",
            " 33%|███▎      | 15/46 [01:01<02:00,  3.87s/it]\u001b[A\n",
            " 35%|███▍      | 16/46 [01:04<01:49,  3.65s/it]\u001b[A\n",
            " 37%|███▋      | 17/46 [01:07<01:41,  3.51s/it]\u001b[A\n",
            " 39%|███▉      | 18/46 [01:12<01:52,  4.02s/it]\u001b[A\n",
            " 41%|████▏     | 19/46 [01:17<01:50,  4.10s/it]\u001b[A\n",
            " 43%|████▎     | 20/46 [01:20<01:39,  3.82s/it]\u001b[A\n",
            " 46%|████▌     | 21/46 [01:23<01:30,  3.62s/it]\u001b[A\n",
            " 48%|████▊     | 22/46 [01:26<01:25,  3.56s/it]\u001b[A\n",
            " 50%|█████     | 23/46 [01:32<01:33,  4.05s/it]\u001b[A\n",
            " 52%|█████▏    | 24/46 [01:36<01:29,  4.05s/it]\u001b[A\n",
            " 54%|█████▍    | 25/46 [01:39<01:19,  3.77s/it]\u001b[A\n",
            " 57%|█████▋    | 26/46 [01:42<01:11,  3.59s/it]\u001b[A\n",
            " 59%|█████▊    | 27/46 [01:46<01:09,  3.65s/it]\u001b[A\n",
            " 61%|██████    | 28/46 [01:51<01:13,  4.07s/it]\u001b[A\n",
            " 63%|██████▎   | 29/46 [01:55<01:07,  3.98s/it]\u001b[A\n",
            " 65%|██████▌   | 30/46 [01:58<00:59,  3.74s/it]\u001b[A\n",
            " 67%|██████▋   | 31/46 [02:01<00:53,  3.55s/it]\u001b[A\n",
            " 70%|██████▉   | 32/46 [02:05<00:52,  3.73s/it]\u001b[A\n",
            " 72%|███████▏  | 33/46 [02:10<00:53,  4.12s/it]\u001b[A\n",
            " 74%|███████▍  | 34/46 [02:14<00:47,  3.95s/it]\u001b[A\n",
            " 76%|███████▌  | 35/46 [02:17<00:40,  3.71s/it]\u001b[A\n",
            " 78%|███████▊  | 36/46 [02:20<00:35,  3.55s/it]\u001b[A\n",
            " 80%|████████  | 37/46 [02:24<00:34,  3.80s/it]\u001b[A\n",
            " 83%|████████▎ | 38/46 [02:29<00:33,  4.16s/it]\u001b[A\n",
            " 85%|████████▍ | 39/46 [02:33<00:27,  3.90s/it]\u001b[A\n",
            " 87%|████████▋ | 40/46 [02:36<00:22,  3.67s/it]\u001b[A\n",
            " 89%|████████▉ | 41/46 [02:39<00:17,  3.51s/it]\u001b[A\n",
            " 91%|█████████▏| 42/46 [02:44<00:15,  3.89s/it]\u001b[A\n",
            " 93%|█████████▎| 43/46 [02:48<00:12,  4.15s/it]\u001b[A\n",
            " 96%|█████████▌| 44/46 [02:52<00:07,  3.85s/it]\u001b[A\n",
            " 98%|█████████▊| 45/46 [02:55<00:03,  3.64s/it]\u001b[A\n",
            "100%|██████████| 46/46 [02:56<00:00,  3.84s/it]\n",
            " 33%|███▎      | 1/3 [40:02<1:20:05, 2402.83s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Validation loss: 0.6717540278382923\n",
            "F1 Score (weighted): 0.7384179171728579\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "Epoch 2:   0%|          | 0/182 [00:00<?, ?it/s]\u001b[A\n",
            "Epoch 2:   0%|          | 0/182 [00:13<?, ?it/s, training_loss=0.241]\u001b[A\n",
            "Epoch 2:   1%|          | 1/182 [00:13<40:10, 13.32s/it, training_loss=0.241]\u001b[A\n",
            "Epoch 2:   1%|          | 1/182 [00:25<40:10, 13.32s/it, training_loss=0.186]\u001b[A\n",
            "Epoch 2:   1%|          | 2/182 [00:25<37:38, 12.55s/it, training_loss=0.186]\u001b[A\n",
            "Epoch 2:   1%|          | 2/182 [00:36<37:38, 12.55s/it, training_loss=0.173]\u001b[A\n",
            "Epoch 2:   2%|▏         | 3/182 [00:36<35:38, 11.94s/it, training_loss=0.173]\u001b[A\n",
            "Epoch 2:   2%|▏         | 3/182 [00:49<35:38, 11.94s/it, training_loss=0.159]\u001b[A\n",
            "Epoch 2:   2%|▏         | 4/182 [00:49<36:57, 12.46s/it, training_loss=0.159]\u001b[A\n",
            "Epoch 2:   2%|▏         | 4/182 [01:01<36:57, 12.46s/it, training_loss=0.213]\u001b[A\n",
            "Epoch 2:   3%|▎         | 5/182 [01:01<35:44, 12.11s/it, training_loss=0.213]\u001b[A\n",
            "Epoch 2:   3%|▎         | 5/182 [01:12<35:44, 12.11s/it, training_loss=0.264]\u001b[A\n",
            "Epoch 2:   3%|▎         | 6/182 [01:12<34:54, 11.90s/it, training_loss=0.264]\u001b[A\n",
            "Epoch 2:   3%|▎         | 6/182 [01:26<34:54, 11.90s/it, training_loss=0.235]\u001b[A\n",
            "Epoch 2:   4%|▍         | 7/182 [01:26<35:59, 12.34s/it, training_loss=0.235]\u001b[A\n",
            "Epoch 2:   4%|▍         | 7/182 [01:37<35:59, 12.34s/it, training_loss=0.260]\u001b[A\n",
            "Epoch 2:   4%|▍         | 8/182 [01:37<34:44, 11.98s/it, training_loss=0.260]\u001b[A\n",
            "Epoch 2:   4%|▍         | 8/182 [01:49<34:44, 11.98s/it, training_loss=0.240]\u001b[A\n",
            "Epoch 2:   5%|▍         | 9/182 [01:49<34:23, 11.93s/it, training_loss=0.240]\u001b[A\n",
            "Epoch 2:   5%|▍         | 9/182 [02:02<34:23, 11.93s/it, training_loss=0.233]\u001b[A\n",
            "Epoch 2:   5%|▌         | 10/182 [02:02<35:25, 12.36s/it, training_loss=0.233]\u001b[A\n",
            "Epoch 2:   5%|▌         | 10/182 [02:13<35:25, 12.36s/it, training_loss=0.264]\u001b[A\n",
            "Epoch 2:   6%|▌         | 11/182 [02:13<34:03, 11.95s/it, training_loss=0.264]\u001b[A\n",
            "Epoch 2:   6%|▌         | 11/182 [02:25<34:03, 11.95s/it, training_loss=0.314]\u001b[A\n",
            "Epoch 2:   7%|▋         | 12/182 [02:25<34:00, 12.00s/it, training_loss=0.314]\u001b[A\n",
            "Epoch 2:   7%|▋         | 12/182 [02:38<34:00, 12.00s/it, training_loss=0.240]\u001b[A\n",
            "Epoch 2:   7%|▋         | 13/182 [02:38<34:56, 12.41s/it, training_loss=0.240]\u001b[A\n",
            "Epoch 2:   7%|▋         | 13/182 [02:49<34:56, 12.41s/it, training_loss=0.234]\u001b[A\n",
            "Epoch 2:   8%|▊         | 14/182 [02:49<33:20, 11.91s/it, training_loss=0.234]\u001b[A\n",
            "Epoch 2:   8%|▊         | 14/182 [03:01<33:20, 11.91s/it, training_loss=0.193]\u001b[A\n",
            "Epoch 2:   8%|▊         | 15/182 [03:01<33:24, 12.00s/it, training_loss=0.193]\u001b[A\n",
            "Epoch 2:   8%|▊         | 15/182 [03:15<33:24, 12.00s/it, training_loss=0.195]\u001b[A\n",
            "Epoch 2:   9%|▉         | 16/182 [03:15<34:16, 12.39s/it, training_loss=0.195]\u001b[A\n",
            "Epoch 2:   9%|▉         | 16/182 [03:25<34:16, 12.39s/it, training_loss=0.254]\u001b[A\n",
            "Epoch 2:   9%|▉         | 17/182 [03:25<32:28, 11.81s/it, training_loss=0.254]\u001b[A\n",
            "Epoch 2:   9%|▉         | 17/182 [03:38<32:28, 11.81s/it, training_loss=0.243]\u001b[A\n",
            "Epoch 2:  10%|▉         | 18/182 [03:38<32:54, 12.04s/it, training_loss=0.243]\u001b[A\n",
            "Epoch 2:  10%|▉         | 18/182 [03:51<32:54, 12.04s/it, training_loss=0.226]\u001b[A\n",
            "Epoch 2:  10%|█         | 19/182 [03:51<33:44, 12.42s/it, training_loss=0.226]\u001b[A\n",
            "Epoch 2:  10%|█         | 19/182 [04:01<33:44, 12.42s/it, training_loss=0.153]\u001b[A\n",
            "Epoch 2:  11%|█         | 20/182 [04:01<31:50, 11.79s/it, training_loss=0.153]\u001b[A\n",
            "Epoch 2:  11%|█         | 20/182 [04:14<31:50, 11.79s/it, training_loss=0.188]\u001b[A\n",
            "Epoch 2:  12%|█▏        | 21/182 [04:14<32:22, 12.06s/it, training_loss=0.188]\u001b[A\n",
            "Epoch 2:  12%|█▏        | 21/182 [04:27<32:22, 12.06s/it, training_loss=0.168]\u001b[A\n",
            "Epoch 2:  12%|█▏        | 22/182 [04:27<33:06, 12.42s/it, training_loss=0.168]\u001b[A\n",
            "Epoch 2:  12%|█▏        | 22/182 [04:37<33:06, 12.42s/it, training_loss=0.250]\u001b[A\n",
            "Epoch 2:  13%|█▎        | 23/182 [04:37<31:08, 11.75s/it, training_loss=0.250]\u001b[A\n",
            "Epoch 2:  13%|█▎        | 23/182 [04:50<31:08, 11.75s/it, training_loss=0.197]\u001b[A\n",
            "Epoch 2:  13%|█▎        | 24/182 [04:50<31:53, 12.11s/it, training_loss=0.197]\u001b[A\n",
            "Epoch 2:  13%|█▎        | 24/182 [05:03<31:53, 12.11s/it, training_loss=0.232]\u001b[A\n",
            "Epoch 2:  14%|█▎        | 25/182 [05:03<32:27, 12.40s/it, training_loss=0.232]\u001b[A\n",
            "Epoch 2:  14%|█▎        | 25/182 [05:14<32:27, 12.40s/it, training_loss=0.230]\u001b[A\n",
            "Epoch 2:  14%|█▍        | 26/182 [05:14<30:26, 11.71s/it, training_loss=0.230]\u001b[A\n",
            "Epoch 2:  14%|█▍        | 26/182 [05:27<30:26, 11.71s/it, training_loss=0.170]\u001b[A\n",
            "Epoch 2:  15%|█▍        | 27/182 [05:27<31:24, 12.16s/it, training_loss=0.170]\u001b[A\n",
            "Epoch 2:  15%|█▍        | 27/182 [05:40<31:24, 12.16s/it, training_loss=0.214]\u001b[A\n",
            "Epoch 2:  15%|█▌        | 28/182 [05:40<31:42, 12.36s/it, training_loss=0.214]\u001b[A\n",
            "Epoch 2:  15%|█▌        | 28/182 [05:50<31:42, 12.36s/it, training_loss=0.161]\u001b[A\n",
            "Epoch 2:  16%|█▌        | 29/182 [05:50<30:04, 11.80s/it, training_loss=0.161]\u001b[A\n",
            "Epoch 2:  16%|█▌        | 29/182 [06:03<30:04, 11.80s/it, training_loss=0.266]\u001b[A\n",
            "Epoch 2:  16%|█▋        | 30/182 [06:03<30:59, 12.23s/it, training_loss=0.266]\u001b[A\n",
            "Epoch 2:  16%|█▋        | 30/182 [06:16<30:59, 12.23s/it, training_loss=0.190]\u001b[A\n",
            "Epoch 2:  17%|█▋        | 31/182 [06:16<30:58, 12.31s/it, training_loss=0.190]\u001b[A\n",
            "Epoch 2:  17%|█▋        | 31/182 [06:27<30:58, 12.31s/it, training_loss=0.268]\u001b[A\n",
            "Epoch 2:  18%|█▊        | 32/182 [06:27<29:35, 11.84s/it, training_loss=0.268]\u001b[A\n",
            "Epoch 2:  18%|█▊        | 32/182 [06:40<29:35, 11.84s/it, training_loss=0.160]\u001b[A\n",
            "Epoch 2:  18%|█▊        | 33/182 [06:40<30:26, 12.26s/it, training_loss=0.160]\u001b[A\n",
            "Epoch 2:  18%|█▊        | 33/182 [06:52<30:26, 12.26s/it, training_loss=0.221]\u001b[A\n",
            "Epoch 2:  19%|█▊        | 34/182 [06:52<30:16, 12.27s/it, training_loss=0.221]\u001b[A\n",
            "Epoch 2:  19%|█▊        | 34/182 [07:03<30:16, 12.27s/it, training_loss=0.258]\u001b[A\n",
            "Epoch 2:  19%|█▉        | 35/182 [07:03<29:03, 11.86s/it, training_loss=0.258]\u001b[A\n",
            "Epoch 2:  19%|█▉        | 35/182 [07:16<29:03, 11.86s/it, training_loss=0.254]\u001b[A\n",
            "Epoch 2:  20%|█▉        | 36/182 [07:16<29:50, 12.26s/it, training_loss=0.254]\u001b[A\n",
            "Epoch 2:  20%|█▉        | 36/182 [07:28<29:50, 12.26s/it, training_loss=0.167]\u001b[A\n",
            "Epoch 2:  20%|██        | 37/182 [07:28<29:26, 12.18s/it, training_loss=0.167]\u001b[A\n",
            "Epoch 2:  20%|██        | 37/182 [07:39<29:26, 12.18s/it, training_loss=0.239]\u001b[A\n",
            "Epoch 2:  21%|██        | 38/182 [07:39<28:29, 11.87s/it, training_loss=0.239]\u001b[A\n",
            "Epoch 2:  21%|██        | 38/182 [07:53<28:29, 11.87s/it, training_loss=0.176]\u001b[A\n",
            "Epoch 2:  21%|██▏       | 39/182 [07:53<29:18, 12.29s/it, training_loss=0.176]\u001b[A\n",
            "Epoch 2:  21%|██▏       | 39/182 [08:04<29:18, 12.29s/it, training_loss=0.151]\u001b[A\n",
            "Epoch 2:  22%|██▏       | 40/182 [08:04<28:45, 12.15s/it, training_loss=0.151]\u001b[A\n",
            "Epoch 2:  22%|██▏       | 40/182 [08:16<28:45, 12.15s/it, training_loss=0.150]\u001b[A\n",
            "Epoch 2:  23%|██▎       | 41/182 [08:16<27:59, 11.91s/it, training_loss=0.150]\u001b[A\n",
            "Epoch 2:  23%|██▎       | 41/182 [08:29<27:59, 11.91s/it, training_loss=0.231]\u001b[A\n",
            "Epoch 2:  23%|██▎       | 42/182 [08:29<28:45, 12.33s/it, training_loss=0.231]\u001b[A\n",
            "Epoch 2:  23%|██▎       | 42/182 [08:41<28:45, 12.33s/it, training_loss=0.215]\u001b[A\n",
            "Epoch 2:  24%|██▎       | 43/182 [08:41<27:59, 12.08s/it, training_loss=0.215]\u001b[A\n",
            "Epoch 2:  24%|██▎       | 43/182 [08:52<27:59, 12.08s/it, training_loss=0.140]\u001b[A\n",
            "Epoch 2:  24%|██▍       | 44/182 [08:52<27:25, 11.92s/it, training_loss=0.140]\u001b[A\n",
            "Epoch 2:  24%|██▍       | 44/182 [09:05<27:25, 11.92s/it, training_loss=0.273]\u001b[A\n",
            "Epoch 2:  25%|██▍       | 45/182 [09:05<28:06, 12.31s/it, training_loss=0.273]\u001b[A\n",
            "Epoch 2:  25%|██▍       | 45/182 [09:17<28:06, 12.31s/it, training_loss=0.192]\u001b[A\n",
            "Epoch 2:  25%|██▌       | 46/182 [09:17<27:07, 11.97s/it, training_loss=0.192]\u001b[A\n",
            "Epoch 2:  25%|██▌       | 46/182 [09:28<27:07, 11.97s/it, training_loss=0.154]\u001b[A\n",
            "Epoch 2:  26%|██▌       | 47/182 [09:28<26:52, 11.95s/it, training_loss=0.154]\u001b[A\n",
            "Epoch 2:  26%|██▌       | 47/182 [09:42<26:52, 11.95s/it, training_loss=0.232]\u001b[A\n",
            "Epoch 2:  26%|██▋       | 48/182 [09:42<27:36, 12.37s/it, training_loss=0.232]\u001b[A\n",
            "Epoch 2:  26%|██▋       | 48/182 [09:53<27:36, 12.37s/it, training_loss=0.171]\u001b[A\n",
            "Epoch 2:  27%|██▋       | 49/182 [09:53<26:21, 11.89s/it, training_loss=0.171]\u001b[A\n",
            "Epoch 2:  27%|██▋       | 49/182 [10:05<26:21, 11.89s/it, training_loss=0.231]\u001b[A\n",
            "Epoch 2:  27%|██▋       | 50/182 [10:05<26:21, 11.98s/it, training_loss=0.231]\u001b[A\n",
            "Epoch 2:  27%|██▋       | 50/182 [10:18<26:21, 11.98s/it, training_loss=0.200]\u001b[A\n",
            "Epoch 2:  28%|██▊       | 51/182 [10:18<27:00, 12.37s/it, training_loss=0.200]\u001b[A\n",
            "Epoch 2:  28%|██▊       | 51/182 [10:29<27:00, 12.37s/it, training_loss=0.173]\u001b[A\n",
            "Epoch 2:  29%|██▊       | 52/182 [10:29<25:39, 11.84s/it, training_loss=0.173]\u001b[A\n",
            "Epoch 2:  29%|██▊       | 52/182 [10:41<25:39, 11.84s/it, training_loss=0.186]\u001b[A\n",
            "Epoch 2:  29%|██▉       | 53/182 [10:41<25:51, 12.03s/it, training_loss=0.186]\u001b[A\n",
            "Epoch 2:  29%|██▉       | 53/182 [10:54<25:51, 12.03s/it, training_loss=0.194]\u001b[A\n",
            "Epoch 2:  30%|██▉       | 54/182 [10:54<26:25, 12.39s/it, training_loss=0.194]\u001b[A\n",
            "Epoch 2:  30%|██▉       | 54/182 [11:05<26:25, 12.39s/it, training_loss=0.154]\u001b[A\n",
            "Epoch 2:  30%|███       | 55/182 [11:05<24:55, 11.78s/it, training_loss=0.154]\u001b[A\n",
            "Epoch 2:  30%|███       | 55/182 [11:17<24:55, 11.78s/it, training_loss=0.150]\u001b[A\n",
            "Epoch 2:  31%|███       | 56/182 [11:17<25:15, 12.03s/it, training_loss=0.150]\u001b[A\n",
            "Epoch 2:  31%|███       | 56/182 [11:31<25:15, 12.03s/it, training_loss=0.190]\u001b[A\n",
            "Epoch 2:  31%|███▏      | 57/182 [11:31<25:49, 12.39s/it, training_loss=0.190]\u001b[A\n",
            "Epoch 2:  31%|███▏      | 57/182 [11:41<25:49, 12.39s/it, training_loss=0.172]\u001b[A\n",
            "Epoch 2:  32%|███▏      | 58/182 [11:41<24:17, 11.76s/it, training_loss=0.172]\u001b[A\n",
            "Epoch 2:  32%|███▏      | 58/182 [11:54<24:17, 11.76s/it, training_loss=0.157]\u001b[A\n",
            "Epoch 2:  32%|███▏      | 59/182 [11:54<24:51, 12.12s/it, training_loss=0.157]\u001b[A\n",
            "Epoch 2:  32%|███▏      | 59/182 [12:07<24:51, 12.12s/it, training_loss=0.202]\u001b[A\n",
            "Epoch 2:  33%|███▎      | 60/182 [12:07<25:20, 12.47s/it, training_loss=0.202]\u001b[A\n",
            "Epoch 2:  33%|███▎      | 60/182 [12:17<25:20, 12.47s/it, training_loss=0.162]\u001b[A\n",
            "Epoch 2:  34%|███▎      | 61/182 [12:17<23:44, 11.78s/it, training_loss=0.162]\u001b[A\n",
            "Epoch 2:  34%|███▎      | 61/182 [12:30<23:44, 11.78s/it, training_loss=0.230]\u001b[A\n",
            "Epoch 2:  34%|███▍      | 62/182 [12:30<24:17, 12.14s/it, training_loss=0.230]\u001b[A\n",
            "Epoch 2:  34%|███▍      | 62/182 [12:43<24:17, 12.14s/it, training_loss=0.187]\u001b[A\n",
            "Epoch 2:  35%|███▍      | 63/182 [12:43<24:34, 12.39s/it, training_loss=0.187]\u001b[A\n",
            "Epoch 2:  35%|███▍      | 63/182 [12:53<24:34, 12.39s/it, training_loss=0.194]\u001b[A\n",
            "Epoch 2:  35%|███▌      | 64/182 [12:53<23:01, 11.71s/it, training_loss=0.194]\u001b[A\n",
            "Epoch 2:  35%|███▌      | 64/182 [13:07<23:01, 11.71s/it, training_loss=0.113]\u001b[A\n",
            "Epoch 2:  36%|███▌      | 65/182 [13:07<23:43, 12.17s/it, training_loss=0.113]\u001b[A\n",
            "Epoch 2:  36%|███▌      | 65/182 [13:19<23:43, 12.17s/it, training_loss=0.133]\u001b[A\n",
            "Epoch 2:  36%|███▋      | 66/182 [13:19<23:54, 12.37s/it, training_loss=0.133]\u001b[A\n",
            "Epoch 2:  36%|███▋      | 66/182 [13:30<23:54, 12.37s/it, training_loss=0.144]\u001b[A\n",
            "Epoch 2:  37%|███▋      | 67/182 [13:30<22:37, 11.81s/it, training_loss=0.144]\u001b[A\n",
            "Epoch 2:  37%|███▋      | 67/182 [13:43<22:37, 11.81s/it, training_loss=0.151]\u001b[A\n",
            "Epoch 2:  37%|███▋      | 68/182 [13:43<23:17, 12.25s/it, training_loss=0.151]\u001b[A\n",
            "Epoch 2:  37%|███▋      | 68/182 [13:56<23:17, 12.25s/it, training_loss=0.132]\u001b[A\n",
            "Epoch 2:  38%|███▊      | 69/182 [13:56<23:15, 12.35s/it, training_loss=0.132]\u001b[A\n",
            "Epoch 2:  38%|███▊      | 69/182 [14:06<23:15, 12.35s/it, training_loss=0.176]\u001b[A\n",
            "Epoch 2:  38%|███▊      | 70/182 [14:06<22:06, 11.85s/it, training_loss=0.176]\u001b[A\n",
            "Epoch 2:  38%|███▊      | 70/182 [14:20<22:06, 11.85s/it, training_loss=0.228]\u001b[A\n",
            "Epoch 2:  39%|███▉      | 71/182 [14:20<22:39, 12.25s/it, training_loss=0.228]\u001b[A\n",
            "Epoch 2:  39%|███▉      | 71/182 [14:32<22:39, 12.25s/it, training_loss=0.181]\u001b[A\n",
            "Epoch 2:  40%|███▉      | 72/182 [14:32<22:26, 12.24s/it, training_loss=0.181]\u001b[A\n",
            "Epoch 2:  40%|███▉      | 72/182 [14:43<22:26, 12.24s/it, training_loss=0.108]\u001b[A\n",
            "Epoch 2:  40%|████      | 73/182 [14:43<21:30, 11.84s/it, training_loss=0.108]\u001b[A\n",
            "Epoch 2:  40%|████      | 73/182 [14:56<21:30, 11.84s/it, training_loss=0.214]\u001b[A\n",
            "Epoch 2:  41%|████      | 74/182 [14:56<22:05, 12.27s/it, training_loss=0.214]\u001b[A\n",
            "Epoch 2:  41%|████      | 74/182 [15:08<22:05, 12.27s/it, training_loss=0.159]\u001b[A\n",
            "Epoch 2:  41%|████      | 75/182 [15:08<21:46, 12.21s/it, training_loss=0.159]\u001b[A\n",
            "Epoch 2:  41%|████      | 75/182 [15:19<21:46, 12.21s/it, training_loss=0.100]\u001b[A\n",
            "Epoch 2:  42%|████▏     | 76/182 [15:19<21:00, 11.89s/it, training_loss=0.100]\u001b[A\n",
            "Epoch 2:  42%|████▏     | 76/182 [15:32<21:00, 11.89s/it, training_loss=0.154]\u001b[A\n",
            "Epoch 2:  42%|████▏     | 77/182 [15:32<21:32, 12.31s/it, training_loss=0.154]\u001b[A\n",
            "Epoch 2:  42%|████▏     | 77/182 [15:44<21:32, 12.31s/it, training_loss=0.154]\u001b[A\n",
            "Epoch 2:  43%|████▎     | 78/182 [15:44<20:59, 12.11s/it, training_loss=0.154]\u001b[A\n",
            "Epoch 2:  43%|████▎     | 78/182 [15:56<20:59, 12.11s/it, training_loss=0.149]\u001b[A\n",
            "Epoch 2:  43%|████▎     | 79/182 [15:56<20:26, 11.91s/it, training_loss=0.149]\u001b[A\n",
            "Epoch 2:  43%|████▎     | 79/182 [16:09<20:26, 11.91s/it, training_loss=0.143]\u001b[A\n",
            "Epoch 2:  44%|████▍     | 80/182 [16:09<20:57, 12.33s/it, training_loss=0.143]\u001b[A\n",
            "Epoch 2:  44%|████▍     | 80/182 [16:20<20:57, 12.33s/it, training_loss=0.182]\u001b[A\n",
            "Epoch 2:  45%|████▍     | 81/182 [16:20<20:18, 12.06s/it, training_loss=0.182]\u001b[A\n",
            "Epoch 2:  45%|████▍     | 81/182 [16:32<20:18, 12.06s/it, training_loss=0.218]\u001b[A\n",
            "Epoch 2:  45%|████▌     | 82/182 [16:32<19:50, 11.91s/it, training_loss=0.218]\u001b[A\n",
            "Epoch 2:  45%|████▌     | 82/182 [16:45<19:50, 11.91s/it, training_loss=0.321]\u001b[A\n",
            "Epoch 2:  46%|████▌     | 83/182 [16:45<20:18, 12.31s/it, training_loss=0.321]\u001b[A\n",
            "Epoch 2:  46%|████▌     | 83/182 [16:56<20:18, 12.31s/it, training_loss=0.173]\u001b[A\n",
            "Epoch 2:  46%|████▌     | 84/182 [16:56<19:33, 11.98s/it, training_loss=0.173]\u001b[A\n",
            "Epoch 2:  46%|████▌     | 84/182 [17:08<19:33, 11.98s/it, training_loss=0.239]\u001b[A\n",
            "Epoch 2:  47%|████▋     | 85/182 [17:08<19:19, 11.96s/it, training_loss=0.239]\u001b[A\n",
            "Epoch 2:  47%|████▋     | 85/182 [17:22<19:19, 11.96s/it, training_loss=0.188]\u001b[A\n",
            "Epoch 2:  47%|████▋     | 86/182 [17:22<19:48, 12.38s/it, training_loss=0.188]\u001b[A\n",
            "Epoch 2:  47%|████▋     | 86/182 [17:32<19:48, 12.38s/it, training_loss=0.170]\u001b[A\n",
            "Epoch 2:  48%|████▊     | 87/182 [17:32<18:51, 11.91s/it, training_loss=0.170]\u001b[A\n",
            "Epoch 2:  48%|████▊     | 87/182 [17:45<18:51, 11.91s/it, training_loss=0.139]\u001b[A\n",
            "Epoch 2:  48%|████▊     | 88/182 [17:45<18:47, 12.00s/it, training_loss=0.139]\u001b[A\n",
            "Epoch 2:  48%|████▊     | 88/182 [17:58<18:47, 12.00s/it, training_loss=0.152]\u001b[A\n",
            "Epoch 2:  49%|████▉     | 89/182 [17:58<19:13, 12.40s/it, training_loss=0.152]\u001b[A\n",
            "Epoch 2:  49%|████▉     | 89/182 [18:09<19:13, 12.40s/it, training_loss=0.244]\u001b[A\n",
            "Epoch 2:  49%|████▉     | 90/182 [18:09<18:11, 11.87s/it, training_loss=0.244]\u001b[A\n",
            "Epoch 2:  49%|████▉     | 90/182 [18:21<18:11, 11.87s/it, training_loss=0.186]\u001b[A\n",
            "Epoch 2:  50%|█████     | 91/182 [18:21<18:14, 12.03s/it, training_loss=0.186]\u001b[A\n",
            "Epoch 2:  50%|█████     | 91/182 [18:34<18:14, 12.03s/it, training_loss=0.118]\u001b[A\n",
            "Epoch 2:  51%|█████     | 92/182 [18:34<18:35, 12.40s/it, training_loss=0.118]\u001b[A\n",
            "Epoch 2:  51%|█████     | 92/182 [18:44<18:35, 12.40s/it, training_loss=0.186]\u001b[A\n",
            "Epoch 2:  51%|█████     | 93/182 [18:44<17:23, 11.73s/it, training_loss=0.186]\u001b[A\n",
            "Epoch 2:  51%|█████     | 93/182 [18:57<17:23, 11.73s/it, training_loss=0.147]\u001b[A\n",
            "Epoch 2:  52%|█████▏    | 94/182 [18:57<17:40, 12.05s/it, training_loss=0.147]\u001b[A\n",
            "Epoch 2:  52%|█████▏    | 94/182 [19:10<17:40, 12.05s/it, training_loss=0.080]\u001b[A\n",
            "Epoch 2:  52%|█████▏    | 95/182 [19:10<17:57, 12.39s/it, training_loss=0.080]\u001b[A\n",
            "Epoch 2:  52%|█████▏    | 95/182 [19:20<17:57, 12.39s/it, training_loss=0.212]\u001b[A\n",
            "Epoch 2:  53%|█████▎    | 96/182 [19:20<16:44, 11.68s/it, training_loss=0.212]\u001b[A\n",
            "Epoch 2:  53%|█████▎    | 96/182 [19:34<16:44, 11.68s/it, training_loss=0.113]\u001b[A\n",
            "Epoch 2:  53%|█████▎    | 97/182 [19:34<17:14, 12.17s/it, training_loss=0.113]\u001b[A\n",
            "Epoch 2:  53%|█████▎    | 97/182 [19:47<17:14, 12.17s/it, training_loss=0.112]\u001b[A\n",
            "Epoch 2:  54%|█████▍    | 98/182 [19:47<17:33, 12.55s/it, training_loss=0.112]\u001b[A\n",
            "Epoch 2:  54%|█████▍    | 98/182 [19:58<17:33, 12.55s/it, training_loss=0.198]\u001b[A\n",
            "Epoch 2:  54%|█████▍    | 99/182 [19:58<16:35, 12.00s/it, training_loss=0.198]\u001b[A\n",
            "Epoch 2:  54%|█████▍    | 99/182 [20:11<16:35, 12.00s/it, training_loss=0.166]\u001b[A\n",
            "Epoch 2:  55%|█████▍    | 100/182 [20:11<17:02, 12.47s/it, training_loss=0.166]\u001b[A\n",
            "Epoch 2:  55%|█████▍    | 100/182 [20:25<17:02, 12.47s/it, training_loss=0.153]\u001b[A\n",
            "Epoch 2:  55%|█████▌    | 101/182 [20:25<17:05, 12.66s/it, training_loss=0.153]\u001b[A\n",
            "Epoch 2:  55%|█████▌    | 101/182 [20:35<17:05, 12.66s/it, training_loss=0.117]\u001b[A\n",
            "Epoch 2:  56%|█████▌    | 102/182 [20:35<15:52, 11.90s/it, training_loss=0.117]\u001b[A\n",
            "Epoch 2:  56%|█████▌    | 102/182 [20:48<15:52, 11.90s/it, training_loss=0.124]\u001b[A\n",
            "Epoch 2:  57%|█████▋    | 103/182 [20:48<16:09, 12.28s/it, training_loss=0.124]\u001b[A\n",
            "Epoch 2:  57%|█████▋    | 103/182 [21:00<16:09, 12.28s/it, training_loss=0.171]\u001b[A\n",
            "Epoch 2:  57%|█████▋    | 104/182 [21:00<16:02, 12.34s/it, training_loss=0.171]\u001b[A\n",
            "Epoch 2:  57%|█████▋    | 104/182 [21:11<16:02, 12.34s/it, training_loss=0.115]\u001b[A\n",
            "Epoch 2:  58%|█████▊    | 105/182 [21:11<15:09, 11.81s/it, training_loss=0.115]\u001b[A\n",
            "Epoch 2:  58%|█████▊    | 105/182 [21:24<15:09, 11.81s/it, training_loss=0.125]\u001b[A\n",
            "Epoch 2:  58%|█████▊    | 106/182 [21:24<15:30, 12.25s/it, training_loss=0.125]\u001b[A\n",
            "Epoch 2:  58%|█████▊    | 106/182 [21:36<15:30, 12.25s/it, training_loss=0.135]\u001b[A\n",
            "Epoch 2:  59%|█████▉    | 107/182 [21:36<15:17, 12.24s/it, training_loss=0.135]\u001b[A\n",
            "Epoch 2:  59%|█████▉    | 107/182 [21:47<15:17, 12.24s/it, training_loss=0.083]\u001b[A\n",
            "Epoch 2:  59%|█████▉    | 108/182 [21:47<14:35, 11.83s/it, training_loss=0.083]\u001b[A\n",
            "Epoch 2:  59%|█████▉    | 108/182 [22:00<14:35, 11.83s/it, training_loss=0.148]\u001b[A\n",
            "Epoch 2:  60%|█████▉    | 109/182 [22:01<14:54, 12.25s/it, training_loss=0.148]\u001b[A\n",
            "Epoch 2:  60%|█████▉    | 109/182 [22:12<14:54, 12.25s/it, training_loss=0.130]\u001b[A\n",
            "Epoch 2:  60%|██████    | 110/182 [22:12<14:33, 12.13s/it, training_loss=0.130]\u001b[A\n",
            "Epoch 2:  60%|██████    | 110/182 [22:24<14:33, 12.13s/it, training_loss=0.155]\u001b[A\n",
            "Epoch 2:  61%|██████    | 111/182 [22:24<14:04, 11.90s/it, training_loss=0.155]\u001b[A\n",
            "Epoch 2:  61%|██████    | 111/182 [22:37<14:04, 11.90s/it, training_loss=0.129]\u001b[A\n",
            "Epoch 2:  62%|██████▏   | 112/182 [22:37<14:20, 12.29s/it, training_loss=0.129]\u001b[A\n",
            "Epoch 2:  62%|██████▏   | 112/182 [22:48<14:20, 12.29s/it, training_loss=0.166]\u001b[A\n",
            "Epoch 2:  62%|██████▏   | 113/182 [22:48<13:48, 12.01s/it, training_loss=0.166]\u001b[A\n",
            "Epoch 2:  62%|██████▏   | 113/182 [23:00<13:48, 12.01s/it, training_loss=0.108]\u001b[A\n",
            "Epoch 2:  63%|██████▎   | 114/182 [23:00<13:28, 11.89s/it, training_loss=0.108]\u001b[A\n",
            "Epoch 2:  63%|██████▎   | 114/182 [23:13<13:28, 11.89s/it, training_loss=0.120]\u001b[A\n",
            "Epoch 2:  63%|██████▎   | 115/182 [23:13<13:44, 12.30s/it, training_loss=0.120]\u001b[A\n",
            "Epoch 2:  63%|██████▎   | 115/182 [23:24<13:44, 12.30s/it, training_loss=0.120]\u001b[A\n",
            "Epoch 2:  64%|██████▎   | 116/182 [23:24<13:06, 11.91s/it, training_loss=0.120]\u001b[A\n",
            "Epoch 2:  64%|██████▎   | 116/182 [23:36<13:06, 11.91s/it, training_loss=0.101]\u001b[A\n",
            "Epoch 2:  64%|██████▍   | 117/182 [23:36<12:56, 11.94s/it, training_loss=0.101]\u001b[A\n",
            "Epoch 2:  64%|██████▍   | 117/182 [23:49<12:56, 11.94s/it, training_loss=0.160]\u001b[A\n",
            "Epoch 2:  65%|██████▍   | 118/182 [23:49<13:10, 12.35s/it, training_loss=0.160]\u001b[A\n",
            "Epoch 2:  65%|██████▍   | 118/182 [24:00<13:10, 12.35s/it, training_loss=0.108]\u001b[A\n",
            "Epoch 2:  65%|██████▌   | 119/182 [24:00<12:27, 11.86s/it, training_loss=0.108]\u001b[A\n",
            "Epoch 2:  65%|██████▌   | 119/182 [24:12<12:27, 11.86s/it, training_loss=0.160]\u001b[A\n",
            "Epoch 2:  66%|██████▌   | 120/182 [24:12<12:23, 11.99s/it, training_loss=0.160]\u001b[A\n",
            "Epoch 2:  66%|██████▌   | 120/182 [24:26<12:23, 11.99s/it, training_loss=0.135]\u001b[A\n",
            "Epoch 2:  66%|██████▋   | 121/182 [24:26<12:34, 12.37s/it, training_loss=0.135]\u001b[A\n",
            "Epoch 2:  66%|██████▋   | 121/182 [24:36<12:34, 12.37s/it, training_loss=0.195]\u001b[A\n",
            "Epoch 2:  67%|██████▋   | 122/182 [24:36<11:44, 11.74s/it, training_loss=0.195]\u001b[A\n",
            "Epoch 2:  67%|██████▋   | 122/182 [24:49<11:44, 11.74s/it, training_loss=0.098]\u001b[A\n",
            "Epoch 2:  68%|██████▊   | 123/182 [24:49<11:48, 12.02s/it, training_loss=0.098]\u001b[A\n",
            "Epoch 2:  68%|██████▊   | 123/182 [25:02<11:48, 12.02s/it, training_loss=0.145]\u001b[A\n",
            "Epoch 2:  68%|██████▊   | 124/182 [25:02<11:58, 12.39s/it, training_loss=0.145]\u001b[A\n",
            "Epoch 2:  68%|██████▊   | 124/182 [25:12<11:58, 12.39s/it, training_loss=0.234]\u001b[A\n",
            "Epoch 2:  69%|██████▊   | 125/182 [25:12<11:07, 11.72s/it, training_loss=0.234]\u001b[A\n",
            "Epoch 2:  69%|██████▊   | 125/182 [25:25<11:07, 11.72s/it, training_loss=0.362]\u001b[A\n",
            "Epoch 2:  69%|██████▉   | 126/182 [25:25<11:18, 12.12s/it, training_loss=0.362]\u001b[A\n",
            "Epoch 2:  69%|██████▉   | 126/182 [25:38<11:18, 12.12s/it, training_loss=0.154]\u001b[A\n",
            "Epoch 2:  70%|██████▉   | 127/182 [25:38<11:23, 12.43s/it, training_loss=0.154]\u001b[A\n",
            "Epoch 2:  70%|██████▉   | 127/182 [25:49<11:23, 12.43s/it, training_loss=0.247]\u001b[A\n",
            "Epoch 2:  70%|███████   | 128/182 [25:49<10:35, 11.77s/it, training_loss=0.247]\u001b[A\n",
            "Epoch 2:  70%|███████   | 128/182 [26:02<10:35, 11.77s/it, training_loss=0.206]\u001b[A\n",
            "Epoch 2:  71%|███████   | 129/182 [26:02<10:47, 12.22s/it, training_loss=0.206]\u001b[A\n",
            "Epoch 2:  71%|███████   | 129/182 [26:15<10:47, 12.22s/it, training_loss=0.142]\u001b[A\n",
            "Epoch 2:  71%|███████▏  | 130/182 [26:15<10:46, 12.43s/it, training_loss=0.142]\u001b[A\n",
            "Epoch 2:  71%|███████▏  | 130/182 [26:25<10:46, 12.43s/it, training_loss=0.196]\u001b[A\n",
            "Epoch 2:  72%|███████▏  | 131/182 [26:25<10:01, 11.79s/it, training_loss=0.196]\u001b[A\n",
            "Epoch 2:  72%|███████▏  | 131/182 [26:38<10:01, 11.79s/it, training_loss=0.172]\u001b[A\n",
            "Epoch 2:  73%|███████▎  | 132/182 [26:38<10:11, 12.23s/it, training_loss=0.172]\u001b[A\n",
            "Epoch 2:  73%|███████▎  | 132/182 [26:51<10:11, 12.23s/it, training_loss=0.096]\u001b[A\n",
            "Epoch 2:  73%|███████▎  | 133/182 [26:51<10:03, 12.32s/it, training_loss=0.096]\u001b[A\n",
            "Epoch 2:  73%|███████▎  | 133/182 [27:01<10:03, 12.32s/it, training_loss=0.204]\u001b[A\n",
            "Epoch 2:  74%|███████▎  | 134/182 [27:01<09:25, 11.77s/it, training_loss=0.204]\u001b[A\n",
            "Epoch 2:  74%|███████▎  | 134/182 [27:14<09:25, 11.77s/it, training_loss=0.058]\u001b[A\n",
            "Epoch 2:  74%|███████▍  | 135/182 [27:14<09:33, 12.19s/it, training_loss=0.058]\u001b[A\n",
            "Epoch 2:  74%|███████▍  | 135/182 [27:27<09:33, 12.19s/it, training_loss=0.179]\u001b[A\n",
            "Epoch 2:  75%|███████▍  | 136/182 [27:27<09:22, 12.22s/it, training_loss=0.179]\u001b[A\n",
            "Epoch 2:  75%|███████▍  | 136/182 [27:38<09:22, 12.22s/it, training_loss=0.175]\u001b[A\n",
            "Epoch 2:  75%|███████▌  | 137/182 [27:38<08:52, 11.84s/it, training_loss=0.175]\u001b[A\n",
            "Epoch 2:  75%|███████▌  | 137/182 [27:51<08:52, 11.84s/it, training_loss=0.304]\u001b[A\n",
            "Epoch 2:  76%|███████▌  | 138/182 [27:51<09:00, 12.28s/it, training_loss=0.304]\u001b[A\n",
            "Epoch 2:  76%|███████▌  | 138/182 [28:03<09:00, 12.28s/it, training_loss=0.223]\u001b[A\n",
            "Epoch 2:  76%|███████▋  | 139/182 [28:03<08:47, 12.26s/it, training_loss=0.223]\u001b[A\n",
            "Epoch 2:  76%|███████▋  | 139/182 [28:14<08:47, 12.26s/it, training_loss=0.091]\u001b[A\n",
            "Epoch 2:  77%|███████▋  | 140/182 [28:14<08:19, 11.88s/it, training_loss=0.091]\u001b[A\n",
            "Epoch 2:  77%|███████▋  | 140/182 [28:27<08:19, 11.88s/it, training_loss=0.106]\u001b[A\n",
            "Epoch 2:  77%|███████▋  | 141/182 [28:27<08:23, 12.29s/it, training_loss=0.106]\u001b[A\n",
            "Epoch 2:  77%|███████▋  | 141/182 [28:39<08:23, 12.29s/it, training_loss=0.273]\u001b[A\n",
            "Epoch 2:  78%|███████▊  | 142/182 [28:39<08:03, 12.10s/it, training_loss=0.273]\u001b[A\n",
            "Epoch 2:  78%|███████▊  | 142/182 [28:50<08:03, 12.10s/it, training_loss=0.180]\u001b[A\n",
            "Epoch 2:  79%|███████▊  | 143/182 [28:50<07:42, 11.86s/it, training_loss=0.180]\u001b[A\n",
            "Epoch 2:  79%|███████▊  | 143/182 [29:04<07:42, 11.86s/it, training_loss=0.375]\u001b[A\n",
            "Epoch 2:  79%|███████▉  | 144/182 [29:04<07:46, 12.28s/it, training_loss=0.375]\u001b[A\n",
            "Epoch 2:  79%|███████▉  | 144/182 [29:15<07:46, 12.28s/it, training_loss=0.205]\u001b[A\n",
            "Epoch 2:  80%|███████▉  | 145/182 [29:15<07:24, 12.01s/it, training_loss=0.205]\u001b[A\n",
            "Epoch 2:  80%|███████▉  | 145/182 [29:27<07:24, 12.01s/it, training_loss=0.133]\u001b[A\n",
            "Epoch 2:  80%|████████  | 146/182 [29:27<07:07, 11.87s/it, training_loss=0.133]\u001b[A\n",
            "Epoch 2:  80%|████████  | 146/182 [29:40<07:07, 11.87s/it, training_loss=0.219]\u001b[A\n",
            "Epoch 2:  81%|████████  | 147/182 [29:40<07:10, 12.30s/it, training_loss=0.219]\u001b[A\n",
            "Epoch 2:  81%|████████  | 147/182 [29:51<07:10, 12.30s/it, training_loss=0.341]\u001b[A\n",
            "Epoch 2:  81%|████████▏ | 148/182 [29:51<06:47, 11.98s/it, training_loss=0.341]\u001b[A\n",
            "Epoch 2:  81%|████████▏ | 148/182 [30:03<06:47, 11.98s/it, training_loss=0.157]\u001b[A\n",
            "Epoch 2:  82%|████████▏ | 149/182 [30:03<06:35, 11.98s/it, training_loss=0.157]\u001b[A\n",
            "Epoch 2:  82%|████████▏ | 149/182 [30:16<06:35, 11.98s/it, training_loss=0.201]\u001b[A\n",
            "Epoch 2:  82%|████████▏ | 150/182 [30:16<06:35, 12.37s/it, training_loss=0.201]\u001b[A\n",
            "Epoch 2:  82%|████████▏ | 150/182 [30:27<06:35, 12.37s/it, training_loss=0.162]\u001b[A\n",
            "Epoch 2:  83%|████████▎ | 151/182 [30:27<06:10, 11.94s/it, training_loss=0.162]\u001b[A\n",
            "Epoch 2:  83%|████████▎ | 151/182 [30:39<06:10, 11.94s/it, training_loss=0.114]\u001b[A\n",
            "Epoch 2:  84%|████████▎ | 152/182 [30:39<05:58, 11.94s/it, training_loss=0.114]\u001b[A\n",
            "Epoch 2:  84%|████████▎ | 152/182 [30:52<05:58, 11.94s/it, training_loss=0.234]\u001b[A\n",
            "Epoch 2:  84%|████████▍ | 153/182 [30:52<05:57, 12.32s/it, training_loss=0.234]\u001b[A\n",
            "Epoch 2:  84%|████████▍ | 153/182 [31:03<05:57, 12.32s/it, training_loss=0.203]\u001b[A\n",
            "Epoch 2:  85%|████████▍ | 154/182 [31:03<05:28, 11.75s/it, training_loss=0.203]\u001b[A\n",
            "Epoch 2:  85%|████████▍ | 154/182 [31:15<05:28, 11.75s/it, training_loss=0.138]\u001b[A\n",
            "Epoch 2:  85%|████████▌ | 155/182 [31:15<05:23, 11.97s/it, training_loss=0.138]\u001b[A\n",
            "Epoch 2:  85%|████████▌ | 155/182 [31:29<05:23, 11.97s/it, training_loss=0.219]\u001b[A\n",
            "Epoch 2:  86%|████████▌ | 156/182 [31:29<05:21, 12.36s/it, training_loss=0.219]\u001b[A\n",
            "Epoch 2:  86%|████████▌ | 156/182 [31:39<05:21, 12.36s/it, training_loss=0.154]\u001b[A\n",
            "Epoch 2:  86%|████████▋ | 157/182 [31:39<04:53, 11.73s/it, training_loss=0.154]\u001b[A\n",
            "Epoch 2:  86%|████████▋ | 157/182 [31:52<04:53, 11.73s/it, training_loss=0.329]\u001b[A\n",
            "Epoch 2:  87%|████████▋ | 158/182 [31:52<04:48, 12.03s/it, training_loss=0.329]\u001b[A\n",
            "Epoch 2:  87%|████████▋ | 158/182 [32:05<04:48, 12.03s/it, training_loss=0.199]\u001b[A\n",
            "Epoch 2:  87%|████████▋ | 159/182 [32:05<04:44, 12.39s/it, training_loss=0.199]\u001b[A\n",
            "Epoch 2:  87%|████████▋ | 159/182 [32:15<04:44, 12.39s/it, training_loss=0.046]\u001b[A\n",
            "Epoch 2:  88%|████████▊ | 160/182 [32:15<04:17, 11.69s/it, training_loss=0.046]\u001b[A\n",
            "Epoch 2:  88%|████████▊ | 160/182 [32:28<04:17, 11.69s/it, training_loss=0.181]\u001b[A\n",
            "Epoch 2:  88%|████████▊ | 161/182 [32:28<04:14, 12.12s/it, training_loss=0.181]\u001b[A\n",
            "Epoch 2:  88%|████████▊ | 161/182 [32:41<04:14, 12.12s/it, training_loss=0.194]\u001b[A\n",
            "Epoch 2:  89%|████████▉ | 162/182 [32:41<04:07, 12.37s/it, training_loss=0.194]\u001b[A\n",
            "Epoch 2:  89%|████████▉ | 162/182 [32:51<04:07, 12.37s/it, training_loss=0.075]\u001b[A\n",
            "Epoch 2:  90%|████████▉ | 163/182 [32:51<03:42, 11.73s/it, training_loss=0.075]\u001b[A\n",
            "Epoch 2:  90%|████████▉ | 163/182 [33:04<03:42, 11.73s/it, training_loss=0.173]\u001b[A\n",
            "Epoch 2:  90%|█████████ | 164/182 [33:04<03:39, 12.19s/it, training_loss=0.173]\u001b[A\n",
            "Epoch 2:  90%|█████████ | 164/182 [33:17<03:39, 12.19s/it, training_loss=0.101]\u001b[A\n",
            "Epoch 2:  91%|█████████ | 165/182 [33:17<03:30, 12.36s/it, training_loss=0.101]\u001b[A\n",
            "Epoch 2:  91%|█████████ | 165/182 [33:28<03:30, 12.36s/it, training_loss=0.165]\u001b[A\n",
            "Epoch 2:  91%|█████████ | 166/182 [33:28<03:08, 11.81s/it, training_loss=0.165]\u001b[A\n",
            "Epoch 2:  91%|█████████ | 166/182 [33:41<03:08, 11.81s/it, training_loss=0.090]\u001b[A\n",
            "Epoch 2:  92%|█████████▏| 167/182 [33:41<03:03, 12.26s/it, training_loss=0.090]\u001b[A\n",
            "Epoch 2:  92%|█████████▏| 167/182 [33:54<03:03, 12.26s/it, training_loss=0.117]\u001b[A\n",
            "Epoch 2:  92%|█████████▏| 168/182 [33:54<02:53, 12.38s/it, training_loss=0.117]\u001b[A\n",
            "Epoch 2:  92%|█████████▏| 168/182 [34:04<02:53, 12.38s/it, training_loss=0.301]\u001b[A\n",
            "Epoch 2:  93%|█████████▎| 169/182 [34:04<02:34, 11.89s/it, training_loss=0.301]\u001b[A\n",
            "Epoch 2:  93%|█████████▎| 169/182 [34:18<02:34, 11.89s/it, training_loss=0.282]\u001b[A\n",
            "Epoch 2:  93%|█████████▎| 170/182 [34:18<02:27, 12.32s/it, training_loss=0.282]\u001b[A\n",
            "Epoch 2:  93%|█████████▎| 170/182 [34:30<02:27, 12.32s/it, training_loss=0.114]\u001b[A\n",
            "Epoch 2:  94%|█████████▍| 171/182 [34:30<02:15, 12.35s/it, training_loss=0.114]\u001b[A\n",
            "Epoch 2:  94%|█████████▍| 171/182 [34:41<02:15, 12.35s/it, training_loss=0.082]\u001b[A\n",
            "Epoch 2:  95%|█████████▍| 172/182 [34:41<01:59, 11.90s/it, training_loss=0.082]\u001b[A\n",
            "Epoch 2:  95%|█████████▍| 172/182 [34:54<01:59, 11.90s/it, training_loss=0.134]\u001b[A\n",
            "Epoch 2:  95%|█████████▌| 173/182 [34:54<01:50, 12.32s/it, training_loss=0.134]\u001b[A\n",
            "Epoch 2:  95%|█████████▌| 173/182 [35:07<01:50, 12.32s/it, training_loss=0.223]\u001b[A\n",
            "Epoch 2:  96%|█████████▌| 174/182 [35:07<01:38, 12.31s/it, training_loss=0.223]\u001b[A\n",
            "Epoch 2:  96%|█████████▌| 174/182 [35:18<01:38, 12.31s/it, training_loss=0.153]\u001b[A\n",
            "Epoch 2:  96%|█████████▌| 175/182 [35:18<01:23, 11.89s/it, training_loss=0.153]\u001b[A\n",
            "Epoch 2:  96%|█████████▌| 175/182 [35:31<01:23, 11.89s/it, training_loss=0.142]\u001b[A\n",
            "Epoch 2:  97%|█████████▋| 176/182 [35:31<01:13, 12.31s/it, training_loss=0.142]\u001b[A\n",
            "Epoch 2:  97%|█████████▋| 176/182 [35:43<01:13, 12.31s/it, training_loss=0.150]\u001b[A\n",
            "Epoch 2:  97%|█████████▋| 177/182 [35:43<01:00, 12.17s/it, training_loss=0.150]\u001b[A\n",
            "Epoch 2:  97%|█████████▋| 177/182 [35:54<01:00, 12.17s/it, training_loss=0.089]\u001b[A\n",
            "Epoch 2:  98%|█████████▊| 178/182 [35:54<00:47, 11.93s/it, training_loss=0.089]\u001b[A\n",
            "Epoch 2:  98%|█████████▊| 178/182 [36:07<00:47, 11.93s/it, training_loss=0.219]\u001b[A\n",
            "Epoch 2:  98%|█████████▊| 179/182 [36:07<00:37, 12.34s/it, training_loss=0.219]\u001b[A\n",
            "Epoch 2:  98%|█████████▊| 179/182 [36:19<00:37, 12.34s/it, training_loss=0.209]\u001b[A\n",
            "Epoch 2:  99%|█████████▉| 180/182 [36:19<00:24, 12.11s/it, training_loss=0.209]\u001b[A\n",
            "Epoch 2:  99%|█████████▉| 180/182 [36:30<00:24, 12.11s/it, training_loss=0.223]\u001b[A\n",
            "Epoch 2:  99%|█████████▉| 181/182 [36:30<00:11, 11.90s/it, training_loss=0.223]\u001b[A\n",
            "Epoch 2:  99%|█████████▉| 181/182 [36:32<00:11, 11.90s/it, training_loss=0.291]\u001b[A\n",
            "Epoch 2: 100%|██████████| 182/182 [36:32<00:00,  8.95s/it, training_loss=0.291]\u001b[A\n",
            " 33%|███▎      | 1/3 [1:16:42<1:20:05, 2402.83s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            " Epoch {epoch}\n",
            "Training loss: {loss_train_avg}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "  0%|          | 0/46 [00:00<?, ?it/s]\u001b[A\n",
            "  2%|▏         | 1/46 [00:03<02:23,  3.18s/it]\u001b[A\n",
            "  4%|▍         | 2/46 [00:06<02:18,  3.14s/it]\u001b[A\n",
            "  7%|▋         | 3/46 [00:09<02:21,  3.30s/it]\u001b[A\n",
            "  9%|▊         | 4/46 [00:15<03:01,  4.33s/it]\u001b[A\n",
            " 11%|█         | 5/46 [00:20<02:58,  4.36s/it]\u001b[A\n",
            " 13%|█▎        | 6/46 [00:24<02:48,  4.22s/it]\u001b[A\n",
            " 15%|█▌        | 7/46 [00:28<02:52,  4.42s/it]\u001b[A\n",
            " 17%|█▋        | 8/46 [00:34<03:00,  4.74s/it]\u001b[A\n",
            " 20%|█▉        | 9/46 [00:38<02:51,  4.64s/it]\u001b[A\n",
            " 22%|██▏       | 10/46 [00:41<02:30,  4.18s/it]\u001b[A\n",
            " 24%|██▍       | 11/46 [00:45<02:15,  3.87s/it]\u001b[A\n",
            " 26%|██▌       | 12/46 [00:48<02:06,  3.71s/it]\u001b[A\n",
            " 28%|██▊       | 13/46 [00:53<02:17,  4.17s/it]\u001b[A\n",
            " 30%|███       | 14/46 [00:57<02:13,  4.17s/it]\u001b[A\n",
            " 33%|███▎      | 15/46 [01:00<01:59,  3.87s/it]\u001b[A\n",
            " 35%|███▍      | 16/46 [01:04<01:49,  3.65s/it]\u001b[A\n",
            " 37%|███▋      | 17/46 [01:07<01:45,  3.65s/it]\u001b[A\n",
            " 39%|███▉      | 18/46 [01:12<01:54,  4.10s/it]\u001b[A\n",
            " 41%|████▏     | 19/46 [01:16<01:49,  4.05s/it]\u001b[A\n",
            " 43%|████▎     | 20/46 [01:19<01:38,  3.78s/it]\u001b[A\n",
            " 46%|████▌     | 21/46 [01:23<01:29,  3.60s/it]\u001b[A\n",
            " 48%|████▊     | 22/46 [01:27<01:29,  3.71s/it]\u001b[A\n",
            " 50%|█████     | 23/46 [01:32<01:34,  4.12s/it]\u001b[A\n",
            " 52%|█████▏    | 24/46 [01:35<01:27,  3.96s/it]\u001b[A\n",
            " 54%|█████▍    | 25/46 [01:39<01:18,  3.75s/it]\u001b[A\n",
            " 57%|█████▋    | 26/46 [01:42<01:11,  3.58s/it]\u001b[A\n",
            " 59%|█████▊    | 27/46 [01:46<01:12,  3.81s/it]\u001b[A\n",
            " 61%|██████    | 28/46 [01:51<01:14,  4.15s/it]\u001b[A\n",
            " 63%|██████▎   | 29/46 [01:54<01:06,  3.92s/it]\u001b[A\n",
            " 65%|██████▌   | 30/46 [01:58<00:59,  3.69s/it]\u001b[A\n",
            " 67%|██████▋   | 31/46 [02:01<00:52,  3.53s/it]\u001b[A\n",
            " 70%|██████▉   | 32/46 [02:05<00:54,  3.86s/it]\u001b[A\n",
            " 72%|███████▏  | 33/46 [02:10<00:54,  4.16s/it]\u001b[A\n",
            " 74%|███████▍  | 34/46 [02:13<00:46,  3.87s/it]\u001b[A\n",
            " 76%|███████▌  | 35/46 [02:17<00:40,  3.65s/it]\u001b[A\n",
            " 78%|███████▊  | 36/46 [02:20<00:35,  3.50s/it]\u001b[A\n",
            " 80%|████████  | 37/46 [02:25<00:35,  3.94s/it]\u001b[A\n",
            " 83%|████████▎ | 38/46 [02:29<00:32,  4.12s/it]\u001b[A\n",
            " 85%|████████▍ | 39/46 [02:32<00:26,  3.84s/it]\u001b[A\n",
            " 87%|████████▋ | 40/46 [02:36<00:21,  3.63s/it]\u001b[A\n",
            " 89%|████████▉ | 41/46 [02:39<00:17,  3.51s/it]\u001b[A\n",
            " 91%|█████████▏| 42/46 [02:44<00:16,  4.01s/it]\u001b[A\n",
            " 93%|█████████▎| 43/46 [02:48<00:12,  4.10s/it]\u001b[A\n",
            " 96%|█████████▌| 44/46 [02:51<00:07,  3.81s/it]\u001b[A\n",
            " 98%|█████████▊| 45/46 [02:55<00:03,  3.62s/it]\u001b[A\n",
            "100%|██████████| 46/46 [02:56<00:00,  3.83s/it]\n",
            " 67%|██████▋   | 2/3 [1:19:39<39:47, 2387.19s/it]  "
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Validation loss: 0.47046577962844266\n",
            "F1 Score (weighted): 0.817587773983123\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "Epoch 3:   0%|          | 0/182 [00:00<?, ?it/s]\u001b[A\n",
            "Epoch 3:   0%|          | 0/182 [00:13<?, ?it/s, training_loss=0.162]\u001b[A\n",
            "Epoch 3:   1%|          | 1/182 [00:13<40:07, 13.30s/it, training_loss=0.162]\u001b[A\n",
            "Epoch 3:   1%|          | 1/182 [00:25<40:07, 13.30s/it, training_loss=0.125]\u001b[A\n",
            "Epoch 3:   1%|          | 2/182 [00:25<38:33, 12.86s/it, training_loss=0.125]\u001b[A\n",
            "Epoch 3:   1%|          | 2/182 [00:36<38:33, 12.86s/it, training_loss=0.171]\u001b[A\n",
            "Epoch 3:   2%|▏         | 3/182 [00:36<35:46, 11.99s/it, training_loss=0.171]\u001b[A\n",
            "Epoch 3:   2%|▏         | 3/182 [00:51<35:46, 11.99s/it, training_loss=0.186]\u001b[A\n",
            "Epoch 3:   2%|▏         | 4/182 [00:51<38:21, 12.93s/it, training_loss=0.186]\u001b[A\n",
            "Epoch 3:   2%|▏         | 4/182 [01:08<38:21, 12.93s/it, training_loss=0.160]\u001b[A\n",
            "Epoch 3:   3%|▎         | 5/182 [01:08<43:12, 14.64s/it, training_loss=0.160]\u001b[A\n",
            "Epoch 3:   3%|▎         | 5/182 [01:26<43:12, 14.64s/it, training_loss=0.165]\u001b[A\n",
            "Epoch 3:   3%|▎         | 6/182 [01:26<45:40, 15.57s/it, training_loss=0.165]\u001b[A\n",
            "Epoch 3:   3%|▎         | 6/182 [01:36<45:40, 15.57s/it, training_loss=0.237]\u001b[A\n",
            "Epoch 3:   4%|▍         | 7/182 [01:36<40:34, 13.91s/it, training_loss=0.237]\u001b[A\n",
            "Epoch 3:   4%|▍         | 7/182 [01:49<40:34, 13.91s/it, training_loss=0.173]\u001b[A\n",
            "Epoch 3:   4%|▍         | 8/182 [01:49<39:21, 13.57s/it, training_loss=0.173]\u001b[A\n",
            "Epoch 3:   4%|▍         | 8/182 [02:07<39:21, 13.57s/it, training_loss=0.273]\u001b[A\n",
            "Epoch 3:   5%|▍         | 9/182 [02:07<43:27, 15.07s/it, training_loss=0.273]\u001b[A\n",
            "Epoch 3:   5%|▍         | 9/182 [02:21<43:27, 15.07s/it, training_loss=0.084]\u001b[A\n",
            "Epoch 3:   5%|▌         | 10/182 [02:21<41:26, 14.46s/it, training_loss=0.084]\u001b[A\n",
            "Epoch 3:   5%|▌         | 10/182 [02:31<41:26, 14.46s/it, training_loss=0.149]\u001b[A\n",
            "Epoch 3:   6%|▌         | 11/182 [02:31<37:32, 13.17s/it, training_loss=0.149]\u001b[A\n",
            "Epoch 3:   6%|▌         | 11/182 [02:44<37:32, 13.17s/it, training_loss=0.125]\u001b[A\n",
            "Epoch 3:   7%|▋         | 12/182 [02:44<37:19, 13.18s/it, training_loss=0.125]\u001b[A\n",
            "Epoch 3:   7%|▋         | 12/182 [02:57<37:19, 13.18s/it, training_loss=0.256]\u001b[A\n",
            "Epoch 3:   7%|▋         | 13/182 [02:57<36:47, 13.06s/it, training_loss=0.256]\u001b[A\n",
            "Epoch 3:   7%|▋         | 13/182 [03:07<36:47, 13.06s/it, training_loss=0.117]\u001b[A\n",
            "Epoch 3:   8%|▊         | 14/182 [03:07<34:23, 12.29s/it, training_loss=0.117]\u001b[A\n",
            "Epoch 3:   8%|▊         | 14/182 [03:25<34:23, 12.29s/it, training_loss=0.086]\u001b[A\n",
            "Epoch 3:   8%|▊         | 15/182 [03:25<38:54, 13.98s/it, training_loss=0.086]\u001b[A\n",
            "Epoch 3:   8%|▊         | 15/182 [03:42<38:54, 13.98s/it, training_loss=0.157]\u001b[A\n",
            "Epoch 3:   9%|▉         | 16/182 [03:42<41:05, 14.85s/it, training_loss=0.157]\u001b[A\n",
            "Epoch 3:   9%|▉         | 16/182 [03:55<41:05, 14.85s/it, training_loss=0.091]\u001b[A\n",
            "Epoch 3:   9%|▉         | 17/182 [03:55<39:38, 14.41s/it, training_loss=0.091]\u001b[A\n",
            "Epoch 3:   9%|▉         | 17/182 [04:06<39:38, 14.41s/it, training_loss=0.117]\u001b[A\n",
            "Epoch 3:  10%|▉         | 18/182 [04:06<36:38, 13.41s/it, training_loss=0.117]\u001b[A\n",
            "Epoch 3:  10%|▉         | 18/182 [04:19<36:38, 13.41s/it, training_loss=0.108]\u001b[A\n",
            "Epoch 3:  10%|█         | 19/182 [04:19<35:20, 13.01s/it, training_loss=0.108]\u001b[A\n",
            "Epoch 3:  10%|█         | 19/182 [04:32<35:20, 13.01s/it, training_loss=0.281]\u001b[A\n",
            "Epoch 3:  11%|█         | 20/182 [04:32<35:26, 13.13s/it, training_loss=0.281]\u001b[A\n",
            "Epoch 3:  11%|█         | 20/182 [04:43<35:26, 13.13s/it, training_loss=0.092]\u001b[A\n",
            "Epoch 3:  12%|█▏        | 21/182 [04:43<33:19, 12.42s/it, training_loss=0.092]\u001b[A\n",
            "Epoch 3:  12%|█▏        | 21/182 [04:55<33:19, 12.42s/it, training_loss=0.120]\u001b[A\n",
            "Epoch 3:  12%|█▏        | 22/182 [04:55<32:59, 12.37s/it, training_loss=0.120]\u001b[A\n",
            "Epoch 3:  12%|█▏        | 22/182 [05:08<32:59, 12.37s/it, training_loss=0.069]\u001b[A\n",
            "Epoch 3:  13%|█▎        | 23/182 [05:08<33:31, 12.65s/it, training_loss=0.069]\u001b[A\n",
            "Epoch 3:  13%|█▎        | 23/182 [05:19<33:31, 12.65s/it, training_loss=0.057]\u001b[A\n",
            "Epoch 3:  13%|█▎        | 24/182 [05:19<31:26, 11.94s/it, training_loss=0.057]\u001b[A\n",
            "Epoch 3:  13%|█▎        | 24/182 [05:31<31:26, 11.94s/it, training_loss=0.099]\u001b[A\n",
            "Epoch 3:  14%|█▎        | 25/182 [05:31<31:59, 12.22s/it, training_loss=0.099]\u001b[A\n",
            "Epoch 3:  14%|█▎        | 25/182 [05:45<31:59, 12.22s/it, training_loss=0.148]\u001b[A\n",
            "Epoch 3:  14%|█▍        | 26/182 [05:45<32:34, 12.53s/it, training_loss=0.148]\u001b[A\n",
            "Epoch 3:  14%|█▍        | 26/182 [05:55<32:34, 12.53s/it, training_loss=0.144]\u001b[A\n",
            "Epoch 3:  15%|█▍        | 27/182 [05:55<30:37, 11.85s/it, training_loss=0.144]\u001b[A\n",
            "Epoch 3:  15%|█▍        | 27/182 [06:08<30:37, 11.85s/it, training_loss=0.053]\u001b[A\n",
            "Epoch 3:  15%|█▌        | 28/182 [06:08<31:25, 12.24s/it, training_loss=0.053]\u001b[A\n",
            "Epoch 3:  15%|█▌        | 28/182 [06:21<31:25, 12.24s/it, training_loss=0.253]\u001b[A\n",
            "Epoch 3:  16%|█▌        | 29/182 [06:21<31:58, 12.54s/it, training_loss=0.253]\u001b[A\n",
            "Epoch 3:  16%|█▌        | 29/182 [06:32<31:58, 12.54s/it, training_loss=0.205]\u001b[A\n",
            "Epoch 3:  16%|█▋        | 30/182 [06:32<30:04, 11.87s/it, training_loss=0.205]\u001b[A\n",
            "Epoch 3:  16%|█▋        | 30/182 [06:45<30:04, 11.87s/it, training_loss=0.124]\u001b[A\n",
            "Epoch 3:  17%|█▋        | 31/182 [06:45<30:56, 12.30s/it, training_loss=0.124]\u001b[A\n",
            "Epoch 3:  17%|█▋        | 31/182 [06:58<30:56, 12.30s/it, training_loss=0.209]\u001b[A\n",
            "Epoch 3:  18%|█▊        | 32/182 [06:58<31:12, 12.49s/it, training_loss=0.209]\u001b[A\n",
            "Epoch 3:  18%|█▊        | 32/182 [07:08<31:12, 12.49s/it, training_loss=0.123]\u001b[A\n",
            "Epoch 3:  18%|█▊        | 33/182 [07:08<29:26, 11.85s/it, training_loss=0.123]\u001b[A\n",
            "Epoch 3:  18%|█▊        | 33/182 [07:22<29:26, 11.85s/it, training_loss=0.121]\u001b[A\n",
            "Epoch 3:  19%|█▊        | 34/182 [07:22<30:15, 12.27s/it, training_loss=0.121]\u001b[A\n",
            "Epoch 3:  19%|█▊        | 34/182 [07:34<30:15, 12.27s/it, training_loss=0.047]\u001b[A\n",
            "Epoch 3:  19%|█▉        | 35/182 [07:34<30:18, 12.37s/it, training_loss=0.047]\u001b[A\n",
            "Epoch 3:  19%|█▉        | 35/182 [07:45<30:18, 12.37s/it, training_loss=0.105]\u001b[A\n",
            "Epoch 3:  20%|█▉        | 36/182 [07:45<28:49, 11.85s/it, training_loss=0.105]\u001b[A\n",
            "Epoch 3:  20%|█▉        | 36/182 [07:58<28:49, 11.85s/it, training_loss=0.117]\u001b[A\n",
            "Epoch 3:  20%|██        | 37/182 [07:58<29:41, 12.29s/it, training_loss=0.117]\u001b[A\n",
            "Epoch 3:  20%|██        | 37/182 [08:10<29:41, 12.29s/it, training_loss=0.123]\u001b[A\n",
            "Epoch 3:  21%|██        | 38/182 [08:10<29:32, 12.31s/it, training_loss=0.123]\u001b[A\n",
            "Epoch 3:  21%|██        | 38/182 [08:21<29:32, 12.31s/it, training_loss=0.220]\u001b[A\n",
            "Epoch 3:  21%|██▏       | 39/182 [08:21<28:23, 11.91s/it, training_loss=0.220]\u001b[A\n",
            "Epoch 3:  21%|██▏       | 39/182 [08:35<28:23, 11.91s/it, training_loss=0.077]\u001b[A\n",
            "Epoch 3:  22%|██▏       | 40/182 [08:35<29:12, 12.34s/it, training_loss=0.077]\u001b[A\n",
            "Epoch 3:  22%|██▏       | 40/182 [08:47<29:12, 12.34s/it, training_loss=0.078]\u001b[A\n",
            "Epoch 3:  23%|██▎       | 41/182 [08:47<28:52, 12.28s/it, training_loss=0.078]\u001b[A\n",
            "Epoch 3:  23%|██▎       | 41/182 [08:58<28:52, 12.28s/it, training_loss=0.111]\u001b[A\n",
            "Epoch 3:  23%|██▎       | 42/182 [08:58<27:49, 11.92s/it, training_loss=0.111]\u001b[A\n",
            "Epoch 3:  23%|██▎       | 42/182 [09:11<27:49, 11.92s/it, training_loss=0.106]\u001b[A\n",
            "Epoch 3:  24%|██▎       | 43/182 [09:11<28:32, 12.32s/it, training_loss=0.106]\u001b[A\n",
            "Epoch 3:  24%|██▎       | 43/182 [09:23<28:32, 12.32s/it, training_loss=0.055]\u001b[A\n",
            "Epoch 3:  24%|██▍       | 44/182 [09:23<27:56, 12.15s/it, training_loss=0.055]\u001b[A\n",
            "Epoch 3:  24%|██▍       | 44/182 [09:34<27:56, 12.15s/it, training_loss=0.165]\u001b[A\n",
            "Epoch 3:  25%|██▍       | 45/182 [09:34<27:09, 11.89s/it, training_loss=0.165]\u001b[A\n",
            "Epoch 3:  25%|██▍       | 45/182 [09:48<27:09, 11.89s/it, training_loss=0.101]\u001b[A\n",
            "Epoch 3:  25%|██▌       | 46/182 [09:48<27:52, 12.30s/it, training_loss=0.101]\u001b[A\n",
            "Epoch 3:  25%|██▌       | 46/182 [09:59<27:52, 12.30s/it, training_loss=0.163]\u001b[A\n",
            "Epoch 3:  26%|██▌       | 47/182 [09:59<27:02, 12.02s/it, training_loss=0.163]\u001b[A\n",
            "Epoch 3:  26%|██▌       | 47/182 [10:11<27:02, 12.02s/it, training_loss=0.105]\u001b[A\n",
            "Epoch 3:  26%|██▋       | 48/182 [10:11<26:35, 11.91s/it, training_loss=0.105]\u001b[A\n",
            "Epoch 3:  26%|██▋       | 48/182 [10:24<26:35, 11.91s/it, training_loss=0.115]\u001b[A\n",
            "Epoch 3:  27%|██▋       | 49/182 [10:24<27:20, 12.33s/it, training_loss=0.115]\u001b[A\n",
            "Epoch 3:  27%|██▋       | 49/182 [10:35<27:20, 12.33s/it, training_loss=0.069]\u001b[A\n",
            "Epoch 3:  27%|██▋       | 50/182 [10:35<26:19, 11.97s/it, training_loss=0.069]\u001b[A\n",
            "Epoch 3:  27%|██▋       | 50/182 [10:47<26:19, 11.97s/it, training_loss=0.050]\u001b[A\n",
            "Epoch 3:  28%|██▊       | 51/182 [10:47<26:15, 12.03s/it, training_loss=0.050]\u001b[A\n",
            "Epoch 3:  28%|██▊       | 51/182 [11:00<26:15, 12.03s/it, training_loss=0.053]\u001b[A\n",
            "Epoch 3:  29%|██▊       | 52/182 [11:00<26:52, 12.41s/it, training_loss=0.053]\u001b[A\n",
            "Epoch 3:  29%|██▊       | 52/182 [11:11<26:52, 12.41s/it, training_loss=0.048]\u001b[A\n",
            "Epoch 3:  29%|██▉       | 53/182 [11:11<25:37, 11.92s/it, training_loss=0.048]\u001b[A\n",
            "Epoch 3:  29%|██▉       | 53/182 [11:23<25:37, 11.92s/it, training_loss=0.136]\u001b[A\n",
            "Epoch 3:  30%|██▉       | 54/182 [11:23<25:36, 12.01s/it, training_loss=0.136]\u001b[A\n",
            "Epoch 3:  30%|██▉       | 54/182 [11:37<25:36, 12.01s/it, training_loss=0.075]\u001b[A\n",
            "Epoch 3:  30%|███       | 55/182 [11:37<26:11, 12.37s/it, training_loss=0.075]\u001b[A\n",
            "Epoch 3:  30%|███       | 55/182 [11:47<26:11, 12.37s/it, training_loss=0.085]\u001b[A\n",
            "Epoch 3:  31%|███       | 56/182 [11:47<24:52, 11.85s/it, training_loss=0.085]\u001b[A\n",
            "Epoch 3:  31%|███       | 56/182 [12:00<24:52, 11.85s/it, training_loss=0.150]\u001b[A\n",
            "Epoch 3:  31%|███▏      | 57/182 [12:00<25:00, 12.01s/it, training_loss=0.150]\u001b[A\n",
            "Epoch 3:  31%|███▏      | 57/182 [12:13<25:00, 12.01s/it, training_loss=0.177]\u001b[A\n",
            "Epoch 3:  32%|███▏      | 58/182 [12:13<25:37, 12.40s/it, training_loss=0.177]\u001b[A\n",
            "Epoch 3:  32%|███▏      | 58/182 [12:23<25:37, 12.40s/it, training_loss=0.207]\u001b[A\n",
            "Epoch 3:  32%|███▏      | 59/182 [12:23<24:13, 11.82s/it, training_loss=0.207]\u001b[A\n",
            "Epoch 3:  32%|███▏      | 59/182 [12:36<24:13, 11.82s/it, training_loss=0.159]\u001b[A\n",
            "Epoch 3:  33%|███▎      | 60/182 [12:36<24:27, 12.03s/it, training_loss=0.159]\u001b[A\n",
            "Epoch 3:  33%|███▎      | 60/182 [12:49<24:27, 12.03s/it, training_loss=0.067]\u001b[A\n",
            "Epoch 3:  34%|███▎      | 61/182 [12:49<24:57, 12.37s/it, training_loss=0.067]\u001b[A\n",
            "Epoch 3:  34%|███▎      | 61/182 [12:59<24:57, 12.37s/it, training_loss=0.127]\u001b[A\n",
            "Epoch 3:  34%|███▍      | 62/182 [12:59<23:23, 11.70s/it, training_loss=0.127]\u001b[A\n",
            "Epoch 3:  34%|███▍      | 62/182 [13:12<23:23, 11.70s/it, training_loss=0.138]\u001b[A\n",
            "Epoch 3:  35%|███▍      | 63/182 [13:12<23:54, 12.05s/it, training_loss=0.138]\u001b[A\n",
            "Epoch 3:  35%|███▍      | 63/182 [13:25<23:54, 12.05s/it, training_loss=0.065]\u001b[A\n",
            "Epoch 3:  35%|███▌      | 64/182 [13:25<24:21, 12.39s/it, training_loss=0.065]\u001b[A\n",
            "Epoch 3:  35%|███▌      | 64/182 [13:35<24:21, 12.39s/it, training_loss=0.348]\u001b[A\n",
            "Epoch 3:  36%|███▌      | 65/182 [13:35<22:47, 11.68s/it, training_loss=0.348]\u001b[A\n",
            "Epoch 3:  36%|███▌      | 65/182 [13:49<22:47, 11.68s/it, training_loss=0.168]\u001b[A\n",
            "Epoch 3:  36%|███▋      | 66/182 [13:49<23:28, 12.15s/it, training_loss=0.168]\u001b[A\n",
            "Epoch 3:  36%|███▋      | 66/182 [14:01<23:28, 12.15s/it, training_loss=0.075]\u001b[A\n",
            "Epoch 3:  37%|███▋      | 67/182 [14:02<23:45, 12.39s/it, training_loss=0.075]\u001b[A\n",
            "Epoch 3:  37%|███▋      | 67/182 [14:12<23:45, 12.39s/it, training_loss=0.143]\u001b[A\n",
            "Epoch 3:  37%|███▋      | 68/182 [14:12<22:22, 11.77s/it, training_loss=0.143]\u001b[A\n",
            "Epoch 3:  37%|███▋      | 68/182 [14:25<22:22, 11.77s/it, training_loss=0.055]\u001b[A\n",
            "Epoch 3:  38%|███▊      | 69/182 [14:25<23:03, 12.24s/it, training_loss=0.055]\u001b[A\n",
            "Epoch 3:  38%|███▊      | 69/182 [14:38<23:03, 12.24s/it, training_loss=0.083]\u001b[A\n",
            "Epoch 3:  38%|███▊      | 70/182 [14:38<23:12, 12.43s/it, training_loss=0.083]\u001b[A\n",
            "Epoch 3:  38%|███▊      | 70/182 [14:50<23:12, 12.43s/it, training_loss=0.154]\u001b[A\n",
            "Epoch 3:  39%|███▉      | 71/182 [14:50<22:32, 12.18s/it, training_loss=0.154]\u001b[A\n",
            "Epoch 3:  39%|███▉      | 71/182 [15:03<22:32, 12.18s/it, training_loss=0.120]\u001b[A\n",
            "Epoch 3:  40%|███▉      | 72/182 [15:03<22:50, 12.46s/it, training_loss=0.120]\u001b[A\n",
            "Epoch 3:  40%|███▉      | 72/182 [15:16<22:50, 12.46s/it, training_loss=0.084]\u001b[A\n",
            "Epoch 3:  40%|████      | 73/182 [15:16<22:51, 12.58s/it, training_loss=0.084]\u001b[A\n",
            "Epoch 3:  40%|████      | 73/182 [15:26<22:51, 12.58s/it, training_loss=0.078]\u001b[A\n",
            "Epoch 3:  41%|████      | 74/182 [15:26<21:24, 11.89s/it, training_loss=0.078]\u001b[A\n",
            "Epoch 3:  41%|████      | 74/182 [15:39<21:24, 11.89s/it, training_loss=0.045]\u001b[A\n",
            "Epoch 3:  41%|████      | 75/182 [15:39<21:54, 12.28s/it, training_loss=0.045]\u001b[A\n",
            "Epoch 3:  41%|████      | 75/182 [15:52<21:54, 12.28s/it, training_loss=0.297]\u001b[A\n",
            "Epoch 3:  42%|████▏     | 76/182 [15:52<21:51, 12.38s/it, training_loss=0.297]\u001b[A\n",
            "Epoch 3:  42%|████▏     | 76/182 [16:02<21:51, 12.38s/it, training_loss=0.080]\u001b[A\n",
            "Epoch 3:  42%|████▏     | 77/182 [16:02<20:46, 11.87s/it, training_loss=0.080]\u001b[A\n",
            "Epoch 3:  42%|████▏     | 77/182 [16:16<20:46, 11.87s/it, training_loss=0.107]\u001b[A\n",
            "Epoch 3:  43%|████▎     | 78/182 [16:16<21:18, 12.30s/it, training_loss=0.107]\u001b[A\n",
            "Epoch 3:  43%|████▎     | 78/182 [16:28<21:18, 12.30s/it, training_loss=0.140]\u001b[A\n",
            "Epoch 3:  43%|████▎     | 79/182 [16:28<21:11, 12.34s/it, training_loss=0.140]\u001b[A\n",
            "Epoch 3:  43%|████▎     | 79/182 [16:39<21:11, 12.34s/it, training_loss=0.111]\u001b[A\n",
            "Epoch 3:  44%|████▍     | 80/182 [16:39<20:10, 11.86s/it, training_loss=0.111]\u001b[A\n",
            "Epoch 3:  44%|████▍     | 80/182 [16:52<20:10, 11.86s/it, training_loss=0.105]\u001b[A\n",
            "Epoch 3:  45%|████▍     | 81/182 [16:52<20:39, 12.27s/it, training_loss=0.105]\u001b[A\n",
            "Epoch 3:  45%|████▍     | 81/182 [17:04<20:39, 12.27s/it, training_loss=0.079]\u001b[A\n",
            "Epoch 3:  45%|████▌     | 82/182 [17:04<20:22, 12.23s/it, training_loss=0.079]\u001b[A\n",
            "Epoch 3:  45%|████▌     | 82/182 [17:15<20:22, 12.23s/it, training_loss=0.111]\u001b[A\n",
            "Epoch 3:  46%|████▌     | 83/182 [17:15<19:34, 11.86s/it, training_loss=0.111]\u001b[A\n",
            "Epoch 3:  46%|████▌     | 83/182 [17:28<19:34, 11.86s/it, training_loss=0.121]\u001b[A\n",
            "Epoch 3:  46%|████▌     | 84/182 [17:28<20:03, 12.28s/it, training_loss=0.121]\u001b[A\n",
            "Epoch 3:  46%|████▌     | 84/182 [17:40<20:03, 12.28s/it, training_loss=0.082]\u001b[A\n",
            "Epoch 3:  47%|████▋     | 85/182 [17:40<19:33, 12.10s/it, training_loss=0.082]\u001b[A\n",
            "Epoch 3:  47%|████▋     | 85/182 [17:51<19:33, 12.10s/it, training_loss=0.117]\u001b[A\n",
            "Epoch 3:  47%|████▋     | 86/182 [17:52<18:59, 11.87s/it, training_loss=0.117]\u001b[A\n",
            "Epoch 3:  47%|████▋     | 86/182 [18:05<18:59, 11.87s/it, training_loss=0.254]\u001b[A\n",
            "Epoch 3:  48%|████▊     | 87/182 [18:05<19:29, 12.32s/it, training_loss=0.254]\u001b[A\n",
            "Epoch 3:  48%|████▊     | 87/182 [18:16<19:29, 12.32s/it, training_loss=0.081]\u001b[A\n",
            "Epoch 3:  48%|████▊     | 88/182 [18:16<18:53, 12.06s/it, training_loss=0.081]\u001b[A\n",
            "Epoch 3:  48%|████▊     | 88/182 [18:28<18:53, 12.06s/it, training_loss=0.043]\u001b[A\n",
            "Epoch 3:  49%|████▉     | 89/182 [18:28<18:28, 11.92s/it, training_loss=0.043]\u001b[A\n",
            "Epoch 3:  49%|████▉     | 89/182 [18:41<18:28, 11.92s/it, training_loss=0.114]\u001b[A\n",
            "Epoch 3:  49%|████▉     | 90/182 [18:41<18:53, 12.32s/it, training_loss=0.114]\u001b[A\n",
            "Epoch 3:  49%|████▉     | 90/182 [18:52<18:53, 12.32s/it, training_loss=0.123]\u001b[A\n",
            "Epoch 3:  50%|█████     | 91/182 [18:52<18:09, 11.97s/it, training_loss=0.123]\u001b[A\n",
            "Epoch 3:  50%|█████     | 91/182 [19:04<18:09, 11.97s/it, training_loss=0.077]\u001b[A\n",
            "Epoch 3:  51%|█████     | 92/182 [19:04<17:54, 11.94s/it, training_loss=0.077]\u001b[A\n",
            "Epoch 3:  51%|█████     | 92/182 [19:17<17:54, 11.94s/it, training_loss=0.054]\u001b[A\n",
            "Epoch 3:  51%|█████     | 93/182 [19:17<18:17, 12.34s/it, training_loss=0.054]\u001b[A\n",
            "Epoch 3:  51%|█████     | 93/182 [19:28<18:17, 12.34s/it, training_loss=0.132]\u001b[A\n",
            "Epoch 3:  52%|█████▏    | 94/182 [19:28<17:25, 11.88s/it, training_loss=0.132]\u001b[A\n",
            "Epoch 3:  52%|█████▏    | 94/182 [19:41<17:25, 11.88s/it, training_loss=0.055]\u001b[A\n",
            "Epoch 3:  52%|█████▏    | 95/182 [19:41<17:23, 11.99s/it, training_loss=0.055]\u001b[A\n",
            "Epoch 3:  52%|█████▏    | 95/182 [19:54<17:23, 11.99s/it, training_loss=0.140]\u001b[A\n",
            "Epoch 3:  53%|█████▎    | 96/182 [19:54<17:46, 12.40s/it, training_loss=0.140]\u001b[A\n",
            "Epoch 3:  53%|█████▎    | 96/182 [20:04<17:46, 12.40s/it, training_loss=0.130]\u001b[A\n",
            "Epoch 3:  53%|█████▎    | 97/182 [20:04<16:48, 11.87s/it, training_loss=0.130]\u001b[A\n",
            "Epoch 3:  53%|█████▎    | 97/182 [20:17<16:48, 11.87s/it, training_loss=0.146]\u001b[A\n",
            "Epoch 3:  54%|█████▍    | 98/182 [20:17<16:52, 12.05s/it, training_loss=0.146]\u001b[A\n",
            "Epoch 3:  54%|█████▍    | 98/182 [20:30<16:52, 12.05s/it, training_loss=0.108]\u001b[A\n",
            "Epoch 3:  54%|█████▍    | 99/182 [20:30<17:10, 12.42s/it, training_loss=0.108]\u001b[A\n",
            "Epoch 3:  54%|█████▍    | 99/182 [20:40<17:10, 12.42s/it, training_loss=0.051]\u001b[A\n",
            "Epoch 3:  55%|█████▍    | 100/182 [20:40<16:01, 11.72s/it, training_loss=0.051]\u001b[A\n",
            "Epoch 3:  55%|█████▍    | 100/182 [20:53<16:01, 11.72s/it, training_loss=0.068]\u001b[A\n",
            "Epoch 3:  55%|█████▌    | 101/182 [20:53<16:16, 12.05s/it, training_loss=0.068]\u001b[A\n",
            "Epoch 3:  55%|█████▌    | 101/182 [21:06<16:16, 12.05s/it, training_loss=0.305]\u001b[A\n",
            "Epoch 3:  56%|█████▌    | 102/182 [21:06<16:28, 12.35s/it, training_loss=0.305]\u001b[A\n",
            "Epoch 3:  56%|█████▌    | 102/182 [21:16<16:28, 12.35s/it, training_loss=0.131]\u001b[A\n",
            "Epoch 3:  57%|█████▋    | 103/182 [21:16<15:18, 11.63s/it, training_loss=0.131]\u001b[A\n",
            "Epoch 3:  57%|█████▋    | 103/182 [21:29<15:18, 11.63s/it, training_loss=0.150]\u001b[A\n",
            "Epoch 3:  57%|█████▋    | 104/182 [21:29<15:43, 12.10s/it, training_loss=0.150]\u001b[A\n",
            "Epoch 3:  57%|█████▋    | 104/182 [21:42<15:43, 12.10s/it, training_loss=0.203]\u001b[A\n",
            "Epoch 3:  58%|█████▊    | 105/182 [21:42<15:48, 12.31s/it, training_loss=0.203]\u001b[A\n",
            "Epoch 3:  58%|█████▊    | 105/182 [21:53<15:48, 12.31s/it, training_loss=0.085]\u001b[A\n",
            "Epoch 3:  58%|█████▊    | 106/182 [21:53<14:51, 11.72s/it, training_loss=0.085]\u001b[A\n",
            "Epoch 3:  58%|█████▊    | 106/182 [22:06<14:51, 11.72s/it, training_loss=0.088]\u001b[A\n",
            "Epoch 3:  59%|█████▉    | 107/182 [22:06<15:13, 12.17s/it, training_loss=0.088]\u001b[A\n",
            "Epoch 3:  59%|█████▉    | 107/182 [22:18<15:13, 12.17s/it, training_loss=0.372]\u001b[A\n",
            "Epoch 3:  59%|█████▉    | 108/182 [22:18<15:08, 12.28s/it, training_loss=0.372]\u001b[A\n",
            "Epoch 3:  59%|█████▉    | 108/182 [22:29<15:08, 12.28s/it, training_loss=0.138]\u001b[A\n",
            "Epoch 3:  60%|█████▉    | 109/182 [22:29<14:21, 11.81s/it, training_loss=0.138]\u001b[A\n",
            "Epoch 3:  60%|█████▉    | 109/182 [22:42<14:21, 11.81s/it, training_loss=0.191]\u001b[A\n",
            "Epoch 3:  60%|██████    | 110/182 [22:42<14:40, 12.22s/it, training_loss=0.191]\u001b[A\n",
            "Epoch 3:  60%|██████    | 110/182 [22:55<14:40, 12.22s/it, training_loss=0.106]\u001b[A\n",
            "Epoch 3:  61%|██████    | 111/182 [22:55<14:30, 12.26s/it, training_loss=0.106]\u001b[A\n",
            "Epoch 3:  61%|██████    | 111/182 [23:05<14:30, 12.26s/it, training_loss=0.082]\u001b[A\n",
            "Epoch 3:  62%|██████▏   | 112/182 [23:05<13:49, 11.85s/it, training_loss=0.082]\u001b[A\n",
            "Epoch 3:  62%|██████▏   | 112/182 [23:19<13:49, 11.85s/it, training_loss=0.068]\u001b[A\n",
            "Epoch 3:  62%|██████▏   | 113/182 [23:19<14:06, 12.27s/it, training_loss=0.068]\u001b[A\n",
            "Epoch 3:  62%|██████▏   | 113/182 [23:31<14:06, 12.27s/it, training_loss=0.089]\u001b[A\n",
            "Epoch 3:  63%|██████▎   | 114/182 [23:31<13:52, 12.24s/it, training_loss=0.089]\u001b[A\n",
            "Epoch 3:  63%|██████▎   | 114/182 [23:42<13:52, 12.24s/it, training_loss=0.054]\u001b[A\n",
            "Epoch 3:  63%|██████▎   | 115/182 [23:42<13:17, 11.91s/it, training_loss=0.054]\u001b[A\n",
            "Epoch 3:  63%|██████▎   | 115/182 [23:55<13:17, 11.91s/it, training_loss=0.274]\u001b[A\n",
            "Epoch 3:  64%|██████▎   | 116/182 [23:55<13:32, 12.32s/it, training_loss=0.274]\u001b[A\n",
            "Epoch 3:  64%|██████▎   | 116/182 [24:07<13:32, 12.32s/it, training_loss=0.095]\u001b[A\n",
            "Epoch 3:  64%|██████▍   | 117/182 [24:07<13:08, 12.13s/it, training_loss=0.095]\u001b[A\n",
            "Epoch 3:  64%|██████▍   | 117/182 [24:18<13:08, 12.13s/it, training_loss=0.072]\u001b[A\n",
            "Epoch 3:  65%|██████▍   | 118/182 [24:18<12:41, 11.90s/it, training_loss=0.072]\u001b[A\n",
            "Epoch 3:  65%|██████▍   | 118/182 [24:32<12:41, 11.90s/it, training_loss=0.164]\u001b[A\n",
            "Epoch 3:  65%|██████▌   | 119/182 [24:32<12:57, 12.34s/it, training_loss=0.164]\u001b[A\n",
            "Epoch 3:  65%|██████▌   | 119/182 [24:43<12:57, 12.34s/it, training_loss=0.091]\u001b[A\n",
            "Epoch 3:  66%|██████▌   | 120/182 [24:43<12:27, 12.05s/it, training_loss=0.091]\u001b[A\n",
            "Epoch 3:  66%|██████▌   | 120/182 [24:55<12:27, 12.05s/it, training_loss=0.068]\u001b[A\n",
            "Epoch 3:  66%|██████▋   | 121/182 [24:55<12:06, 11.92s/it, training_loss=0.068]\u001b[A\n",
            "Epoch 3:  66%|██████▋   | 121/182 [25:08<12:06, 11.92s/it, training_loss=0.203]\u001b[A\n",
            "Epoch 3:  67%|██████▋   | 122/182 [25:08<12:19, 12.33s/it, training_loss=0.203]\u001b[A\n",
            "Epoch 3:  67%|██████▋   | 122/182 [25:19<12:19, 12.33s/it, training_loss=0.047]\u001b[A\n",
            "Epoch 3:  68%|██████▊   | 123/182 [25:19<11:48, 12.01s/it, training_loss=0.047]\u001b[A\n",
            "Epoch 3:  68%|██████▊   | 123/182 [25:31<11:48, 12.01s/it, training_loss=0.058]\u001b[A\n",
            "Epoch 3:  68%|██████▊   | 124/182 [25:31<11:34, 11.97s/it, training_loss=0.058]\u001b[A\n",
            "Epoch 3:  68%|██████▊   | 124/182 [25:44<11:34, 11.97s/it, training_loss=0.073]\u001b[A\n",
            "Epoch 3:  69%|██████▊   | 125/182 [25:44<11:45, 12.38s/it, training_loss=0.073]\u001b[A\n",
            "Epoch 3:  69%|██████▊   | 125/182 [25:55<11:45, 12.38s/it, training_loss=0.105]\u001b[A\n",
            "Epoch 3:  69%|██████▉   | 126/182 [25:56<11:11, 12.00s/it, training_loss=0.105]\u001b[A\n",
            "Epoch 3:  69%|██████▉   | 126/182 [26:08<11:11, 12.00s/it, training_loss=0.086]\u001b[A\n",
            "Epoch 3:  70%|██████▉   | 127/182 [26:08<11:01, 12.03s/it, training_loss=0.086]\u001b[A\n",
            "Epoch 3:  70%|██████▉   | 127/182 [26:21<11:01, 12.03s/it, training_loss=0.132]\u001b[A\n",
            "Epoch 3:  70%|███████   | 128/182 [26:21<11:11, 12.43s/it, training_loss=0.132]\u001b[A\n",
            "Epoch 3:  70%|███████   | 128/182 [26:32<11:11, 12.43s/it, training_loss=0.222]\u001b[A\n",
            "Epoch 3:  71%|███████   | 129/182 [26:32<10:31, 11.92s/it, training_loss=0.222]\u001b[A\n",
            "Epoch 3:  71%|███████   | 129/182 [26:44<10:31, 11.92s/it, training_loss=0.229]\u001b[A\n",
            "Epoch 3:  71%|███████▏  | 130/182 [26:44<10:25, 12.02s/it, training_loss=0.229]\u001b[A\n",
            "Epoch 3:  71%|███████▏  | 130/182 [26:57<10:25, 12.02s/it, training_loss=0.096]\u001b[A\n",
            "Epoch 3:  72%|███████▏  | 131/182 [26:57<10:32, 12.40s/it, training_loss=0.096]\u001b[A\n",
            "Epoch 3:  72%|███████▏  | 131/182 [27:08<10:32, 12.40s/it, training_loss=0.161]\u001b[A\n",
            "Epoch 3:  73%|███████▎  | 132/182 [27:08<09:48, 11.77s/it, training_loss=0.161]\u001b[A\n",
            "Epoch 3:  73%|███████▎  | 132/182 [27:20<09:48, 11.77s/it, training_loss=0.076]\u001b[A\n",
            "Epoch 3:  73%|███████▎  | 133/182 [27:20<09:48, 12.02s/it, training_loss=0.076]\u001b[A\n",
            "Epoch 3:  73%|███████▎  | 133/182 [27:33<09:48, 12.02s/it, training_loss=0.106]\u001b[A\n",
            "Epoch 3:  74%|███████▎  | 134/182 [27:33<09:54, 12.38s/it, training_loss=0.106]\u001b[A\n",
            "Epoch 3:  74%|███████▎  | 134/182 [27:43<09:54, 12.38s/it, training_loss=0.074]\u001b[A\n",
            "Epoch 3:  74%|███████▍  | 135/182 [27:43<09:08, 11.68s/it, training_loss=0.074]\u001b[A\n",
            "Epoch 3:  74%|███████▍  | 135/182 [27:57<09:08, 11.68s/it, training_loss=0.258]\u001b[A\n",
            "Epoch 3:  75%|███████▍  | 136/182 [27:57<09:18, 12.14s/it, training_loss=0.258]\u001b[A\n",
            "Epoch 3:  75%|███████▍  | 136/182 [28:10<09:18, 12.14s/it, training_loss=0.175]\u001b[A\n",
            "Epoch 3:  75%|███████▌  | 137/182 [28:10<09:16, 12.37s/it, training_loss=0.175]\u001b[A\n",
            "Epoch 3:  75%|███████▌  | 137/182 [28:20<09:16, 12.37s/it, training_loss=0.277]\u001b[A\n",
            "Epoch 3:  76%|███████▌  | 138/182 [28:20<08:37, 11.76s/it, training_loss=0.277]\u001b[A\n",
            "Epoch 3:  76%|███████▌  | 138/182 [28:33<08:37, 11.76s/it, training_loss=0.154]\u001b[A\n",
            "Epoch 3:  76%|███████▋  | 139/182 [28:33<08:45, 12.23s/it, training_loss=0.154]\u001b[A\n",
            "Epoch 3:  76%|███████▋  | 139/182 [28:46<08:45, 12.23s/it, training_loss=0.173]\u001b[A\n",
            "Epoch 3:  77%|███████▋  | 140/182 [28:46<08:38, 12.35s/it, training_loss=0.173]\u001b[A\n",
            "Epoch 3:  77%|███████▋  | 140/182 [28:56<08:38, 12.35s/it, training_loss=0.039]\u001b[A\n",
            "Epoch 3:  77%|███████▋  | 141/182 [28:56<08:03, 11.80s/it, training_loss=0.039]\u001b[A\n",
            "Epoch 3:  77%|███████▋  | 141/182 [29:10<08:03, 11.80s/it, training_loss=0.044]\u001b[A\n",
            "Epoch 3:  78%|███████▊  | 142/182 [29:10<08:08, 12.22s/it, training_loss=0.044]\u001b[A\n",
            "Epoch 3:  78%|███████▊  | 142/182 [29:22<08:08, 12.22s/it, training_loss=0.121]\u001b[A\n",
            "Epoch 3:  79%|███████▊  | 143/182 [29:22<07:57, 12.23s/it, training_loss=0.121]\u001b[A\n",
            "Epoch 3:  79%|███████▊  | 143/182 [29:33<07:57, 12.23s/it, training_loss=0.063]\u001b[A\n",
            "Epoch 3:  79%|███████▉  | 144/182 [29:33<07:29, 11.82s/it, training_loss=0.063]\u001b[A\n",
            "Epoch 3:  79%|███████▉  | 144/182 [29:46<07:29, 11.82s/it, training_loss=0.085]\u001b[A\n",
            "Epoch 3:  80%|███████▉  | 145/182 [29:46<07:32, 12.24s/it, training_loss=0.085]\u001b[A\n",
            "Epoch 3:  80%|███████▉  | 145/182 [29:58<07:32, 12.24s/it, training_loss=0.047]\u001b[A\n",
            "Epoch 3:  80%|████████  | 146/182 [29:58<07:17, 12.16s/it, training_loss=0.047]\u001b[A\n",
            "Epoch 3:  80%|████████  | 146/182 [30:27<07:17, 12.16s/it, training_loss=0.084]\u001b[A\n",
            "Epoch 3:  81%|████████  | 147/182 [30:27<09:59, 17.12s/it, training_loss=0.084]\u001b[A\n",
            "Epoch 3:  81%|████████  | 147/182 [30:39<09:59, 17.12s/it, training_loss=0.110]\u001b[A\n",
            "Epoch 3:  81%|████████▏ | 148/182 [30:39<08:54, 15.71s/it, training_loss=0.110]\u001b[A\n",
            "Epoch 3:  81%|████████▏ | 148/182 [30:50<08:54, 15.71s/it, training_loss=0.048]\u001b[A\n",
            "Epoch 3:  82%|████████▏ | 149/182 [30:50<07:50, 14.26s/it, training_loss=0.048]\u001b[A\n",
            "Epoch 3:  82%|████████▏ | 149/182 [31:03<07:50, 14.26s/it, training_loss=0.046]\u001b[A\n",
            "Epoch 3:  82%|████████▏ | 150/182 [31:03<07:26, 13.94s/it, training_loss=0.046]\u001b[A\n",
            "Epoch 3:  82%|████████▏ | 150/182 [31:15<07:26, 13.94s/it, training_loss=0.282]\u001b[A\n",
            "Epoch 3:  83%|████████▎ | 151/182 [31:15<06:53, 13.34s/it, training_loss=0.282]\u001b[A\n",
            "Epoch 3:  83%|████████▎ | 151/182 [31:41<06:53, 13.34s/it, training_loss=0.136]\u001b[A\n",
            "Epoch 3:  84%|████████▎ | 152/182 [31:41<08:33, 17.11s/it, training_loss=0.136]\u001b[A\n",
            "Epoch 3:  84%|████████▎ | 152/182 [31:55<08:33, 17.11s/it, training_loss=0.110]\u001b[A\n",
            "Epoch 3:  84%|████████▍ | 153/182 [31:55<07:51, 16.27s/it, training_loss=0.110]\u001b[A\n",
            "Epoch 3:  84%|████████▍ | 153/182 [32:06<07:51, 16.27s/it, training_loss=0.096]\u001b[A\n",
            "Epoch 3:  85%|████████▍ | 154/182 [32:06<06:47, 14.54s/it, training_loss=0.096]\u001b[A\n",
            "Epoch 3:  85%|████████▍ | 154/182 [32:19<06:47, 14.54s/it, training_loss=0.236]\u001b[A\n",
            "Epoch 3:  85%|████████▌ | 155/182 [32:19<06:21, 14.15s/it, training_loss=0.236]\u001b[A\n",
            "Epoch 3:  85%|████████▌ | 155/182 [32:31<06:21, 14.15s/it, training_loss=0.114]\u001b[A\n",
            "Epoch 3:  86%|████████▌ | 156/182 [32:31<05:54, 13.65s/it, training_loss=0.114]\u001b[A\n",
            "Epoch 3:  86%|████████▌ | 156/182 [32:42<05:54, 13.65s/it, training_loss=0.280]\u001b[A\n",
            "Epoch 3:  86%|████████▋ | 157/182 [32:42<05:19, 12.78s/it, training_loss=0.280]\u001b[A\n",
            "Epoch 3:  86%|████████▋ | 157/182 [32:55<05:19, 12.78s/it, training_loss=0.121]\u001b[A\n",
            "Epoch 3:  87%|████████▋ | 158/182 [32:55<05:10, 12.94s/it, training_loss=0.121]\u001b[A\n",
            "Epoch 3:  87%|████████▋ | 158/182 [33:08<05:10, 12.94s/it, training_loss=0.224]\u001b[A\n",
            "Epoch 3:  87%|████████▋ | 159/182 [33:08<04:53, 12.78s/it, training_loss=0.224]\u001b[A\n",
            "Epoch 3:  87%|████████▋ | 159/182 [33:23<04:53, 12.78s/it, training_loss=0.037]\u001b[A\n",
            "Epoch 3:  88%|████████▊ | 160/182 [33:23<04:58, 13.55s/it, training_loss=0.037]\u001b[A\n",
            "Epoch 3:  88%|████████▊ | 160/182 [33:44<04:58, 13.55s/it, training_loss=0.280]\u001b[A\n",
            "Epoch 3:  88%|████████▊ | 161/182 [33:44<05:29, 15.70s/it, training_loss=0.280]\u001b[A\n",
            "Epoch 3:  88%|████████▊ | 161/182 [34:06<05:29, 15.70s/it, training_loss=0.063]\u001b[A\n",
            "Epoch 3:  89%|████████▉ | 162/182 [34:06<05:52, 17.65s/it, training_loss=0.063]\u001b[A\n",
            "Epoch 3:  89%|████████▉ | 162/182 [34:18<05:52, 17.65s/it, training_loss=0.140]\u001b[A\n",
            "Epoch 3:  90%|████████▉ | 163/182 [34:18<05:00, 15.83s/it, training_loss=0.140]\u001b[A\n",
            "Epoch 3:  90%|████████▉ | 163/182 [34:31<05:00, 15.83s/it, training_loss=0.069]\u001b[A\n",
            "Epoch 3:  90%|█████████ | 164/182 [34:31<04:31, 15.07s/it, training_loss=0.069]\u001b[A\n",
            "Epoch 3:  90%|█████████ | 164/182 [34:43<04:31, 15.07s/it, training_loss=0.052]\u001b[A\n",
            "Epoch 3:  91%|█████████ | 165/182 [34:43<04:02, 14.26s/it, training_loss=0.052]\u001b[A\n",
            "Epoch 3:  91%|█████████ | 165/182 [34:54<04:02, 14.26s/it, training_loss=0.057]\u001b[A\n",
            "Epoch 3:  91%|█████████ | 166/182 [34:54<03:30, 13.18s/it, training_loss=0.057]\u001b[A\n",
            "Epoch 3:  91%|█████████ | 166/182 [35:07<03:30, 13.18s/it, training_loss=0.143]\u001b[A\n",
            "Epoch 3:  92%|█████████▏| 167/182 [35:07<03:18, 13.22s/it, training_loss=0.143]\u001b[A\n",
            "Epoch 3:  92%|█████████▏| 167/182 [35:20<03:18, 13.22s/it, training_loss=0.143]\u001b[A\n",
            "Epoch 3:  92%|█████████▏| 168/182 [35:20<03:01, 12.98s/it, training_loss=0.143]\u001b[A\n",
            "Epoch 3:  92%|█████████▏| 168/182 [35:31<03:01, 12.98s/it, training_loss=0.172]\u001b[A\n",
            "Epoch 3:  93%|█████████▎| 169/182 [35:31<02:41, 12.42s/it, training_loss=0.172]\u001b[A\n",
            "Epoch 3:  93%|█████████▎| 169/182 [35:44<02:41, 12.42s/it, training_loss=0.152]\u001b[A\n",
            "Epoch 3:  93%|█████████▎| 170/182 [35:44<02:32, 12.67s/it, training_loss=0.152]\u001b[A\n",
            "Epoch 3:  93%|█████████▎| 170/182 [35:56<02:32, 12.67s/it, training_loss=0.218]\u001b[A\n",
            "Epoch 3:  94%|█████████▍| 171/182 [35:56<02:17, 12.48s/it, training_loss=0.218]\u001b[A\n",
            "Epoch 3:  94%|█████████▍| 171/182 [36:07<02:17, 12.48s/it, training_loss=0.129]\u001b[A\n",
            "Epoch 3:  95%|█████████▍| 172/182 [36:07<02:01, 12.11s/it, training_loss=0.129]\u001b[A\n",
            "Epoch 3:  95%|█████████▍| 172/182 [36:21<02:01, 12.11s/it, training_loss=0.229]\u001b[A\n",
            "Epoch 3:  95%|█████████▌| 173/182 [36:21<01:52, 12.48s/it, training_loss=0.229]\u001b[A\n",
            "Epoch 3:  95%|█████████▌| 173/182 [36:32<01:52, 12.48s/it, training_loss=0.073]\u001b[A\n",
            "Epoch 3:  96%|█████████▌| 174/182 [36:32<01:38, 12.25s/it, training_loss=0.073]\u001b[A\n",
            "Epoch 3:  96%|█████████▌| 174/182 [36:44<01:38, 12.25s/it, training_loss=0.153]\u001b[A\n",
            "Epoch 3:  96%|█████████▌| 175/182 [36:44<01:23, 11.97s/it, training_loss=0.153]\u001b[A\n",
            "Epoch 3:  96%|█████████▌| 175/182 [36:57<01:23, 11.97s/it, training_loss=0.121]\u001b[A\n",
            "Epoch 3:  97%|█████████▋| 176/182 [36:57<01:14, 12.35s/it, training_loss=0.121]\u001b[A\n",
            "Epoch 3:  97%|█████████▋| 176/182 [37:08<01:14, 12.35s/it, training_loss=0.052]\u001b[A\n",
            "Epoch 3:  97%|█████████▋| 177/182 [37:08<01:00, 12.07s/it, training_loss=0.052]\u001b[A\n",
            "Epoch 3:  97%|█████████▋| 177/182 [37:20<01:00, 12.07s/it, training_loss=0.128]\u001b[A\n",
            "Epoch 3:  98%|█████████▊| 178/182 [37:20<00:47, 11.88s/it, training_loss=0.128]\u001b[A\n",
            "Epoch 3:  98%|█████████▊| 178/182 [37:33<00:47, 11.88s/it, training_loss=0.047]\u001b[A\n",
            "Epoch 3:  98%|█████████▊| 179/182 [37:33<00:36, 12.30s/it, training_loss=0.047]\u001b[A\n",
            "Epoch 3:  98%|█████████▊| 179/182 [37:44<00:36, 12.30s/it, training_loss=0.096]\u001b[A\n",
            "Epoch 3:  99%|█████████▉| 180/182 [37:44<00:23, 11.89s/it, training_loss=0.096]\u001b[A\n",
            "Epoch 3:  99%|█████████▉| 180/182 [37:56<00:23, 11.89s/it, training_loss=0.065]\u001b[A\n",
            "Epoch 3:  99%|█████████▉| 181/182 [37:56<00:11, 11.94s/it, training_loss=0.065]\u001b[A\n",
            "Epoch 3:  99%|█████████▉| 181/182 [37:58<00:11, 11.94s/it, training_loss=0.074]\u001b[A\n",
            "Epoch 3: 100%|██████████| 182/182 [37:58<00:00,  8.97s/it, training_loss=0.074]\u001b[A\n",
            " 67%|██████▋   | 2/3 [1:57:45<39:47, 2387.19s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            " Epoch {epoch}\n",
            "Training loss: {loss_train_avg}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "  0%|          | 0/46 [00:00<?, ?it/s]\u001b[A\n",
            "  2%|▏         | 1/46 [00:03<02:22,  3.18s/it]\u001b[A\n",
            "  4%|▍         | 2/46 [00:06<02:18,  3.15s/it]\u001b[A\n",
            "  7%|▋         | 3/46 [00:10<02:30,  3.51s/it]\u001b[A\n",
            "  9%|▊         | 4/46 [00:16<03:06,  4.44s/it]\u001b[A\n",
            " 11%|█         | 5/46 [00:20<03:04,  4.51s/it]\u001b[A\n",
            " 13%|█▎        | 6/46 [00:25<03:01,  4.53s/it]\u001b[A\n",
            " 15%|█▌        | 7/46 [00:29<02:56,  4.54s/it]\u001b[A\n",
            " 17%|█▋        | 8/46 [00:34<02:59,  4.72s/it]\u001b[A\n",
            " 20%|█▉        | 9/46 [00:38<02:45,  4.47s/it]\u001b[A\n",
            " 22%|██▏       | 10/46 [00:43<02:45,  4.60s/it]\u001b[A\n",
            " 24%|██▍       | 11/46 [00:47<02:31,  4.34s/it]\u001b[A\n",
            " 26%|██▌       | 12/46 [00:52<02:36,  4.60s/it]\u001b[A\n",
            " 28%|██▊       | 13/46 [00:56<02:27,  4.48s/it]\u001b[A\n",
            " 30%|███       | 14/46 [01:00<02:10,  4.07s/it]\u001b[A\n",
            " 33%|███▎      | 15/46 [01:03<01:57,  3.79s/it]\u001b[A\n",
            " 35%|███▍      | 16/46 [01:06<01:50,  3.69s/it]\u001b[A\n",
            " 37%|███▋      | 17/46 [01:11<01:59,  4.12s/it]\u001b[A\n",
            " 39%|███▉      | 18/46 [01:15<01:54,  4.09s/it]\u001b[A\n",
            " 41%|████▏     | 19/46 [01:18<01:42,  3.81s/it]\u001b[A\n",
            " 43%|████▎     | 20/46 [01:22<01:34,  3.62s/it]\u001b[A\n",
            " 46%|████▌     | 21/46 [01:25<01:30,  3.63s/it]\u001b[A\n",
            " 48%|████▊     | 22/46 [01:30<01:37,  4.07s/it]\u001b[A\n",
            " 50%|█████     | 23/46 [01:34<01:32,  4.01s/it]\u001b[A\n",
            " 52%|█████▏    | 24/46 [01:37<01:22,  3.75s/it]\u001b[A\n",
            " 54%|█████▍    | 25/46 [01:41<01:14,  3.57s/it]\u001b[A\n",
            " 57%|█████▋    | 26/46 [01:44<01:13,  3.68s/it]\u001b[A\n",
            " 59%|█████▊    | 27/46 [01:50<01:18,  4.11s/it]\u001b[A\n",
            " 61%|██████    | 28/46 [01:53<01:11,  3.97s/it]\u001b[A\n",
            " 63%|██████▎   | 29/46 [01:56<01:03,  3.72s/it]\u001b[A\n",
            " 65%|██████▌   | 30/46 [02:00<00:56,  3.56s/it]\u001b[A\n",
            " 67%|██████▋   | 31/46 [02:04<00:56,  3.78s/it]\u001b[A\n",
            " 70%|██████▉   | 32/46 [02:09<00:57,  4.13s/it]\u001b[A\n",
            " 72%|███████▏  | 33/46 [02:12<00:50,  3.90s/it]\u001b[A\n",
            " 74%|███████▍  | 34/46 [02:15<00:44,  3.67s/it]\u001b[A\n",
            " 76%|███████▌  | 35/46 [02:18<00:38,  3.51s/it]\u001b[A\n",
            " 78%|███████▊  | 36/46 [02:23<00:38,  3.85s/it]\u001b[A\n",
            " 80%|████████  | 37/46 [02:28<00:37,  4.17s/it]\u001b[A\n",
            " 83%|████████▎ | 38/46 [02:31<00:30,  3.86s/it]\u001b[A\n",
            " 85%|████████▍ | 39/46 [02:34<00:25,  3.65s/it]\u001b[A\n",
            " 87%|████████▋ | 40/46 [02:37<00:20,  3.49s/it]\u001b[A\n",
            " 89%|████████▉ | 41/46 [02:42<00:19,  3.92s/it]\u001b[A\n",
            " 91%|█████████▏| 42/46 [02:47<00:16,  4.11s/it]\u001b[A\n",
            " 93%|█████████▎| 43/46 [02:50<00:11,  3.83s/it]\u001b[A\n",
            " 96%|█████████▌| 44/46 [02:53<00:07,  3.63s/it]\u001b[A\n",
            " 98%|█████████▊| 45/46 [02:56<00:03,  3.48s/it]\u001b[A\n",
            "100%|██████████| 46/46 [02:58<00:00,  3.89s/it]\n",
            "100%|██████████| 3/3 [2:00:43<00:00, 2414.65s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Validation loss: 0.42946075955810753\n",
            "F1 Score (weighted): 0.8295515603719594\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        }
      ],
      "source": [
        "from tqdm import tqdm\n",
        "\n",
        "for epoch in tqdm(range(1, epochs+1)):\n",
        "    \n",
        "    model.train()\n",
        "    \n",
        "    loss_train_total = 0\n",
        "    \n",
        "    progress_bar = tqdm(dataloader_train, \n",
        "                        desc = 'Epoch {:1d}'.format(epoch), \n",
        "                        leave = False, \n",
        "                        disable = False)\n",
        "    \n",
        "    for batch in progress_bar:\n",
        "        \n",
        "        model.zero_grad() #set gradient to 0\n",
        "    \n",
        "        batch = tuple(b.to(device) for b in batch)\n",
        "        \n",
        "        inputs = {'input_ids': batch[0], \n",
        "                  'attention_mask': batch[1], \n",
        "                  'labels': batch[2]}\n",
        "        \n",
        "        outputs = model(**inputs) #unpack the dict straight into inputs\n",
        "        \n",
        "        loss = outputs[0]\n",
        "        loss_train_total += loss.item()\n",
        "        loss.backward()\n",
        "        \n",
        "        torch.nn.utils.clip_grad_norm_(model.parameters(), 1.0)\n",
        "        \n",
        "        optimizer.step()\n",
        "        scheduler.step()\n",
        "        progress_bar.set_postfix({'training_loss': '{:.3f}'.format(loss.item() / len(batch))})\n",
        "        \n",
        "    torch.save(model.state_dict(), f'/content/gdrive/MyDrive/NLP/BERT_ft_epoch{epoch}.model')\n",
        "    \n",
        "    tqdm.write('\\n Epoch {epoch}')\n",
        "    \n",
        "    loss_train_ave = loss_train_total / len(dataloader_train)\n",
        "    tqdm.write('Training loss: {loss_train_avg}')\n",
        "    \n",
        "    val_loss, predictions, true_vals = evaluate(dataloader_val)\n",
        "    val_f1 = f1_score_func(predictions, true_vals)\n",
        "    tqdm.write(f'Validation loss: {val_loss}')\n",
        "    tqdm.write(f'F1 Score (weighted): {val_f1}')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 212,
      "metadata": {
        "id": "tPQEu0MvcrLJ",
        "outputId": "a3bd36e2-78f3-4a60-9db8-4b1b7bb6f987",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 46/46 [02:56<00:00,  3.84s/it]\n"
          ]
        }
      ],
      "source": [
        "_, predictions, true_vals = evaluate(dataloader_val)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 213,
      "metadata": {
        "id": "uAaDclgnspW3",
        "outputId": "3e15e78f-311d-4743-8678-d7dbb8739169",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy:123/128\n",
            " -> 0.9609375\n",
            "Accuracy:82/107\n",
            " -> 0.7663551401869159\n",
            "Accuracy:97/128\n",
            " -> 0.7578125\n"
          ]
        }
      ],
      "source": [
        "true_vals.shape\n",
        "accuracy_per_class(predictions, true_vals)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Jf3em8pJMLPQ"
      },
      "source": [
        "###Testing with the Arabic Dataset.\n",
        "\n",
        "\n",
        "1.   Load the model.\n",
        "2.   Load the dataset.\n",
        "3.   Translate the dataset and preprocess it.\n",
        "4.   Test using the model.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 214,
      "metadata": {
        "id": "TwlpV9c_MI5H",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "06797fc0-1782-465b-d039-13b6e12eb3e5"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/gdrive; to attempt to forcibly remount, call drive.mount(\"/content/gdrive\", force_remount=True).\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "from IPython.display import display # Allows the use of display() for DataFrames\n",
        "drive.mount('/content/gdrive')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "if torch.cuda.is_available():\n",
        "    device = torch.device('cuda')\n",
        "else:\n",
        "    device = torch.device('cpu')"
      ],
      "metadata": {
        "id": "AOWhqUTEVs-y"
      },
      "execution_count": 215,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 42,
      "metadata": {
        "id": "zcm5wY4-i-Dy",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "851fccf3-208e-4852-d3ef-af73d2fea681"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertForSequenceClassification: ['cls.predictions.transform.LayerNorm.weight', 'cls.predictions.decoder.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.transform.dense.weight', 'cls.seq_relationship.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.seq_relationship.bias', 'cls.predictions.bias']\n",
            "- This IS expected if you are initializing BertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing BertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.weight', 'classifier.bias']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<All keys matched successfully>"
            ]
          },
          "metadata": {},
          "execution_count": 42
        }
      ],
      "source": [
        "from transformers import BertTokenizer,BertForSequenceClassification\n",
        "\n",
        "tokenizer = BertTokenizer.from_pretrained(\"bert-base-uncased\")\n",
        "model = BertForSequenceClassification.from_pretrained('bert-base-uncased',\n",
        "                                                      num_labels = 3,\n",
        "                                                      id2label={0: 'negative', 1: 'neutral', 2: 'positive'},\n",
        "                                                      output_attentions = False,\n",
        "                                                      output_hidden_states = False).to(device)\n",
        "                                                      \n",
        "path = F\"/content/gdrive/MyDrive/NLP/BERT_ft_epoch3.model\"\n",
        "model.load_state_dict(torch.load(path))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 43,
      "metadata": {
        "id": "kozbV9TAi-GP",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "edbf254a-e49e-4ee4-c387-3d20982ae82a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/pipelines/text_classification.py:104: UserWarning: `return_all_scores` is now deprecated,  if want a similar funcionality use `top_k=None` instead of `return_all_scores=True` or `top_k=1` instead of `return_all_scores=False`.\n",
            "  warnings.warn(\n"
          ]
        }
      ],
      "source": [
        "from transformers import TextClassificationPipeline\n",
        "\n",
        "pipe = TextClassificationPipeline(model=model, tokenizer=tokenizer, return_all_scores=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "j1sPJAvrMB-b",
        "outputId": "3bada442-ed52-4798-de70-e92f81088b78"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                                             Sentence    id     label\n",
              "0   انخفضت أرباح شركة الخليج للمواشي إلى 12،1 مليو...    36  negative\n",
              "1   تناقش عمومية شركة أرامكس يوم 21 مارس توزيع أرب...  1962  positive\n",
              "2   حققت العين الأهلية للتأمين أرباحاً بلغت 2 .50 ...  2838  positive\n",
              "3   ارتفعت أرباح اسمنت أم القيوين بنسبة 30% إلى 7 ...  1599  positive\n",
              "4   قررت الجمعية العمومية لشركة صناعات أسمنت الفجي...  1528  negative\n",
              "5   ينعقد يوم الثلاثاء المقبل اجتماع مجلس إدارة بن...  3615   neutral\n",
              "6   دبي \"الخليج\":بلغت أرباح شركة \"دبي للتطوير\" في ...  5050  positive\n",
              "7   أعلنت شركة العين الأهلية للتأمين عن أنها ستفصح...   220   neutral\n",
              "8   يعتزم بنك إتش إس بي سي إنشاء صندوق بقيمة 100 م...  2101  positive\n",
              "9   يعقد اجتماع مجلس الإدارة للشركة العربية للصناع...  4559   neutral\n",
              "10  تراجعت أرباح شركة رأس الخيمة للأسمنت الأبيض إل...  2112  negative\n",
              "11  أقرت الجمعية العمومية للمؤسسة الوطنية للسياحة ...  1835  positive\n",
              "12  أعلنت شركة رأس الخيمة للاسمنت الأبيض انها ستكش...  6381   neutral\n",
              "13  ارتفعت أرباح شركة أبوظبي الوطنية للتكافل إلى 9...  2998  positive\n",
              "14  تراجع سهم ديبا في بورصة دبي العالمية أمس بنسبة...  1136  negative\n",
              "15  أعلنت شركة أبوظبي الوطنية للطاقة طاقة عن إعادة...  5015  positive\n",
              "16  دبي: «الخليج»قررت شركة «أملاك» عقد اجتماع مجلس...  2956   neutral\n",
              "17  تأجلت الجمعية العمومية لشركة دانة غاز لعدم اكت...  2697  negative\n",
              "18  وافقت هيئة الأوراق المالية والسلع على طلب شراء...  3629  positive\n",
              "19  سجل سهم بنك دبي التجاري أمس ارتفاعاً قوياً بوا...  4073  positive\n",
              "20  ينعقد مجلس إدارة شركة الفردوس القابضة الأربعاء...  2635   neutral\n",
              "21  اقترب دبي المالي من اختراق أعلى سعر مسجل منذ ع...  2595  positive\n",
              "22  بلغت مكاسب سوق دبي المالي منذ بداية الربع الثا...  3227  positive\n",
              "23  يعقد مجلس إدارة شركة تبريد اجتماعاً عند الساعة...  5209   neutral\n",
              "24  أظهرت النتائج المالية لشركة الهلال الأخضر للتأ...  6263  negative\n",
              "25  قررت الجمعية العمومية لشركة طيران أبوظبي أمس ت...  5539   neutral\n",
              "26  شهدت تداولات المطلعين شراء 200 ألف سهم مصرف عج...  5987   neutral\n",
              "27  أعلن سوق دبي المالي أمس أنه تم تفعيل قرار تخفي...   917  negative\n",
              "28  ينعقد مجلس إدارة تبريد في الساعة 00:11 صباحاً ...  2043   neutral\n",
              "29  ارتفعت أرباح اسمنت أم القيوين بنسبة 30% إلى 7 ...  1599  positive\n",
              "30  تراجعت أرباح شركة طيران أبوظبي بنسبة 1% إلى 3 ...  3621  negative\n",
              "31  أعلن مجلس إدارة شركة دريك آند سكل انه وافق على...  1807   neutral\n",
              "32  تراجعت أرباح شركة رأس الخيمة للأسمنت الأبيض إل...  2112  negative\n",
              "33  يجتمع مجلس إدارة شركة دار التكافل في الرابع عش...  3405   neutral\n",
              "34  أعلن سوق دبي المالي عن اضافة أسهم زيادة رأس ال...  1282  positive\n",
              "35  حقق مركز الفجيرة التجاري أرباحاً بقيمة 895 ألف...  3618  positive"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-a5e05c07-0dfe-49ac-877a-c314c5bbfbbc\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Sentence</th>\n",
              "      <th>id</th>\n",
              "      <th>label</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>انخفضت أرباح شركة الخليج للمواشي إلى 12،1 مليو...</td>\n",
              "      <td>36</td>\n",
              "      <td>negative</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>تناقش عمومية شركة أرامكس يوم 21 مارس توزيع أرب...</td>\n",
              "      <td>1962</td>\n",
              "      <td>positive</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>حققت العين الأهلية للتأمين أرباحاً بلغت 2 .50 ...</td>\n",
              "      <td>2838</td>\n",
              "      <td>positive</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>ارتفعت أرباح اسمنت أم القيوين بنسبة 30% إلى 7 ...</td>\n",
              "      <td>1599</td>\n",
              "      <td>positive</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>قررت الجمعية العمومية لشركة صناعات أسمنت الفجي...</td>\n",
              "      <td>1528</td>\n",
              "      <td>negative</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>ينعقد يوم الثلاثاء المقبل اجتماع مجلس إدارة بن...</td>\n",
              "      <td>3615</td>\n",
              "      <td>neutral</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>دبي \"الخليج\":بلغت أرباح شركة \"دبي للتطوير\" في ...</td>\n",
              "      <td>5050</td>\n",
              "      <td>positive</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>أعلنت شركة العين الأهلية للتأمين عن أنها ستفصح...</td>\n",
              "      <td>220</td>\n",
              "      <td>neutral</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>يعتزم بنك إتش إس بي سي إنشاء صندوق بقيمة 100 م...</td>\n",
              "      <td>2101</td>\n",
              "      <td>positive</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>يعقد اجتماع مجلس الإدارة للشركة العربية للصناع...</td>\n",
              "      <td>4559</td>\n",
              "      <td>neutral</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>10</th>\n",
              "      <td>تراجعت أرباح شركة رأس الخيمة للأسمنت الأبيض إل...</td>\n",
              "      <td>2112</td>\n",
              "      <td>negative</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>11</th>\n",
              "      <td>أقرت الجمعية العمومية للمؤسسة الوطنية للسياحة ...</td>\n",
              "      <td>1835</td>\n",
              "      <td>positive</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>12</th>\n",
              "      <td>أعلنت شركة رأس الخيمة للاسمنت الأبيض انها ستكش...</td>\n",
              "      <td>6381</td>\n",
              "      <td>neutral</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>13</th>\n",
              "      <td>ارتفعت أرباح شركة أبوظبي الوطنية للتكافل إلى 9...</td>\n",
              "      <td>2998</td>\n",
              "      <td>positive</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>14</th>\n",
              "      <td>تراجع سهم ديبا في بورصة دبي العالمية أمس بنسبة...</td>\n",
              "      <td>1136</td>\n",
              "      <td>negative</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>15</th>\n",
              "      <td>أعلنت شركة أبوظبي الوطنية للطاقة طاقة عن إعادة...</td>\n",
              "      <td>5015</td>\n",
              "      <td>positive</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>16</th>\n",
              "      <td>دبي: «الخليج»قررت شركة «أملاك» عقد اجتماع مجلس...</td>\n",
              "      <td>2956</td>\n",
              "      <td>neutral</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>17</th>\n",
              "      <td>تأجلت الجمعية العمومية لشركة دانة غاز لعدم اكت...</td>\n",
              "      <td>2697</td>\n",
              "      <td>negative</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>18</th>\n",
              "      <td>وافقت هيئة الأوراق المالية والسلع على طلب شراء...</td>\n",
              "      <td>3629</td>\n",
              "      <td>positive</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>19</th>\n",
              "      <td>سجل سهم بنك دبي التجاري أمس ارتفاعاً قوياً بوا...</td>\n",
              "      <td>4073</td>\n",
              "      <td>positive</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>20</th>\n",
              "      <td>ينعقد مجلس إدارة شركة الفردوس القابضة الأربعاء...</td>\n",
              "      <td>2635</td>\n",
              "      <td>neutral</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>21</th>\n",
              "      <td>اقترب دبي المالي من اختراق أعلى سعر مسجل منذ ع...</td>\n",
              "      <td>2595</td>\n",
              "      <td>positive</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>22</th>\n",
              "      <td>بلغت مكاسب سوق دبي المالي منذ بداية الربع الثا...</td>\n",
              "      <td>3227</td>\n",
              "      <td>positive</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>23</th>\n",
              "      <td>يعقد مجلس إدارة شركة تبريد اجتماعاً عند الساعة...</td>\n",
              "      <td>5209</td>\n",
              "      <td>neutral</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>24</th>\n",
              "      <td>أظهرت النتائج المالية لشركة الهلال الأخضر للتأ...</td>\n",
              "      <td>6263</td>\n",
              "      <td>negative</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>25</th>\n",
              "      <td>قررت الجمعية العمومية لشركة طيران أبوظبي أمس ت...</td>\n",
              "      <td>5539</td>\n",
              "      <td>neutral</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>26</th>\n",
              "      <td>شهدت تداولات المطلعين شراء 200 ألف سهم مصرف عج...</td>\n",
              "      <td>5987</td>\n",
              "      <td>neutral</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>27</th>\n",
              "      <td>أعلن سوق دبي المالي أمس أنه تم تفعيل قرار تخفي...</td>\n",
              "      <td>917</td>\n",
              "      <td>negative</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>28</th>\n",
              "      <td>ينعقد مجلس إدارة تبريد في الساعة 00:11 صباحاً ...</td>\n",
              "      <td>2043</td>\n",
              "      <td>neutral</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>29</th>\n",
              "      <td>ارتفعت أرباح اسمنت أم القيوين بنسبة 30% إلى 7 ...</td>\n",
              "      <td>1599</td>\n",
              "      <td>positive</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>30</th>\n",
              "      <td>تراجعت أرباح شركة طيران أبوظبي بنسبة 1% إلى 3 ...</td>\n",
              "      <td>3621</td>\n",
              "      <td>negative</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>31</th>\n",
              "      <td>أعلن مجلس إدارة شركة دريك آند سكل انه وافق على...</td>\n",
              "      <td>1807</td>\n",
              "      <td>neutral</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>32</th>\n",
              "      <td>تراجعت أرباح شركة رأس الخيمة للأسمنت الأبيض إل...</td>\n",
              "      <td>2112</td>\n",
              "      <td>negative</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>33</th>\n",
              "      <td>يجتمع مجلس إدارة شركة دار التكافل في الرابع عش...</td>\n",
              "      <td>3405</td>\n",
              "      <td>neutral</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>34</th>\n",
              "      <td>أعلن سوق دبي المالي عن اضافة أسهم زيادة رأس ال...</td>\n",
              "      <td>1282</td>\n",
              "      <td>positive</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>35</th>\n",
              "      <td>حقق مركز الفجيرة التجاري أرباحاً بقيمة 895 ألف...</td>\n",
              "      <td>3618</td>\n",
              "      <td>positive</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-a5e05c07-0dfe-49ac-877a-c314c5bbfbbc')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-a5e05c07-0dfe-49ac-877a-c314c5bbfbbc button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-a5e05c07-0dfe-49ac-877a-c314c5bbfbbc');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "dfTest = pd.read_csv('/content/gdrive/MyDrive/NLP/labelled.csv' ,engine=\"python\")\n",
        "dfTest"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "kaVnG-iuyugI",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "18ff85fe-c8de-4a85-e1d7-504a4ae08c20"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/models/marian/tokenization_marian.py:194: UserWarning: Recommended: pip install sacremoses.\n",
            "  warnings.warn(\"Recommended: pip install sacremoses.\")\n"
          ]
        }
      ],
      "source": [
        "from transformers import MarianTokenizer, MarianMTModel\n",
        "mname = \"Helsinki-NLP/opus-mt-tc-big-ar-en\"\n",
        "tokenizer = MarianTokenizer.from_pretrained(mname)\n",
        "model_translate = MarianMTModel.from_pretrained(mname)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "aGfkclBC0wxq",
        "outputId": "20bfae8b-8d2a-4210-bc26-05eaf3ad5e38",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py:1346: UserWarning: Using `max_length`'s default (512) to control the generation length. This behaviour is deprecated and will be removed from the config in v5 of Transformers -- we recommend using `max_new_tokens` to control the maximum length of the generation.\n",
            "  warnings.warn(\n"
          ]
        }
      ],
      "source": [
        "translated = []\n",
        "for i in range(len(dfTest)):\n",
        "  input = dfTest['Sentence'][i]\n",
        "  translated_tokens = model_translate.generate(**tokenizer.prepare_seq2seq_batch([input], return_tensors=\"pt\"))\n",
        "  translated_text = [tokenizer.decode(t, skip_special_tokens=True) for t in translated_tokens]\n",
        "  translated.append(translated_text[0])\n",
        "dfTest['English'] = translated"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "dfTest = dfTest.drop([\"Sentence\",\"id\"] , axis =1)\n",
        "dfTest = dfTest.rename(columns={'label': 'Sentiment', 'English':'Sentence'})\n",
        "dfTest['Sentiment'] = dfTest['Sentiment'].replace(['negative','neutral','positive'],[0,1,2])\n",
        "dfTest"
      ],
      "metadata": {
        "id": "hW7gLGQZb2VJ",
        "outputId": "ad0f088f-8285-4aab-fa61-b1802eb4ef3f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "    Sentiment                                           Sentence\n",
              "0           0  The profits of the Gulf Livestock Company fell...\n",
              "1           2    Aramex to discuss cash dividend of 16% for 2016\n",
              "2           2  Al Ain Al Ahlia Insurance achieved a profit of...\n",
              "3           2  Umm Al Quwain Cement’s profit increased by 30%...\n",
              "4           0  The General Assembly of Fujairah Cement Indust...\n",
              "5           1  Next Tuesday, ADCB’s Board of Directors will m...\n",
              "6           2  Dubai: Last year, Dubai Development Company pr...\n",
              "7           1  Al Ain Al Ahlia Insurance Company announced th...\n",
              "8           2  HSBC to set up $100 million fund to support UA...\n",
              "9           1  The meeting of the Board of Directors of the A...\n",
              "10          0  Ras Al Khaimah White Cement Company profits fe...\n",
              "11          2  The General Assembly of the National Corporati...\n",
              "12          1  Ras Al Khaimah White Cement Company announced ...\n",
              "13          2  Abu Dhabi National Takaful Company increased p...\n",
              "14          0  Depa’s shares on the Dubai World Exchange fell...\n",
              "15          2  Abu Dhabi National Energy Company (ADNEC) anno...\n",
              "16          1  Dubai: Amlak decided to hold a board meeting o...\n",
              "17          0  Dana Gas’s general assembly has been postponed...\n",
              "18          2  The Securities and Commodities Authority (SCA)...\n",
              "19          2  Dubai Commercial Bank shares rose 29.14% to AE...\n",
              "20          1  The Board of Directors of Al-Fardous Holding C...\n",
              "21          2  Dubai Financial is close to breaking the highe...\n",
              "22          2  The Dubai Financial Market (DFM) has gained 29...\n",
              "23          1  The Board of Directors of Tabreed Company will...\n",
              "24          0  The financial results of Green Crescent Insura...\n",
              "25          1  The General Assembly of Abu Dhabi Airlines dec...\n",
              "26          1  Insider trading witnessed the purchase of 200,...\n",
              "27          0  Dubai Financial Market (DFM) announced yesterd...\n",
              "28          1  The Board of Directors of Tabreed will meet at...\n",
              "29          2  Umm Al Quwain Cement’s profits increased by 30...\n",
              "30          0  Abu Dhabi Air’s profit fell by 1% to AED 3.212...\n",
              "31          1  The Board of Directors of Drake & Scull announ...\n",
              "32          0  The profits of Ras Al Khaimah White Cement Com...\n",
              "33          1  The Board of Directors of Dar Al Takaful Compa...\n",
              "34          2  The Dubai Financial Market (DFM) announced the...\n",
              "35          2  Fujairah Commercial Center achieved a profit o..."
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-94f9a96e-7756-4245-9966-cdebde192bcf\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Sentiment</th>\n",
              "      <th>Sentence</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>The profits of the Gulf Livestock Company fell...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>2</td>\n",
              "      <td>Aramex to discuss cash dividend of 16% for 2016</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2</td>\n",
              "      <td>Al Ain Al Ahlia Insurance achieved a profit of...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>2</td>\n",
              "      <td>Umm Al Quwain Cement’s profit increased by 30%...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0</td>\n",
              "      <td>The General Assembly of Fujairah Cement Indust...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>1</td>\n",
              "      <td>Next Tuesday, ADCB’s Board of Directors will m...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>2</td>\n",
              "      <td>Dubai: Last year, Dubai Development Company pr...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>1</td>\n",
              "      <td>Al Ain Al Ahlia Insurance Company announced th...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>2</td>\n",
              "      <td>HSBC to set up $100 million fund to support UA...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>1</td>\n",
              "      <td>The meeting of the Board of Directors of the A...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>10</th>\n",
              "      <td>0</td>\n",
              "      <td>Ras Al Khaimah White Cement Company profits fe...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>11</th>\n",
              "      <td>2</td>\n",
              "      <td>The General Assembly of the National Corporati...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>12</th>\n",
              "      <td>1</td>\n",
              "      <td>Ras Al Khaimah White Cement Company announced ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>13</th>\n",
              "      <td>2</td>\n",
              "      <td>Abu Dhabi National Takaful Company increased p...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>14</th>\n",
              "      <td>0</td>\n",
              "      <td>Depa’s shares on the Dubai World Exchange fell...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>15</th>\n",
              "      <td>2</td>\n",
              "      <td>Abu Dhabi National Energy Company (ADNEC) anno...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>16</th>\n",
              "      <td>1</td>\n",
              "      <td>Dubai: Amlak decided to hold a board meeting o...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>17</th>\n",
              "      <td>0</td>\n",
              "      <td>Dana Gas’s general assembly has been postponed...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>18</th>\n",
              "      <td>2</td>\n",
              "      <td>The Securities and Commodities Authority (SCA)...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>19</th>\n",
              "      <td>2</td>\n",
              "      <td>Dubai Commercial Bank shares rose 29.14% to AE...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>20</th>\n",
              "      <td>1</td>\n",
              "      <td>The Board of Directors of Al-Fardous Holding C...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>21</th>\n",
              "      <td>2</td>\n",
              "      <td>Dubai Financial is close to breaking the highe...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>22</th>\n",
              "      <td>2</td>\n",
              "      <td>The Dubai Financial Market (DFM) has gained 29...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>23</th>\n",
              "      <td>1</td>\n",
              "      <td>The Board of Directors of Tabreed Company will...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>24</th>\n",
              "      <td>0</td>\n",
              "      <td>The financial results of Green Crescent Insura...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>25</th>\n",
              "      <td>1</td>\n",
              "      <td>The General Assembly of Abu Dhabi Airlines dec...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>26</th>\n",
              "      <td>1</td>\n",
              "      <td>Insider trading witnessed the purchase of 200,...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>27</th>\n",
              "      <td>0</td>\n",
              "      <td>Dubai Financial Market (DFM) announced yesterd...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>28</th>\n",
              "      <td>1</td>\n",
              "      <td>The Board of Directors of Tabreed will meet at...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>29</th>\n",
              "      <td>2</td>\n",
              "      <td>Umm Al Quwain Cement’s profits increased by 30...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>30</th>\n",
              "      <td>0</td>\n",
              "      <td>Abu Dhabi Air’s profit fell by 1% to AED 3.212...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>31</th>\n",
              "      <td>1</td>\n",
              "      <td>The Board of Directors of Drake &amp; Scull announ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>32</th>\n",
              "      <td>0</td>\n",
              "      <td>The profits of Ras Al Khaimah White Cement Com...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>33</th>\n",
              "      <td>1</td>\n",
              "      <td>The Board of Directors of Dar Al Takaful Compa...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>34</th>\n",
              "      <td>2</td>\n",
              "      <td>The Dubai Financial Market (DFM) announced the...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>35</th>\n",
              "      <td>2</td>\n",
              "      <td>Fujairah Commercial Center achieved a profit o...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-94f9a96e-7756-4245-9966-cdebde192bcf')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-94f9a96e-7756-4245-9966-cdebde192bcf button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-94f9a96e-7756-4245-9966-cdebde192bcf');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#encode Arabic Testing set\n",
        "encoded_data_val_Arabic = tokenizer.batch_encode_plus( dfTest.Sentence.values,\n",
        "                                                       add_special_tokens = True,\n",
        "                                                       return_attention_mask = True,\n",
        "                                                       pad_to_max_length = True,\n",
        "                                                       max_length = 80,\n",
        "                                                       return_tensors = 'pt', \n",
        "                                                       truncation=True)"
      ],
      "metadata": {
        "id": "64uIZ1UghOCW"
      },
      "execution_count": 52,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "input_ids_val_Arabic = encoded_data_val_Arabic['input_ids']\n",
        "attention_masks_val_Arabic = encoded_data_val_Arabic['attention_mask']\n",
        "labels_val_Arabic = torch.tensor(dfTest.Sentiment.values)"
      ],
      "metadata": {
        "id": "21x_6f90gmpF"
      },
      "execution_count": 53,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from torch.utils.data import TensorDataset\n",
        "\n",
        "#Arabic Validation set\n",
        "dataset_val_Arabic = TensorDataset(input_ids_val_Arabic, \n",
        "                                   attention_masks_val_Arabic, \n",
        "                                   labels_val_Arabic)"
      ],
      "metadata": {
        "id": "c1s8LKorjyBB"
      },
      "execution_count": 54,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from torch.utils.data import DataLoader, RandomSampler, SequentialSampler\n",
        "\n",
        "batch_size = 3\n",
        "\n",
        "\n",
        "\n",
        "#Arabic validation set\n",
        "dataloader_val_Arabic = DataLoader(dataset_val_Arabic,\n",
        "                                   sampler = RandomSampler(dataset_val_Arabic),\n",
        "                                   batch_size = 3) #since we don't have to do backpropagation for this step"
      ],
      "metadata": {
        "id": "-jmhZNXbgmy2"
      },
      "execution_count": 55,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#accuracy score\n",
        "def accuracy_per_class(preds, labels):\n",
        "    #label_dict_inverse = {v: k for k, v in label_dict.items()}\n",
        "    \n",
        "    #make prediction\n",
        "    preds_flat = np.argmax(preds, axis=1).flatten()\n",
        "    labels_flat = labels.flatten()\n",
        "    \n",
        "    for label in np.unique(labels_flat):\n",
        "        y_preds = preds_flat[labels_flat==label]\n",
        "        y_true = labels_flat[labels_flat==label]\n",
        "        #print(f'Class: {label_dict_inverse[label]}')\n",
        "        print(f'Accuracy:{len(y_preds[y_preds==label])}/{len(y_true)}\\n -> {len(y_preds[y_preds==label]) / len(y_true)}')"
      ],
      "metadata": {
        "id": "7I5ZL4GlbCeg"
      },
      "execution_count": 56,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def evaluate(dataloader_val):\n",
        "\n",
        "    #evaluation mode \n",
        "    model.eval()\n",
        "    #tracking variables\n",
        "    loss_val_total = 0\n",
        "    predictions, true_vals = [], []\n",
        "\n",
        "    for batch in tqdm(dataloader_val):\n",
        "\n",
        "        #load into GPU\n",
        "        batch = tuple(b.to(device) for b in batch)\n",
        "\n",
        "        #define inputs\n",
        "        inputs = {'input_ids':      batch[0],\n",
        "                  'attention_mask': batch[1],\n",
        "                  'labels':         batch[2]}\n",
        "\n",
        "        #compute logits\n",
        "        with torch.no_grad():        \n",
        "            outputs = model(**inputs)\n",
        "        \n",
        "        #compute loss\n",
        "        loss = outputs[0]\n",
        "        logits = outputs[1]\n",
        "        loss_val_total += loss.item()\n",
        "\n",
        "        #compute accuracy\n",
        "        logits = logits.detach().cpu().numpy()\n",
        "        label_ids = inputs['labels'].cpu().numpy()\n",
        "        predictions.append(logits)\n",
        "        true_vals.append(label_ids)\n",
        "    \n",
        "    #compute average loss\n",
        "    loss_val_avg = loss_val_total/len(dataloader_val) \n",
        "    \n",
        "    predictions = np.concatenate(predictions, axis=0)\n",
        "    true_vals = np.concatenate(true_vals, axis=0)\n",
        "            \n",
        "    return loss_val_avg, predictions, true_vals"
      ],
      "metadata": {
        "id": "Z9QlC1x0gm9L"
      },
      "execution_count": 57,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from tqdm import tqdm\n",
        "\n",
        "_,predictions, true_vals = evaluate(dataloader_val_Arabic)"
      ],
      "metadata": {
        "id": "2sU0xD0AeEm6",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "746945a6-db64-4d57-c9f9-c25dc51b0139"
      },
      "execution_count": 58,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 12/12 [00:41<00:00,  3.47s/it]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "true_vals.shape\n",
        "accuracy_per_class(predictions, true_vals)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "A660E1OVqzV5",
        "outputId": "6a8229ff-6378-4f23-cdad-7252aeacc601"
      },
      "execution_count": 59,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy:9/9\n",
            " -> 1.0\n",
            "Accuracy:12/12\n",
            " -> 1.0\n",
            "Accuracy:11/15\n",
            " -> 0.7333333333333333\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# preprocess the sentence\n",
        "correct = 0\n",
        "false = 0\n",
        "positive = 0\n",
        "negative = 0\n",
        "neutral = 0\n",
        "for i in range(len(dfTest)):\n",
        "  row = dfTest.iloc[i]\n",
        "  sentence = row['Sentence']\n",
        "  label = row['Sentiment']\n",
        "  input_ids = torch.tensor(tokenizer.encode(sentence, add_special_tokens=True)).unsqueeze(0)\n",
        "  attention_mask = torch.tensor([1] * input_ids.shape[1]).unsqueeze(0)\n",
        "\n",
        "  # get the predicted sentiment label\n",
        "  with torch.no_grad():\n",
        "      outputs = model(input_ids=input_ids, attention_mask=attention_mask)\n",
        "      _, predicted_label = torch.max(outputs[0], dim=1)\n",
        "  print(sentence, predicted_label,label)\n",
        "  if(label == 0):\n",
        "    negative = negative + 1\n",
        "  elif(label == 1):\n",
        "    neutral = neutral + 1\n",
        "  elif(label == 2):\n",
        "    positive = positive + 1\n",
        "  if(predicted_label == label):\n",
        "    correct = correct + 1\n",
        "  else:\n",
        "    false = false + 1\n",
        "  print(correct,false)"
      ],
      "metadata": {
        "id": "5V4Ur-PXWxkk",
        "outputId": "d84d2f6a-9db3-4b0f-ff53-f891e8bb707f",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 50,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The profits of the Gulf Livestock Company fell to 12.1 million dirhams in 2010, compared to 27.6 million dirhams in 2009. tensor([0]) 0\n",
            "1 0\n",
            "Aramex to discuss cash dividend of 16% for 2016 tensor([2]) 2\n",
            "2 0\n",
            "Al Ain Al Ahlia Insurance achieved a profit of AED 2.50 million in 2012 compared to AED 2.53 million in 2011. tensor([2]) 2\n",
            "3 0\n",
            "Umm Al Quwain Cement’s profit increased by 30% to AED 7.22 million in the first quarter of this year tensor([2]) 2\n",
            "4 0\n",
            "The General Assembly of Fujairah Cement Industries decided not to distribute cash dividends or shares for the year 2010. tensor([0]) 0\n",
            "5 0\n",
            "Next Tuesday, ADCB’s Board of Directors will meet to discuss some general matters. tensor([1]) 1\n",
            "6 0\n",
            "Dubai: Last year, Dubai Development Company profit reached AED 735,000 compared to AED 9,444,000 in 2013 tensor([2]) 2\n",
            "7 0\n",
            "Al Ain Al Ahlia Insurance Company announced that it will disclose its financial results for the third quarter of 2011 on 31/10/2011 tensor([1]) 1\n",
            "8 0\n",
            "HSBC to set up $100 million fund to support UAE SMEs tensor([2]) 2\n",
            "9 0\n",
            "The meeting of the Board of Directors of the Arab Company for Heavy Industries will be held on 17-12-2012 to discuss routine work only tensor([1]) 1\n",
            "10 0\n",
            "Ras Al Khaimah White Cement Company profits fell to AED 37.8 million in 2012 from AED 68.8 million in 2011 tensor([0]) 0\n",
            "11 0\n",
            "The General Assembly of the National Corporation for Tourism and Hotels approved the distribution of 60% cash dividends to its shareholders yesterday tensor([1]) 2\n",
            "11 1\n",
            "Ras Al Khaimah White Cement Company announced that it will announce the results of its work during the first quarter of this year next Saturday tensor([1]) 1\n",
            "12 1\n",
            "Abu Dhabi National Takaful Company increased profits to AED 9.26 million in 2012 from AED 4.24 million in 2011 tensor([2]) 2\n",
            "13 1\n",
            "Depa’s shares on the Dubai World Exchange fell 1.32 percent to close at $1.49, trading 261.4 thousand shares worth $392,000. tensor([0]) 0\n",
            "14 1\n",
            "Abu Dhabi National Energy Company (ADNEC) announced the repurchase of 2.2 million shares yesterday, with an average share purchase price of AED 1.97 tensor([1]) 2\n",
            "14 2\n",
            "Dubai: Amlak decided to hold a board meeting on February 26 to discuss the company’s regular business. tensor([1]) 1\n",
            "15 2\n",
            "Dana Gas’s general assembly has been postponed due to lack of quorum until April 23 next year. tensor([0]) 0\n",
            "16 2\n",
            "The Securities and Commodities Authority (SCA) has approved the purchase order of Bank of Sharjah for its shares not exceeding 10% (21,000,000 shares) of the company’s capital. tensor([1]) 2\n",
            "16 3\n",
            "Dubai Commercial Bank shares rose 29.14% to AED 4 yesterday by trading 5,655,000 shares in 12 transactions worth AED 3.2 million tensor([2]) 2\n",
            "17 3\n",
            "The Board of Directors of Al-Fardous Holding Company meets on Wednesday 26-6-2013 at 00:4 pm to approve the financial statements ended on 31-3-2013 tensor([1]) 1\n",
            "18 3\n",
            "Dubai Financial is close to breaking the highest price recorded in a year at AED 42.1 as it closed yesterday up 19.2% to AED 4.1 with trades of AED 109 million tensor([2]) 2\n",
            "19 3\n",
            "The Dubai Financial Market (DFM) has gained 29% since the start of the second quarter to record the second best performance among the 94 global indicators monitored by Bloomberg after Greece tensor([2]) 2\n",
            "20 3\n",
            "The Board of Directors of Tabreed Company will hold a meeting at 2:00 pm on Thursday 31 October to discuss the activities and business of the company tensor([1]) 1\n",
            "21 3\n",
            "The financial results of Green Crescent Insurance Company showed that the company suffered financial losses during the first period of this year amounted to 8 million dirhams tensor([0]) 0\n",
            "22 3\n",
            "The General Assembly of Abu Dhabi Airlines decided yesterday to distribute 7.5 percent in cash. tensor([1]) 1\n",
            "23 3\n",
            "Insider trading witnessed the purchase of 200,000 shares of Ajman Bank at a price of AED 0.86. tensor([1]) 1\n",
            "24 3\n",
            "Dubai Financial Market (DFM) announced yesterday that the decision to reduce the capital of Emirates Takaful by 33.33% has been activated. tensor([0]) 0\n",
            "25 3\n",
            "The Board of Directors of Tabreed will meet at 00:11 a.m. this afternoon to discuss the activities and business of the company. tensor([1]) 1\n",
            "26 3\n",
            "Umm Al Quwain Cement’s profits increased by 30% to AED 7.22 million in the first quarter of this year. tensor([2]) 2\n",
            "27 3\n",
            "Abu Dhabi Air’s profit fell by 1% to AED 3.212 million in 2013 and revenue by 2% to AED 6.1 billion. tensor([0]) 0\n",
            "28 3\n",
            "The Board of Directors of Drake & Scull announced that it has approved the appointment of Sultan Bin Rashid Al Dhaheri as a new Board Member. tensor([1]) 1\n",
            "29 3\n",
            "The profits of Ras Al Khaimah White Cement Company fell to AED 37.8 million in 2012, compared to a profit of AED 68.8 million in 2011. tensor([0]) 0\n",
            "30 3\n",
            "The Board of Directors of Dar Al Takaful Company will meet on the 14th of this month to approve the financial statements for the second quarter of this year. tensor([1]) 1\n",
            "31 3\n",
            "The Dubai Financial Market (DFM) announced the addition of Emirates Islamic Bank’s capital increase shares to shareholders’ accounts as at the closing date of the company’s register on 21/7/2010. tensor([1]) 2\n",
            "31 4\n",
            "Fujairah Commercial Center achieved a profit of AED 895,000 during the first half of this year compared to AED 841,000 during the same period last year. tensor([2]) 2\n",
            "32 4\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Accuracy of testing = \", 100 * correct / (correct + false)) \n",
        "print(negative,positive,neutral) "
      ],
      "metadata": {
        "id": "XUyGjdrnlroB",
        "outputId": "d8e2735d-ef85-4983-9cf3-be290eaaa9bc",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 51,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy of testing =  88.88888888888889\n",
            "9 15 12\n"
          ]
        }
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "mount_file_id": "15LJzeGhGZBWboYjAF0vXgAnVMaYVClB5",
      "authorship_tag": "ABX9TyN+KbGVLq1u5TibT4gYFioz",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}