{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "collapsed_sections": [
        "-vfxcPDmttis"
      ],
      "mount_file_id": "15LJzeGhGZBWboYjAF0vXgAnVMaYVClB5",
      "authorship_tag": "ABX9TyNOInJwoler15H5YmsmFLEf",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/GeorgeSherif/NLP-ChatEGP/blob/main/Translate_Ar_En5.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Installing & Importing the Necessary Libraries and Mounting the drive**"
      ],
      "metadata": {
        "id": "OAw4nlDbEZUQ"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "SDVJd_TDyswW",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "98750b7d-9e09-44b7-e6ce-efa38d6b602c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Successfully installed GitPython-3.1.31 aiohttp-3.8.4 aiosignal-1.3.1 async-timeout-4.0.2 blinker-1.6.2 datasets-2.12.0 dill-0.3.6 docker-pycreds-0.4.0 frozenlist-1.3.3 gitdb-4.0.10 huggingface-hub-0.14.1 importlib-metadata-6.6.0 multidict-6.0.4 multiprocess-0.70.14 pathtools-0.1.2 pydeck-0.8.1b0 pygal-3.0.0 pympler-1.0.1 responses-0.18.0 sentencepiece-0.1.99 sentry-sdk-1.22.2 seqeval-1.2.2 setproctitle-1.3.2 simpletransformers-0.63.11 smmap-5.0.0 streamlit-1.22.0 tokenizers-0.13.3 transformers-4.29.0 validators-0.20.0 wandb-0.15.2 watchdog-3.0.0 xxhash-3.2.0 yarl-1.9.2\n"
          ]
        }
      ],
      "source": [
        "!pip3 install transformers sentencepiece nltk protobuf torch pygal simpletransformers torchvision\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "from IPython.display import display # Allows the use of display() for DataFrames\n",
        "drive.mount('/content/gdrive')\n"
      ],
      "metadata": {
        "id": "9UP_-BDdA37e"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from nltk.corpus import stopwords\n",
        "import os\n",
        "import warnings\n",
        "import csv\n",
        "from textblob import TextBlob\n",
        "import re\n",
        "from nltk.stem.isri import ISRIStemmer\n",
        "import nltk\n",
        "nltk.download('stopwords')\n",
        "nltk.download('punkt')\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt \n",
        "import plotly.express as px\n",
        "import plotly.graph_objects as go\n",
        "import pygal as py\n",
        "import matplotlib\n",
        "plt.rcParams[\"figure.figsize\"] = (8,5)\n",
        "matplotlib.rc('xtick', labelsize=7) \n",
        "matplotlib.rc('ytick', labelsize=7) \n",
        "from textblob import TextBlob\n",
        "\n",
        "import torch\n",
        "import torchvision\n",
        "\n",
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "\n",
        "warnings.filterwarnings(\"ignore\", category=FutureWarning)\n",
        "%matplotlib inline "
      ],
      "metadata": {
        "id": "8eiG5KriE7bY",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "334c0974-2a45-4cc0-e27f-e36d04d36e7d"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/stopwords.zip.\n",
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt.zip.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "if torch.cuda.is_available():\n",
        "    device = torch.device('cuda')\n",
        "else:\n",
        "    device = torch.device('cpu')"
      ],
      "metadata": {
        "id": "Ah5YDfy94Jqg"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Approach 1: Evaluate the English Model (BERT)**\n",
        "\n",
        "\n",
        "*   English Train Data\n",
        "*   Arabic Test Data\n",
        "*   Train with the English Dataset\n",
        "*   Translate the Arabic Dataset\n",
        "*   Evaluate Model\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "haDPqEitD7k7"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Load the English Dataset"
      ],
      "metadata": {
        "id": "PcdWNYwxG7b8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df = pd.read_csv('/content/gdrive/MyDrive/NLP/English Dataset.csv' ,engine=\"python\", encoding = \"ISO-8859-1\")\n",
        "#df = pd.read_csv('/content/gdrive/MyDrive/NLP/preprocessed.csv' ,engine=\"python\", encoding = \"ISO-8859-1\")\n",
        "\n",
        "df['Sentiment'] = df['Sentiment'].replace(['negative','neutral','positive'],[0,1,2])\n",
        "df"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 423
        },
        "id": "GHd4hXPPG6Rn",
        "outputId": "e5d3bc13-fe5b-4859-f01d-e3fe6abd9e56"
      },
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "      Sentiment                                           Sentence\n",
              "0             1  According to Gran , the company has no plans t...\n",
              "1             1  Technopolis plans to develop in stages an area...\n",
              "2             0  The international electronic industry company ...\n",
              "3             2  With the new production plant the company woul...\n",
              "4             2  According to the company 's updated strategy f...\n",
              "...         ...                                                ...\n",
              "4841          0  LONDON MarketWatch -- Share prices ended lower...\n",
              "4842          1  Rinkuskiai 's beer sales fell by 6.5 per cent ...\n",
              "4843          0  Operating profit fell to EUR 35.4 mn from EUR ...\n",
              "4844          0  Net sales of the Paper segment decreased to EU...\n",
              "4845          0  Sales in Finland decreased by 10.5 % in Januar...\n",
              "\n",
              "[4846 rows x 2 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-47ca86d8-5d5d-4a13-97db-6042e208c9d0\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Sentiment</th>\n",
              "      <th>Sentence</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1</td>\n",
              "      <td>According to Gran , the company has no plans t...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1</td>\n",
              "      <td>Technopolis plans to develop in stages an area...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0</td>\n",
              "      <td>The international electronic industry company ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>2</td>\n",
              "      <td>With the new production plant the company woul...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>2</td>\n",
              "      <td>According to the company 's updated strategy f...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4841</th>\n",
              "      <td>0</td>\n",
              "      <td>LONDON MarketWatch -- Share prices ended lower...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4842</th>\n",
              "      <td>1</td>\n",
              "      <td>Rinkuskiai 's beer sales fell by 6.5 per cent ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4843</th>\n",
              "      <td>0</td>\n",
              "      <td>Operating profit fell to EUR 35.4 mn from EUR ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4844</th>\n",
              "      <td>0</td>\n",
              "      <td>Net sales of the Paper segment decreased to EU...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4845</th>\n",
              "      <td>0</td>\n",
              "      <td>Sales in Finland decreased by 10.5 % in Januar...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>4846 rows × 2 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-47ca86d8-5d5d-4a13-97db-6042e208c9d0')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-47ca86d8-5d5d-4a13-97db-6042e208c9d0 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-47ca86d8-5d5d-4a13-97db-6042e208c9d0');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 32
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "sns.countplot(y=\"Sentiment\",data=df)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 478
        },
        "id": "r5E8aFGXG6Zl",
        "outputId": "05607b4c-2e32-4015-a62d-85856dbff28c"
      },
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<Axes: xlabel='count', ylabel='Sentiment'>"
            ]
          },
          "metadata": {},
          "execution_count": 33
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 800x500 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df.drop_duplicates(subset=['Sentence'],keep='first',inplace=True)\n",
        "df"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 423
        },
        "id": "yIn3Q46wlVV6",
        "outputId": "20c445ce-862f-4742-f32e-2eabeeef9a7d"
      },
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "      Sentiment                                           Sentence\n",
              "0             1  According to Gran , the company has no plans t...\n",
              "1             1  Technopolis plans to develop in stages an area...\n",
              "2             0  The international electronic industry company ...\n",
              "3             2  With the new production plant the company woul...\n",
              "4             2  According to the company 's updated strategy f...\n",
              "...         ...                                                ...\n",
              "4841          0  LONDON MarketWatch -- Share prices ended lower...\n",
              "4842          1  Rinkuskiai 's beer sales fell by 6.5 per cent ...\n",
              "4843          0  Operating profit fell to EUR 35.4 mn from EUR ...\n",
              "4844          0  Net sales of the Paper segment decreased to EU...\n",
              "4845          0  Sales in Finland decreased by 10.5 % in Januar...\n",
              "\n",
              "[4838 rows x 2 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-f92374b5-8d90-481b-aff5-300a07d8e3e4\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Sentiment</th>\n",
              "      <th>Sentence</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1</td>\n",
              "      <td>According to Gran , the company has no plans t...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1</td>\n",
              "      <td>Technopolis plans to develop in stages an area...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0</td>\n",
              "      <td>The international electronic industry company ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>2</td>\n",
              "      <td>With the new production plant the company woul...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>2</td>\n",
              "      <td>According to the company 's updated strategy f...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4841</th>\n",
              "      <td>0</td>\n",
              "      <td>LONDON MarketWatch -- Share prices ended lower...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4842</th>\n",
              "      <td>1</td>\n",
              "      <td>Rinkuskiai 's beer sales fell by 6.5 per cent ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4843</th>\n",
              "      <td>0</td>\n",
              "      <td>Operating profit fell to EUR 35.4 mn from EUR ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4844</th>\n",
              "      <td>0</td>\n",
              "      <td>Net sales of the Paper segment decreased to EU...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4845</th>\n",
              "      <td>0</td>\n",
              "      <td>Sales in Finland decreased by 10.5 % in Januar...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>4838 rows × 2 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-f92374b5-8d90-481b-aff5-300a07d8e3e4')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-f92374b5-8d90-481b-aff5-300a07d8e3e4 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-f92374b5-8d90-481b-aff5-300a07d8e3e4');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 34
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Determinig the sentiment using TextBlob Polarity"
      ],
      "metadata": {
        "id": "WUgy1Tc6XqT3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def preprocess(ReviewText):\n",
        "    ReviewText = ReviewText.str.replace(\"(<br/>)\", \"\")\n",
        "    ReviewText = ReviewText.str.replace('(<a).*(>).*(</a>)', '')\n",
        "    ReviewText = ReviewText.str.replace('(&amp)', '')\n",
        "    ReviewText = ReviewText.str.replace('(&gt)', '')\n",
        "    ReviewText = ReviewText.str.replace('(&lt)', '')\n",
        "    ReviewText = ReviewText.str.replace('(\\xa0)', '')\n",
        "    ReviewText = ReviewText.str.replace(',', '')\n",
        "    ReviewText = ReviewText.str.replace('--', '')    \n",
        "    ReviewText = ReviewText.str.replace('`', '')    \n",
        "\n",
        "    return ReviewText\n",
        "df['Review Text'] = preprocess(df['Sentence'])\n",
        "\n",
        "df['polarity'] = df['Sentence'].map(lambda text: TextBlob(text).sentiment.polarity)\n",
        "df['sentence_len'] = df['Review Text'].astype(str).apply(len)\n",
        "df['word_count'] = df['Sentence'].apply(lambda x: len(str(x).split()))"
      ],
      "metadata": {
        "id": "-3ssMm1PG6bz"
      },
      "execution_count": 35,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df = df.drop([\"sentence_len\", \"Sentence\",\"word_count\",\"polarity\" ] , axis =1)\n"
      ],
      "metadata": {
        "id": "l6UVSjnUrJZ7"
      },
      "execution_count": 36,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Sentiment Analysis using BERT"
      ],
      "metadata": {
        "id": "u_LkJij6lsOf"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "X_features = df[\"Review Text\"]\n",
        "Y_features = df[\"Sentiment\"]\n",
        "X_train, X_val, y_train, y_val = train_test_split(df.index.values, df.Sentiment.values, test_size=0.2, random_state=42, shuffle=True)"
      ],
      "metadata": {
        "id": "7fS-iD5jlygM"
      },
      "execution_count": 37,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import BertTokenizer,BertForSequenceClassification\n",
        "\n",
        "tokenizer = BertTokenizer.from_pretrained(\"bert-base-uncased\")\n",
        "model = BertForSequenceClassification.from_pretrained('bert-base-uncased',\n",
        "                                                      num_labels = 3,\n",
        "                                                      id2label={0: 'negative', 1: 'neutral', 2: 'positive'},\n",
        "                                                      output_attentions = False,\n",
        "                                                      output_hidden_states = False).to(device)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NFqRzcKbntvM",
        "outputId": "19aae264-efa5-4fcb-e0bd-cf88aca39bc5"
      },
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertForSequenceClassification: ['cls.predictions.decoder.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.transform.LayerNorm.bias', 'cls.seq_relationship.weight', 'cls.predictions.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.seq_relationship.bias', 'cls.predictions.transform.dense.weight']\n",
            "- This IS expected if you are initializing BertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing BertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.weight', 'classifier.bias']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df['data_type'] = ['not_set'] * df.shape[0]\n",
        "\n",
        "df.loc[X_train, 'data_type'] = 'train'\n",
        "df.loc[X_val, 'data_type'] = 'val'\n",
        "\n",
        "#groupby count\n",
        "df.groupby([ 'Sentiment', 'data_type']).count()\n",
        "df = df.rename(columns={'Review Text': 'Sentence'})\n"
      ],
      "metadata": {
        "id": "XvfkG7kv0MX1"
      },
      "execution_count": 39,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#encode train set\n",
        "encoded_data_train = tokenizer.batch_encode_plus(df[df.data_type == 'train'].Sentence.values,\n",
        "                                                add_special_tokens = True,\n",
        "                                                return_attention_mask = True,\n",
        "                                                pad_to_max_length = True,\n",
        "                                                max_length = 80,\n",
        "                                                return_tensors = 'pt')\n",
        "                                                \n",
        "#encode validation set\n",
        "encoded_data_val = tokenizer.batch_encode_plus( df[df.data_type == 'val'].Sentence.values,\n",
        "                                                add_special_tokens = True,\n",
        "                                                return_attention_mask = True,\n",
        "                                                pad_to_max_length = True,\n",
        "                                                max_length = 80,\n",
        "                                                return_tensors = 'pt')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_t00AHGuvgAo",
        "outputId": "7d340bba-e637-4b1e-edc6-c25de723b07a"
      },
      "execution_count": 40,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#train set\n",
        "input_ids_train = encoded_data_train['input_ids']\n",
        "attention_masks_train = encoded_data_train['attention_mask']\n",
        "labels_train = torch.tensor(df[df.data_type == 'train'].Sentiment.values)\n",
        "\n",
        "#validation set\n",
        "input_ids_val = encoded_data_val['input_ids']\n",
        "attention_masks_val = encoded_data_val['attention_mask']\n",
        "labels_val = torch.tensor(df[df.data_type == 'val'].Sentiment.values)\n",
        "     "
      ],
      "metadata": {
        "id": "-J5twuCRxA7O"
      },
      "execution_count": 41,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from torch.utils.data import TensorDataset\n",
        "\n",
        "#train set\n",
        "dataset_train = TensorDataset(input_ids_train, \n",
        "                              attention_masks_train,\n",
        "                              labels_train)\n",
        "\n",
        "#validation set\n",
        "dataset_val = TensorDataset(input_ids_val, \n",
        "                             attention_masks_val, \n",
        "                             labels_val)"
      ],
      "metadata": {
        "id": "joRW8_E34QX3"
      },
      "execution_count": 42,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from torch.utils.data import DataLoader, RandomSampler, SequentialSampler\n",
        "\n",
        "batch_size = 8\n",
        "\n",
        "#train set\n",
        "dataloader_train = DataLoader(dataset_train,\n",
        "                              sampler = RandomSampler(dataset_train),\n",
        "                              batch_size = batch_size)\n",
        "\n",
        "#validation set\n",
        "dataloader_val = DataLoader(dataset_val,\n",
        "                              sampler = RandomSampler(dataset_val),\n",
        "                              batch_size = 8) #since we don't have to do backpropagation for this step"
      ],
      "metadata": {
        "id": "kue1cFIC4QaZ"
      },
      "execution_count": 43,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import AdamW, get_linear_schedule_with_warmup\n",
        "\n",
        "optimizer = AdamW(model.parameters(),\n",
        "                 lr = 1e-5,\n",
        "                 eps = 1e-7) #2e-5 > 5e-5\n",
        "                 \n",
        "epochs = 5\n",
        "\n",
        "scheduler = get_linear_schedule_with_warmup(optimizer,\n",
        "                                           num_warmup_steps = 0,\n",
        "                                           num_training_steps =len(dataloader_train)*epochs)\n"
      ],
      "metadata": {
        "id": "nfrQRiNf4Qc1"
      },
      "execution_count": 44,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def evaluate(dataloader_val):\n",
        "\n",
        "    #evaluation mode \n",
        "    model.eval()\n",
        "    \n",
        "    #tracking variables\n",
        "    loss_val_total = 0\n",
        "    predictions, true_vals = [], []\n",
        "    \n",
        "    for batch in tqdm(dataloader_val):\n",
        "        \n",
        "        #load into GPU\n",
        "        batch = tuple(b.to(device) for b in batch)\n",
        "        \n",
        "        #define inputs\n",
        "        inputs = {'input_ids':      batch[0],\n",
        "                  'attention_mask': batch[1],\n",
        "                  'labels':         batch[2]}\n",
        "\n",
        "        #compute logits\n",
        "        with torch.no_grad():        \n",
        "            outputs = model(**inputs)\n",
        "        \n",
        "        #compute loss\n",
        "        loss = outputs[0]\n",
        "        logits = outputs[1]\n",
        "        loss_val_total += loss.item()\n",
        "\n",
        "        #compute accuracy\n",
        "        logits = logits.detach().cpu().numpy()\n",
        "        label_ids = inputs['labels'].cpu().numpy()\n",
        "        predictions.append(logits)\n",
        "        true_vals.append(label_ids)\n",
        "    \n",
        "    #compute average loss\n",
        "    loss_val_avg = loss_val_total/len(dataloader_val) \n",
        "    \n",
        "    predictions = np.concatenate(predictions, axis=0)\n",
        "    true_vals = np.concatenate(true_vals, axis=0)\n",
        "            \n",
        "    return loss_val_avg, predictions, true_vals"
      ],
      "metadata": {
        "id": "_hTFuvA04Xg_"
      },
      "execution_count": 45,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import f1_score\n",
        "\n",
        "def f1_score_func(preds, labels):\n",
        "    preds_flat = np.argmax(preds, axis = 1).flatten()\n",
        "    labels_flat = labels.flatten()\n",
        "    return f1_score(labels_flat, preds_flat, average = 'weighted')"
      ],
      "metadata": {
        "id": "sIzdaLGr4ara"
      },
      "execution_count": 46,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#accuracy score\n",
        "def accuracy_per_class(preds, labels):\n",
        "    #label_dict_inverse = {v: k for k, v in label_dict.items()}\n",
        "    \n",
        "    #make prediction\n",
        "    preds_flat = np.argmax(preds, axis=1).flatten()\n",
        "    labels_flat = labels.flatten()\n",
        "    \n",
        "    for label in np.unique(labels_flat):\n",
        "        y_preds = preds_flat[labels_flat==label]\n",
        "        y_true = labels_flat[labels_flat==label]\n",
        "        #print(f'Class: {label_dict_inverse[label]}')\n",
        "        print(f'Accuracy:{len(y_preds[y_preds==label])}/{len(y_true)}\\n -> {len(y_preds[y_preds==label]) / len(y_true)}')"
      ],
      "metadata": {
        "id": "Z9CCDzC14dMH"
      },
      "execution_count": 47,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import random\n",
        "\n",
        "seed_val = 17\n",
        "random.seed(seed_val)\n",
        "np.random.seed(seed_val)\n",
        "torch.manual_seed(seed_val)\n",
        "torch.cuda.manual_seed_all(seed_val)"
      ],
      "metadata": {
        "id": "OehAW6vX4e7B"
      },
      "execution_count": 48,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from tqdm import tqdm\n",
        "\n",
        "for epoch in tqdm(range(1, epochs+1)):\n",
        "    \n",
        "    model.train()\n",
        "    \n",
        "    loss_train_total = 0\n",
        "    \n",
        "    progress_bar = tqdm(dataloader_train, \n",
        "                        desc = 'Epoch {:1d}'.format(epoch), \n",
        "                        leave = False, \n",
        "                        disable = False)\n",
        "    \n",
        "    for batch in progress_bar:\n",
        "        \n",
        "        model.zero_grad() #set gradient to 0\n",
        "    \n",
        "        batch = tuple(b.to(device) for b in batch)\n",
        "        \n",
        "        inputs = {'input_ids': batch[0], \n",
        "                  'attention_mask': batch[1], \n",
        "                  'labels': batch[2]}\n",
        "        \n",
        "        outputs = model(**inputs) #unpack the dict straight into inputs\n",
        "        \n",
        "        loss = outputs[0]\n",
        "        loss_train_total += loss.item()\n",
        "        loss.backward()\n",
        "        \n",
        "        torch.nn.utils.clip_grad_norm_(model.parameters(), 1.0)\n",
        "        \n",
        "        optimizer.step()\n",
        "        scheduler.step()\n",
        "        progress_bar.set_postfix({'training_loss': '{:.3f}'.format(loss.item() / len(batch))})\n",
        "        \n",
        "    torch.save(model.state_dict(), f'/content/gdrive/MyDrive/NLP/BERT_ft_epoch{epoch}.model')\n",
        "    \n",
        "    tqdm.write('\\n Epoch {epoch}')\n",
        "    \n",
        "    loss_train_ave = loss_train_total / len(dataloader_train)\n",
        "    tqdm.write('Training loss: {loss_train_avg}')\n",
        "    \n",
        "    val_loss, predictions, true_vals = evaluate(dataloader_val)\n",
        "    val_f1 = f1_score_func(predictions, true_vals)\n",
        "    tqdm.write(f'Validation loss: {val_loss}')\n",
        "    tqdm.write(f'F1 Score (weighted): {val_f1}')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "d5EMKCDo4hmk",
        "outputId": "902b6d3c-530b-4984-dac6-37764fe4e8d7"
      },
      "execution_count": 49,
      "outputs": [
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "  0%|          | 0/5 [00:00<?, ?it/s]\n",
            "Epoch 1:   0%|          | 0/484 [00:00<?, ?it/s]\u001b[A\n",
            "Epoch 1:   0%|          | 0/484 [00:11<?, ?it/s, training_loss=0.386]\u001b[A\n",
            "Epoch 1:   0%|          | 1/484 [00:11<1:32:55, 11.54s/it, training_loss=0.386]\u001b[A\n",
            "Epoch 1:   0%|          | 1/484 [00:19<1:32:55, 11.54s/it, training_loss=0.380]\u001b[A\n",
            "Epoch 1:   0%|          | 2/484 [00:19<1:17:43,  9.67s/it, training_loss=0.380]\u001b[A\n",
            "Epoch 1:   0%|          | 2/484 [00:26<1:17:43,  9.67s/it, training_loss=0.402]\u001b[A\n",
            "Epoch 1:   1%|          | 3/484 [00:26<1:06:26,  8.29s/it, training_loss=0.402]\u001b[A\n",
            "Epoch 1:   1%|          | 3/484 [00:36<1:06:26,  8.29s/it, training_loss=0.384]\u001b[A\n",
            "Epoch 1:   1%|          | 4/484 [00:36<1:10:00,  8.75s/it, training_loss=0.384]\u001b[A\n",
            "Epoch 1:   1%|          | 4/484 [00:42<1:10:00,  8.75s/it, training_loss=0.365]\u001b[A\n",
            "Epoch 1:   1%|          | 5/484 [00:42<1:03:20,  7.93s/it, training_loss=0.365]\u001b[A\n",
            "Epoch 1:   1%|          | 5/484 [00:51<1:03:20,  7.93s/it, training_loss=0.382]\u001b[A\n",
            "Epoch 1:   1%|          | 6/484 [00:51<1:06:37,  8.36s/it, training_loss=0.382]\u001b[A\n",
            "Epoch 1:   1%|          | 6/484 [00:58<1:06:37,  8.36s/it, training_loss=0.346]\u001b[A\n",
            "Epoch 1:   1%|▏         | 7/484 [00:58<1:02:37,  7.88s/it, training_loss=0.346]\u001b[A\n",
            "Epoch 1:   1%|▏         | 7/484 [01:06<1:02:37,  7.88s/it, training_loss=0.339]\u001b[A\n",
            "Epoch 1:   2%|▏         | 8/484 [01:06<1:01:47,  7.79s/it, training_loss=0.339]\u001b[A\n",
            "Epoch 1:   2%|▏         | 8/484 [01:14<1:01:47,  7.79s/it, training_loss=0.346]\u001b[A\n",
            "Epoch 1:   2%|▏         | 9/484 [01:14<1:02:41,  7.92s/it, training_loss=0.346]\u001b[A\n",
            "Epoch 1:   2%|▏         | 9/484 [01:20<1:02:41,  7.92s/it, training_loss=0.323]\u001b[A\n",
            "Epoch 1:   2%|▏         | 10/484 [01:20<58:57,  7.46s/it, training_loss=0.323] \u001b[A\n",
            "Epoch 1:   2%|▏         | 10/484 [01:30<58:57,  7.46s/it, training_loss=0.354]\u001b[A\n",
            "Epoch 1:   2%|▏         | 11/484 [01:30<1:03:58,  8.12s/it, training_loss=0.354]\u001b[A\n",
            "Epoch 1:   2%|▏         | 11/484 [01:36<1:03:58,  8.12s/it, training_loss=0.382]\u001b[A\n",
            "Epoch 1:   2%|▏         | 12/484 [01:36<59:55,  7.62s/it, training_loss=0.382]  \u001b[A\n",
            "Epoch 1:   2%|▏         | 12/484 [01:45<59:55,  7.62s/it, training_loss=0.373]\u001b[A\n",
            "Epoch 1:   3%|▎         | 13/484 [01:45<1:02:30,  7.96s/it, training_loss=0.373]\u001b[A\n",
            "Epoch 1:   3%|▎         | 13/484 [01:52<1:02:30,  7.96s/it, training_loss=0.364]\u001b[A\n",
            "Epoch 1:   3%|▎         | 14/484 [01:52<1:00:40,  7.75s/it, training_loss=0.364]\u001b[A\n",
            "Epoch 1:   3%|▎         | 14/484 [01:59<1:00:40,  7.75s/it, training_loss=0.317]\u001b[A\n",
            "Epoch 1:   3%|▎         | 15/484 [01:59<58:53,  7.53s/it, training_loss=0.317]  \u001b[A\n",
            "Epoch 1:   3%|▎         | 15/484 [02:08<58:53,  7.53s/it, training_loss=0.374]\u001b[A\n",
            "Epoch 1:   3%|▎         | 16/484 [02:08<1:01:37,  7.90s/it, training_loss=0.374]\u001b[A\n",
            "Epoch 1:   3%|▎         | 16/484 [02:15<1:01:37,  7.90s/it, training_loss=0.324]\u001b[A\n",
            "Epoch 1:   4%|▎         | 17/484 [02:15<58:12,  7.48s/it, training_loss=0.324]  \u001b[A\n",
            "Epoch 1:   4%|▎         | 17/484 [02:24<58:12,  7.48s/it, training_loss=0.313]\u001b[A\n",
            "Epoch 1:   4%|▎         | 18/484 [02:24<1:02:53,  8.10s/it, training_loss=0.313]\u001b[A\n",
            "Epoch 1:   4%|▎         | 18/484 [02:31<1:02:53,  8.10s/it, training_loss=0.326]\u001b[A\n",
            "Epoch 1:   4%|▍         | 19/484 [02:31<59:05,  7.62s/it, training_loss=0.326]  \u001b[A\n",
            "Epoch 1:   4%|▍         | 19/484 [02:39<59:05,  7.62s/it, training_loss=0.330]\u001b[A\n",
            "Epoch 1:   4%|▍         | 20/484 [02:39<1:00:27,  7.82s/it, training_loss=0.330]\u001b[A\n",
            "Epoch 1:   4%|▍         | 20/484 [02:47<1:00:27,  7.82s/it, training_loss=0.332]\u001b[A\n",
            "Epoch 1:   4%|▍         | 21/484 [02:47<1:00:04,  7.78s/it, training_loss=0.332]\u001b[A\n",
            "Epoch 1:   4%|▍         | 21/484 [02:53<1:00:04,  7.78s/it, training_loss=0.338]\u001b[A\n",
            "Epoch 1:   5%|▍         | 22/484 [02:53<57:26,  7.46s/it, training_loss=0.338]  \u001b[A\n",
            "Epoch 1:   5%|▍         | 22/484 [03:03<57:26,  7.46s/it, training_loss=0.346]\u001b[A\n",
            "Epoch 1:   5%|▍         | 23/484 [03:03<1:01:30,  8.00s/it, training_loss=0.346]\u001b[A\n",
            "Epoch 1:   5%|▍         | 23/484 [03:09<1:01:30,  8.00s/it, training_loss=0.311]\u001b[A\n",
            "Epoch 1:   5%|▍         | 24/484 [03:09<57:52,  7.55s/it, training_loss=0.311]  \u001b[A\n",
            "Epoch 1:   5%|▍         | 24/484 [03:19<57:52,  7.55s/it, training_loss=0.366]\u001b[A\n",
            "Epoch 1:   5%|▌         | 25/484 [03:19<1:01:52,  8.09s/it, training_loss=0.366]\u001b[A\n",
            "Epoch 1:   5%|▌         | 25/484 [03:25<1:01:52,  8.09s/it, training_loss=0.315]\u001b[A\n",
            "Epoch 1:   5%|▌         | 26/484 [03:25<58:49,  7.71s/it, training_loss=0.315]  \u001b[A\n",
            "Epoch 1:   5%|▌         | 26/484 [03:33<58:49,  7.71s/it, training_loss=0.291]\u001b[A\n",
            "Epoch 1:   6%|▌         | 27/484 [03:33<58:49,  7.72s/it, training_loss=0.291]\u001b[A\n",
            "Epoch 1:   6%|▌         | 27/484 [03:41<58:49,  7.72s/it, training_loss=0.325]\u001b[A\n",
            "Epoch 1:   6%|▌         | 28/484 [03:41<59:30,  7.83s/it, training_loss=0.325]\u001b[A\n",
            "Epoch 1:   6%|▌         | 28/484 [03:48<59:30,  7.83s/it, training_loss=0.281]\u001b[A\n",
            "Epoch 1:   6%|▌         | 29/484 [03:48<56:15,  7.42s/it, training_loss=0.281]\u001b[A\n",
            "Epoch 1:   6%|▌         | 29/484 [03:57<56:15,  7.42s/it, training_loss=0.324]\u001b[A\n",
            "Epoch 1:   6%|▌         | 30/484 [03:57<1:01:03,  8.07s/it, training_loss=0.324]\u001b[A\n",
            "Epoch 1:   6%|▌         | 30/484 [04:04<1:01:03,  8.07s/it, training_loss=0.326]\u001b[A\n",
            "Epoch 1:   6%|▋         | 31/484 [04:04<57:22,  7.60s/it, training_loss=0.326]  \u001b[A\n",
            "Epoch 1:   6%|▋         | 31/484 [04:13<57:22,  7.60s/it, training_loss=0.358]\u001b[A\n",
            "Epoch 1:   7%|▋         | 32/484 [04:13<1:00:30,  8.03s/it, training_loss=0.358]\u001b[A\n",
            "Epoch 1:   7%|▋         | 32/484 [04:20<1:00:30,  8.03s/it, training_loss=0.290]\u001b[A\n",
            "Epoch 1:   7%|▋         | 33/484 [04:20<58:05,  7.73s/it, training_loss=0.290]  \u001b[A\n",
            "Epoch 1:   7%|▋         | 33/484 [04:27<58:05,  7.73s/it, training_loss=0.316]\u001b[A\n",
            "Epoch 1:   7%|▋         | 34/484 [04:27<57:19,  7.64s/it, training_loss=0.316]\u001b[A\n",
            "Epoch 1:   7%|▋         | 34/484 [04:36<57:19,  7.64s/it, training_loss=0.393]\u001b[A\n",
            "Epoch 1:   7%|▋         | 35/484 [04:36<58:51,  7.87s/it, training_loss=0.393]\u001b[A\n",
            "Epoch 1:   7%|▋         | 35/484 [04:42<58:51,  7.87s/it, training_loss=0.303]\u001b[A\n",
            "Epoch 1:   7%|▋         | 36/484 [04:42<55:38,  7.45s/it, training_loss=0.303]\u001b[A\n",
            "Epoch 1:   7%|▋         | 36/484 [04:52<55:38,  7.45s/it, training_loss=0.352]\u001b[A\n",
            "Epoch 1:   8%|▊         | 37/484 [04:52<1:00:17,  8.09s/it, training_loss=0.352]\u001b[A\n",
            "Epoch 1:   8%|▊         | 37/484 [04:58<1:00:17,  8.09s/it, training_loss=0.299]\u001b[A\n",
            "Epoch 1:   8%|▊         | 38/484 [04:58<56:33,  7.61s/it, training_loss=0.299]  \u001b[A\n",
            "Epoch 1:   8%|▊         | 38/484 [05:07<56:33,  7.61s/it, training_loss=0.311]\u001b[A\n",
            "Epoch 1:   8%|▊         | 39/484 [05:07<58:59,  7.95s/it, training_loss=0.311]\u001b[A\n",
            "Epoch 1:   8%|▊         | 39/484 [05:14<58:59,  7.95s/it, training_loss=0.289]\u001b[A\n",
            "Epoch 1:   8%|▊         | 40/484 [05:14<57:18,  7.74s/it, training_loss=0.289]\u001b[A\n",
            "Epoch 1:   8%|▊         | 40/484 [05:21<57:18,  7.74s/it, training_loss=0.376]\u001b[A\n",
            "Epoch 1:   8%|▊         | 41/484 [05:21<55:58,  7.58s/it, training_loss=0.376]\u001b[A\n",
            "Epoch 1:   8%|▊         | 41/484 [05:30<55:58,  7.58s/it, training_loss=0.359]\u001b[A\n",
            "Epoch 1:   9%|▊         | 42/484 [05:30<58:20,  7.92s/it, training_loss=0.359]\u001b[A\n",
            "Epoch 1:   9%|▊         | 42/484 [05:37<58:20,  7.92s/it, training_loss=0.251]\u001b[A\n",
            "Epoch 1:   9%|▉         | 43/484 [05:37<54:57,  7.48s/it, training_loss=0.251]\u001b[A\n",
            "Epoch 1:   9%|▉         | 43/484 [05:46<54:57,  7.48s/it, training_loss=0.265]\u001b[A\n",
            "Epoch 1:   9%|▉         | 44/484 [05:46<59:22,  8.10s/it, training_loss=0.265]\u001b[A\n",
            "Epoch 1:   9%|▉         | 44/484 [05:53<59:22,  8.10s/it, training_loss=0.352]\u001b[A\n",
            "Epoch 1:   9%|▉         | 45/484 [05:53<55:36,  7.60s/it, training_loss=0.352]\u001b[A\n",
            "Epoch 1:   9%|▉         | 45/484 [06:01<55:36,  7.60s/it, training_loss=0.343]\u001b[A\n",
            "Epoch 1:  10%|▉         | 46/484 [06:01<57:07,  7.83s/it, training_loss=0.343]\u001b[A\n",
            "Epoch 1:  10%|▉         | 46/484 [06:08<57:07,  7.83s/it, training_loss=0.295]\u001b[A\n",
            "Epoch 1:  10%|▉         | 47/484 [06:08<56:26,  7.75s/it, training_loss=0.295]\u001b[A\n",
            "Epoch 1:  10%|▉         | 47/484 [06:15<56:26,  7.75s/it, training_loss=0.280]\u001b[A\n",
            "Epoch 1:  10%|▉         | 48/484 [06:15<53:53,  7.42s/it, training_loss=0.280]\u001b[A\n",
            "Epoch 1:  10%|▉         | 48/484 [06:24<53:53,  7.42s/it, training_loss=0.284]\u001b[A\n",
            "Epoch 1:  10%|█         | 49/484 [06:24<57:45,  7.97s/it, training_loss=0.284]\u001b[A\n",
            "Epoch 1:  10%|█         | 49/484 [06:31<57:45,  7.97s/it, training_loss=0.292]\u001b[A\n",
            "Epoch 1:  10%|█         | 50/484 [06:31<54:22,  7.52s/it, training_loss=0.292]\u001b[A\n",
            "Epoch 1:  10%|█         | 50/484 [06:40<54:22,  7.52s/it, training_loss=0.290]\u001b[A\n",
            "Epoch 1:  11%|█         | 51/484 [06:40<58:03,  8.04s/it, training_loss=0.290]\u001b[A\n",
            "Epoch 1:  11%|█         | 51/484 [06:47<58:03,  8.04s/it, training_loss=0.382]\u001b[A\n",
            "Epoch 1:  11%|█         | 52/484 [06:47<55:05,  7.65s/it, training_loss=0.382]\u001b[A\n",
            "Epoch 1:  11%|█         | 52/484 [06:55<55:05,  7.65s/it, training_loss=0.324]\u001b[A\n",
            "Epoch 1:  11%|█         | 53/484 [06:55<55:28,  7.72s/it, training_loss=0.324]\u001b[A\n",
            "Epoch 1:  11%|█         | 53/484 [07:03<55:28,  7.72s/it, training_loss=0.296]\u001b[A\n",
            "Epoch 1:  11%|█         | 54/484 [07:03<56:20,  7.86s/it, training_loss=0.296]\u001b[A\n",
            "Epoch 1:  11%|█         | 54/484 [07:10<56:20,  7.86s/it, training_loss=0.271]\u001b[A\n",
            "Epoch 1:  11%|█▏        | 55/484 [07:10<53:33,  7.49s/it, training_loss=0.271]\u001b[A\n",
            "Epoch 1:  11%|█▏        | 55/484 [07:19<53:33,  7.49s/it, training_loss=0.260]\u001b[A\n",
            "Epoch 1:  12%|█▏        | 56/484 [07:19<57:50,  8.11s/it, training_loss=0.260]\u001b[A\n",
            "Epoch 1:  12%|█▏        | 56/484 [07:26<57:50,  8.11s/it, training_loss=0.377]\u001b[A\n",
            "Epoch 1:  12%|█▏        | 57/484 [07:26<54:08,  7.61s/it, training_loss=0.377]\u001b[A\n",
            "Epoch 1:  12%|█▏        | 57/484 [07:35<54:08,  7.61s/it, training_loss=0.375]\u001b[A\n",
            "Epoch 1:  12%|█▏        | 58/484 [07:35<56:59,  8.03s/it, training_loss=0.375]\u001b[A\n",
            "Epoch 1:  12%|█▏        | 58/484 [07:42<56:59,  8.03s/it, training_loss=0.294]\u001b[A\n",
            "Epoch 1:  12%|█▏        | 59/484 [07:42<54:40,  7.72s/it, training_loss=0.294]\u001b[A\n",
            "Epoch 1:  12%|█▏        | 59/484 [07:49<54:40,  7.72s/it, training_loss=0.327]\u001b[A\n",
            "Epoch 1:  12%|█▏        | 60/484 [07:49<53:50,  7.62s/it, training_loss=0.327]\u001b[A\n",
            "Epoch 1:  12%|█▏        | 60/484 [07:57<53:50,  7.62s/it, training_loss=0.290]\u001b[A\n",
            "Epoch 1:  13%|█▎        | 61/484 [07:57<55:28,  7.87s/it, training_loss=0.290]\u001b[A\n",
            "Epoch 1:  13%|█▎        | 61/484 [08:04<55:28,  7.87s/it, training_loss=0.267]\u001b[A\n",
            "Epoch 1:  13%|█▎        | 62/484 [08:04<52:25,  7.45s/it, training_loss=0.267]\u001b[A\n",
            "Epoch 1:  13%|█▎        | 62/484 [08:13<52:25,  7.45s/it, training_loss=0.324]\u001b[A\n",
            "Epoch 1:  13%|█▎        | 63/484 [08:13<56:51,  8.10s/it, training_loss=0.324]\u001b[A\n",
            "Epoch 1:  13%|█▎        | 63/484 [08:20<56:51,  8.10s/it, training_loss=0.225]\u001b[A\n",
            "Epoch 1:  13%|█▎        | 64/484 [08:20<53:16,  7.61s/it, training_loss=0.225]\u001b[A\n",
            "Epoch 1:  13%|█▎        | 64/484 [08:29<53:16,  7.61s/it, training_loss=0.336]\u001b[A\n",
            "Epoch 1:  13%|█▎        | 65/484 [08:29<55:23,  7.93s/it, training_loss=0.336]\u001b[A\n",
            "Epoch 1:  13%|█▎        | 65/484 [08:36<55:23,  7.93s/it, training_loss=0.271]\u001b[A\n",
            "Epoch 1:  14%|█▎        | 66/484 [08:36<54:10,  7.78s/it, training_loss=0.271]\u001b[A\n",
            "Epoch 1:  14%|█▎        | 66/484 [08:43<54:10,  7.78s/it, training_loss=0.357]\u001b[A\n",
            "Epoch 1:  14%|█▍        | 67/484 [08:43<52:07,  7.50s/it, training_loss=0.357]\u001b[A\n",
            "Epoch 1:  14%|█▍        | 67/484 [08:52<52:07,  7.50s/it, training_loss=0.232]\u001b[A\n",
            "Epoch 1:  14%|█▍        | 68/484 [08:52<55:00,  7.93s/it, training_loss=0.232]\u001b[A\n",
            "Epoch 1:  14%|█▍        | 68/484 [08:58<55:00,  7.93s/it, training_loss=0.237]\u001b[A\n",
            "Epoch 1:  14%|█▍        | 69/484 [08:58<51:57,  7.51s/it, training_loss=0.237]\u001b[A\n",
            "Epoch 1:  14%|█▍        | 69/484 [09:08<51:57,  7.51s/it, training_loss=0.298]\u001b[A\n",
            "Epoch 1:  14%|█▍        | 70/484 [09:08<55:53,  8.10s/it, training_loss=0.298]\u001b[A\n",
            "Epoch 1:  14%|█▍        | 70/484 [09:14<55:53,  8.10s/it, training_loss=0.296]\u001b[A\n",
            "Epoch 1:  15%|█▍        | 71/484 [09:14<52:36,  7.64s/it, training_loss=0.296]\u001b[A\n",
            "Epoch 1:  15%|█▍        | 71/484 [09:23<52:36,  7.64s/it, training_loss=0.282]\u001b[A\n",
            "Epoch 1:  15%|█▍        | 72/484 [09:23<53:33,  7.80s/it, training_loss=0.282]\u001b[A\n",
            "Epoch 1:  15%|█▍        | 72/484 [09:31<53:33,  7.80s/it, training_loss=0.275]\u001b[A\n",
            "Epoch 1:  15%|█▌        | 73/484 [09:31<54:40,  7.98s/it, training_loss=0.275]\u001b[A\n",
            "Epoch 1:  15%|█▌        | 73/484 [09:40<54:40,  7.98s/it, training_loss=0.258]\u001b[A\n",
            "Epoch 1:  15%|█▌        | 74/484 [09:40<56:40,  8.29s/it, training_loss=0.258]\u001b[A\n",
            "Epoch 1:  15%|█▌        | 74/484 [09:48<56:40,  8.29s/it, training_loss=0.287]\u001b[A\n",
            "Epoch 1:  15%|█▌        | 75/484 [09:48<56:02,  8.22s/it, training_loss=0.287]\u001b[A\n",
            "Epoch 1:  15%|█▌        | 75/484 [09:54<56:02,  8.22s/it, training_loss=0.187]\u001b[A\n",
            "Epoch 1:  16%|█▌        | 76/484 [09:54<52:12,  7.68s/it, training_loss=0.187]\u001b[A\n",
            "Epoch 1:  16%|█▌        | 76/484 [10:04<52:12,  7.68s/it, training_loss=0.254]\u001b[A\n",
            "Epoch 1:  16%|█▌        | 77/484 [10:04<56:02,  8.26s/it, training_loss=0.254]\u001b[A\n",
            "Epoch 1:  16%|█▌        | 77/484 [10:11<56:02,  8.26s/it, training_loss=0.180]\u001b[A\n",
            "Epoch 1:  16%|█▌        | 78/484 [10:11<52:12,  7.72s/it, training_loss=0.180]\u001b[A\n",
            "Epoch 1:  16%|█▌        | 78/484 [10:19<52:12,  7.72s/it, training_loss=0.195]\u001b[A\n",
            "Epoch 1:  16%|█▋        | 79/484 [10:19<54:33,  8.08s/it, training_loss=0.195]\u001b[A\n",
            "Epoch 1:  16%|█▋        | 79/484 [10:27<54:33,  8.08s/it, training_loss=0.208]\u001b[A\n",
            "Epoch 1:  17%|█▋        | 80/484 [10:27<52:32,  7.80s/it, training_loss=0.208]\u001b[A\n",
            "Epoch 1:  17%|█▋        | 80/484 [10:34<52:32,  7.80s/it, training_loss=0.306]\u001b[A\n",
            "Epoch 1:  17%|█▋        | 81/484 [10:34<51:19,  7.64s/it, training_loss=0.306]\u001b[A\n",
            "Epoch 1:  17%|█▋        | 81/484 [10:42<51:19,  7.64s/it, training_loss=0.233]\u001b[A\n",
            "Epoch 1:  17%|█▋        | 82/484 [10:42<53:07,  7.93s/it, training_loss=0.233]\u001b[A\n",
            "Epoch 1:  17%|█▋        | 82/484 [10:49<53:07,  7.93s/it, training_loss=0.180]\u001b[A\n",
            "Epoch 1:  17%|█▋        | 83/484 [10:49<50:09,  7.51s/it, training_loss=0.180]\u001b[A\n",
            "Epoch 1:  17%|█▋        | 83/484 [10:59<50:09,  7.51s/it, training_loss=0.257]\u001b[A\n",
            "Epoch 1:  17%|█▋        | 84/484 [10:59<54:15,  8.14s/it, training_loss=0.257]\u001b[A\n",
            "Epoch 1:  17%|█▋        | 84/484 [11:05<54:15,  8.14s/it, training_loss=0.260]\u001b[A\n",
            "Epoch 1:  18%|█▊        | 85/484 [11:05<50:42,  7.63s/it, training_loss=0.260]\u001b[A\n",
            "Epoch 1:  18%|█▊        | 85/484 [11:14<50:42,  7.63s/it, training_loss=0.195]\u001b[A\n",
            "Epoch 1:  18%|█▊        | 86/484 [11:14<52:20,  7.89s/it, training_loss=0.195]\u001b[A\n",
            "Epoch 1:  18%|█▊        | 86/484 [11:21<52:20,  7.89s/it, training_loss=0.149]\u001b[A\n",
            "Epoch 1:  18%|█▊        | 87/484 [11:21<51:27,  7.78s/it, training_loss=0.149]\u001b[A\n",
            "Epoch 1:  18%|█▊        | 87/484 [11:28<51:27,  7.78s/it, training_loss=0.225]\u001b[A\n",
            "Epoch 1:  18%|█▊        | 88/484 [11:28<49:26,  7.49s/it, training_loss=0.225]\u001b[A\n",
            "Epoch 1:  18%|█▊        | 88/484 [11:37<49:26,  7.49s/it, training_loss=0.158]\u001b[A\n",
            "Epoch 1:  18%|█▊        | 89/484 [11:37<52:17,  7.94s/it, training_loss=0.158]\u001b[A\n",
            "Epoch 1:  18%|█▊        | 89/484 [11:43<52:17,  7.94s/it, training_loss=0.255]\u001b[A\n",
            "Epoch 1:  19%|█▊        | 90/484 [11:43<49:16,  7.50s/it, training_loss=0.255]\u001b[A\n",
            "Epoch 1:  19%|█▊        | 90/484 [11:53<49:16,  7.50s/it, training_loss=0.092]\u001b[A\n",
            "Epoch 1:  19%|█▉        | 91/484 [11:53<52:50,  8.07s/it, training_loss=0.092]\u001b[A\n",
            "Epoch 1:  19%|█▉        | 91/484 [11:59<52:50,  8.07s/it, training_loss=0.311]\u001b[A\n",
            "Epoch 1:  19%|█▉        | 92/484 [11:59<49:48,  7.62s/it, training_loss=0.311]\u001b[A\n",
            "Epoch 1:  19%|█▉        | 92/484 [12:07<49:48,  7.62s/it, training_loss=0.374]\u001b[A\n",
            "Epoch 1:  19%|█▉        | 93/484 [12:07<50:22,  7.73s/it, training_loss=0.374]\u001b[A\n",
            "Epoch 1:  19%|█▉        | 93/484 [12:15<50:22,  7.73s/it, training_loss=0.194]\u001b[A\n",
            "Epoch 1:  19%|█▉        | 94/484 [12:15<50:37,  7.79s/it, training_loss=0.194]\u001b[A\n",
            "Epoch 1:  19%|█▉        | 94/484 [12:22<50:37,  7.79s/it, training_loss=0.338]\u001b[A\n",
            "Epoch 1:  20%|█▉        | 95/484 [12:22<48:02,  7.41s/it, training_loss=0.338]\u001b[A\n",
            "Epoch 1:  20%|█▉        | 95/484 [12:31<48:02,  7.41s/it, training_loss=0.286]\u001b[A\n",
            "Epoch 1:  20%|█▉        | 96/484 [12:31<52:00,  8.04s/it, training_loss=0.286]\u001b[A\n",
            "Epoch 1:  20%|█▉        | 96/484 [12:38<52:00,  8.04s/it, training_loss=0.219]\u001b[A\n",
            "Epoch 1:  20%|██        | 97/484 [12:38<48:45,  7.56s/it, training_loss=0.219]\u001b[A\n",
            "Epoch 1:  20%|██        | 97/484 [12:47<48:45,  7.56s/it, training_loss=0.176]\u001b[A\n",
            "Epoch 1:  20%|██        | 98/484 [12:47<51:23,  7.99s/it, training_loss=0.176]\u001b[A\n",
            "Epoch 1:  20%|██        | 98/484 [12:54<51:23,  7.99s/it, training_loss=0.227]\u001b[A\n",
            "Epoch 1:  20%|██        | 99/484 [12:54<49:22,  7.69s/it, training_loss=0.227]\u001b[A\n",
            "Epoch 1:  20%|██        | 99/484 [13:01<49:22,  7.69s/it, training_loss=0.221]\u001b[A\n",
            "Epoch 1:  21%|██        | 100/484 [13:01<48:23,  7.56s/it, training_loss=0.221]\u001b[A\n",
            "Epoch 1:  21%|██        | 100/484 [13:09<48:23,  7.56s/it, training_loss=0.234]\u001b[A\n",
            "Epoch 1:  21%|██        | 101/484 [13:09<50:00,  7.83s/it, training_loss=0.234]\u001b[A\n",
            "Epoch 1:  21%|██        | 101/484 [13:16<50:00,  7.83s/it, training_loss=0.412]\u001b[A\n",
            "Epoch 1:  21%|██        | 102/484 [13:16<47:20,  7.44s/it, training_loss=0.412]\u001b[A\n",
            "Epoch 1:  21%|██        | 102/484 [13:26<47:20,  7.44s/it, training_loss=0.295]\u001b[A\n",
            "Epoch 1:  21%|██▏       | 103/484 [13:26<51:25,  8.10s/it, training_loss=0.295]\u001b[A\n",
            "Epoch 1:  21%|██▏       | 103/484 [13:32<51:25,  8.10s/it, training_loss=0.136]\u001b[A\n",
            "Epoch 1:  21%|██▏       | 104/484 [13:32<48:11,  7.61s/it, training_loss=0.136]\u001b[A\n",
            "Epoch 1:  21%|██▏       | 104/484 [13:41<48:11,  7.61s/it, training_loss=0.280]\u001b[A\n",
            "Epoch 1:  22%|██▏       | 105/484 [13:41<49:58,  7.91s/it, training_loss=0.280]\u001b[A\n",
            "Epoch 1:  22%|██▏       | 105/484 [13:48<49:58,  7.91s/it, training_loss=0.288]\u001b[A\n",
            "Epoch 1:  22%|██▏       | 106/484 [13:48<48:45,  7.74s/it, training_loss=0.288]\u001b[A\n",
            "Epoch 1:  22%|██▏       | 106/484 [13:55<48:45,  7.74s/it, training_loss=0.295]\u001b[A\n",
            "Epoch 1:  22%|██▏       | 107/484 [13:55<47:09,  7.51s/it, training_loss=0.295]\u001b[A\n",
            "Epoch 1:  22%|██▏       | 107/484 [14:04<47:09,  7.51s/it, training_loss=0.199]\u001b[A\n",
            "Epoch 1:  22%|██▏       | 108/484 [14:04<49:41,  7.93s/it, training_loss=0.199]\u001b[A\n",
            "Epoch 1:  22%|██▏       | 108/484 [14:10<49:41,  7.93s/it, training_loss=0.228]\u001b[A\n",
            "Epoch 1:  23%|██▎       | 109/484 [14:10<46:53,  7.50s/it, training_loss=0.228]\u001b[A\n",
            "Epoch 1:  23%|██▎       | 109/484 [14:20<46:53,  7.50s/it, training_loss=0.180]\u001b[A\n",
            "Epoch 1:  23%|██▎       | 110/484 [14:20<50:33,  8.11s/it, training_loss=0.180]\u001b[A\n",
            "Epoch 1:  23%|██▎       | 110/484 [14:26<50:33,  8.11s/it, training_loss=0.183]\u001b[A\n",
            "Epoch 1:  23%|██▎       | 111/484 [14:27<47:34,  7.65s/it, training_loss=0.183]\u001b[A\n",
            "Epoch 1:  23%|██▎       | 111/484 [14:35<47:34,  7.65s/it, training_loss=0.228]\u001b[A\n",
            "Epoch 1:  23%|██▎       | 112/484 [14:35<48:19,  7.79s/it, training_loss=0.228]\u001b[A\n",
            "Epoch 1:  23%|██▎       | 112/484 [14:42<48:19,  7.79s/it, training_loss=0.393]\u001b[A\n",
            "Epoch 1:  23%|██▎       | 113/484 [14:42<48:19,  7.81s/it, training_loss=0.393]\u001b[A\n",
            "Epoch 1:  23%|██▎       | 113/484 [14:49<48:19,  7.81s/it, training_loss=0.191]\u001b[A\n",
            "Epoch 1:  24%|██▎       | 114/484 [14:49<45:54,  7.44s/it, training_loss=0.191]\u001b[A\n",
            "Epoch 1:  24%|██▎       | 114/484 [14:59<45:54,  7.44s/it, training_loss=0.375]\u001b[A\n",
            "Epoch 1:  24%|██▍       | 115/484 [14:59<49:34,  8.06s/it, training_loss=0.375]\u001b[A\n",
            "Epoch 1:  24%|██▍       | 115/484 [15:05<49:34,  8.06s/it, training_loss=0.156]\u001b[A\n",
            "Epoch 1:  24%|██▍       | 116/484 [15:05<46:32,  7.59s/it, training_loss=0.156]\u001b[A\n",
            "Epoch 1:  24%|██▍       | 116/484 [15:14<46:32,  7.59s/it, training_loss=0.287]\u001b[A\n",
            "Epoch 1:  24%|██▍       | 117/484 [15:14<49:26,  8.08s/it, training_loss=0.287]\u001b[A\n",
            "Epoch 1:  24%|██▍       | 117/484 [15:21<49:26,  8.08s/it, training_loss=0.129]\u001b[A\n",
            "Epoch 1:  24%|██▍       | 118/484 [15:21<47:00,  7.71s/it, training_loss=0.129]\u001b[A\n",
            "Epoch 1:  24%|██▍       | 118/484 [15:29<47:00,  7.71s/it, training_loss=0.287]\u001b[A\n",
            "Epoch 1:  25%|██▍       | 119/484 [15:29<46:38,  7.67s/it, training_loss=0.287]\u001b[A\n",
            "Epoch 1:  25%|██▍       | 119/484 [15:37<46:38,  7.67s/it, training_loss=0.242]\u001b[A\n",
            "Epoch 1:  25%|██▍       | 120/484 [15:37<47:35,  7.84s/it, training_loss=0.242]\u001b[A\n",
            "Epoch 1:  25%|██▍       | 120/484 [15:43<47:35,  7.84s/it, training_loss=0.180]\u001b[A\n",
            "Epoch 1:  25%|██▌       | 121/484 [15:43<44:53,  7.42s/it, training_loss=0.180]\u001b[A\n",
            "Epoch 1:  25%|██▌       | 121/484 [15:53<44:53,  7.42s/it, training_loss=0.260]\u001b[A\n",
            "Epoch 1:  25%|██▌       | 122/484 [15:53<48:45,  8.08s/it, training_loss=0.260]\u001b[A\n",
            "Epoch 1:  25%|██▌       | 122/484 [16:00<48:45,  8.08s/it, training_loss=0.346]\u001b[A\n",
            "Epoch 1:  25%|██▌       | 123/484 [16:00<45:48,  7.61s/it, training_loss=0.346]\u001b[A\n",
            "Epoch 1:  25%|██▌       | 123/484 [16:08<45:48,  7.61s/it, training_loss=0.172]\u001b[A\n",
            "Epoch 1:  26%|██▌       | 124/484 [16:08<47:44,  7.96s/it, training_loss=0.172]\u001b[A\n",
            "Epoch 1:  26%|██▌       | 124/484 [16:17<47:44,  7.96s/it, training_loss=0.254]\u001b[A\n",
            "Epoch 1:  26%|██▌       | 125/484 [16:17<49:23,  8.25s/it, training_loss=0.254]\u001b[A\n",
            "Epoch 1:  26%|██▌       | 125/484 [16:24<49:23,  8.25s/it, training_loss=0.184]\u001b[A\n",
            "Epoch 1:  26%|██▌       | 126/484 [16:24<47:15,  7.92s/it, training_loss=0.184]\u001b[A\n",
            "Epoch 1:  26%|██▌       | 126/484 [16:33<47:15,  7.92s/it, training_loss=0.153]\u001b[A\n",
            "Epoch 1:  26%|██▌       | 127/484 [16:33<48:34,  8.16s/it, training_loss=0.153]\u001b[A\n",
            "Epoch 1:  26%|██▌       | 127/484 [16:40<48:34,  8.16s/it, training_loss=0.199]\u001b[A\n",
            "Epoch 1:  26%|██▋       | 128/484 [16:40<45:26,  7.66s/it, training_loss=0.199]\u001b[A\n",
            "Epoch 1:  26%|██▋       | 128/484 [16:49<45:26,  7.66s/it, training_loss=0.268]\u001b[A\n",
            "Epoch 1:  27%|██▋       | 129/484 [16:49<48:45,  8.24s/it, training_loss=0.268]\u001b[A\n",
            "Epoch 1:  27%|██▋       | 129/484 [16:56<48:45,  8.24s/it, training_loss=0.208]\u001b[A\n",
            "Epoch 1:  27%|██▋       | 130/484 [16:56<45:33,  7.72s/it, training_loss=0.208]\u001b[A\n",
            "Epoch 1:  27%|██▋       | 130/484 [17:04<45:33,  7.72s/it, training_loss=0.293]\u001b[A\n",
            "Epoch 1:  27%|██▋       | 131/484 [17:04<46:48,  7.96s/it, training_loss=0.293]\u001b[A\n",
            "Epoch 1:  27%|██▋       | 131/484 [17:12<46:48,  7.96s/it, training_loss=0.242]\u001b[A\n",
            "Epoch 1:  27%|██▋       | 132/484 [17:12<45:54,  7.83s/it, training_loss=0.242]\u001b[A\n",
            "Epoch 1:  27%|██▋       | 132/484 [17:19<45:54,  7.83s/it, training_loss=0.280]\u001b[A\n",
            "Epoch 1:  27%|██▋       | 133/484 [17:19<44:03,  7.53s/it, training_loss=0.280]\u001b[A\n",
            "Epoch 1:  27%|██▋       | 133/484 [17:28<44:03,  7.53s/it, training_loss=0.208]\u001b[A\n",
            "Epoch 1:  28%|██▊       | 134/484 [17:28<46:28,  7.97s/it, training_loss=0.208]\u001b[A\n",
            "Epoch 1:  28%|██▊       | 134/484 [17:34<46:28,  7.97s/it, training_loss=0.264]\u001b[A\n",
            "Epoch 1:  28%|██▊       | 135/484 [17:34<43:40,  7.51s/it, training_loss=0.264]\u001b[A\n",
            "Epoch 1:  28%|██▊       | 135/484 [17:43<43:40,  7.51s/it, training_loss=0.282]\u001b[A\n",
            "Epoch 1:  28%|██▊       | 136/484 [17:43<46:47,  8.07s/it, training_loss=0.282]\u001b[A\n",
            "Epoch 1:  28%|██▊       | 136/484 [17:50<46:47,  8.07s/it, training_loss=0.276]\u001b[A\n",
            "Epoch 1:  28%|██▊       | 137/484 [17:50<44:08,  7.63s/it, training_loss=0.276]\u001b[A\n",
            "Epoch 1:  28%|██▊       | 137/484 [17:58<44:08,  7.63s/it, training_loss=0.203]\u001b[A\n",
            "Epoch 1:  29%|██▊       | 138/484 [17:58<44:24,  7.70s/it, training_loss=0.203]\u001b[A\n",
            "Epoch 1:  29%|██▊       | 138/484 [18:06<44:24,  7.70s/it, training_loss=0.161]\u001b[A\n",
            "Epoch 1:  29%|██▊       | 139/484 [18:06<44:41,  7.77s/it, training_loss=0.161]\u001b[A\n",
            "Epoch 1:  29%|██▊       | 139/484 [18:12<44:41,  7.77s/it, training_loss=0.310]\u001b[A\n",
            "Epoch 1:  29%|██▉       | 140/484 [18:12<42:24,  7.40s/it, training_loss=0.310]\u001b[A\n",
            "Epoch 1:  29%|██▉       | 140/484 [18:22<42:24,  7.40s/it, training_loss=0.176]\u001b[A\n",
            "Epoch 1:  29%|██▉       | 141/484 [18:22<46:02,  8.05s/it, training_loss=0.176]\u001b[A\n",
            "Epoch 1:  29%|██▉       | 141/484 [18:28<46:02,  8.05s/it, training_loss=0.199]\u001b[A\n",
            "Epoch 1:  29%|██▉       | 142/484 [18:28<43:16,  7.59s/it, training_loss=0.199]\u001b[A\n",
            "Epoch 1:  29%|██▉       | 142/484 [18:37<43:16,  7.59s/it, training_loss=0.352]\u001b[A\n",
            "Epoch 1:  30%|██▉       | 143/484 [18:37<45:41,  8.04s/it, training_loss=0.352]\u001b[A\n",
            "Epoch 1:  30%|██▉       | 143/484 [18:44<45:41,  8.04s/it, training_loss=0.317]\u001b[A\n",
            "Epoch 1:  30%|██▉       | 144/484 [18:44<43:39,  7.71s/it, training_loss=0.317]\u001b[A\n",
            "Epoch 1:  30%|██▉       | 144/484 [18:52<43:39,  7.71s/it, training_loss=0.171]\u001b[A\n",
            "Epoch 1:  30%|██▉       | 145/484 [18:52<43:21,  7.68s/it, training_loss=0.171]\u001b[A\n",
            "Epoch 1:  30%|██▉       | 145/484 [19:00<43:21,  7.68s/it, training_loss=0.184]\u001b[A\n",
            "Epoch 1:  30%|███       | 146/484 [19:00<44:18,  7.87s/it, training_loss=0.184]\u001b[A\n",
            "Epoch 1:  30%|███       | 146/484 [19:07<44:18,  7.87s/it, training_loss=0.292]\u001b[A\n",
            "Epoch 1:  30%|███       | 147/484 [19:07<41:51,  7.45s/it, training_loss=0.292]\u001b[A\n",
            "Epoch 1:  30%|███       | 147/484 [19:16<41:51,  7.45s/it, training_loss=0.199]\u001b[A\n",
            "Epoch 1:  31%|███       | 148/484 [19:16<45:27,  8.12s/it, training_loss=0.199]\u001b[A\n",
            "Epoch 1:  31%|███       | 148/484 [19:23<45:27,  8.12s/it, training_loss=0.206]\u001b[A\n",
            "Epoch 1:  31%|███       | 149/484 [19:23<42:33,  7.62s/it, training_loss=0.206]\u001b[A\n",
            "Epoch 1:  31%|███       | 149/484 [19:32<42:33,  7.62s/it, training_loss=0.399]\u001b[A\n",
            "Epoch 1:  31%|███       | 150/484 [19:32<44:08,  7.93s/it, training_loss=0.399]\u001b[A\n",
            "Epoch 1:  31%|███       | 150/484 [19:39<44:08,  7.93s/it, training_loss=0.157]\u001b[A\n",
            "Epoch 1:  31%|███       | 151/484 [19:39<42:59,  7.74s/it, training_loss=0.157]\u001b[A\n",
            "Epoch 1:  31%|███       | 151/484 [19:46<42:59,  7.74s/it, training_loss=0.236]\u001b[A\n",
            "Epoch 1:  31%|███▏      | 152/484 [19:46<41:47,  7.55s/it, training_loss=0.236]\u001b[A\n",
            "Epoch 1:  31%|███▏      | 152/484 [19:55<41:47,  7.55s/it, training_loss=0.226]\u001b[A\n",
            "Epoch 1:  32%|███▏      | 153/484 [19:55<44:20,  8.04s/it, training_loss=0.226]\u001b[A\n",
            "Epoch 1:  32%|███▏      | 153/484 [20:02<44:20,  8.04s/it, training_loss=0.330]\u001b[A\n",
            "Epoch 1:  32%|███▏      | 154/484 [20:02<41:34,  7.56s/it, training_loss=0.330]\u001b[A\n",
            "Epoch 1:  32%|███▏      | 154/484 [20:11<41:34,  7.56s/it, training_loss=0.191]\u001b[A\n",
            "Epoch 1:  32%|███▏      | 155/484 [20:11<44:47,  8.17s/it, training_loss=0.191]\u001b[A\n",
            "Epoch 1:  32%|███▏      | 155/484 [20:18<44:47,  8.17s/it, training_loss=0.141]\u001b[A\n",
            "Epoch 1:  32%|███▏      | 156/484 [20:18<41:57,  7.67s/it, training_loss=0.141]\u001b[A\n",
            "Epoch 1:  32%|███▏      | 156/484 [20:26<41:57,  7.67s/it, training_loss=0.275]\u001b[A\n",
            "Epoch 1:  32%|███▏      | 157/484 [20:26<43:02,  7.90s/it, training_loss=0.275]\u001b[A\n",
            "Epoch 1:  32%|███▏      | 157/484 [20:34<43:02,  7.90s/it, training_loss=0.193]\u001b[A\n",
            "Epoch 1:  33%|███▎      | 158/484 [20:34<42:20,  7.79s/it, training_loss=0.193]\u001b[A\n",
            "Epoch 1:  33%|███▎      | 158/484 [20:40<42:20,  7.79s/it, training_loss=0.288]\u001b[A\n",
            "Epoch 1:  33%|███▎      | 159/484 [20:40<40:33,  7.49s/it, training_loss=0.288]\u001b[A\n",
            "Epoch 1:  33%|███▎      | 159/484 [20:50<40:33,  7.49s/it, training_loss=0.136]\u001b[A\n",
            "Epoch 1:  33%|███▎      | 160/484 [20:50<43:03,  7.97s/it, training_loss=0.136]\u001b[A\n",
            "Epoch 1:  33%|███▎      | 160/484 [20:56<43:03,  7.97s/it, training_loss=0.322]\u001b[A\n",
            "Epoch 1:  33%|███▎      | 161/484 [20:56<40:31,  7.53s/it, training_loss=0.322]\u001b[A\n",
            "Epoch 1:  33%|███▎      | 161/484 [21:05<40:31,  7.53s/it, training_loss=0.267]\u001b[A\n",
            "Epoch 1:  33%|███▎      | 162/484 [21:05<43:20,  8.08s/it, training_loss=0.267]\u001b[A\n",
            "Epoch 1:  33%|███▎      | 162/484 [21:12<43:20,  8.08s/it, training_loss=0.268]\u001b[A\n",
            "Epoch 1:  34%|███▎      | 163/484 [21:12<40:45,  7.62s/it, training_loss=0.268]\u001b[A\n",
            "Epoch 1:  34%|███▎      | 163/484 [21:20<40:45,  7.62s/it, training_loss=0.216]\u001b[A\n",
            "Epoch 1:  34%|███▍      | 164/484 [21:20<41:00,  7.69s/it, training_loss=0.216]\u001b[A\n",
            "Epoch 1:  34%|███▍      | 164/484 [21:28<41:00,  7.69s/it, training_loss=0.147]\u001b[A\n",
            "Epoch 1:  34%|███▍      | 165/484 [21:28<41:11,  7.75s/it, training_loss=0.147]\u001b[A\n",
            "Epoch 1:  34%|███▍      | 165/484 [21:34<41:11,  7.75s/it, training_loss=0.171]\u001b[A\n",
            "Epoch 1:  34%|███▍      | 166/484 [21:34<38:56,  7.35s/it, training_loss=0.171]\u001b[A\n",
            "Epoch 1:  34%|███▍      | 166/484 [21:44<38:56,  7.35s/it, training_loss=0.305]\u001b[A\n",
            "Epoch 1:  35%|███▍      | 167/484 [21:44<42:21,  8.02s/it, training_loss=0.305]\u001b[A\n",
            "Epoch 1:  35%|███▍      | 167/484 [21:50<42:21,  8.02s/it, training_loss=0.294]\u001b[A\n",
            "Epoch 1:  35%|███▍      | 168/484 [21:50<39:45,  7.55s/it, training_loss=0.294]\u001b[A\n",
            "Epoch 1:  35%|███▍      | 168/484 [21:59<39:45,  7.55s/it, training_loss=0.241]\u001b[A\n",
            "Epoch 1:  35%|███▍      | 169/484 [21:59<41:44,  7.95s/it, training_loss=0.241]\u001b[A\n",
            "Epoch 1:  35%|███▍      | 169/484 [22:06<41:44,  7.95s/it, training_loss=0.188]\u001b[A\n",
            "Epoch 1:  35%|███▌      | 170/484 [22:06<40:10,  7.68s/it, training_loss=0.188]\u001b[A\n",
            "Epoch 1:  35%|███▌      | 170/484 [22:13<40:10,  7.68s/it, training_loss=0.261]\u001b[A\n",
            "Epoch 1:  35%|███▌      | 171/484 [22:13<39:23,  7.55s/it, training_loss=0.261]\u001b[A\n",
            "Epoch 1:  35%|███▌      | 171/484 [22:22<39:23,  7.55s/it, training_loss=0.242]\u001b[A\n",
            "Epoch 1:  36%|███▌      | 172/484 [22:22<40:56,  7.87s/it, training_loss=0.242]\u001b[A\n",
            "Epoch 1:  36%|███▌      | 172/484 [22:28<40:56,  7.87s/it, training_loss=0.244]\u001b[A\n",
            "Epoch 1:  36%|███▌      | 173/484 [22:28<38:40,  7.46s/it, training_loss=0.244]\u001b[A\n",
            "Epoch 1:  36%|███▌      | 173/484 [22:38<38:40,  7.46s/it, training_loss=0.341]\u001b[A\n",
            "Epoch 1:  36%|███▌      | 174/484 [22:38<41:52,  8.10s/it, training_loss=0.341]\u001b[A\n",
            "Epoch 1:  36%|███▌      | 174/484 [22:45<41:52,  8.10s/it, training_loss=0.211]\u001b[A\n",
            "Epoch 1:  36%|███▌      | 175/484 [22:45<39:11,  7.61s/it, training_loss=0.211]\u001b[A\n",
            "Epoch 1:  36%|███▌      | 175/484 [22:53<39:11,  7.61s/it, training_loss=0.213]\u001b[A\n",
            "Epoch 1:  36%|███▋      | 176/484 [22:53<40:41,  7.93s/it, training_loss=0.213]\u001b[A\n",
            "Epoch 1:  36%|███▋      | 176/484 [23:01<40:41,  7.93s/it, training_loss=0.303]\u001b[A\n",
            "Epoch 1:  37%|███▋      | 177/484 [23:01<39:50,  7.79s/it, training_loss=0.303]\u001b[A\n",
            "Epoch 1:  37%|███▋      | 177/484 [23:08<39:50,  7.79s/it, training_loss=0.233]\u001b[A\n",
            "Epoch 1:  37%|███▋      | 178/484 [23:08<38:17,  7.51s/it, training_loss=0.233]\u001b[A\n",
            "Epoch 1:  37%|███▋      | 178/484 [23:17<38:17,  7.51s/it, training_loss=0.172]\u001b[A\n",
            "Epoch 1:  37%|███▋      | 179/484 [23:17<40:27,  7.96s/it, training_loss=0.172]\u001b[A\n",
            "Epoch 1:  37%|███▋      | 179/484 [23:23<40:27,  7.96s/it, training_loss=0.178]\u001b[A\n",
            "Epoch 1:  37%|███▋      | 180/484 [23:23<38:05,  7.52s/it, training_loss=0.178]\u001b[A\n",
            "Epoch 1:  37%|███▋      | 180/484 [23:32<38:05,  7.52s/it, training_loss=0.181]\u001b[A\n",
            "Epoch 1:  37%|███▋      | 181/484 [23:32<40:51,  8.09s/it, training_loss=0.181]\u001b[A\n",
            "Epoch 1:  37%|███▋      | 181/484 [23:39<40:51,  8.09s/it, training_loss=0.220]\u001b[A\n",
            "Epoch 1:  38%|███▊      | 182/484 [23:39<38:28,  7.64s/it, training_loss=0.220]\u001b[A\n",
            "Epoch 1:  38%|███▊      | 182/484 [23:47<38:28,  7.64s/it, training_loss=0.287]\u001b[A\n",
            "Epoch 1:  38%|███▊      | 183/484 [23:47<38:57,  7.77s/it, training_loss=0.287]\u001b[A\n",
            "Epoch 1:  38%|███▊      | 183/484 [23:55<38:57,  7.77s/it, training_loss=0.163]\u001b[A\n",
            "Epoch 1:  38%|███▊      | 184/484 [23:55<39:00,  7.80s/it, training_loss=0.163]\u001b[A\n",
            "Epoch 1:  38%|███▊      | 184/484 [24:02<39:00,  7.80s/it, training_loss=0.220]\u001b[A\n",
            "Epoch 1:  38%|███▊      | 185/484 [24:02<37:00,  7.43s/it, training_loss=0.220]\u001b[A\n",
            "Epoch 1:  38%|███▊      | 185/484 [24:11<37:00,  7.43s/it, training_loss=0.238]\u001b[A\n",
            "Epoch 1:  38%|███▊      | 186/484 [24:11<39:50,  8.02s/it, training_loss=0.238]\u001b[A\n",
            "Epoch 1:  38%|███▊      | 186/484 [24:17<39:50,  8.02s/it, training_loss=0.136]\u001b[A\n",
            "Epoch 1:  39%|███▊      | 187/484 [24:18<37:31,  7.58s/it, training_loss=0.136]\u001b[A\n",
            "Epoch 1:  39%|███▊      | 187/484 [24:27<37:31,  7.58s/it, training_loss=0.213]\u001b[A\n",
            "Epoch 1:  39%|███▉      | 188/484 [24:27<39:40,  8.04s/it, training_loss=0.213]\u001b[A\n",
            "Epoch 1:  39%|███▉      | 188/484 [24:33<39:40,  8.04s/it, training_loss=0.253]\u001b[A\n",
            "Epoch 1:  39%|███▉      | 189/484 [24:33<37:48,  7.69s/it, training_loss=0.253]\u001b[A\n",
            "Epoch 1:  39%|███▉      | 189/484 [24:41<37:48,  7.69s/it, training_loss=0.198]\u001b[A\n",
            "Epoch 1:  39%|███▉      | 190/484 [24:41<37:26,  7.64s/it, training_loss=0.198]\u001b[A\n",
            "Epoch 1:  39%|███▉      | 190/484 [24:49<37:26,  7.64s/it, training_loss=0.225]\u001b[A\n",
            "Epoch 1:  39%|███▉      | 191/484 [24:49<38:19,  7.85s/it, training_loss=0.225]\u001b[A\n",
            "Epoch 1:  39%|███▉      | 191/484 [24:56<38:19,  7.85s/it, training_loss=0.187]\u001b[A\n",
            "Epoch 1:  40%|███▉      | 192/484 [24:56<36:12,  7.44s/it, training_loss=0.187]\u001b[A\n",
            "Epoch 1:  40%|███▉      | 192/484 [25:05<36:12,  7.44s/it, training_loss=0.193]\u001b[A\n",
            "Epoch 1:  40%|███▉      | 193/484 [25:05<39:17,  8.10s/it, training_loss=0.193]\u001b[A\n",
            "Epoch 1:  40%|███▉      | 193/484 [25:12<39:17,  8.10s/it, training_loss=0.229]\u001b[A\n",
            "Epoch 1:  40%|████      | 194/484 [25:12<36:44,  7.60s/it, training_loss=0.229]\u001b[A\n",
            "Epoch 1:  40%|████      | 194/484 [25:21<36:44,  7.60s/it, training_loss=0.199]\u001b[A\n",
            "Epoch 1:  40%|████      | 195/484 [25:21<38:17,  7.95s/it, training_loss=0.199]\u001b[A\n",
            "Epoch 1:  40%|████      | 195/484 [25:28<38:17,  7.95s/it, training_loss=0.245]\u001b[A\n",
            "Epoch 1:  40%|████      | 196/484 [25:28<37:07,  7.73s/it, training_loss=0.245]\u001b[A\n",
            "Epoch 1:  40%|████      | 196/484 [25:35<37:07,  7.73s/it, training_loss=0.240]\u001b[A\n",
            "Epoch 1:  41%|████      | 197/484 [25:35<36:10,  7.56s/it, training_loss=0.240]\u001b[A\n",
            "Epoch 1:  41%|████      | 197/484 [25:44<36:10,  7.56s/it, training_loss=0.175]\u001b[A\n",
            "Epoch 1:  41%|████      | 198/484 [25:44<37:38,  7.90s/it, training_loss=0.175]\u001b[A\n",
            "Epoch 1:  41%|████      | 198/484 [25:50<37:38,  7.90s/it, training_loss=0.226]\u001b[A\n",
            "Epoch 1:  41%|████      | 199/484 [25:50<35:28,  7.47s/it, training_loss=0.226]\u001b[A\n",
            "Epoch 1:  41%|████      | 199/484 [26:00<35:28,  7.47s/it, training_loss=0.211]\u001b[A\n",
            "Epoch 1:  41%|████▏     | 200/484 [26:00<38:14,  8.08s/it, training_loss=0.211]\u001b[A\n",
            "Epoch 1:  41%|████▏     | 200/484 [26:06<38:14,  8.08s/it, training_loss=0.146]\u001b[A\n",
            "Epoch 1:  42%|████▏     | 201/484 [26:06<35:45,  7.58s/it, training_loss=0.146]\u001b[A\n",
            "Epoch 1:  42%|████▏     | 201/484 [26:14<35:45,  7.58s/it, training_loss=0.282]\u001b[A\n",
            "Epoch 1:  42%|████▏     | 202/484 [26:14<36:28,  7.76s/it, training_loss=0.282]\u001b[A\n",
            "Epoch 1:  42%|████▏     | 202/484 [26:22<36:28,  7.76s/it, training_loss=0.202]\u001b[A\n",
            "Epoch 1:  42%|████▏     | 203/484 [26:22<36:19,  7.76s/it, training_loss=0.202]\u001b[A\n",
            "Epoch 1:  42%|████▏     | 203/484 [26:29<36:19,  7.76s/it, training_loss=0.405]\u001b[A\n",
            "Epoch 1:  42%|████▏     | 204/484 [26:29<34:37,  7.42s/it, training_loss=0.405]\u001b[A\n",
            "Epoch 1:  42%|████▏     | 204/484 [26:38<34:37,  7.42s/it, training_loss=0.141]\u001b[A\n",
            "Epoch 1:  42%|████▏     | 205/484 [26:38<37:06,  7.98s/it, training_loss=0.141]\u001b[A\n",
            "Epoch 1:  42%|████▏     | 205/484 [26:44<37:06,  7.98s/it, training_loss=0.228]\u001b[A\n",
            "Epoch 1:  43%|████▎     | 206/484 [26:44<34:49,  7.52s/it, training_loss=0.228]\u001b[A\n",
            "Epoch 1:  43%|████▎     | 206/484 [26:54<34:49,  7.52s/it, training_loss=0.160]\u001b[A\n",
            "Epoch 1:  43%|████▎     | 207/484 [26:54<37:02,  8.02s/it, training_loss=0.160]\u001b[A\n",
            "Epoch 1:  43%|████▎     | 207/484 [27:00<37:02,  8.02s/it, training_loss=0.198]\u001b[A\n",
            "Epoch 1:  43%|████▎     | 208/484 [27:00<35:11,  7.65s/it, training_loss=0.198]\u001b[A\n",
            "Epoch 1:  43%|████▎     | 208/484 [27:08<35:11,  7.65s/it, training_loss=0.169]\u001b[A\n",
            "Epoch 1:  43%|████▎     | 209/484 [27:08<35:02,  7.65s/it, training_loss=0.169]\u001b[A\n",
            "Epoch 1:  43%|████▎     | 209/484 [27:16<35:02,  7.65s/it, training_loss=0.144]\u001b[A\n",
            "Epoch 1:  43%|████▎     | 210/484 [27:16<35:36,  7.80s/it, training_loss=0.144]\u001b[A\n",
            "Epoch 1:  43%|████▎     | 210/484 [27:23<35:36,  7.80s/it, training_loss=0.166]\u001b[A\n",
            "Epoch 1:  44%|████▎     | 211/484 [27:23<33:35,  7.38s/it, training_loss=0.166]\u001b[A\n",
            "Epoch 1:  44%|████▎     | 211/484 [27:32<33:35,  7.38s/it, training_loss=0.270]\u001b[A\n",
            "Epoch 1:  44%|████▍     | 212/484 [27:32<36:27,  8.04s/it, training_loss=0.270]\u001b[A\n",
            "Epoch 1:  44%|████▍     | 212/484 [27:39<36:27,  8.04s/it, training_loss=0.226]\u001b[A\n",
            "Epoch 1:  44%|████▍     | 213/484 [27:39<34:09,  7.56s/it, training_loss=0.226]\u001b[A\n",
            "Epoch 1:  44%|████▍     | 213/484 [27:47<34:09,  7.56s/it, training_loss=0.195]\u001b[A\n",
            "Epoch 1:  44%|████▍     | 214/484 [27:47<35:42,  7.94s/it, training_loss=0.195]\u001b[A\n",
            "Epoch 1:  44%|████▍     | 214/484 [27:55<35:42,  7.94s/it, training_loss=0.148]\u001b[A\n",
            "Epoch 1:  44%|████▍     | 215/484 [27:55<34:31,  7.70s/it, training_loss=0.148]\u001b[A\n",
            "Epoch 1:  44%|████▍     | 215/484 [28:02<34:31,  7.70s/it, training_loss=0.258]\u001b[A\n",
            "Epoch 1:  45%|████▍     | 216/484 [28:02<33:37,  7.53s/it, training_loss=0.258]\u001b[A\n",
            "Epoch 1:  45%|████▍     | 216/484 [28:10<33:37,  7.53s/it, training_loss=0.187]\u001b[A\n",
            "Epoch 1:  45%|████▍     | 217/484 [28:10<35:06,  7.89s/it, training_loss=0.187]\u001b[A\n",
            "Epoch 1:  45%|████▍     | 217/484 [28:17<35:06,  7.89s/it, training_loss=0.156]\u001b[A\n",
            "Epoch 1:  45%|████▌     | 218/484 [28:17<33:07,  7.47s/it, training_loss=0.156]\u001b[A\n",
            "Epoch 1:  45%|████▌     | 218/484 [28:27<33:07,  7.47s/it, training_loss=0.123]\u001b[A\n",
            "Epoch 1:  45%|████▌     | 219/484 [28:27<35:50,  8.11s/it, training_loss=0.123]\u001b[A\n",
            "Epoch 1:  45%|████▌     | 219/484 [28:33<35:50,  8.11s/it, training_loss=0.219]\u001b[A\n",
            "Epoch 1:  45%|████▌     | 220/484 [28:33<33:34,  7.63s/it, training_loss=0.219]\u001b[A\n",
            "Epoch 1:  45%|████▌     | 220/484 [28:42<33:34,  7.63s/it, training_loss=0.232]\u001b[A\n",
            "Epoch 1:  46%|████▌     | 221/484 [28:42<34:34,  7.89s/it, training_loss=0.232]\u001b[A\n",
            "Epoch 1:  46%|████▌     | 221/484 [28:49<34:34,  7.89s/it, training_loss=0.267]\u001b[A\n",
            "Epoch 1:  46%|████▌     | 222/484 [28:49<33:59,  7.78s/it, training_loss=0.267]\u001b[A\n",
            "Epoch 1:  46%|████▌     | 222/484 [28:56<33:59,  7.78s/it, training_loss=0.242]\u001b[A\n",
            "Epoch 1:  46%|████▌     | 223/484 [28:56<32:42,  7.52s/it, training_loss=0.242]\u001b[A\n",
            "Epoch 1:  46%|████▌     | 223/484 [29:05<32:42,  7.52s/it, training_loss=0.199]\u001b[A\n",
            "Epoch 1:  46%|████▋     | 224/484 [29:05<34:36,  7.99s/it, training_loss=0.199]\u001b[A\n",
            "Epoch 1:  46%|████▋     | 224/484 [29:12<34:36,  7.99s/it, training_loss=0.176]\u001b[A\n",
            "Epoch 1:  46%|████▋     | 225/484 [29:12<32:32,  7.54s/it, training_loss=0.176]\u001b[A\n",
            "Epoch 1:  46%|████▋     | 225/484 [29:21<32:32,  7.54s/it, training_loss=0.191]\u001b[A\n",
            "Epoch 1:  47%|████▋     | 226/484 [29:21<34:54,  8.12s/it, training_loss=0.191]\u001b[A\n",
            "Epoch 1:  47%|████▋     | 226/484 [29:28<34:54,  8.12s/it, training_loss=0.166]\u001b[A\n",
            "Epoch 1:  47%|████▋     | 227/484 [29:28<32:50,  7.67s/it, training_loss=0.166]\u001b[A\n",
            "Epoch 1:  47%|████▋     | 227/484 [29:36<32:50,  7.67s/it, training_loss=0.216]\u001b[A\n",
            "Epoch 1:  47%|████▋     | 228/484 [29:36<33:15,  7.79s/it, training_loss=0.216]\u001b[A\n",
            "Epoch 1:  47%|████▋     | 228/484 [29:44<33:15,  7.79s/it, training_loss=0.214]\u001b[A\n",
            "Epoch 1:  47%|████▋     | 229/484 [29:44<33:08,  7.80s/it, training_loss=0.214]\u001b[A\n",
            "Epoch 1:  47%|████▋     | 229/484 [29:50<33:08,  7.80s/it, training_loss=0.208]\u001b[A\n",
            "Epoch 1:  48%|████▊     | 230/484 [29:50<31:27,  7.43s/it, training_loss=0.208]\u001b[A\n",
            "Epoch 1:  48%|████▊     | 230/484 [30:00<31:27,  7.43s/it, training_loss=0.204]\u001b[A\n",
            "Epoch 1:  48%|████▊     | 231/484 [30:00<33:55,  8.04s/it, training_loss=0.204]\u001b[A\n",
            "Epoch 1:  48%|████▊     | 231/484 [30:06<33:55,  8.04s/it, training_loss=0.232]\u001b[A\n",
            "Epoch 1:  48%|████▊     | 232/484 [30:06<31:46,  7.57s/it, training_loss=0.232]\u001b[A\n",
            "Epoch 1:  48%|████▊     | 232/484 [30:16<31:46,  7.57s/it, training_loss=0.188]\u001b[A\n",
            "Epoch 1:  48%|████▊     | 233/484 [30:16<34:08,  8.16s/it, training_loss=0.188]\u001b[A\n",
            "Epoch 1:  48%|████▊     | 233/484 [30:23<34:08,  8.16s/it, training_loss=0.107]\u001b[A\n",
            "Epoch 1:  48%|████▊     | 234/484 [30:23<33:11,  7.96s/it, training_loss=0.107]\u001b[A\n",
            "Epoch 1:  48%|████▊     | 234/484 [30:32<33:11,  7.96s/it, training_loss=0.219]\u001b[A\n",
            "Epoch 1:  49%|████▊     | 235/484 [30:32<33:53,  8.17s/it, training_loss=0.219]\u001b[A\n",
            "Epoch 1:  49%|████▊     | 235/484 [30:40<33:53,  8.17s/it, training_loss=0.179]\u001b[A\n",
            "Epoch 1:  49%|████▉     | 236/484 [30:40<34:00,  8.23s/it, training_loss=0.179]\u001b[A\n",
            "Epoch 1:  49%|████▉     | 236/484 [30:48<34:00,  8.23s/it, training_loss=0.142]\u001b[A\n",
            "Epoch 1:  49%|████▉     | 237/484 [30:48<32:58,  8.01s/it, training_loss=0.142]\u001b[A\n",
            "Epoch 1:  49%|████▉     | 237/484 [30:57<32:58,  8.01s/it, training_loss=0.191]\u001b[A\n",
            "Epoch 1:  49%|████▉     | 238/484 [30:57<34:05,  8.32s/it, training_loss=0.191]\u001b[A\n",
            "Epoch 1:  49%|████▉     | 238/484 [31:03<34:05,  8.32s/it, training_loss=0.382]\u001b[A\n",
            "Epoch 1:  49%|████▉     | 239/484 [31:03<31:46,  7.78s/it, training_loss=0.382]\u001b[A\n",
            "Epoch 1:  49%|████▉     | 239/484 [31:13<31:46,  7.78s/it, training_loss=0.168]\u001b[A\n",
            "Epoch 1:  50%|████▉     | 240/484 [31:13<33:46,  8.31s/it, training_loss=0.168]\u001b[A\n",
            "Epoch 1:  50%|████▉     | 240/484 [31:19<33:46,  8.31s/it, training_loss=0.308]\u001b[A\n",
            "Epoch 1:  50%|████▉     | 241/484 [31:19<31:30,  7.78s/it, training_loss=0.308]\u001b[A\n",
            "Epoch 1:  50%|████▉     | 241/484 [31:27<31:30,  7.78s/it, training_loss=0.201]\u001b[A\n",
            "Epoch 1:  50%|█████     | 242/484 [31:27<31:50,  7.90s/it, training_loss=0.201]\u001b[A\n",
            "Epoch 1:  50%|█████     | 242/484 [31:35<31:50,  7.90s/it, training_loss=0.156]\u001b[A\n",
            "Epoch 1:  50%|█████     | 243/484 [31:35<31:34,  7.86s/it, training_loss=0.156]\u001b[A\n",
            "Epoch 1:  50%|█████     | 243/484 [31:42<31:34,  7.86s/it, training_loss=0.107]\u001b[A\n",
            "Epoch 1:  50%|█████     | 244/484 [31:42<29:51,  7.47s/it, training_loss=0.107]\u001b[A\n",
            "Epoch 1:  50%|█████     | 244/484 [31:51<29:51,  7.47s/it, training_loss=0.090]\u001b[A\n",
            "Epoch 1:  51%|█████     | 245/484 [31:51<32:08,  8.07s/it, training_loss=0.090]\u001b[A\n",
            "Epoch 1:  51%|█████     | 245/484 [31:58<32:08,  8.07s/it, training_loss=0.154]\u001b[A\n",
            "Epoch 1:  51%|█████     | 246/484 [31:58<30:06,  7.59s/it, training_loss=0.154]\u001b[A\n",
            "Epoch 1:  51%|█████     | 246/484 [32:07<30:06,  7.59s/it, training_loss=0.271]\u001b[A\n",
            "Epoch 1:  51%|█████     | 247/484 [32:07<31:48,  8.05s/it, training_loss=0.271]\u001b[A\n",
            "Epoch 1:  51%|█████     | 247/484 [32:14<31:48,  8.05s/it, training_loss=0.106]\u001b[A\n",
            "Epoch 1:  51%|█████     | 248/484 [32:14<30:55,  7.86s/it, training_loss=0.106]\u001b[A\n",
            "Epoch 1:  51%|█████     | 248/484 [32:22<30:55,  7.86s/it, training_loss=0.340]\u001b[A\n",
            "Epoch 1:  51%|█████▏    | 249/484 [32:22<31:00,  7.92s/it, training_loss=0.340]\u001b[A\n",
            "Epoch 1:  51%|█████▏    | 249/484 [32:30<31:00,  7.92s/it, training_loss=0.330]\u001b[A\n",
            "Epoch 1:  52%|█████▏    | 250/484 [32:30<30:58,  7.94s/it, training_loss=0.330]\u001b[A\n",
            "Epoch 1:  52%|█████▏    | 250/484 [32:37<30:58,  7.94s/it, training_loss=0.133]\u001b[A\n",
            "Epoch 1:  52%|█████▏    | 251/484 [32:37<29:16,  7.54s/it, training_loss=0.133]\u001b[A\n",
            "Epoch 1:  52%|█████▏    | 251/484 [32:46<29:16,  7.54s/it, training_loss=0.111]\u001b[A\n",
            "Epoch 1:  52%|█████▏    | 252/484 [32:46<31:27,  8.13s/it, training_loss=0.111]\u001b[A\n",
            "Epoch 1:  52%|█████▏    | 252/484 [32:53<31:27,  8.13s/it, training_loss=0.052]\u001b[A\n",
            "Epoch 1:  52%|█████▏    | 253/484 [32:53<29:25,  7.64s/it, training_loss=0.052]\u001b[A\n",
            "Epoch 1:  52%|█████▏    | 253/484 [33:02<29:25,  7.64s/it, training_loss=0.078]\u001b[A\n",
            "Epoch 1:  52%|█████▏    | 254/484 [33:02<30:51,  8.05s/it, training_loss=0.078]\u001b[A\n",
            "Epoch 1:  52%|█████▏    | 254/484 [33:09<30:51,  8.05s/it, training_loss=0.138]\u001b[A\n",
            "Epoch 1:  53%|█████▎    | 255/484 [33:09<29:30,  7.73s/it, training_loss=0.138]\u001b[A\n",
            "Epoch 1:  53%|█████▎    | 255/484 [33:16<29:30,  7.73s/it, training_loss=0.213]\u001b[A\n",
            "Epoch 1:  53%|█████▎    | 256/484 [33:16<28:53,  7.60s/it, training_loss=0.213]\u001b[A\n",
            "Epoch 1:  53%|█████▎    | 256/484 [33:25<28:53,  7.60s/it, training_loss=0.208]\u001b[A\n",
            "Epoch 1:  53%|█████▎    | 257/484 [33:25<29:43,  7.86s/it, training_loss=0.208]\u001b[A\n",
            "Epoch 1:  53%|█████▎    | 257/484 [33:31<29:43,  7.86s/it, training_loss=0.286]\u001b[A\n",
            "Epoch 1:  53%|█████▎    | 258/484 [33:31<27:58,  7.43s/it, training_loss=0.286]\u001b[A\n",
            "Epoch 1:  53%|█████▎    | 258/484 [33:41<27:58,  7.43s/it, training_loss=0.205]\u001b[A\n",
            "Epoch 1:  54%|█████▎    | 259/484 [33:41<30:14,  8.07s/it, training_loss=0.205]\u001b[A\n",
            "Epoch 1:  54%|█████▎    | 259/484 [33:47<30:14,  8.07s/it, training_loss=0.149]\u001b[A\n",
            "Epoch 1:  54%|█████▎    | 260/484 [33:47<28:14,  7.57s/it, training_loss=0.149]\u001b[A\n",
            "Epoch 1:  54%|█████▎    | 260/484 [33:55<28:14,  7.57s/it, training_loss=0.120]\u001b[A\n",
            "Epoch 1:  54%|█████▍    | 261/484 [33:56<29:08,  7.84s/it, training_loss=0.120]\u001b[A\n",
            "Epoch 1:  54%|█████▍    | 261/484 [34:03<29:08,  7.84s/it, training_loss=0.164]\u001b[A\n",
            "Epoch 1:  54%|█████▍    | 262/484 [34:03<28:36,  7.73s/it, training_loss=0.164]\u001b[A\n",
            "Epoch 1:  54%|█████▍    | 262/484 [34:10<28:36,  7.73s/it, training_loss=0.177]\u001b[A\n",
            "Epoch 1:  54%|█████▍    | 263/484 [34:10<27:22,  7.43s/it, training_loss=0.177]\u001b[A\n",
            "Epoch 1:  54%|█████▍    | 263/484 [34:19<27:22,  7.43s/it, training_loss=0.318]\u001b[A\n",
            "Epoch 1:  55%|█████▍    | 264/484 [34:19<29:04,  7.93s/it, training_loss=0.318]\u001b[A\n",
            "Epoch 1:  55%|█████▍    | 264/484 [34:25<29:04,  7.93s/it, training_loss=0.136]\u001b[A\n",
            "Epoch 1:  55%|█████▍    | 265/484 [34:25<27:18,  7.48s/it, training_loss=0.136]\u001b[A\n",
            "Epoch 1:  55%|█████▍    | 265/484 [34:35<27:18,  7.48s/it, training_loss=0.158]\u001b[A\n",
            "Epoch 1:  55%|█████▍    | 266/484 [34:35<29:08,  8.02s/it, training_loss=0.158]\u001b[A\n",
            "Epoch 1:  55%|█████▍    | 266/484 [34:41<29:08,  8.02s/it, training_loss=0.073]\u001b[A\n",
            "Epoch 1:  55%|█████▌    | 267/484 [34:41<27:34,  7.62s/it, training_loss=0.073]\u001b[A\n",
            "Epoch 1:  55%|█████▌    | 267/484 [34:49<27:34,  7.62s/it, training_loss=0.181]\u001b[A\n",
            "Epoch 1:  55%|█████▌    | 268/484 [34:49<27:43,  7.70s/it, training_loss=0.181]\u001b[A\n",
            "Epoch 1:  55%|█████▌    | 268/484 [34:57<27:43,  7.70s/it, training_loss=0.090]\u001b[A\n",
            "Epoch 1:  56%|█████▌    | 269/484 [34:57<27:57,  7.80s/it, training_loss=0.090]\u001b[A\n",
            "Epoch 1:  56%|█████▌    | 269/484 [35:04<27:57,  7.80s/it, training_loss=0.243]\u001b[A\n",
            "Epoch 1:  56%|█████▌    | 270/484 [35:04<26:27,  7.42s/it, training_loss=0.243]\u001b[A\n",
            "Epoch 1:  56%|█████▌    | 270/484 [35:13<26:27,  7.42s/it, training_loss=0.141]\u001b[A\n",
            "Epoch 1:  56%|█████▌    | 271/484 [35:13<28:32,  8.04s/it, training_loss=0.141]\u001b[A\n",
            "Epoch 1:  56%|█████▌    | 271/484 [35:20<28:32,  8.04s/it, training_loss=0.173]\u001b[A\n",
            "Epoch 1:  56%|█████▌    | 272/484 [35:20<26:44,  7.57s/it, training_loss=0.173]\u001b[A\n",
            "Epoch 1:  56%|█████▌    | 272/484 [35:28<26:44,  7.57s/it, training_loss=0.213]\u001b[A\n",
            "Epoch 1:  56%|█████▋    | 273/484 [35:28<27:58,  7.96s/it, training_loss=0.213]\u001b[A\n",
            "Epoch 1:  56%|█████▋    | 273/484 [35:36<27:58,  7.96s/it, training_loss=0.116]\u001b[A\n",
            "Epoch 1:  57%|█████▋    | 274/484 [35:36<26:54,  7.69s/it, training_loss=0.116]\u001b[A\n",
            "Epoch 1:  57%|█████▋    | 274/484 [35:43<26:54,  7.69s/it, training_loss=0.185]\u001b[A\n",
            "Epoch 1:  57%|█████▋    | 275/484 [35:43<26:18,  7.55s/it, training_loss=0.185]\u001b[A\n",
            "Epoch 1:  57%|█████▋    | 275/484 [35:51<26:18,  7.55s/it, training_loss=0.272]\u001b[A\n",
            "Epoch 1:  57%|█████▋    | 276/484 [35:51<27:13,  7.85s/it, training_loss=0.272]\u001b[A\n",
            "Epoch 1:  57%|█████▋    | 276/484 [35:58<27:13,  7.85s/it, training_loss=0.305]\u001b[A\n",
            "Epoch 1:  57%|█████▋    | 277/484 [35:58<25:38,  7.43s/it, training_loss=0.305]\u001b[A\n",
            "Epoch 1:  57%|█████▋    | 277/484 [36:07<25:38,  7.43s/it, training_loss=0.090]\u001b[A\n",
            "Epoch 1:  57%|█████▋    | 278/484 [36:07<27:40,  8.06s/it, training_loss=0.090]\u001b[A\n",
            "Epoch 1:  57%|█████▋    | 278/484 [36:14<27:40,  8.06s/it, training_loss=0.149]\u001b[A\n",
            "Epoch 1:  58%|█████▊    | 279/484 [36:14<25:57,  7.60s/it, training_loss=0.149]\u001b[A\n",
            "Epoch 1:  58%|█████▊    | 279/484 [36:22<25:57,  7.60s/it, training_loss=0.164]\u001b[A\n",
            "Epoch 1:  58%|█████▊    | 280/484 [36:22<26:37,  7.83s/it, training_loss=0.164]\u001b[A\n",
            "Epoch 1:  58%|█████▊    | 280/484 [36:30<26:37,  7.83s/it, training_loss=0.148]\u001b[A\n",
            "Epoch 1:  58%|█████▊    | 281/484 [36:30<26:18,  7.78s/it, training_loss=0.148]\u001b[A\n",
            "Epoch 1:  58%|█████▊    | 281/484 [36:36<26:18,  7.78s/it, training_loss=0.128]\u001b[A\n",
            "Epoch 1:  58%|█████▊    | 282/484 [36:37<25:02,  7.44s/it, training_loss=0.128]\u001b[A\n",
            "Epoch 1:  58%|█████▊    | 282/484 [36:46<25:02,  7.44s/it, training_loss=0.173]\u001b[A\n",
            "Epoch 1:  58%|█████▊    | 283/484 [36:46<26:40,  7.96s/it, training_loss=0.173]\u001b[A\n",
            "Epoch 1:  58%|█████▊    | 283/484 [36:52<26:40,  7.96s/it, training_loss=0.187]\u001b[A\n",
            "Epoch 1:  59%|█████▊    | 284/484 [36:52<25:03,  7.52s/it, training_loss=0.187]\u001b[A\n",
            "Epoch 1:  59%|█████▊    | 284/484 [37:02<25:03,  7.52s/it, training_loss=0.161]\u001b[A\n",
            "Epoch 1:  59%|█████▉    | 285/484 [37:02<26:46,  8.07s/it, training_loss=0.161]\u001b[A\n",
            "Epoch 1:  59%|█████▉    | 285/484 [37:08<26:46,  8.07s/it, training_loss=0.091]\u001b[A\n",
            "Epoch 1:  59%|█████▉    | 286/484 [37:08<25:17,  7.66s/it, training_loss=0.091]\u001b[A\n",
            "Epoch 1:  59%|█████▉    | 286/484 [37:16<25:17,  7.66s/it, training_loss=0.193]\u001b[A\n",
            "Epoch 1:  59%|█████▉    | 287/484 [37:16<25:12,  7.68s/it, training_loss=0.193]\u001b[A\n",
            "Epoch 1:  59%|█████▉    | 287/484 [37:24<25:12,  7.68s/it, training_loss=0.155]\u001b[A\n",
            "Epoch 1:  60%|█████▉    | 288/484 [37:24<25:27,  7.79s/it, training_loss=0.155]\u001b[A\n",
            "Epoch 1:  60%|█████▉    | 288/484 [37:30<25:27,  7.79s/it, training_loss=0.110]\u001b[A\n",
            "Epoch 1:  60%|█████▉    | 289/484 [37:30<24:01,  7.39s/it, training_loss=0.110]\u001b[A\n",
            "Epoch 1:  60%|█████▉    | 289/484 [37:40<24:01,  7.39s/it, training_loss=0.154]\u001b[A\n",
            "Epoch 1:  60%|█████▉    | 290/484 [37:40<26:01,  8.05s/it, training_loss=0.154]\u001b[A\n",
            "Epoch 1:  60%|█████▉    | 290/484 [37:46<26:01,  8.05s/it, training_loss=0.077]\u001b[A\n",
            "Epoch 1:  60%|██████    | 291/484 [37:46<24:20,  7.57s/it, training_loss=0.077]\u001b[A\n",
            "Epoch 1:  60%|██████    | 291/484 [37:55<24:20,  7.57s/it, training_loss=0.137]\u001b[A\n",
            "Epoch 1:  60%|██████    | 292/484 [37:55<25:25,  7.95s/it, training_loss=0.137]\u001b[A\n",
            "Epoch 1:  60%|██████    | 292/484 [38:02<25:25,  7.95s/it, training_loss=0.059]\u001b[A\n",
            "Epoch 1:  61%|██████    | 293/484 [38:02<24:30,  7.70s/it, training_loss=0.059]\u001b[A\n",
            "Epoch 1:  61%|██████    | 293/484 [38:10<24:30,  7.70s/it, training_loss=0.160]\u001b[A\n",
            "Epoch 1:  61%|██████    | 294/484 [38:10<23:51,  7.54s/it, training_loss=0.160]\u001b[A\n",
            "Epoch 1:  61%|██████    | 294/484 [38:18<23:51,  7.54s/it, training_loss=0.227]\u001b[A\n",
            "Epoch 1:  61%|██████    | 295/484 [38:18<24:51,  7.89s/it, training_loss=0.227]\u001b[A\n",
            "Epoch 1:  61%|██████    | 295/484 [38:25<24:51,  7.89s/it, training_loss=0.041]\u001b[A\n",
            "Epoch 1:  61%|██████    | 296/484 [38:25<23:28,  7.49s/it, training_loss=0.041]\u001b[A\n",
            "Epoch 1:  61%|██████    | 296/484 [38:35<23:28,  7.49s/it, training_loss=0.148]\u001b[A\n",
            "Epoch 1:  61%|██████▏   | 297/484 [38:35<25:22,  8.14s/it, training_loss=0.148]\u001b[A\n",
            "Epoch 1:  61%|██████▏   | 297/484 [38:41<25:22,  8.14s/it, training_loss=0.081]\u001b[A\n",
            "Epoch 1:  62%|██████▏   | 298/484 [38:41<23:41,  7.64s/it, training_loss=0.081]\u001b[A\n",
            "Epoch 1:  62%|██████▏   | 298/484 [38:50<23:41,  7.64s/it, training_loss=0.162]\u001b[A\n",
            "Epoch 1:  62%|██████▏   | 299/484 [38:50<24:23,  7.91s/it, training_loss=0.162]\u001b[A\n",
            "Epoch 1:  62%|██████▏   | 299/484 [38:57<24:23,  7.91s/it, training_loss=0.165]\u001b[A\n",
            "Epoch 1:  62%|██████▏   | 300/484 [38:57<23:56,  7.81s/it, training_loss=0.165]\u001b[A\n",
            "Epoch 1:  62%|██████▏   | 300/484 [39:04<23:56,  7.81s/it, training_loss=0.071]\u001b[A\n",
            "Epoch 1:  62%|██████▏   | 301/484 [39:04<22:55,  7.51s/it, training_loss=0.071]\u001b[A\n",
            "Epoch 1:  62%|██████▏   | 301/484 [39:13<22:55,  7.51s/it, training_loss=0.162]\u001b[A\n",
            "Epoch 1:  62%|██████▏   | 302/484 [39:13<24:11,  7.98s/it, training_loss=0.162]\u001b[A\n",
            "Epoch 1:  62%|██████▏   | 302/484 [39:20<24:11,  7.98s/it, training_loss=0.201]\u001b[A\n",
            "Epoch 1:  63%|██████▎   | 303/484 [39:20<22:44,  7.54s/it, training_loss=0.201]\u001b[A\n",
            "Epoch 1:  63%|██████▎   | 303/484 [39:29<22:44,  7.54s/it, training_loss=0.124]\u001b[A\n",
            "Epoch 1:  63%|██████▎   | 304/484 [39:29<24:17,  8.10s/it, training_loss=0.124]\u001b[A\n",
            "Epoch 1:  63%|██████▎   | 304/484 [39:36<24:17,  8.10s/it, training_loss=0.210]\u001b[A\n",
            "Epoch 1:  63%|██████▎   | 305/484 [39:36<22:51,  7.66s/it, training_loss=0.210]\u001b[A\n",
            "Epoch 1:  63%|██████▎   | 305/484 [39:44<22:51,  7.66s/it, training_loss=0.219]\u001b[A\n",
            "Epoch 1:  63%|██████▎   | 306/484 [39:44<22:58,  7.75s/it, training_loss=0.219]\u001b[A\n",
            "Epoch 1:  63%|██████▎   | 306/484 [39:52<22:58,  7.75s/it, training_loss=0.105]\u001b[A\n",
            "Epoch 1:  63%|██████▎   | 307/484 [39:52<23:04,  7.82s/it, training_loss=0.105]\u001b[A\n",
            "Epoch 1:  63%|██████▎   | 307/484 [39:58<23:04,  7.82s/it, training_loss=0.142]\u001b[A\n",
            "Epoch 1:  64%|██████▎   | 308/484 [39:58<21:48,  7.44s/it, training_loss=0.142]\u001b[A\n",
            "Epoch 1:  64%|██████▎   | 308/484 [40:08<21:48,  7.44s/it, training_loss=0.231]\u001b[A\n",
            "Epoch 1:  64%|██████▍   | 309/484 [40:08<23:33,  8.08s/it, training_loss=0.231]\u001b[A\n",
            "Epoch 1:  64%|██████▍   | 309/484 [40:14<23:33,  8.08s/it, training_loss=0.170]\u001b[A\n",
            "Epoch 1:  64%|██████▍   | 310/484 [40:14<22:03,  7.61s/it, training_loss=0.170]\u001b[A\n",
            "Epoch 1:  64%|██████▍   | 310/484 [40:23<22:03,  7.61s/it, training_loss=0.182]\u001b[A\n",
            "Epoch 1:  64%|██████▍   | 311/484 [40:23<23:12,  8.05s/it, training_loss=0.182]\u001b[A\n",
            "Epoch 1:  64%|██████▍   | 311/484 [40:30<23:12,  8.05s/it, training_loss=0.143]\u001b[A\n",
            "Epoch 1:  64%|██████▍   | 312/484 [40:30<22:10,  7.74s/it, training_loss=0.143]\u001b[A\n",
            "Epoch 1:  64%|██████▍   | 312/484 [40:38<22:10,  7.74s/it, training_loss=0.060]\u001b[A\n",
            "Epoch 1:  65%|██████▍   | 313/484 [40:38<21:45,  7.64s/it, training_loss=0.060]\u001b[A\n",
            "Epoch 1:  65%|██████▍   | 313/484 [40:46<21:45,  7.64s/it, training_loss=0.058]\u001b[A\n",
            "Epoch 1:  65%|██████▍   | 314/484 [40:46<22:19,  7.88s/it, training_loss=0.058]\u001b[A\n",
            "Epoch 1:  65%|██████▍   | 314/484 [40:53<22:19,  7.88s/it, training_loss=0.090]\u001b[A\n",
            "Epoch 1:  65%|██████▌   | 315/484 [40:53<21:02,  7.47s/it, training_loss=0.090]\u001b[A\n",
            "Epoch 1:  65%|██████▌   | 315/484 [41:02<21:02,  7.47s/it, training_loss=0.142]\u001b[A\n",
            "Epoch 1:  65%|██████▌   | 316/484 [41:02<22:47,  8.14s/it, training_loss=0.142]\u001b[A\n",
            "Epoch 1:  65%|██████▌   | 316/484 [41:09<22:47,  8.14s/it, training_loss=0.097]\u001b[A\n",
            "Epoch 1:  65%|██████▌   | 317/484 [41:09<21:15,  7.64s/it, training_loss=0.097]\u001b[A\n",
            "Epoch 1:  65%|██████▌   | 317/484 [41:17<21:15,  7.64s/it, training_loss=0.222]\u001b[A\n",
            "Epoch 1:  66%|██████▌   | 318/484 [41:17<21:58,  7.94s/it, training_loss=0.222]\u001b[A\n",
            "Epoch 1:  66%|██████▌   | 318/484 [41:25<21:58,  7.94s/it, training_loss=0.310]\u001b[A\n",
            "Epoch 1:  66%|██████▌   | 319/484 [41:25<21:21,  7.76s/it, training_loss=0.310]\u001b[A\n",
            "Epoch 1:  66%|██████▌   | 319/484 [41:32<21:21,  7.76s/it, training_loss=0.226]\u001b[A\n",
            "Epoch 1:  66%|██████▌   | 320/484 [41:32<20:26,  7.48s/it, training_loss=0.226]\u001b[A\n",
            "Epoch 1:  66%|██████▌   | 320/484 [41:41<20:26,  7.48s/it, training_loss=0.087]\u001b[A\n",
            "Epoch 1:  66%|██████▋   | 321/484 [41:41<21:31,  7.92s/it, training_loss=0.087]\u001b[A\n",
            "Epoch 1:  66%|██████▋   | 321/484 [41:47<21:31,  7.92s/it, training_loss=0.203]\u001b[A\n",
            "Epoch 1:  67%|██████▋   | 322/484 [41:47<20:11,  7.48s/it, training_loss=0.203]\u001b[A\n",
            "Epoch 1:  67%|██████▋   | 322/484 [41:56<20:11,  7.48s/it, training_loss=0.116]\u001b[A\n",
            "Epoch 1:  67%|██████▋   | 323/484 [41:56<21:39,  8.07s/it, training_loss=0.116]\u001b[A\n",
            "Epoch 1:  67%|██████▋   | 323/484 [42:03<21:39,  8.07s/it, training_loss=0.173]\u001b[A\n",
            "Epoch 1:  67%|██████▋   | 324/484 [42:03<20:19,  7.62s/it, training_loss=0.173]\u001b[A\n",
            "Epoch 1:  67%|██████▋   | 324/484 [42:11<20:19,  7.62s/it, training_loss=0.063]\u001b[A\n",
            "Epoch 1:  67%|██████▋   | 325/484 [42:11<20:25,  7.71s/it, training_loss=0.063]\u001b[A\n",
            "Epoch 1:  67%|██████▋   | 325/484 [42:19<20:25,  7.71s/it, training_loss=0.127]\u001b[A\n",
            "Epoch 1:  67%|██████▋   | 326/484 [42:19<20:31,  7.79s/it, training_loss=0.127]\u001b[A\n",
            "Epoch 1:  67%|██████▋   | 326/484 [42:26<20:31,  7.79s/it, training_loss=0.088]\u001b[A\n",
            "Epoch 1:  68%|██████▊   | 327/484 [42:26<19:28,  7.44s/it, training_loss=0.088]\u001b[A\n",
            "Epoch 1:  68%|██████▊   | 327/484 [42:35<19:28,  7.44s/it, training_loss=0.135]\u001b[A\n",
            "Epoch 1:  68%|██████▊   | 328/484 [42:35<20:54,  8.04s/it, training_loss=0.135]\u001b[A\n",
            "Epoch 1:  68%|██████▊   | 328/484 [42:41<20:54,  8.04s/it, training_loss=0.223]\u001b[A\n",
            "Epoch 1:  68%|██████▊   | 329/484 [42:41<19:33,  7.57s/it, training_loss=0.223]\u001b[A\n",
            "Epoch 1:  68%|██████▊   | 329/484 [42:51<19:33,  7.57s/it, training_loss=0.200]\u001b[A\n",
            "Epoch 1:  68%|██████▊   | 330/484 [42:51<20:40,  8.05s/it, training_loss=0.200]\u001b[A\n",
            "Epoch 1:  68%|██████▊   | 330/484 [42:58<20:40,  8.05s/it, training_loss=0.044]\u001b[A\n",
            "Epoch 1:  68%|██████▊   | 331/484 [42:58<19:43,  7.74s/it, training_loss=0.044]\u001b[A\n",
            "Epoch 1:  68%|██████▊   | 331/484 [43:05<19:43,  7.74s/it, training_loss=0.181]\u001b[A\n",
            "Epoch 1:  69%|██████▊   | 332/484 [43:05<19:30,  7.70s/it, training_loss=0.181]\u001b[A\n",
            "Epoch 1:  69%|██████▊   | 332/484 [43:16<19:30,  7.70s/it, training_loss=0.238]\u001b[A\n",
            "Epoch 1:  69%|██████▉   | 333/484 [43:16<21:52,  8.69s/it, training_loss=0.238]\u001b[A\n",
            "Epoch 1:  69%|██████▉   | 333/484 [43:26<21:52,  8.69s/it, training_loss=0.035]\u001b[A\n",
            "Epoch 1:  69%|██████▉   | 334/484 [43:26<22:20,  8.94s/it, training_loss=0.035]\u001b[A\n",
            "Epoch 1:  69%|██████▉   | 334/484 [43:33<22:20,  8.94s/it, training_loss=0.067]\u001b[A\n",
            "Epoch 1:  69%|██████▉   | 335/484 [43:33<21:15,  8.56s/it, training_loss=0.067]\u001b[A\n",
            "Epoch 1:  69%|██████▉   | 335/484 [43:40<21:15,  8.56s/it, training_loss=0.146]\u001b[A\n",
            "Epoch 1:  69%|██████▉   | 336/484 [43:40<19:43,  8.00s/it, training_loss=0.146]\u001b[A\n",
            "Epoch 1:  69%|██████▉   | 336/484 [43:49<19:43,  8.00s/it, training_loss=0.080]\u001b[A\n",
            "Epoch 1:  70%|██████▉   | 337/484 [43:49<20:25,  8.34s/it, training_loss=0.080]\u001b[A\n",
            "Epoch 1:  70%|██████▉   | 337/484 [43:56<20:25,  8.34s/it, training_loss=0.107]\u001b[A\n",
            "Epoch 1:  70%|██████▉   | 338/484 [43:56<18:59,  7.81s/it, training_loss=0.107]\u001b[A\n",
            "Epoch 1:  70%|██████▉   | 338/484 [44:05<18:59,  7.81s/it, training_loss=0.225]\u001b[A\n",
            "Epoch 1:  70%|███████   | 339/484 [44:05<19:58,  8.27s/it, training_loss=0.225]\u001b[A\n",
            "Epoch 1:  70%|███████   | 339/484 [44:12<19:58,  8.27s/it, training_loss=0.022]\u001b[A\n",
            "Epoch 1:  70%|███████   | 340/484 [44:12<18:50,  7.85s/it, training_loss=0.022]\u001b[A\n",
            "Epoch 1:  70%|███████   | 340/484 [44:20<18:50,  7.85s/it, training_loss=0.183]\u001b[A\n",
            "Epoch 1:  70%|███████   | 341/484 [44:20<18:46,  7.88s/it, training_loss=0.183]\u001b[A\n",
            "Epoch 1:  70%|███████   | 341/484 [44:28<18:46,  7.88s/it, training_loss=0.035]\u001b[A\n",
            "Epoch 1:  71%|███████   | 342/484 [44:28<18:50,  7.96s/it, training_loss=0.035]\u001b[A\n",
            "Epoch 1:  71%|███████   | 342/484 [44:35<18:50,  7.96s/it, training_loss=0.055]\u001b[A\n",
            "Epoch 1:  71%|███████   | 343/484 [44:35<17:47,  7.57s/it, training_loss=0.055]\u001b[A\n",
            "Epoch 1:  71%|███████   | 343/484 [44:44<17:47,  7.57s/it, training_loss=0.250]\u001b[A\n",
            "Epoch 1:  71%|███████   | 344/484 [44:44<19:03,  8.17s/it, training_loss=0.250]\u001b[A\n",
            "Epoch 1:  71%|███████   | 344/484 [44:51<19:03,  8.17s/it, training_loss=0.190]\u001b[A\n",
            "Epoch 1:  71%|███████▏  | 345/484 [44:51<17:45,  7.67s/it, training_loss=0.190]\u001b[A\n",
            "Epoch 1:  71%|███████▏  | 345/484 [45:00<17:45,  7.67s/it, training_loss=0.098]\u001b[A\n",
            "Epoch 1:  71%|███████▏  | 346/484 [45:00<18:41,  8.13s/it, training_loss=0.098]\u001b[A\n",
            "Epoch 1:  71%|███████▏  | 346/484 [45:07<18:41,  8.13s/it, training_loss=0.078]\u001b[A\n",
            "Epoch 1:  72%|███████▏  | 347/484 [45:07<17:47,  7.80s/it, training_loss=0.078]\u001b[A\n",
            "Epoch 1:  72%|███████▏  | 347/484 [45:15<17:47,  7.80s/it, training_loss=0.172]\u001b[A\n",
            "Epoch 1:  72%|███████▏  | 348/484 [45:15<17:29,  7.72s/it, training_loss=0.172]\u001b[A\n",
            "Epoch 1:  72%|███████▏  | 348/484 [45:23<17:29,  7.72s/it, training_loss=0.101]\u001b[A\n",
            "Epoch 1:  72%|███████▏  | 349/484 [45:23<17:50,  7.93s/it, training_loss=0.101]\u001b[A\n",
            "Epoch 1:  72%|███████▏  | 349/484 [45:30<17:50,  7.93s/it, training_loss=0.143]\u001b[A\n",
            "Epoch 1:  72%|███████▏  | 350/484 [45:30<16:45,  7.50s/it, training_loss=0.143]\u001b[A\n",
            "Epoch 1:  72%|███████▏  | 350/484 [45:39<16:45,  7.50s/it, training_loss=0.153]\u001b[A\n",
            "Epoch 1:  73%|███████▎  | 351/484 [45:39<18:07,  8.17s/it, training_loss=0.153]\u001b[A\n",
            "Epoch 1:  73%|███████▎  | 351/484 [45:46<18:07,  8.17s/it, training_loss=0.284]\u001b[A\n",
            "Epoch 1:  73%|███████▎  | 352/484 [45:46<16:52,  7.67s/it, training_loss=0.284]\u001b[A\n",
            "Epoch 1:  73%|███████▎  | 352/484 [45:55<16:52,  7.67s/it, training_loss=0.066]\u001b[A\n",
            "Epoch 1:  73%|███████▎  | 353/484 [45:55<17:26,  7.99s/it, training_loss=0.066]\u001b[A\n",
            "Epoch 1:  73%|███████▎  | 353/484 [46:02<17:26,  7.99s/it, training_loss=0.227]\u001b[A\n",
            "Epoch 1:  73%|███████▎  | 354/484 [46:02<16:53,  7.80s/it, training_loss=0.227]\u001b[A\n",
            "Epoch 1:  73%|███████▎  | 354/484 [46:09<16:53,  7.80s/it, training_loss=0.081]\u001b[A\n",
            "Epoch 1:  73%|███████▎  | 355/484 [46:09<16:18,  7.58s/it, training_loss=0.081]\u001b[A\n",
            "Epoch 1:  73%|███████▎  | 355/484 [46:18<16:18,  7.58s/it, training_loss=0.030]\u001b[A\n",
            "Epoch 1:  74%|███████▎  | 356/484 [46:18<17:00,  7.97s/it, training_loss=0.030]\u001b[A\n",
            "Epoch 1:  74%|███████▎  | 356/484 [46:24<17:00,  7.97s/it, training_loss=0.362]\u001b[A\n",
            "Epoch 1:  74%|███████▍  | 357/484 [46:24<15:58,  7.55s/it, training_loss=0.362]\u001b[A\n",
            "Epoch 1:  74%|███████▍  | 357/484 [46:34<15:58,  7.55s/it, training_loss=0.079]\u001b[A\n",
            "Epoch 1:  74%|███████▍  | 358/484 [46:34<17:09,  8.17s/it, training_loss=0.079]\u001b[A\n",
            "Epoch 1:  74%|███████▍  | 358/484 [46:41<17:09,  8.17s/it, training_loss=0.122]\u001b[A\n",
            "Epoch 1:  74%|███████▍  | 359/484 [46:41<15:58,  7.67s/it, training_loss=0.122]\u001b[A\n",
            "Epoch 1:  74%|███████▍  | 359/484 [46:49<15:58,  7.67s/it, training_loss=0.089]\u001b[A\n",
            "Epoch 1:  74%|███████▍  | 360/484 [46:49<16:21,  7.92s/it, training_loss=0.089]\u001b[A\n",
            "Epoch 1:  74%|███████▍  | 360/484 [46:57<16:21,  7.92s/it, training_loss=0.095]\u001b[A\n",
            "Epoch 1:  75%|███████▍  | 361/484 [46:57<16:01,  7.81s/it, training_loss=0.095]\u001b[A\n",
            "Epoch 1:  75%|███████▍  | 361/484 [47:03<16:01,  7.81s/it, training_loss=0.371]\u001b[A\n",
            "Epoch 1:  75%|███████▍  | 362/484 [47:03<15:14,  7.50s/it, training_loss=0.371]\u001b[A\n",
            "Epoch 1:  75%|███████▍  | 362/484 [47:12<15:14,  7.50s/it, training_loss=0.168]\u001b[A\n",
            "Epoch 1:  75%|███████▌  | 363/484 [47:12<16:05,  7.98s/it, training_loss=0.168]\u001b[A\n",
            "Epoch 1:  75%|███████▌  | 363/484 [47:19<16:05,  7.98s/it, training_loss=0.182]\u001b[A\n",
            "Epoch 1:  75%|███████▌  | 364/484 [47:19<15:04,  7.53s/it, training_loss=0.182]\u001b[A\n",
            "Epoch 1:  75%|███████▌  | 364/484 [47:28<15:04,  7.53s/it, training_loss=0.052]\u001b[A\n",
            "Epoch 1:  75%|███████▌  | 365/484 [47:28<16:01,  8.08s/it, training_loss=0.052]\u001b[A\n",
            "Epoch 1:  75%|███████▌  | 365/484 [47:35<16:01,  8.08s/it, training_loss=0.046]\u001b[A\n",
            "Epoch 1:  76%|███████▌  | 366/484 [47:35<15:05,  7.67s/it, training_loss=0.046]\u001b[A\n",
            "Epoch 1:  76%|███████▌  | 366/484 [47:43<15:05,  7.67s/it, training_loss=0.074]\u001b[A\n",
            "Epoch 1:  76%|███████▌  | 367/484 [47:43<15:03,  7.72s/it, training_loss=0.074]\u001b[A\n",
            "Epoch 1:  76%|███████▌  | 367/484 [47:51<15:03,  7.72s/it, training_loss=0.120]\u001b[A\n",
            "Epoch 1:  76%|███████▌  | 368/484 [47:51<15:03,  7.79s/it, training_loss=0.120]\u001b[A\n",
            "Epoch 1:  76%|███████▌  | 368/484 [47:57<15:03,  7.79s/it, training_loss=0.153]\u001b[A\n",
            "Epoch 1:  76%|███████▌  | 369/484 [47:57<14:13,  7.42s/it, training_loss=0.153]\u001b[A\n",
            "Epoch 1:  76%|███████▌  | 369/484 [48:07<14:13,  7.42s/it, training_loss=0.060]\u001b[A\n",
            "Epoch 1:  76%|███████▋  | 370/484 [48:07<15:20,  8.08s/it, training_loss=0.060]\u001b[A\n",
            "Epoch 1:  76%|███████▋  | 370/484 [48:14<15:20,  8.08s/it, training_loss=0.041]\u001b[A\n",
            "Epoch 1:  77%|███████▋  | 371/484 [48:14<14:22,  7.64s/it, training_loss=0.041]\u001b[A\n",
            "Epoch 1:  77%|███████▋  | 371/484 [48:23<14:22,  7.64s/it, training_loss=0.248]\u001b[A\n",
            "Epoch 1:  77%|███████▋  | 372/484 [48:23<15:05,  8.09s/it, training_loss=0.248]\u001b[A\n",
            "Epoch 1:  77%|███████▋  | 372/484 [48:30<15:05,  8.09s/it, training_loss=0.094]\u001b[A\n",
            "Epoch 1:  77%|███████▋  | 373/484 [48:30<14:23,  7.78s/it, training_loss=0.094]\u001b[A\n",
            "Epoch 1:  77%|███████▋  | 373/484 [48:37<14:23,  7.78s/it, training_loss=0.015]\u001b[A\n",
            "Epoch 1:  77%|███████▋  | 374/484 [48:37<14:08,  7.71s/it, training_loss=0.015]\u001b[A\n",
            "Epoch 1:  77%|███████▋  | 374/484 [48:46<14:08,  7.71s/it, training_loss=0.285]\u001b[A\n",
            "Epoch 1:  77%|███████▋  | 375/484 [48:46<14:21,  7.90s/it, training_loss=0.285]\u001b[A\n",
            "Epoch 1:  77%|███████▋  | 375/484 [48:52<14:21,  7.90s/it, training_loss=0.306]\u001b[A\n",
            "Epoch 1:  78%|███████▊  | 376/484 [48:52<13:29,  7.50s/it, training_loss=0.306]\u001b[A\n",
            "Epoch 1:  78%|███████▊  | 376/484 [49:02<13:29,  7.50s/it, training_loss=0.312]\u001b[A\n",
            "Epoch 1:  78%|███████▊  | 377/484 [49:02<14:32,  8.15s/it, training_loss=0.312]\u001b[A\n",
            "Epoch 1:  78%|███████▊  | 377/484 [49:08<14:32,  8.15s/it, training_loss=0.218]\u001b[A\n",
            "Epoch 1:  78%|███████▊  | 378/484 [49:08<13:30,  7.65s/it, training_loss=0.218]\u001b[A\n",
            "Epoch 1:  78%|███████▊  | 378/484 [49:20<13:30,  7.65s/it, training_loss=0.237]\u001b[A\n",
            "Epoch 1:  78%|███████▊  | 379/484 [49:20<15:13,  8.70s/it, training_loss=0.237]\u001b[A\n",
            "Epoch 1:  78%|███████▊  | 379/484 [49:30<15:13,  8.70s/it, training_loss=0.151]\u001b[A\n",
            "Epoch 1:  79%|███████▊  | 380/484 [49:30<15:44,  9.08s/it, training_loss=0.151]\u001b[A\n",
            "Epoch 1:  79%|███████▊  | 380/484 [49:44<15:44,  9.08s/it, training_loss=0.096]\u001b[A\n",
            "Epoch 1:  79%|███████▊  | 381/484 [49:44<18:24, 10.73s/it, training_loss=0.096]\u001b[A\n",
            "Epoch 1:  79%|███████▊  | 381/484 [49:58<18:24, 10.73s/it, training_loss=0.270]\u001b[A\n",
            "Epoch 1:  79%|███████▉  | 382/484 [49:58<20:01, 11.78s/it, training_loss=0.270]\u001b[A\n",
            "Epoch 1:  79%|███████▉  | 382/484 [50:08<20:01, 11.78s/it, training_loss=0.047]\u001b[A\n",
            "Epoch 1:  79%|███████▉  | 383/484 [50:08<18:52, 11.22s/it, training_loss=0.047]\u001b[A\n",
            "Epoch 1:  79%|███████▉  | 383/484 [50:20<18:52, 11.22s/it, training_loss=0.027]\u001b[A\n",
            "Epoch 1:  79%|███████▉  | 384/484 [50:20<18:52, 11.33s/it, training_loss=0.027]\u001b[A\n",
            "Epoch 1:  79%|███████▉  | 384/484 [50:28<18:52, 11.33s/it, training_loss=0.337]\u001b[A\n",
            "Epoch 1:  80%|███████▉  | 385/484 [50:28<16:55, 10.26s/it, training_loss=0.337]\u001b[A\n",
            "Epoch 1:  80%|███████▉  | 385/484 [50:37<16:55, 10.26s/it, training_loss=0.106]\u001b[A\n",
            "Epoch 1:  80%|███████▉  | 386/484 [50:37<16:15,  9.95s/it, training_loss=0.106]\u001b[A\n",
            "Epoch 1:  80%|███████▉  | 386/484 [50:43<16:15,  9.95s/it, training_loss=0.277]\u001b[A\n",
            "Epoch 1:  80%|███████▉  | 387/484 [50:43<14:26,  8.93s/it, training_loss=0.277]\u001b[A\n",
            "Epoch 1:  80%|███████▉  | 387/484 [50:53<14:26,  8.93s/it, training_loss=0.168]\u001b[A\n",
            "Epoch 1:  80%|████████  | 388/484 [50:53<14:31,  9.07s/it, training_loss=0.168]\u001b[A\n",
            "Epoch 1:  80%|████████  | 388/484 [50:59<14:31,  9.07s/it, training_loss=0.176]\u001b[A\n",
            "Epoch 1:  80%|████████  | 389/484 [50:59<13:13,  8.36s/it, training_loss=0.176]\u001b[A\n",
            "Epoch 1:  80%|████████  | 389/484 [51:07<13:13,  8.36s/it, training_loss=0.161]\u001b[A\n",
            "Epoch 1:  81%|████████  | 390/484 [51:07<12:52,  8.22s/it, training_loss=0.161]\u001b[A\n",
            "Epoch 1:  81%|████████  | 390/484 [51:15<12:52,  8.22s/it, training_loss=0.195]\u001b[A\n",
            "Epoch 1:  81%|████████  | 391/484 [51:15<12:36,  8.13s/it, training_loss=0.195]\u001b[A\n",
            "Epoch 1:  81%|████████  | 391/484 [51:22<12:36,  8.13s/it, training_loss=0.094]\u001b[A\n",
            "Epoch 1:  81%|████████  | 392/484 [51:22<11:44,  7.66s/it, training_loss=0.094]\u001b[A\n",
            "Epoch 1:  81%|████████  | 392/484 [51:31<11:44,  7.66s/it, training_loss=0.061]\u001b[A\n",
            "Epoch 1:  81%|████████  | 393/484 [51:31<12:29,  8.24s/it, training_loss=0.061]\u001b[A\n",
            "Epoch 1:  81%|████████  | 393/484 [51:38<12:29,  8.24s/it, training_loss=0.140]\u001b[A\n",
            "Epoch 1:  81%|████████▏ | 394/484 [51:38<11:33,  7.70s/it, training_loss=0.140]\u001b[A\n",
            "Epoch 1:  81%|████████▏ | 394/484 [51:47<11:33,  7.70s/it, training_loss=0.109]\u001b[A\n",
            "Epoch 1:  82%|████████▏ | 395/484 [51:47<11:58,  8.07s/it, training_loss=0.109]\u001b[A\n",
            "Epoch 1:  82%|████████▏ | 395/484 [51:54<11:58,  8.07s/it, training_loss=0.044]\u001b[A\n",
            "Epoch 1:  82%|████████▏ | 396/484 [51:54<11:24,  7.78s/it, training_loss=0.044]\u001b[A\n",
            "Epoch 1:  82%|████████▏ | 396/484 [52:01<11:24,  7.78s/it, training_loss=0.162]\u001b[A\n",
            "Epoch 1:  82%|████████▏ | 397/484 [52:01<11:03,  7.63s/it, training_loss=0.162]\u001b[A\n",
            "Epoch 1:  82%|████████▏ | 397/484 [52:10<11:03,  7.63s/it, training_loss=0.134]\u001b[A\n",
            "Epoch 1:  82%|████████▏ | 398/484 [52:10<11:20,  7.91s/it, training_loss=0.134]\u001b[A\n",
            "Epoch 1:  82%|████████▏ | 398/484 [52:16<11:20,  7.91s/it, training_loss=0.205]\u001b[A\n",
            "Epoch 1:  82%|████████▏ | 399/484 [52:16<10:39,  7.52s/it, training_loss=0.205]\u001b[A\n",
            "Epoch 1:  82%|████████▏ | 399/484 [52:26<10:39,  7.52s/it, training_loss=0.095]\u001b[A\n",
            "Epoch 1:  83%|████████▎ | 400/484 [52:26<11:26,  8.17s/it, training_loss=0.095]\u001b[A\n",
            "Epoch 1:  83%|████████▎ | 400/484 [52:33<11:26,  8.17s/it, training_loss=0.255]\u001b[A\n",
            "Epoch 1:  83%|████████▎ | 401/484 [52:33<10:37,  7.68s/it, training_loss=0.255]\u001b[A\n",
            "Epoch 1:  83%|████████▎ | 401/484 [52:41<10:37,  7.68s/it, training_loss=0.201]\u001b[A\n",
            "Epoch 1:  83%|████████▎ | 402/484 [52:41<10:53,  7.97s/it, training_loss=0.201]\u001b[A\n",
            "Epoch 1:  83%|████████▎ | 402/484 [52:49<10:53,  7.97s/it, training_loss=0.100]\u001b[A\n",
            "Epoch 1:  83%|████████▎ | 403/484 [52:49<10:32,  7.80s/it, training_loss=0.100]\u001b[A\n",
            "Epoch 1:  83%|████████▎ | 403/484 [52:56<10:32,  7.80s/it, training_loss=0.086]\u001b[A\n",
            "Epoch 1:  83%|████████▎ | 404/484 [52:56<10:07,  7.59s/it, training_loss=0.086]\u001b[A\n",
            "Epoch 1:  83%|████████▎ | 404/484 [53:05<10:07,  7.59s/it, training_loss=0.043]\u001b[A\n",
            "Epoch 1:  84%|████████▎ | 405/484 [53:05<10:29,  7.97s/it, training_loss=0.043]\u001b[A\n",
            "Epoch 1:  84%|████████▎ | 405/484 [53:11<10:29,  7.97s/it, training_loss=0.083]\u001b[A\n",
            "Epoch 1:  84%|████████▍ | 406/484 [53:11<09:46,  7.52s/it, training_loss=0.083]\u001b[A\n",
            "Epoch 1:  84%|████████▍ | 406/484 [53:21<09:46,  7.52s/it, training_loss=0.335]\u001b[A\n",
            "Epoch 1:  84%|████████▍ | 407/484 [53:21<10:25,  8.12s/it, training_loss=0.335]\u001b[A\n",
            "Epoch 1:  84%|████████▍ | 407/484 [53:27<10:25,  8.12s/it, training_loss=0.115]\u001b[A\n",
            "Epoch 1:  84%|████████▍ | 408/484 [53:27<09:40,  7.64s/it, training_loss=0.115]\u001b[A\n",
            "Epoch 1:  84%|████████▍ | 408/484 [53:35<09:40,  7.64s/it, training_loss=0.138]\u001b[A\n",
            "Epoch 1:  85%|████████▍ | 409/484 [53:35<09:46,  7.82s/it, training_loss=0.138]\u001b[A\n",
            "Epoch 1:  85%|████████▍ | 409/484 [53:43<09:46,  7.82s/it, training_loss=0.069]\u001b[A\n",
            "Epoch 1:  85%|████████▍ | 410/484 [53:43<09:35,  7.77s/it, training_loss=0.069]\u001b[A\n",
            "Epoch 1:  85%|████████▍ | 410/484 [53:50<09:35,  7.77s/it, training_loss=0.147]\u001b[A\n",
            "Epoch 1:  85%|████████▍ | 411/484 [53:50<08:59,  7.40s/it, training_loss=0.147]\u001b[A\n",
            "Epoch 1:  85%|████████▍ | 411/484 [53:59<08:59,  7.40s/it, training_loss=0.145]\u001b[A\n",
            "Epoch 1:  85%|████████▌ | 412/484 [53:59<09:33,  7.97s/it, training_loss=0.145]\u001b[A\n",
            "Epoch 1:  85%|████████▌ | 412/484 [54:05<09:33,  7.97s/it, training_loss=0.047]\u001b[A\n",
            "Epoch 1:  85%|████████▌ | 413/484 [54:05<08:52,  7.51s/it, training_loss=0.047]\u001b[A\n",
            "Epoch 1:  85%|████████▌ | 413/484 [54:14<08:52,  7.51s/it, training_loss=0.076]\u001b[A\n",
            "Epoch 1:  86%|████████▌ | 414/484 [54:14<09:20,  8.00s/it, training_loss=0.076]\u001b[A\n",
            "Epoch 1:  86%|████████▌ | 414/484 [54:21<09:20,  8.00s/it, training_loss=0.106]\u001b[A\n",
            "Epoch 1:  86%|████████▌ | 415/484 [54:21<08:48,  7.66s/it, training_loss=0.106]\u001b[A\n",
            "Epoch 1:  86%|████████▌ | 415/484 [54:29<08:48,  7.66s/it, training_loss=0.108]\u001b[A\n",
            "Epoch 1:  86%|████████▌ | 416/484 [54:29<08:40,  7.65s/it, training_loss=0.108]\u001b[A\n",
            "Epoch 1:  86%|████████▌ | 416/484 [54:37<08:40,  7.65s/it, training_loss=0.042]\u001b[A\n",
            "Epoch 1:  86%|████████▌ | 417/484 [54:37<08:44,  7.83s/it, training_loss=0.042]\u001b[A\n",
            "Epoch 1:  86%|████████▌ | 417/484 [54:44<08:44,  7.83s/it, training_loss=0.038]\u001b[A\n",
            "Epoch 1:  86%|████████▋ | 418/484 [54:44<08:10,  7.43s/it, training_loss=0.038]\u001b[A\n",
            "Epoch 1:  86%|████████▋ | 418/484 [54:53<08:10,  7.43s/it, training_loss=0.134]\u001b[A\n",
            "Epoch 1:  87%|████████▋ | 419/484 [54:53<08:46,  8.10s/it, training_loss=0.134]\u001b[A\n",
            "Epoch 1:  87%|████████▋ | 419/484 [55:00<08:46,  8.10s/it, training_loss=0.057]\u001b[A\n",
            "Epoch 1:  87%|████████▋ | 420/484 [55:00<08:07,  7.62s/it, training_loss=0.057]\u001b[A\n",
            "Epoch 1:  87%|████████▋ | 420/484 [55:09<08:07,  7.62s/it, training_loss=0.069]\u001b[A\n",
            "Epoch 1:  87%|████████▋ | 421/484 [55:09<08:22,  7.97s/it, training_loss=0.069]\u001b[A\n",
            "Epoch 1:  87%|████████▋ | 421/484 [55:16<08:22,  7.97s/it, training_loss=0.089]\u001b[A\n",
            "Epoch 1:  87%|████████▋ | 422/484 [55:16<07:57,  7.71s/it, training_loss=0.089]\u001b[A\n",
            "Epoch 1:  87%|████████▋ | 422/484 [55:23<07:57,  7.71s/it, training_loss=0.031]\u001b[A\n",
            "Epoch 1:  87%|████████▋ | 423/484 [55:23<07:41,  7.57s/it, training_loss=0.031]\u001b[A\n",
            "Epoch 1:  87%|████████▋ | 423/484 [55:31<07:41,  7.57s/it, training_loss=0.112]\u001b[A\n",
            "Epoch 1:  88%|████████▊ | 424/484 [55:31<07:52,  7.87s/it, training_loss=0.112]\u001b[A\n",
            "Epoch 1:  88%|████████▊ | 424/484 [55:38<07:52,  7.87s/it, training_loss=0.170]\u001b[A\n",
            "Epoch 1:  88%|████████▊ | 425/484 [55:38<07:19,  7.44s/it, training_loss=0.170]\u001b[A\n",
            "Epoch 1:  88%|████████▊ | 425/484 [55:47<07:19,  7.44s/it, training_loss=0.074]\u001b[A\n",
            "Epoch 1:  88%|████████▊ | 426/484 [55:47<07:48,  8.08s/it, training_loss=0.074]\u001b[A\n",
            "Epoch 1:  88%|████████▊ | 426/484 [55:54<07:48,  8.08s/it, training_loss=0.120]\u001b[A\n",
            "Epoch 1:  88%|████████▊ | 427/484 [55:54<07:12,  7.59s/it, training_loss=0.120]\u001b[A\n",
            "Epoch 1:  88%|████████▊ | 427/484 [56:02<07:12,  7.59s/it, training_loss=0.184]\u001b[A\n",
            "Epoch 1:  88%|████████▊ | 428/484 [56:02<07:18,  7.82s/it, training_loss=0.184]\u001b[A\n",
            "Epoch 1:  88%|████████▊ | 428/484 [56:10<07:18,  7.82s/it, training_loss=0.140]\u001b[A\n",
            "Epoch 1:  89%|████████▊ | 429/484 [56:10<07:06,  7.75s/it, training_loss=0.140]\u001b[A\n",
            "Epoch 1:  89%|████████▊ | 429/484 [56:17<07:06,  7.75s/it, training_loss=0.253]\u001b[A\n",
            "Epoch 1:  89%|████████▉ | 430/484 [56:17<06:41,  7.44s/it, training_loss=0.253]\u001b[A\n",
            "Epoch 1:  89%|████████▉ | 430/484 [56:26<06:41,  7.44s/it, training_loss=0.083]\u001b[A\n",
            "Epoch 1:  89%|████████▉ | 431/484 [56:26<07:01,  7.96s/it, training_loss=0.083]\u001b[A\n",
            "Epoch 1:  89%|████████▉ | 431/484 [56:32<07:01,  7.96s/it, training_loss=0.209]\u001b[A\n",
            "Epoch 1:  89%|████████▉ | 432/484 [56:32<06:31,  7.53s/it, training_loss=0.209]\u001b[A\n",
            "Epoch 1:  89%|████████▉ | 432/484 [56:42<06:31,  7.53s/it, training_loss=0.162]\u001b[A\n",
            "Epoch 1:  89%|████████▉ | 433/484 [56:42<06:51,  8.07s/it, training_loss=0.162]\u001b[A\n",
            "Epoch 1:  89%|████████▉ | 433/484 [56:48<06:51,  8.07s/it, training_loss=0.105]\u001b[A\n",
            "Epoch 1:  90%|████████▉ | 434/484 [56:48<06:21,  7.64s/it, training_loss=0.105]\u001b[A\n",
            "Epoch 1:  90%|████████▉ | 434/484 [56:56<06:21,  7.64s/it, training_loss=0.133]\u001b[A\n",
            "Epoch 1:  90%|████████▉ | 435/484 [56:56<06:18,  7.73s/it, training_loss=0.133]\u001b[A\n",
            "Epoch 1:  90%|████████▉ | 435/484 [57:04<06:18,  7.73s/it, training_loss=0.124]\u001b[A\n",
            "Epoch 1:  90%|█████████ | 436/484 [57:04<06:13,  7.79s/it, training_loss=0.124]\u001b[A\n",
            "Epoch 1:  90%|█████████ | 436/484 [57:11<06:13,  7.79s/it, training_loss=0.112]\u001b[A\n",
            "Epoch 1:  90%|█████████ | 437/484 [57:11<05:47,  7.39s/it, training_loss=0.112]\u001b[A\n",
            "Epoch 1:  90%|█████████ | 437/484 [57:20<05:47,  7.39s/it, training_loss=0.311]\u001b[A\n",
            "Epoch 1:  90%|█████████ | 438/484 [57:20<06:09,  8.03s/it, training_loss=0.311]\u001b[A\n",
            "Epoch 1:  90%|█████████ | 438/484 [57:27<06:09,  8.03s/it, training_loss=0.086]\u001b[A\n",
            "Epoch 1:  91%|█████████ | 439/484 [57:27<05:40,  7.57s/it, training_loss=0.086]\u001b[A\n",
            "Epoch 1:  91%|█████████ | 439/484 [57:36<05:40,  7.57s/it, training_loss=0.051]\u001b[A\n",
            "Epoch 1:  91%|█████████ | 440/484 [57:36<05:51,  7.98s/it, training_loss=0.051]\u001b[A\n",
            "Epoch 1:  91%|█████████ | 440/484 [57:43<05:51,  7.98s/it, training_loss=0.168]\u001b[A\n",
            "Epoch 1:  91%|█████████ | 441/484 [57:43<05:30,  7.69s/it, training_loss=0.168]\u001b[A\n",
            "Epoch 1:  91%|█████████ | 441/484 [57:50<05:30,  7.69s/it, training_loss=0.148]\u001b[A\n",
            "Epoch 1:  91%|█████████▏| 442/484 [57:50<05:17,  7.57s/it, training_loss=0.148]\u001b[A\n",
            "Epoch 1:  91%|█████████▏| 442/484 [57:58<05:17,  7.57s/it, training_loss=0.043]\u001b[A\n",
            "Epoch 1:  92%|█████████▏| 443/484 [57:58<05:22,  7.85s/it, training_loss=0.043]\u001b[A\n",
            "Epoch 1:  92%|█████████▏| 443/484 [58:05<05:22,  7.85s/it, training_loss=0.243]\u001b[A\n",
            "Epoch 1:  92%|█████████▏| 444/484 [58:05<04:58,  7.46s/it, training_loss=0.243]\u001b[A\n",
            "Epoch 1:  92%|█████████▏| 444/484 [58:15<04:58,  7.46s/it, training_loss=0.300]\u001b[A\n",
            "Epoch 1:  92%|█████████▏| 445/484 [58:15<05:16,  8.11s/it, training_loss=0.300]\u001b[A\n",
            "Epoch 1:  92%|█████████▏| 445/484 [58:21<05:16,  8.11s/it, training_loss=0.213]\u001b[A\n",
            "Epoch 1:  92%|█████████▏| 446/484 [58:21<04:50,  7.64s/it, training_loss=0.213]\u001b[A\n",
            "Epoch 1:  92%|█████████▏| 446/484 [58:30<04:50,  7.64s/it, training_loss=0.333]\u001b[A\n",
            "Epoch 1:  92%|█████████▏| 447/484 [58:30<04:54,  7.95s/it, training_loss=0.333]\u001b[A\n",
            "Epoch 1:  92%|█████████▏| 447/484 [58:37<04:54,  7.95s/it, training_loss=0.200]\u001b[A\n",
            "Epoch 1:  93%|█████████▎| 448/484 [58:37<04:39,  7.76s/it, training_loss=0.200]\u001b[A\n",
            "Epoch 1:  93%|█████████▎| 448/484 [58:44<04:39,  7.76s/it, training_loss=0.089]\u001b[A\n",
            "Epoch 1:  93%|█████████▎| 449/484 [58:44<04:23,  7.54s/it, training_loss=0.089]\u001b[A\n",
            "Epoch 1:  93%|█████████▎| 449/484 [58:53<04:23,  7.54s/it, training_loss=0.267]\u001b[A\n",
            "Epoch 1:  93%|█████████▎| 450/484 [58:53<04:30,  7.94s/it, training_loss=0.267]\u001b[A\n",
            "Epoch 1:  93%|█████████▎| 450/484 [59:00<04:30,  7.94s/it, training_loss=0.291]\u001b[A\n",
            "Epoch 1:  93%|█████████▎| 451/484 [59:00<04:08,  7.54s/it, training_loss=0.291]\u001b[A\n",
            "Epoch 1:  93%|█████████▎| 451/484 [59:09<04:08,  7.54s/it, training_loss=0.128]\u001b[A\n",
            "Epoch 1:  93%|█████████▎| 452/484 [59:09<04:21,  8.16s/it, training_loss=0.128]\u001b[A\n",
            "Epoch 1:  93%|█████████▎| 452/484 [59:16<04:21,  8.16s/it, training_loss=0.292]\u001b[A\n",
            "Epoch 1:  94%|█████████▎| 453/484 [59:16<03:57,  7.66s/it, training_loss=0.292]\u001b[A\n",
            "Epoch 1:  94%|█████████▎| 453/484 [59:24<03:57,  7.66s/it, training_loss=0.126]\u001b[A\n",
            "Epoch 1:  94%|█████████▍| 454/484 [59:24<03:55,  7.84s/it, training_loss=0.126]\u001b[A\n",
            "Epoch 1:  94%|█████████▍| 454/484 [59:32<03:55,  7.84s/it, training_loss=0.098]\u001b[A\n",
            "Epoch 1:  94%|█████████▍| 455/484 [59:32<03:46,  7.82s/it, training_loss=0.098]\u001b[A\n",
            "Epoch 1:  94%|█████████▍| 455/484 [59:38<03:46,  7.82s/it, training_loss=0.242]\u001b[A\n",
            "Epoch 1:  94%|█████████▍| 456/484 [59:38<03:29,  7.48s/it, training_loss=0.242]\u001b[A\n",
            "Epoch 1:  94%|█████████▍| 456/484 [59:48<03:29,  7.48s/it, training_loss=0.219]\u001b[A\n",
            "Epoch 1:  94%|█████████▍| 457/484 [59:48<03:36,  8.02s/it, training_loss=0.219]\u001b[A\n",
            "Epoch 1:  94%|█████████▍| 457/484 [59:54<03:36,  8.02s/it, training_loss=0.269]\u001b[A\n",
            "Epoch 1:  95%|█████████▍| 458/484 [59:54<03:16,  7.57s/it, training_loss=0.269]\u001b[A\n",
            "Epoch 1:  95%|█████████▍| 458/484 [1:00:03<03:16,  7.57s/it, training_loss=0.053]\u001b[A\n",
            "Epoch 1:  95%|█████████▍| 459/484 [1:00:03<03:22,  8.08s/it, training_loss=0.053]\u001b[A\n",
            "Epoch 1:  95%|█████████▍| 459/484 [1:00:10<03:22,  8.08s/it, training_loss=0.399]\u001b[A\n",
            "Epoch 1:  95%|█████████▌| 460/484 [1:00:10<03:04,  7.70s/it, training_loss=0.399]\u001b[A\n",
            "Epoch 1:  95%|█████████▌| 460/484 [1:00:19<03:04,  7.70s/it, training_loss=0.315]\u001b[A\n",
            "Epoch 1:  95%|█████████▌| 461/484 [1:00:19<03:06,  8.11s/it, training_loss=0.315]\u001b[A\n",
            "Epoch 1:  95%|█████████▌| 461/484 [1:00:27<03:06,  8.11s/it, training_loss=0.084]\u001b[A\n",
            "Epoch 1:  95%|█████████▌| 462/484 [1:00:27<02:57,  8.05s/it, training_loss=0.084]\u001b[A\n",
            "Epoch 1:  95%|█████████▌| 462/484 [1:00:34<02:57,  8.05s/it, training_loss=0.168]\u001b[A\n",
            "Epoch 1:  96%|█████████▌| 463/484 [1:00:34<02:40,  7.65s/it, training_loss=0.168]\u001b[A\n",
            "Epoch 1:  96%|█████████▌| 463/484 [1:00:43<02:40,  7.65s/it, training_loss=0.067]\u001b[A\n",
            "Epoch 1:  96%|█████████▌| 464/484 [1:00:43<02:43,  8.15s/it, training_loss=0.067]\u001b[A\n",
            "Epoch 1:  96%|█████████▌| 464/484 [1:00:50<02:43,  8.15s/it, training_loss=0.156]\u001b[A\n",
            "Epoch 1:  96%|█████████▌| 465/484 [1:00:50<02:25,  7.68s/it, training_loss=0.156]\u001b[A\n",
            "Epoch 1:  96%|█████████▌| 465/484 [1:00:59<02:25,  7.68s/it, training_loss=0.100]\u001b[A\n",
            "Epoch 1:  96%|█████████▋| 466/484 [1:00:59<02:26,  8.16s/it, training_loss=0.100]\u001b[A\n",
            "Epoch 1:  96%|█████████▋| 466/484 [1:01:06<02:26,  8.16s/it, training_loss=0.031]\u001b[A\n",
            "Epoch 1:  96%|█████████▋| 467/484 [1:01:06<02:11,  7.76s/it, training_loss=0.031]\u001b[A\n",
            "Epoch 1:  96%|█████████▋| 467/484 [1:01:14<02:11,  7.76s/it, training_loss=0.258]\u001b[A\n",
            "Epoch 1:  97%|█████████▋| 468/484 [1:01:14<02:04,  7.77s/it, training_loss=0.258]\u001b[A\n",
            "Epoch 1:  97%|█████████▋| 468/484 [1:01:22<02:04,  7.77s/it, training_loss=0.398]\u001b[A\n",
            "Epoch 1:  97%|█████████▋| 469/484 [1:01:22<01:58,  7.88s/it, training_loss=0.398]\u001b[A\n",
            "Epoch 1:  97%|█████████▋| 469/484 [1:01:29<01:58,  7.88s/it, training_loss=0.119]\u001b[A\n",
            "Epoch 1:  97%|█████████▋| 470/484 [1:01:29<01:44,  7.49s/it, training_loss=0.119]\u001b[A\n",
            "Epoch 1:  97%|█████████▋| 470/484 [1:01:38<01:44,  7.49s/it, training_loss=0.176]\u001b[A\n",
            "Epoch 1:  97%|█████████▋| 471/484 [1:01:38<01:45,  8.13s/it, training_loss=0.176]\u001b[A\n",
            "Epoch 1:  97%|█████████▋| 471/484 [1:01:45<01:45,  8.13s/it, training_loss=0.094]\u001b[A\n",
            "Epoch 1:  98%|█████████▊| 472/484 [1:01:45<01:31,  7.64s/it, training_loss=0.094]\u001b[A\n",
            "Epoch 1:  98%|█████████▊| 472/484 [1:01:54<01:31,  7.64s/it, training_loss=0.061]\u001b[A\n",
            "Epoch 1:  98%|█████████▊| 473/484 [1:01:54<01:28,  8.04s/it, training_loss=0.061]\u001b[A\n",
            "Epoch 1:  98%|█████████▊| 473/484 [1:02:01<01:28,  8.04s/it, training_loss=0.196]\u001b[A\n",
            "Epoch 1:  98%|█████████▊| 474/484 [1:02:01<01:17,  7.75s/it, training_loss=0.196]\u001b[A\n",
            "Epoch 1:  98%|█████████▊| 474/484 [1:02:08<01:17,  7.75s/it, training_loss=0.099]\u001b[A\n",
            "Epoch 1:  98%|█████████▊| 475/484 [1:02:08<01:08,  7.62s/it, training_loss=0.099]\u001b[A\n",
            "Epoch 1:  98%|█████████▊| 475/484 [1:02:17<01:08,  7.62s/it, training_loss=0.286]\u001b[A\n",
            "Epoch 1:  98%|█████████▊| 476/484 [1:02:17<01:03,  7.93s/it, training_loss=0.286]\u001b[A\n",
            "Epoch 1:  98%|█████████▊| 476/484 [1:02:23<01:03,  7.93s/it, training_loss=0.094]\u001b[A\n",
            "Epoch 1:  99%|█████████▊| 477/484 [1:02:23<00:52,  7.52s/it, training_loss=0.094]\u001b[A\n",
            "Epoch 1:  99%|█████████▊| 477/484 [1:02:33<00:52,  7.52s/it, training_loss=0.076]\u001b[A\n",
            "Epoch 1:  99%|█████████▉| 478/484 [1:02:33<00:49,  8.19s/it, training_loss=0.076]\u001b[A\n",
            "Epoch 1:  99%|█████████▉| 478/484 [1:02:39<00:49,  8.19s/it, training_loss=0.273]\u001b[A\n",
            "Epoch 1:  99%|█████████▉| 479/484 [1:02:39<00:38,  7.68s/it, training_loss=0.273]\u001b[A\n",
            "Epoch 1:  99%|█████████▉| 479/484 [1:02:48<00:38,  7.68s/it, training_loss=0.220]\u001b[A\n",
            "Epoch 1:  99%|█████████▉| 480/484 [1:02:48<00:31,  7.99s/it, training_loss=0.220]\u001b[A\n",
            "Epoch 1:  99%|█████████▉| 480/484 [1:02:56<00:31,  7.99s/it, training_loss=0.129]\u001b[A\n",
            "Epoch 1:  99%|█████████▉| 481/484 [1:02:56<00:23,  7.82s/it, training_loss=0.129]\u001b[A\n",
            "Epoch 1:  99%|█████████▉| 481/484 [1:03:03<00:23,  7.82s/it, training_loss=0.112]\u001b[A\n",
            "Epoch 1: 100%|█████████▉| 482/484 [1:03:03<00:15,  7.62s/it, training_loss=0.112]\u001b[A\n",
            "Epoch 1: 100%|█████████▉| 482/484 [1:03:12<00:15,  7.62s/it, training_loss=0.235]\u001b[A\n",
            "Epoch 1: 100%|█████████▉| 483/484 [1:03:12<00:07,  7.97s/it, training_loss=0.235]\u001b[A\n",
            "Epoch 1: 100%|█████████▉| 483/484 [1:03:17<00:07,  7.97s/it, training_loss=0.225]\u001b[A\n",
            "Epoch 1: 100%|██████████| 484/484 [1:03:17<00:00,  7.12s/it, training_loss=0.225]\u001b[A\n",
            "  0%|          | 0/5 [1:03:19<?, ?it/s]"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            " Epoch {epoch}\n",
            "Training loss: {loss_train_avg}\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n",
            "  0%|          | 0/121 [00:00<?, ?it/s]\u001b[A\n",
            "  1%|          | 1/121 [00:03<06:27,  3.23s/it]\u001b[A\n",
            "  2%|▏         | 2/121 [00:06<06:17,  3.17s/it]\u001b[A\n",
            "  2%|▏         | 3/121 [00:09<06:19,  3.21s/it]\u001b[A\n",
            "  3%|▎         | 4/121 [00:12<05:48,  2.98s/it]\u001b[A\n",
            "  4%|▍         | 5/121 [00:14<05:02,  2.60s/it]\u001b[A\n",
            "  5%|▍         | 6/121 [00:16<04:32,  2.37s/it]\u001b[A\n",
            "  6%|▌         | 7/121 [00:18<04:13,  2.23s/it]\u001b[A\n",
            "  7%|▋         | 8/121 [00:20<04:29,  2.39s/it]\u001b[A\n",
            "  7%|▋         | 9/121 [00:23<04:54,  2.63s/it]\u001b[A\n",
            "  8%|▊         | 10/121 [00:26<05:03,  2.74s/it]\u001b[A\n",
            "  9%|▉         | 11/121 [00:28<04:36,  2.51s/it]\u001b[A\n",
            " 10%|▉         | 12/121 [00:30<04:13,  2.33s/it]\u001b[A\n",
            " 11%|█         | 13/121 [00:32<03:58,  2.21s/it]\u001b[A\n",
            " 12%|█▏        | 14/121 [00:34<03:46,  2.12s/it]\u001b[A\n",
            " 12%|█▏        | 15/121 [00:36<03:39,  2.07s/it]\u001b[A\n",
            " 13%|█▎        | 16/121 [00:39<04:01,  2.30s/it]\u001b[A\n",
            " 14%|█▍        | 17/121 [00:42<04:26,  2.56s/it]\u001b[A\n",
            " 15%|█▍        | 18/121 [00:45<04:35,  2.68s/it]\u001b[A\n",
            " 16%|█▌        | 19/121 [00:47<04:11,  2.47s/it]\u001b[A\n",
            " 17%|█▋        | 20/121 [00:49<03:52,  2.30s/it]\u001b[A\n",
            " 17%|█▋        | 21/121 [00:51<03:39,  2.20s/it]\u001b[A\n",
            " 18%|█▊        | 22/121 [00:53<03:29,  2.11s/it]\u001b[A\n",
            " 19%|█▉        | 23/121 [00:55<03:21,  2.06s/it]\u001b[A\n",
            " 20%|█▉        | 24/121 [00:58<03:44,  2.31s/it]\u001b[A\n",
            " 21%|██        | 25/121 [01:01<04:05,  2.55s/it]\u001b[A\n",
            " 21%|██▏       | 26/121 [01:04<04:13,  2.67s/it]\u001b[A\n",
            " 22%|██▏       | 27/121 [01:06<03:49,  2.44s/it]\u001b[A\n",
            " 23%|██▎       | 28/121 [01:08<03:33,  2.30s/it]\u001b[A\n",
            " 24%|██▍       | 29/121 [01:10<03:22,  2.20s/it]\u001b[A\n",
            " 25%|██▍       | 30/121 [01:12<03:13,  2.12s/it]\u001b[A\n",
            " 26%|██▌       | 31/121 [01:13<03:06,  2.08s/it]\u001b[A\n",
            " 26%|██▋       | 32/121 [01:17<03:31,  2.38s/it]\u001b[A\n",
            " 27%|██▋       | 33/121 [01:20<03:48,  2.60s/it]\u001b[A\n",
            " 28%|██▊       | 34/121 [01:22<03:51,  2.66s/it]\u001b[A\n",
            " 29%|██▉       | 35/121 [01:24<03:30,  2.44s/it]\u001b[A\n",
            " 30%|██▉       | 36/121 [01:26<03:15,  2.30s/it]\u001b[A\n",
            " 31%|███       | 37/121 [01:28<03:03,  2.19s/it]\u001b[A\n",
            " 31%|███▏      | 38/121 [01:30<02:55,  2.12s/it]\u001b[A\n",
            " 32%|███▏      | 39/121 [01:32<02:49,  2.07s/it]\u001b[A\n",
            " 33%|███▎      | 40/121 [01:35<03:15,  2.41s/it]\u001b[A\n",
            " 34%|███▍      | 41/121 [01:39<03:29,  2.61s/it]\u001b[A\n",
            " 35%|███▍      | 42/121 [01:41<03:29,  2.65s/it]\u001b[A\n",
            " 36%|███▌      | 43/121 [01:43<03:09,  2.43s/it]\u001b[A\n",
            " 36%|███▋      | 44/121 [01:45<02:55,  2.28s/it]\u001b[A\n",
            " 37%|███▋      | 45/121 [01:47<02:45,  2.18s/it]\u001b[A\n",
            " 38%|███▊      | 46/121 [01:49<02:38,  2.11s/it]\u001b[A\n",
            " 39%|███▉      | 47/121 [01:51<02:34,  2.09s/it]\u001b[A\n",
            " 40%|███▉      | 48/121 [01:54<02:57,  2.43s/it]\u001b[A\n",
            " 40%|████      | 49/121 [01:57<03:07,  2.61s/it]\u001b[A\n",
            " 41%|████▏     | 50/121 [02:00<03:05,  2.61s/it]\u001b[A\n",
            " 42%|████▏     | 51/121 [02:02<02:49,  2.42s/it]\u001b[A\n",
            " 43%|████▎     | 52/121 [02:04<02:36,  2.27s/it]\u001b[A\n",
            " 44%|████▍     | 53/121 [02:06<02:27,  2.18s/it]\u001b[A\n",
            " 45%|████▍     | 54/121 [02:08<02:21,  2.11s/it]\u001b[A\n",
            " 45%|████▌     | 55/121 [02:10<02:20,  2.12s/it]\u001b[A\n",
            " 46%|████▋     | 56/121 [02:13<02:39,  2.45s/it]\u001b[A\n",
            " 47%|████▋     | 57/121 [02:16<02:48,  2.63s/it]\u001b[A\n",
            " 48%|████▊     | 58/121 [02:19<02:43,  2.60s/it]\u001b[A\n",
            " 49%|████▉     | 59/121 [02:21<02:28,  2.40s/it]\u001b[A\n",
            " 50%|████▉     | 60/121 [02:23<02:18,  2.27s/it]\u001b[A\n",
            " 50%|█████     | 61/121 [02:24<02:09,  2.16s/it]\u001b[A\n",
            " 51%|█████     | 62/121 [02:26<02:03,  2.10s/it]\u001b[A\n",
            " 52%|█████▏    | 63/121 [02:29<02:03,  2.12s/it]\u001b[A\n",
            " 53%|█████▎    | 64/121 [02:32<02:19,  2.44s/it]\u001b[A\n",
            " 54%|█████▎    | 65/121 [02:35<02:26,  2.62s/it]\u001b[A\n",
            " 55%|█████▍    | 66/121 [02:37<02:22,  2.59s/it]\u001b[A\n",
            " 55%|█████▌    | 67/121 [02:39<02:09,  2.40s/it]\u001b[A\n",
            " 56%|█████▌    | 68/121 [02:41<02:00,  2.26s/it]\u001b[A\n",
            " 57%|█████▋    | 69/121 [02:43<01:52,  2.17s/it]\u001b[A\n",
            " 58%|█████▊    | 70/121 [02:45<01:47,  2.10s/it]\u001b[A\n",
            " 59%|█████▊    | 71/121 [02:47<01:48,  2.17s/it]\u001b[A\n",
            " 60%|█████▉    | 72/121 [02:51<02:01,  2.49s/it]\u001b[A\n",
            " 60%|██████    | 73/121 [02:54<02:06,  2.64s/it]\u001b[A\n",
            " 61%|██████    | 74/121 [02:56<02:00,  2.56s/it]\u001b[A\n",
            " 62%|██████▏   | 75/121 [02:58<01:49,  2.38s/it]\u001b[A\n",
            " 63%|██████▎   | 76/121 [03:00<01:41,  2.25s/it]\u001b[A\n",
            " 64%|██████▎   | 77/121 [03:02<01:34,  2.15s/it]\u001b[A\n",
            " 64%|██████▍   | 78/121 [03:04<01:29,  2.09s/it]\u001b[A\n",
            " 65%|██████▌   | 79/121 [03:06<01:31,  2.19s/it]\u001b[A\n",
            " 66%|██████▌   | 80/121 [03:09<01:42,  2.50s/it]\u001b[A\n",
            " 67%|██████▋   | 81/121 [03:12<01:45,  2.65s/it]\u001b[A\n",
            " 68%|██████▊   | 82/121 [03:15<01:38,  2.54s/it]\u001b[A\n",
            " 69%|██████▊   | 83/121 [03:17<01:29,  2.36s/it]\u001b[A\n",
            " 69%|██████▉   | 84/121 [03:19<01:22,  2.23s/it]\u001b[A\n",
            " 70%|███████   | 85/121 [03:21<01:17,  2.14s/it]\u001b[A\n",
            " 71%|███████   | 86/121 [03:22<01:12,  2.08s/it]\u001b[A\n",
            " 72%|███████▏  | 87/121 [03:25<01:15,  2.23s/it]\u001b[A\n",
            " 73%|███████▎  | 88/121 [03:28<01:23,  2.53s/it]\u001b[A\n",
            " 74%|███████▎  | 89/121 [03:31<01:24,  2.65s/it]\u001b[A\n",
            " 74%|███████▍  | 90/121 [03:33<01:17,  2.51s/it]\u001b[A\n",
            " 75%|███████▌  | 91/121 [03:35<01:10,  2.33s/it]\u001b[A\n",
            " 76%|███████▌  | 92/121 [03:37<01:04,  2.22s/it]\u001b[A\n",
            " 77%|███████▋  | 93/121 [03:39<00:59,  2.14s/it]\u001b[A\n",
            " 78%|███████▊  | 94/121 [03:41<00:56,  2.08s/it]\u001b[A\n",
            " 79%|███████▊  | 95/121 [03:44<00:58,  2.26s/it]\u001b[A\n",
            " 79%|███████▉  | 96/121 [03:47<01:03,  2.55s/it]\u001b[A\n",
            " 80%|████████  | 97/121 [03:50<01:04,  2.67s/it]\u001b[A\n",
            " 81%|████████  | 98/121 [03:52<00:57,  2.48s/it]\u001b[A\n",
            " 82%|████████▏ | 99/121 [03:54<00:50,  2.32s/it]\u001b[A\n",
            " 83%|████████▎ | 100/121 [03:56<00:46,  2.20s/it]\u001b[A\n",
            " 83%|████████▎ | 101/121 [03:58<00:42,  2.12s/it]\u001b[A\n",
            " 84%|████████▍ | 102/121 [04:00<00:39,  2.06s/it]\u001b[A\n",
            " 85%|████████▌ | 103/121 [04:03<00:41,  2.29s/it]\u001b[A\n",
            " 86%|████████▌ | 104/121 [04:06<00:43,  2.55s/it]\u001b[A\n",
            " 87%|████████▋ | 105/121 [04:09<00:42,  2.67s/it]\u001b[A\n",
            " 88%|████████▊ | 106/121 [04:11<00:37,  2.47s/it]\u001b[A\n",
            " 88%|████████▊ | 107/121 [04:13<00:32,  2.31s/it]\u001b[A\n",
            " 89%|████████▉ | 108/121 [04:15<00:28,  2.20s/it]\u001b[A\n",
            " 90%|█████████ | 109/121 [04:17<00:25,  2.12s/it]\u001b[A\n",
            " 91%|█████████ | 110/121 [04:18<00:22,  2.07s/it]\u001b[A\n",
            " 92%|█████████▏| 111/121 [04:21<00:23,  2.33s/it]\u001b[A\n",
            " 93%|█████████▎| 112/121 [04:25<00:23,  2.58s/it]\u001b[A\n",
            " 93%|█████████▎| 113/121 [04:27<00:21,  2.67s/it]\u001b[A\n",
            " 94%|█████████▍| 114/121 [04:29<00:17,  2.45s/it]\u001b[A\n",
            " 95%|█████████▌| 115/121 [04:31<00:13,  2.30s/it]\u001b[A\n",
            " 96%|█████████▌| 116/121 [04:33<00:10,  2.20s/it]\u001b[A\n",
            " 97%|█████████▋| 117/121 [04:35<00:08,  2.12s/it]\u001b[A\n",
            " 98%|█████████▊| 118/121 [04:37<00:06,  2.07s/it]\u001b[A\n",
            " 98%|█████████▊| 119/121 [04:40<00:04,  2.37s/it]\u001b[A\n",
            " 99%|█████████▉| 120/121 [04:43<00:02,  2.60s/it]\u001b[A\n",
            "100%|██████████| 121/121 [04:46<00:00,  2.37s/it]\n",
            " 20%|██        | 1/5 [1:08:06<4:32:24, 4086.21s/it]"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Validation loss: 0.45824441794028953\n",
            "F1 Score (weighted): 0.8226942733516385\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n",
            "Epoch 2:   0%|          | 0/484 [00:00<?, ?it/s]\u001b[A\n",
            "Epoch 2:   0%|          | 0/484 [00:06<?, ?it/s, training_loss=0.172]\u001b[A\n",
            "Epoch 2:   0%|          | 1/484 [00:06<53:49,  6.69s/it, training_loss=0.172]\u001b[A\n",
            "Epoch 2:   0%|          | 1/484 [00:15<53:49,  6.69s/it, training_loss=0.067]\u001b[A\n",
            "Epoch 2:   0%|          | 2/484 [00:15<1:02:50,  7.82s/it, training_loss=0.067]\u001b[A\n",
            "Epoch 2:   0%|          | 2/484 [00:22<1:02:50,  7.82s/it, training_loss=0.104]\u001b[A\n",
            "Epoch 2:   1%|          | 3/484 [00:22<1:01:33,  7.68s/it, training_loss=0.104]\u001b[A\n",
            "Epoch 2:   1%|          | 3/484 [00:29<1:01:33,  7.68s/it, training_loss=0.135]\u001b[A\n",
            "Epoch 2:   1%|          | 4/484 [00:29<59:11,  7.40s/it, training_loss=0.135]  \u001b[A\n",
            "Epoch 2:   1%|          | 4/484 [00:38<59:11,  7.40s/it, training_loss=0.058]\u001b[A\n",
            "Epoch 2:   1%|          | 5/484 [00:38<1:03:34,  7.96s/it, training_loss=0.058]\u001b[A\n",
            "Epoch 2:   1%|          | 5/484 [00:45<1:03:34,  7.96s/it, training_loss=0.086]\u001b[A\n",
            "Epoch 2:   1%|          | 6/484 [00:45<59:32,  7.47s/it, training_loss=0.086]  \u001b[A\n",
            "Epoch 2:   1%|          | 6/484 [00:54<59:32,  7.47s/it, training_loss=0.045]\u001b[A\n",
            "Epoch 2:   1%|▏         | 7/484 [00:54<1:04:58,  8.17s/it, training_loss=0.045]\u001b[A\n",
            "Epoch 2:   1%|▏         | 7/484 [01:01<1:04:58,  8.17s/it, training_loss=0.130]\u001b[A\n",
            "Epoch 2:   2%|▏         | 8/484 [01:01<1:00:39,  7.65s/it, training_loss=0.130]\u001b[A\n",
            "Epoch 2:   2%|▏         | 8/484 [01:09<1:00:39,  7.65s/it, training_loss=0.163]\u001b[A\n",
            "Epoch 2:   2%|▏         | 9/484 [01:09<1:01:49,  7.81s/it, training_loss=0.163]\u001b[A\n",
            "Epoch 2:   2%|▏         | 9/484 [01:17<1:01:49,  7.81s/it, training_loss=0.215]\u001b[A\n",
            "Epoch 2:   2%|▏         | 10/484 [01:17<1:01:20,  7.76s/it, training_loss=0.215]\u001b[A\n",
            "Epoch 2:   2%|▏         | 10/484 [01:23<1:01:20,  7.76s/it, training_loss=0.102]\u001b[A\n",
            "Epoch 2:   2%|▏         | 11/484 [01:23<58:30,  7.42s/it, training_loss=0.102]  \u001b[A\n",
            "Epoch 2:   2%|▏         | 11/484 [01:33<58:30,  7.42s/it, training_loss=0.090]\u001b[A\n",
            "Epoch 2:   2%|▏         | 12/484 [01:33<1:02:54,  8.00s/it, training_loss=0.090]\u001b[A\n",
            "Epoch 2:   2%|▏         | 12/484 [01:39<1:02:54,  8.00s/it, training_loss=0.094]\u001b[A\n",
            "Epoch 2:   3%|▎         | 13/484 [01:39<59:08,  7.53s/it, training_loss=0.094]  \u001b[A\n",
            "Epoch 2:   3%|▎         | 13/484 [01:48<59:08,  7.53s/it, training_loss=0.062]\u001b[A\n",
            "Epoch 2:   3%|▎         | 14/484 [01:48<1:02:51,  8.03s/it, training_loss=0.062]\u001b[A\n",
            "Epoch 2:   3%|▎         | 14/484 [01:55<1:02:51,  8.03s/it, training_loss=0.045]\u001b[A\n",
            "Epoch 2:   3%|▎         | 15/484 [01:55<59:57,  7.67s/it, training_loss=0.045]  \u001b[A\n",
            "Epoch 2:   3%|▎         | 15/484 [02:03<59:57,  7.67s/it, training_loss=0.099]\u001b[A\n",
            "Epoch 2:   3%|▎         | 16/484 [02:03<59:54,  7.68s/it, training_loss=0.099]\u001b[A\n",
            "Epoch 2:   3%|▎         | 16/484 [02:11<59:54,  7.68s/it, training_loss=0.206]\u001b[A\n",
            "Epoch 2:   4%|▎         | 17/484 [02:11<1:00:47,  7.81s/it, training_loss=0.206]\u001b[A\n",
            "Epoch 2:   4%|▎         | 17/484 [02:18<1:00:47,  7.81s/it, training_loss=0.200]\u001b[A\n",
            "Epoch 2:   4%|▎         | 18/484 [02:18<57:43,  7.43s/it, training_loss=0.200]  \u001b[A\n",
            "Epoch 2:   4%|▎         | 18/484 [02:27<57:43,  7.43s/it, training_loss=0.242]\u001b[A\n",
            "Epoch 2:   4%|▍         | 19/484 [02:27<1:02:48,  8.10s/it, training_loss=0.242]\u001b[A\n",
            "Epoch 2:   4%|▍         | 19/484 [02:34<1:02:48,  8.10s/it, training_loss=0.105]\u001b[A\n",
            "Epoch 2:   4%|▍         | 20/484 [02:34<59:02,  7.63s/it, training_loss=0.105]  \u001b[A\n",
            "Epoch 2:   4%|▍         | 20/484 [02:43<59:02,  7.63s/it, training_loss=0.051]\u001b[A\n",
            "Epoch 2:   4%|▍         | 21/484 [02:43<1:02:05,  8.05s/it, training_loss=0.051]\u001b[A\n",
            "Epoch 2:   4%|▍         | 21/484 [02:50<1:02:05,  8.05s/it, training_loss=0.239]\u001b[A\n",
            "Epoch 2:   5%|▍         | 22/484 [02:50<59:46,  7.76s/it, training_loss=0.239]  \u001b[A\n",
            "Epoch 2:   5%|▍         | 22/484 [02:57<59:46,  7.76s/it, training_loss=0.196]\u001b[A\n",
            "Epoch 2:   5%|▍         | 23/484 [02:57<58:55,  7.67s/it, training_loss=0.196]\u001b[A\n",
            "Epoch 2:   5%|▍         | 23/484 [03:06<58:55,  7.67s/it, training_loss=0.063]\u001b[A\n",
            "Epoch 2:   5%|▍         | 24/484 [03:06<1:00:35,  7.90s/it, training_loss=0.063]\u001b[A\n",
            "Epoch 2:   5%|▍         | 24/484 [03:12<1:00:35,  7.90s/it, training_loss=0.039]\u001b[A\n",
            "Epoch 2:   5%|▌         | 25/484 [03:12<57:17,  7.49s/it, training_loss=0.039]  \u001b[A\n",
            "Epoch 2:   5%|▌         | 25/484 [03:22<57:17,  7.49s/it, training_loss=0.066]\u001b[A\n",
            "Epoch 2:   5%|▌         | 26/484 [03:22<1:02:06,  8.14s/it, training_loss=0.066]\u001b[A\n",
            "Epoch 2:   5%|▌         | 26/484 [03:28<1:02:06,  8.14s/it, training_loss=0.019]\u001b[A\n",
            "Epoch 2:   6%|▌         | 27/484 [03:28<58:05,  7.63s/it, training_loss=0.019]  \u001b[A\n",
            "Epoch 2:   6%|▌         | 27/484 [03:37<58:05,  7.63s/it, training_loss=0.124]\u001b[A\n",
            "Epoch 2:   6%|▌         | 28/484 [03:37<59:54,  7.88s/it, training_loss=0.124]\u001b[A\n",
            "Epoch 2:   6%|▌         | 28/484 [03:44<59:54,  7.88s/it, training_loss=0.128]\u001b[A\n",
            "Epoch 2:   6%|▌         | 29/484 [03:44<58:43,  7.74s/it, training_loss=0.128]\u001b[A\n",
            "Epoch 2:   6%|▌         | 29/484 [03:51<58:43,  7.74s/it, training_loss=0.107]\u001b[A\n",
            "Epoch 2:   6%|▌         | 30/484 [03:51<56:25,  7.46s/it, training_loss=0.107]\u001b[A\n",
            "Epoch 2:   6%|▌         | 30/484 [04:00<56:25,  7.46s/it, training_loss=0.232]\u001b[A\n",
            "Epoch 2:   6%|▋         | 31/484 [04:00<1:00:01,  7.95s/it, training_loss=0.232]\u001b[A\n",
            "Epoch 2:   6%|▋         | 31/484 [04:07<1:00:01,  7.95s/it, training_loss=0.117]\u001b[A\n",
            "Epoch 2:   7%|▋         | 32/484 [04:07<56:33,  7.51s/it, training_loss=0.117]  \u001b[A\n",
            "Epoch 2:   7%|▋         | 32/484 [04:16<56:33,  7.51s/it, training_loss=0.128]\u001b[A\n",
            "Epoch 2:   7%|▋         | 33/484 [04:16<1:00:45,  8.08s/it, training_loss=0.128]\u001b[A\n",
            "Epoch 2:   7%|▋         | 33/484 [04:23<1:00:45,  8.08s/it, training_loss=0.065]\u001b[A\n",
            "Epoch 2:   7%|▋         | 34/484 [04:23<57:18,  7.64s/it, training_loss=0.065]  \u001b[A\n",
            "Epoch 2:   7%|▋         | 34/484 [04:31<57:18,  7.64s/it, training_loss=0.043]\u001b[A\n",
            "Epoch 2:   7%|▋         | 35/484 [04:31<57:58,  7.75s/it, training_loss=0.043]\u001b[A\n",
            "Epoch 2:   7%|▋         | 35/484 [04:38<57:58,  7.75s/it, training_loss=0.055]\u001b[A\n",
            "Epoch 2:   7%|▋         | 36/484 [04:38<58:03,  7.78s/it, training_loss=0.055]\u001b[A\n",
            "Epoch 2:   7%|▋         | 36/484 [04:45<58:03,  7.78s/it, training_loss=0.095]\u001b[A\n",
            "Epoch 2:   8%|▊         | 37/484 [04:45<55:13,  7.41s/it, training_loss=0.095]\u001b[A\n",
            "Epoch 2:   8%|▊         | 37/484 [04:55<55:13,  7.41s/it, training_loss=0.033]\u001b[A\n",
            "Epoch 2:   8%|▊         | 38/484 [04:55<59:44,  8.04s/it, training_loss=0.033]\u001b[A\n",
            "Epoch 2:   8%|▊         | 38/484 [05:01<59:44,  8.04s/it, training_loss=0.132]\u001b[A\n",
            "Epoch 2:   8%|▊         | 39/484 [05:01<56:08,  7.57s/it, training_loss=0.132]\u001b[A\n",
            "Epoch 2:   8%|▊         | 39/484 [05:10<56:08,  7.57s/it, training_loss=0.168]\u001b[A\n",
            "Epoch 2:   8%|▊         | 40/484 [05:10<59:15,  8.01s/it, training_loss=0.168]\u001b[A\n",
            "Epoch 2:   8%|▊         | 40/484 [05:17<59:15,  8.01s/it, training_loss=0.059]\u001b[A\n",
            "Epoch 2:   8%|▊         | 41/484 [05:17<56:46,  7.69s/it, training_loss=0.059]\u001b[A\n",
            "Epoch 2:   8%|▊         | 41/484 [05:25<56:46,  7.69s/it, training_loss=0.285]\u001b[A\n",
            "Epoch 2:   9%|▊         | 42/484 [05:25<56:14,  7.63s/it, training_loss=0.285]\u001b[A\n",
            "Epoch 2:   9%|▊         | 42/484 [05:33<56:14,  7.63s/it, training_loss=0.153]\u001b[A\n",
            "Epoch 2:   9%|▉         | 43/484 [05:33<57:37,  7.84s/it, training_loss=0.153]\u001b[A\n",
            "Epoch 2:   9%|▉         | 43/484 [05:39<57:37,  7.84s/it, training_loss=0.080]\u001b[A\n",
            "Epoch 2:   9%|▉         | 44/484 [05:39<54:20,  7.41s/it, training_loss=0.080]\u001b[A\n",
            "Epoch 2:   9%|▉         | 44/484 [05:49<54:20,  7.41s/it, training_loss=0.027]\u001b[A\n",
            "Epoch 2:   9%|▉         | 45/484 [05:49<59:09,  8.09s/it, training_loss=0.027]\u001b[A\n",
            "Epoch 2:   9%|▉         | 45/484 [05:55<59:09,  8.09s/it, training_loss=0.037]\u001b[A\n",
            "Epoch 2:  10%|▉         | 46/484 [05:55<55:32,  7.61s/it, training_loss=0.037]\u001b[A\n",
            "Epoch 2:  10%|▉         | 46/484 [06:04<55:32,  7.61s/it, training_loss=0.066]\u001b[A\n",
            "Epoch 2:  10%|▉         | 47/484 [06:04<57:52,  7.95s/it, training_loss=0.066]\u001b[A\n",
            "Epoch 2:  10%|▉         | 47/484 [06:11<57:52,  7.95s/it, training_loss=0.132]\u001b[A\n",
            "Epoch 2:  10%|▉         | 48/484 [06:11<56:20,  7.75s/it, training_loss=0.132]\u001b[A\n",
            "Epoch 2:  10%|▉         | 48/484 [06:19<56:20,  7.75s/it, training_loss=0.069]\u001b[A\n",
            "Epoch 2:  10%|█         | 49/484 [06:19<54:57,  7.58s/it, training_loss=0.069]\u001b[A\n",
            "Epoch 2:  10%|█         | 49/484 [06:27<54:57,  7.58s/it, training_loss=0.094]\u001b[A\n",
            "Epoch 2:  10%|█         | 50/484 [06:27<57:26,  7.94s/it, training_loss=0.094]\u001b[A\n",
            "Epoch 2:  10%|█         | 50/484 [06:34<57:26,  7.94s/it, training_loss=0.044]\u001b[A\n",
            "Epoch 2:  11%|█         | 51/484 [06:34<54:13,  7.51s/it, training_loss=0.044]\u001b[A\n",
            "Epoch 2:  11%|█         | 51/484 [06:44<54:13,  7.51s/it, training_loss=0.118]\u001b[A\n",
            "Epoch 2:  11%|█         | 52/484 [06:44<58:38,  8.15s/it, training_loss=0.118]\u001b[A\n",
            "Epoch 2:  11%|█         | 52/484 [06:50<58:38,  8.15s/it, training_loss=0.076]\u001b[A\n",
            "Epoch 2:  11%|█         | 53/484 [06:50<55:01,  7.66s/it, training_loss=0.076]\u001b[A\n",
            "Epoch 2:  11%|█         | 53/484 [06:59<55:01,  7.66s/it, training_loss=0.027]\u001b[A\n",
            "Epoch 2:  11%|█         | 54/484 [06:59<56:40,  7.91s/it, training_loss=0.027]\u001b[A\n",
            "Epoch 2:  11%|█         | 54/484 [07:06<56:40,  7.91s/it, training_loss=0.165]\u001b[A\n",
            "Epoch 2:  11%|█▏        | 55/484 [07:06<55:50,  7.81s/it, training_loss=0.165]\u001b[A\n",
            "Epoch 2:  11%|█▏        | 55/484 [07:13<55:50,  7.81s/it, training_loss=0.038]\u001b[A\n",
            "Epoch 2:  12%|█▏        | 56/484 [07:13<53:19,  7.48s/it, training_loss=0.038]\u001b[A\n",
            "Epoch 2:  12%|█▏        | 56/484 [07:22<53:19,  7.48s/it, training_loss=0.203]\u001b[A\n",
            "Epoch 2:  12%|█▏        | 57/484 [07:22<56:50,  7.99s/it, training_loss=0.203]\u001b[A\n",
            "Epoch 2:  12%|█▏        | 57/484 [07:28<56:50,  7.99s/it, training_loss=0.087]\u001b[A\n",
            "Epoch 2:  12%|█▏        | 58/484 [07:28<53:29,  7.53s/it, training_loss=0.087]\u001b[A\n",
            "Epoch 2:  12%|█▏        | 58/484 [07:38<53:29,  7.53s/it, training_loss=0.033]\u001b[A\n",
            "Epoch 2:  12%|█▏        | 59/484 [07:38<57:05,  8.06s/it, training_loss=0.033]\u001b[A\n",
            "Epoch 2:  12%|█▏        | 59/484 [07:44<57:05,  8.06s/it, training_loss=0.070]\u001b[A\n",
            "Epoch 2:  12%|█▏        | 60/484 [07:44<54:06,  7.66s/it, training_loss=0.070]\u001b[A\n",
            "Epoch 2:  12%|█▏        | 60/484 [07:52<54:06,  7.66s/it, training_loss=0.027]\u001b[A\n",
            "Epoch 2:  13%|█▎        | 61/484 [07:52<54:17,  7.70s/it, training_loss=0.027]\u001b[A\n",
            "Epoch 2:  13%|█▎        | 61/484 [08:00<54:17,  7.70s/it, training_loss=0.205]\u001b[A\n",
            "Epoch 2:  13%|█▎        | 62/484 [08:00<55:02,  7.83s/it, training_loss=0.205]\u001b[A\n",
            "Epoch 2:  13%|█▎        | 62/484 [08:07<55:02,  7.83s/it, training_loss=0.049]\u001b[A\n",
            "Epoch 2:  13%|█▎        | 63/484 [08:07<52:14,  7.45s/it, training_loss=0.049]\u001b[A\n",
            "Epoch 2:  13%|█▎        | 63/484 [08:17<52:14,  7.45s/it, training_loss=0.025]\u001b[A\n",
            "Epoch 2:  13%|█▎        | 64/484 [08:17<57:05,  8.16s/it, training_loss=0.025]\u001b[A\n",
            "Epoch 2:  13%|█▎        | 64/484 [08:23<57:05,  8.16s/it, training_loss=0.108]\u001b[A\n",
            "Epoch 2:  13%|█▎        | 65/484 [08:23<53:38,  7.68s/it, training_loss=0.108]\u001b[A\n",
            "Epoch 2:  13%|█▎        | 65/484 [08:32<53:38,  7.68s/it, training_loss=0.071]\u001b[A\n",
            "Epoch 2:  14%|█▎        | 66/484 [08:32<56:28,  8.11s/it, training_loss=0.071]\u001b[A\n",
            "Epoch 2:  14%|█▎        | 66/484 [08:40<56:28,  8.11s/it, training_loss=0.089]\u001b[A\n",
            "Epoch 2:  14%|█▍        | 67/484 [08:40<54:24,  7.83s/it, training_loss=0.089]\u001b[A\n",
            "Epoch 2:  14%|█▍        | 67/484 [08:47<54:24,  7.83s/it, training_loss=0.153]\u001b[A\n",
            "Epoch 2:  14%|█▍        | 68/484 [08:47<54:08,  7.81s/it, training_loss=0.153]\u001b[A\n",
            "Epoch 2:  14%|█▍        | 68/484 [08:56<54:08,  7.81s/it, training_loss=0.025]\u001b[A\n",
            "Epoch 2:  14%|█▍        | 69/484 [08:56<54:43,  7.91s/it, training_loss=0.025]\u001b[A\n",
            "Epoch 2:  14%|█▍        | 69/484 [09:02<54:43,  7.91s/it, training_loss=0.022]\u001b[A\n",
            "Epoch 2:  14%|█▍        | 70/484 [09:02<51:40,  7.49s/it, training_loss=0.022]\u001b[A\n",
            "Epoch 2:  14%|█▍        | 70/484 [09:12<51:40,  7.49s/it, training_loss=0.015]\u001b[A\n",
            "Epoch 2:  15%|█▍        | 71/484 [09:12<55:57,  8.13s/it, training_loss=0.015]\u001b[A\n",
            "Epoch 2:  15%|█▍        | 71/484 [09:18<55:57,  8.13s/it, training_loss=0.097]\u001b[A\n",
            "Epoch 2:  15%|█▍        | 72/484 [09:18<52:23,  7.63s/it, training_loss=0.097]\u001b[A\n",
            "Epoch 2:  15%|█▍        | 72/484 [09:27<52:23,  7.63s/it, training_loss=0.117]\u001b[A\n",
            "Epoch 2:  15%|█▌        | 73/484 [09:27<54:50,  8.00s/it, training_loss=0.117]\u001b[A\n",
            "Epoch 2:  15%|█▌        | 73/484 [09:34<54:50,  8.00s/it, training_loss=0.027]\u001b[A\n",
            "Epoch 2:  15%|█▌        | 74/484 [09:34<52:57,  7.75s/it, training_loss=0.027]\u001b[A\n",
            "Epoch 2:  15%|█▌        | 74/484 [09:41<52:57,  7.75s/it, training_loss=0.175]\u001b[A\n",
            "Epoch 2:  15%|█▌        | 75/484 [09:41<51:43,  7.59s/it, training_loss=0.175]\u001b[A\n",
            "Epoch 2:  15%|█▌        | 75/484 [09:50<51:43,  7.59s/it, training_loss=0.011]\u001b[A\n",
            "Epoch 2:  16%|█▌        | 76/484 [09:50<53:41,  7.90s/it, training_loss=0.011]\u001b[A\n",
            "Epoch 2:  16%|█▌        | 76/484 [09:57<53:41,  7.90s/it, training_loss=0.046]\u001b[A\n",
            "Epoch 2:  16%|█▌        | 77/484 [09:57<50:45,  7.48s/it, training_loss=0.046]\u001b[A\n",
            "Epoch 2:  16%|█▌        | 77/484 [10:06<50:45,  7.48s/it, training_loss=0.023]\u001b[A\n",
            "Epoch 2:  16%|█▌        | 78/484 [10:06<55:01,  8.13s/it, training_loss=0.023]\u001b[A\n",
            "Epoch 2:  16%|█▌        | 78/484 [10:13<55:01,  8.13s/it, training_loss=0.116]\u001b[A\n",
            "Epoch 2:  16%|█▋        | 79/484 [10:13<51:41,  7.66s/it, training_loss=0.116]\u001b[A\n",
            "Epoch 2:  16%|█▋        | 79/484 [10:21<51:41,  7.66s/it, training_loss=0.029]\u001b[A\n",
            "Epoch 2:  17%|█▋        | 80/484 [10:21<53:48,  7.99s/it, training_loss=0.029]\u001b[A\n",
            "Epoch 2:  17%|█▋        | 80/484 [10:29<53:48,  7.99s/it, training_loss=0.020]\u001b[A\n",
            "Epoch 2:  17%|█▋        | 81/484 [10:29<52:25,  7.81s/it, training_loss=0.020]\u001b[A\n",
            "Epoch 2:  17%|█▋        | 81/484 [10:36<52:25,  7.81s/it, training_loss=0.086]\u001b[A\n",
            "Epoch 2:  17%|█▋        | 82/484 [10:36<50:42,  7.57s/it, training_loss=0.086]\u001b[A\n",
            "Epoch 2:  17%|█▋        | 82/484 [10:45<50:42,  7.57s/it, training_loss=0.181]\u001b[A\n",
            "Epoch 2:  17%|█▋        | 83/484 [10:45<53:10,  7.96s/it, training_loss=0.181]\u001b[A\n",
            "Epoch 2:  17%|█▋        | 83/484 [10:51<53:10,  7.96s/it, training_loss=0.144]\u001b[A\n",
            "Epoch 2:  17%|█▋        | 84/484 [10:51<50:12,  7.53s/it, training_loss=0.144]\u001b[A\n",
            "Epoch 2:  17%|█▋        | 84/484 [11:01<50:12,  7.53s/it, training_loss=0.069]\u001b[A\n",
            "Epoch 2:  18%|█▊        | 85/484 [11:01<54:11,  8.15s/it, training_loss=0.069]\u001b[A\n",
            "Epoch 2:  18%|█▊        | 85/484 [11:07<54:11,  8.15s/it, training_loss=0.036]\u001b[A\n",
            "Epoch 2:  18%|█▊        | 86/484 [11:07<50:46,  7.65s/it, training_loss=0.036]\u001b[A\n",
            "Epoch 2:  18%|█▊        | 86/484 [11:16<50:46,  7.65s/it, training_loss=0.048]\u001b[A\n",
            "Epoch 2:  18%|█▊        | 87/484 [11:16<51:52,  7.84s/it, training_loss=0.048]\u001b[A\n",
            "Epoch 2:  18%|█▊        | 87/484 [11:23<51:52,  7.84s/it, training_loss=0.070]\u001b[A\n",
            "Epoch 2:  18%|█▊        | 88/484 [11:23<51:23,  7.79s/it, training_loss=0.070]\u001b[A\n",
            "Epoch 2:  18%|█▊        | 88/484 [11:30<51:23,  7.79s/it, training_loss=0.041]\u001b[A\n",
            "Epoch 2:  18%|█▊        | 89/484 [11:30<49:00,  7.44s/it, training_loss=0.041]\u001b[A\n",
            "Epoch 2:  18%|█▊        | 89/484 [11:39<49:00,  7.44s/it, training_loss=0.138]\u001b[A\n",
            "Epoch 2:  19%|█▊        | 90/484 [11:39<52:21,  7.97s/it, training_loss=0.138]\u001b[A\n",
            "Epoch 2:  19%|█▊        | 90/484 [11:46<52:21,  7.97s/it, training_loss=0.242]\u001b[A\n",
            "Epoch 2:  19%|█▉        | 91/484 [11:46<49:15,  7.52s/it, training_loss=0.242]\u001b[A\n",
            "Epoch 2:  19%|█▉        | 91/484 [11:55<49:15,  7.52s/it, training_loss=0.075]\u001b[A\n",
            "Epoch 2:  19%|█▉        | 92/484 [11:55<52:19,  8.01s/it, training_loss=0.075]\u001b[A\n",
            "Epoch 2:  19%|█▉        | 92/484 [12:02<52:19,  8.01s/it, training_loss=0.245]\u001b[A\n",
            "Epoch 2:  19%|█▉        | 93/484 [12:02<49:53,  7.66s/it, training_loss=0.245]\u001b[A\n",
            "Epoch 2:  19%|█▉        | 93/484 [12:09<49:53,  7.66s/it, training_loss=0.035]\u001b[A\n",
            "Epoch 2:  19%|█▉        | 94/484 [12:09<49:45,  7.65s/it, training_loss=0.035]\u001b[A\n",
            "Epoch 2:  19%|█▉        | 94/484 [12:17<49:45,  7.65s/it, training_loss=0.035]\u001b[A\n",
            "Epoch 2:  20%|█▉        | 95/484 [12:17<50:43,  7.83s/it, training_loss=0.035]\u001b[A\n",
            "Epoch 2:  20%|█▉        | 95/484 [12:24<50:43,  7.83s/it, training_loss=0.094]\u001b[A\n",
            "Epoch 2:  20%|█▉        | 96/484 [12:24<48:08,  7.44s/it, training_loss=0.094]\u001b[A\n",
            "Epoch 2:  20%|█▉        | 96/484 [12:34<48:08,  7.44s/it, training_loss=0.045]\u001b[A\n",
            "Epoch 2:  20%|██        | 97/484 [12:34<52:15,  8.10s/it, training_loss=0.045]\u001b[A\n",
            "Epoch 2:  20%|██        | 97/484 [12:40<52:15,  8.10s/it, training_loss=0.034]\u001b[A\n",
            "Epoch 2:  20%|██        | 98/484 [12:40<49:02,  7.62s/it, training_loss=0.034]\u001b[A\n",
            "Epoch 2:  20%|██        | 98/484 [12:49<49:02,  7.62s/it, training_loss=0.028]\u001b[A\n",
            "Epoch 2:  20%|██        | 99/484 [12:49<51:28,  8.02s/it, training_loss=0.028]\u001b[A\n",
            "Epoch 2:  20%|██        | 99/484 [12:56<51:28,  8.02s/it, training_loss=0.232]\u001b[A\n",
            "Epoch 2:  21%|██        | 100/484 [12:56<49:32,  7.74s/it, training_loss=0.232]\u001b[A\n",
            "Epoch 2:  21%|██        | 100/484 [13:03<49:32,  7.74s/it, training_loss=0.149]\u001b[A\n",
            "Epoch 2:  21%|██        | 101/484 [13:03<48:21,  7.58s/it, training_loss=0.149]\u001b[A\n",
            "Epoch 2:  21%|██        | 101/484 [13:12<48:21,  7.58s/it, training_loss=0.204]\u001b[A\n",
            "Epoch 2:  21%|██        | 102/484 [13:12<50:04,  7.86s/it, training_loss=0.204]\u001b[A\n",
            "Epoch 2:  21%|██        | 102/484 [13:18<50:04,  7.86s/it, training_loss=0.017]\u001b[A\n",
            "Epoch 2:  21%|██▏       | 103/484 [13:18<47:11,  7.43s/it, training_loss=0.017]\u001b[A\n",
            "Epoch 2:  21%|██▏       | 103/484 [13:28<47:11,  7.43s/it, training_loss=0.010]\u001b[A\n",
            "Epoch 2:  21%|██▏       | 104/484 [13:28<51:13,  8.09s/it, training_loss=0.010]\u001b[A\n",
            "Epoch 2:  21%|██▏       | 104/484 [13:34<51:13,  8.09s/it, training_loss=0.101]\u001b[A\n",
            "Epoch 2:  22%|██▏       | 105/484 [13:34<47:59,  7.60s/it, training_loss=0.101]\u001b[A\n",
            "Epoch 2:  22%|██▏       | 105/484 [13:43<47:59,  7.60s/it, training_loss=0.247]\u001b[A\n",
            "Epoch 2:  22%|██▏       | 106/484 [13:43<49:23,  7.84s/it, training_loss=0.247]\u001b[A\n",
            "Epoch 2:  22%|██▏       | 106/484 [13:50<49:23,  7.84s/it, training_loss=0.010]\u001b[A\n",
            "Epoch 2:  22%|██▏       | 107/484 [13:50<48:35,  7.73s/it, training_loss=0.010]\u001b[A\n",
            "Epoch 2:  22%|██▏       | 107/484 [13:57<48:35,  7.73s/it, training_loss=0.009]\u001b[A\n",
            "Epoch 2:  22%|██▏       | 108/484 [13:57<46:37,  7.44s/it, training_loss=0.009]\u001b[A\n",
            "Epoch 2:  22%|██▏       | 108/484 [14:06<46:37,  7.44s/it, training_loss=0.089]\u001b[A\n",
            "Epoch 2:  23%|██▎       | 109/484 [14:06<49:38,  7.94s/it, training_loss=0.089]\u001b[A\n",
            "Epoch 2:  23%|██▎       | 109/484 [14:13<49:38,  7.94s/it, training_loss=0.058]\u001b[A\n",
            "Epoch 2:  23%|██▎       | 110/484 [14:13<46:55,  7.53s/it, training_loss=0.058]\u001b[A\n",
            "Epoch 2:  23%|██▎       | 110/484 [14:22<46:55,  7.53s/it, training_loss=0.031]\u001b[A\n",
            "Epoch 2:  23%|██▎       | 111/484 [14:22<50:15,  8.08s/it, training_loss=0.031]\u001b[A\n",
            "Epoch 2:  23%|██▎       | 111/484 [14:29<50:15,  8.08s/it, training_loss=0.108]\u001b[A\n",
            "Epoch 2:  23%|██▎       | 112/484 [14:29<47:29,  7.66s/it, training_loss=0.108]\u001b[A\n",
            "Epoch 2:  23%|██▎       | 112/484 [14:37<47:29,  7.66s/it, training_loss=0.164]\u001b[A\n",
            "Epoch 2:  23%|██▎       | 113/484 [14:37<47:53,  7.75s/it, training_loss=0.164]\u001b[A\n",
            "Epoch 2:  23%|██▎       | 113/484 [14:45<47:53,  7.75s/it, training_loss=0.012]\u001b[A\n",
            "Epoch 2:  24%|██▎       | 114/484 [14:45<48:03,  7.79s/it, training_loss=0.012]\u001b[A\n",
            "Epoch 2:  24%|██▎       | 114/484 [14:51<48:03,  7.79s/it, training_loss=0.022]\u001b[A\n",
            "Epoch 2:  24%|██▍       | 115/484 [14:51<45:59,  7.48s/it, training_loss=0.022]\u001b[A\n",
            "Epoch 2:  24%|██▍       | 115/484 [15:01<45:59,  7.48s/it, training_loss=0.169]\u001b[A\n",
            "Epoch 2:  24%|██▍       | 116/484 [15:01<49:37,  8.09s/it, training_loss=0.169]\u001b[A\n",
            "Epoch 2:  24%|██▍       | 116/484 [15:07<49:37,  8.09s/it, training_loss=0.028]\u001b[A\n",
            "Epoch 2:  24%|██▍       | 117/484 [15:07<46:30,  7.60s/it, training_loss=0.028]\u001b[A\n",
            "Epoch 2:  24%|██▍       | 117/484 [15:17<46:30,  7.60s/it, training_loss=0.123]\u001b[A\n",
            "Epoch 2:  24%|██▍       | 118/484 [15:17<49:17,  8.08s/it, training_loss=0.123]\u001b[A\n",
            "Epoch 2:  24%|██▍       | 118/484 [15:23<49:17,  8.08s/it, training_loss=0.308]\u001b[A\n",
            "Epoch 2:  25%|██▍       | 119/484 [15:23<46:47,  7.69s/it, training_loss=0.308]\u001b[A\n",
            "Epoch 2:  25%|██▍       | 119/484 [15:31<46:47,  7.69s/it, training_loss=0.100]\u001b[A\n",
            "Epoch 2:  25%|██▍       | 120/484 [15:31<46:44,  7.70s/it, training_loss=0.100]\u001b[A\n",
            "Epoch 2:  25%|██▍       | 120/484 [15:39<46:44,  7.70s/it, training_loss=0.020]\u001b[A\n",
            "Epoch 2:  25%|██▌       | 121/484 [15:39<47:39,  7.88s/it, training_loss=0.020]\u001b[A\n",
            "Epoch 2:  25%|██▌       | 121/484 [15:46<47:39,  7.88s/it, training_loss=0.016]\u001b[A\n",
            "Epoch 2:  25%|██▌       | 122/484 [15:46<45:03,  7.47s/it, training_loss=0.016]\u001b[A\n",
            "Epoch 2:  25%|██▌       | 122/484 [15:56<45:03,  7.47s/it, training_loss=0.025]\u001b[A\n",
            "Epoch 2:  25%|██▌       | 123/484 [15:56<48:49,  8.11s/it, training_loss=0.025]\u001b[A\n",
            "Epoch 2:  25%|██▌       | 123/484 [16:02<48:49,  8.11s/it, training_loss=0.024]\u001b[A\n",
            "Epoch 2:  26%|██▌       | 124/484 [16:02<45:49,  7.64s/it, training_loss=0.024]\u001b[A\n",
            "Epoch 2:  26%|██▌       | 124/484 [16:11<45:49,  7.64s/it, training_loss=0.079]\u001b[A\n",
            "Epoch 2:  26%|██▌       | 125/484 [16:11<48:18,  8.07s/it, training_loss=0.079]\u001b[A\n",
            "Epoch 2:  26%|██▌       | 125/484 [16:18<48:18,  8.07s/it, training_loss=0.094]\u001b[A\n",
            "Epoch 2:  26%|██▌       | 126/484 [16:18<46:19,  7.76s/it, training_loss=0.094]\u001b[A\n",
            "Epoch 2:  26%|██▌       | 126/484 [16:26<46:19,  7.76s/it, training_loss=0.056]\u001b[A\n",
            "Epoch 2:  26%|██▌       | 127/484 [16:26<45:49,  7.70s/it, training_loss=0.056]\u001b[A\n",
            "Epoch 2:  26%|██▌       | 127/484 [16:34<45:49,  7.70s/it, training_loss=0.008]\u001b[A\n",
            "Epoch 2:  26%|██▋       | 128/484 [16:34<46:54,  7.91s/it, training_loss=0.008]\u001b[A\n",
            "Epoch 2:  26%|██▋       | 128/484 [16:41<46:54,  7.91s/it, training_loss=0.007]\u001b[A\n",
            "Epoch 2:  27%|██▋       | 129/484 [16:41<44:17,  7.49s/it, training_loss=0.007]\u001b[A\n",
            "Epoch 2:  27%|██▋       | 129/484 [16:50<44:17,  7.49s/it, training_loss=0.198]\u001b[A\n",
            "Epoch 2:  27%|██▋       | 130/484 [16:50<48:06,  8.15s/it, training_loss=0.198]\u001b[A\n",
            "Epoch 2:  27%|██▋       | 130/484 [16:57<48:06,  8.15s/it, training_loss=0.035]\u001b[A\n",
            "Epoch 2:  27%|██▋       | 131/484 [16:57<45:04,  7.66s/it, training_loss=0.035]\u001b[A\n",
            "Epoch 2:  27%|██▋       | 131/484 [17:06<45:04,  7.66s/it, training_loss=0.333]\u001b[A\n",
            "Epoch 2:  27%|██▋       | 132/484 [17:06<46:53,  7.99s/it, training_loss=0.333]\u001b[A\n",
            "Epoch 2:  27%|██▋       | 132/484 [17:13<46:53,  7.99s/it, training_loss=0.021]\u001b[A\n",
            "Epoch 2:  27%|██▋       | 133/484 [17:13<45:22,  7.76s/it, training_loss=0.021]\u001b[A\n",
            "Epoch 2:  27%|██▋       | 133/484 [17:20<45:22,  7.76s/it, training_loss=0.021]\u001b[A\n",
            "Epoch 2:  28%|██▊       | 134/484 [17:20<44:09,  7.57s/it, training_loss=0.021]\u001b[A\n",
            "Epoch 2:  28%|██▊       | 134/484 [17:29<44:09,  7.57s/it, training_loss=0.193]\u001b[A\n",
            "Epoch 2:  28%|██▊       | 135/484 [17:29<46:05,  7.92s/it, training_loss=0.193]\u001b[A\n",
            "Epoch 2:  28%|██▊       | 135/484 [17:35<46:05,  7.92s/it, training_loss=0.019]\u001b[A\n",
            "Epoch 2:  28%|██▊       | 136/484 [17:35<43:21,  7.47s/it, training_loss=0.019]\u001b[A\n",
            "Epoch 2:  28%|██▊       | 136/484 [17:45<43:21,  7.47s/it, training_loss=0.221]\u001b[A\n",
            "Epoch 2:  28%|██▊       | 137/484 [17:45<46:50,  8.10s/it, training_loss=0.221]\u001b[A\n",
            "Epoch 2:  28%|██▊       | 137/484 [17:51<46:50,  8.10s/it, training_loss=0.321]\u001b[A\n",
            "Epoch 2:  29%|██▊       | 138/484 [17:51<43:49,  7.60s/it, training_loss=0.321]\u001b[A\n",
            "Epoch 2:  29%|██▊       | 138/484 [18:00<43:49,  7.60s/it, training_loss=0.054]\u001b[A\n",
            "Epoch 2:  29%|██▊       | 139/484 [18:00<45:08,  7.85s/it, training_loss=0.054]\u001b[A\n",
            "Epoch 2:  29%|██▊       | 139/484 [18:07<45:08,  7.85s/it, training_loss=0.113]\u001b[A\n",
            "Epoch 2:  29%|██▉       | 140/484 [18:07<44:29,  7.76s/it, training_loss=0.113]\u001b[A\n",
            "Epoch 2:  29%|██▉       | 140/484 [18:14<44:29,  7.76s/it, training_loss=0.244]\u001b[A\n",
            "Epoch 2:  29%|██▉       | 141/484 [18:14<42:34,  7.45s/it, training_loss=0.244]\u001b[A\n",
            "Epoch 2:  29%|██▉       | 141/484 [18:23<42:34,  7.45s/it, training_loss=0.005]\u001b[A\n",
            "Epoch 2:  29%|██▉       | 142/484 [18:23<45:27,  7.98s/it, training_loss=0.005]\u001b[A\n",
            "Epoch 2:  29%|██▉       | 142/484 [18:30<45:27,  7.98s/it, training_loss=0.017]\u001b[A\n",
            "Epoch 2:  30%|██▉       | 143/484 [18:30<42:52,  7.54s/it, training_loss=0.017]\u001b[A\n",
            "Epoch 2:  30%|██▉       | 143/484 [18:39<42:52,  7.54s/it, training_loss=0.026]\u001b[A\n",
            "Epoch 2:  30%|██▉       | 144/484 [18:39<45:56,  8.11s/it, training_loss=0.026]\u001b[A\n",
            "Epoch 2:  30%|██▉       | 144/484 [18:46<45:56,  8.11s/it, training_loss=0.011]\u001b[A\n",
            "Epoch 2:  30%|██▉       | 145/484 [18:46<43:20,  7.67s/it, training_loss=0.011]\u001b[A\n",
            "Epoch 2:  30%|██▉       | 145/484 [18:54<43:20,  7.67s/it, training_loss=0.210]\u001b[A\n",
            "Epoch 2:  30%|███       | 146/484 [18:54<43:44,  7.76s/it, training_loss=0.210]\u001b[A\n",
            "Epoch 2:  30%|███       | 146/484 [19:02<43:44,  7.76s/it, training_loss=0.041]\u001b[A\n",
            "Epoch 2:  30%|███       | 147/484 [19:02<43:55,  7.82s/it, training_loss=0.041]\u001b[A\n",
            "Epoch 2:  30%|███       | 147/484 [19:08<43:55,  7.82s/it, training_loss=0.151]\u001b[A\n",
            "Epoch 2:  31%|███       | 148/484 [19:08<41:31,  7.42s/it, training_loss=0.151]\u001b[A\n",
            "Epoch 2:  31%|███       | 148/484 [19:18<41:31,  7.42s/it, training_loss=0.091]\u001b[A\n",
            "Epoch 2:  31%|███       | 149/484 [19:18<44:56,  8.05s/it, training_loss=0.091]\u001b[A\n",
            "Epoch 2:  31%|███       | 149/484 [19:24<44:56,  8.05s/it, training_loss=0.148]\u001b[A\n",
            "Epoch 2:  31%|███       | 150/484 [19:24<42:10,  7.58s/it, training_loss=0.148]\u001b[A\n",
            "Epoch 2:  31%|███       | 150/484 [19:33<42:10,  7.58s/it, training_loss=0.319]\u001b[A\n",
            "Epoch 2:  31%|███       | 151/484 [19:33<44:14,  7.97s/it, training_loss=0.319]\u001b[A\n",
            "Epoch 2:  31%|███       | 151/484 [19:40<44:14,  7.97s/it, training_loss=0.043]\u001b[A\n",
            "Epoch 2:  31%|███▏      | 152/484 [19:40<42:34,  7.69s/it, training_loss=0.043]\u001b[A\n",
            "Epoch 2:  31%|███▏      | 152/484 [19:47<42:34,  7.69s/it, training_loss=0.156]\u001b[A\n",
            "Epoch 2:  32%|███▏      | 153/484 [19:47<41:35,  7.54s/it, training_loss=0.156]\u001b[A\n",
            "Epoch 2:  32%|███▏      | 153/484 [19:56<41:35,  7.54s/it, training_loss=0.165]\u001b[A\n",
            "Epoch 2:  32%|███▏      | 154/484 [19:56<43:13,  7.86s/it, training_loss=0.165]\u001b[A\n",
            "Epoch 2:  32%|███▏      | 154/484 [20:02<43:13,  7.86s/it, training_loss=0.039]\u001b[A\n",
            "Epoch 2:  32%|███▏      | 155/484 [20:02<40:52,  7.45s/it, training_loss=0.039]\u001b[A\n",
            "Epoch 2:  32%|███▏      | 155/484 [20:13<40:52,  7.45s/it, training_loss=0.316]\u001b[A\n",
            "Epoch 2:  32%|███▏      | 156/484 [20:13<45:45,  8.37s/it, training_loss=0.316]\u001b[A\n",
            "Epoch 2:  32%|███▏      | 156/484 [20:19<45:45,  8.37s/it, training_loss=0.171]\u001b[A\n",
            "Epoch 2:  32%|███▏      | 157/484 [20:19<42:37,  7.82s/it, training_loss=0.171]\u001b[A\n",
            "Epoch 2:  32%|███▏      | 157/484 [20:28<42:37,  7.82s/it, training_loss=0.307]\u001b[A\n",
            "Epoch 2:  33%|███▎      | 158/484 [20:28<43:48,  8.06s/it, training_loss=0.307]\u001b[A\n",
            "Epoch 2:  33%|███▎      | 158/484 [20:35<43:48,  8.06s/it, training_loss=0.168]\u001b[A\n",
            "Epoch 2:  33%|███▎      | 159/484 [20:35<42:43,  7.89s/it, training_loss=0.168]\u001b[A\n",
            "Epoch 2:  33%|███▎      | 159/484 [20:42<42:43,  7.89s/it, training_loss=0.084]\u001b[A\n",
            "Epoch 2:  33%|███▎      | 160/484 [20:42<40:57,  7.58s/it, training_loss=0.084]\u001b[A\n",
            "Epoch 2:  33%|███▎      | 160/484 [20:51<40:57,  7.58s/it, training_loss=0.297]\u001b[A\n",
            "Epoch 2:  33%|███▎      | 161/484 [20:51<43:10,  8.02s/it, training_loss=0.297]\u001b[A\n",
            "Epoch 2:  33%|███▎      | 161/484 [20:58<43:10,  8.02s/it, training_loss=0.141]\u001b[A\n",
            "Epoch 2:  33%|███▎      | 162/484 [20:58<40:39,  7.57s/it, training_loss=0.141]\u001b[A\n",
            "Epoch 2:  33%|███▎      | 162/484 [21:07<40:39,  7.57s/it, training_loss=0.085]\u001b[A\n",
            "Epoch 2:  34%|███▎      | 163/484 [21:07<43:33,  8.14s/it, training_loss=0.085]\u001b[A\n",
            "Epoch 2:  34%|███▎      | 163/484 [21:14<43:33,  8.14s/it, training_loss=0.135]\u001b[A\n",
            "Epoch 2:  34%|███▍      | 164/484 [21:14<40:56,  7.68s/it, training_loss=0.135]\u001b[A\n",
            "Epoch 2:  34%|███▍      | 164/484 [21:22<40:56,  7.68s/it, training_loss=0.011]\u001b[A\n",
            "Epoch 2:  34%|███▍      | 165/484 [21:22<41:31,  7.81s/it, training_loss=0.011]\u001b[A\n",
            "Epoch 2:  34%|███▍      | 165/484 [21:30<41:31,  7.81s/it, training_loss=0.030]\u001b[A\n",
            "Epoch 2:  34%|███▍      | 166/484 [21:30<41:25,  7.82s/it, training_loss=0.030]\u001b[A\n",
            "Epoch 2:  34%|███▍      | 166/484 [21:36<41:25,  7.82s/it, training_loss=0.487]\u001b[A\n",
            "Epoch 2:  35%|███▍      | 167/484 [21:36<39:14,  7.43s/it, training_loss=0.487]\u001b[A\n",
            "Epoch 2:  35%|███▍      | 167/484 [21:46<39:14,  7.43s/it, training_loss=0.277]\u001b[A\n",
            "Epoch 2:  35%|███▍      | 168/484 [21:46<42:15,  8.02s/it, training_loss=0.277]\u001b[A\n",
            "Epoch 2:  35%|███▍      | 168/484 [21:52<42:15,  8.02s/it, training_loss=0.110]\u001b[A\n",
            "Epoch 2:  35%|███▍      | 169/484 [21:52<39:44,  7.57s/it, training_loss=0.110]\u001b[A\n",
            "Epoch 2:  35%|███▍      | 169/484 [22:02<39:44,  7.57s/it, training_loss=0.238]\u001b[A\n",
            "Epoch 2:  35%|███▌      | 170/484 [22:02<42:08,  8.05s/it, training_loss=0.238]\u001b[A\n",
            "Epoch 2:  35%|███▌      | 170/484 [22:08<42:08,  8.05s/it, training_loss=0.178]\u001b[A\n",
            "Epoch 2:  35%|███▌      | 171/484 [22:08<40:12,  7.71s/it, training_loss=0.178]\u001b[A\n",
            "Epoch 2:  35%|███▌      | 171/484 [22:16<40:12,  7.71s/it, training_loss=0.033]\u001b[A\n",
            "Epoch 2:  36%|███▌      | 172/484 [22:16<40:04,  7.71s/it, training_loss=0.033]\u001b[A\n",
            "Epoch 2:  36%|███▌      | 172/484 [22:24<40:04,  7.71s/it, training_loss=0.358]\u001b[A\n",
            "Epoch 2:  36%|███▌      | 173/484 [22:24<40:47,  7.87s/it, training_loss=0.358]\u001b[A\n",
            "Epoch 2:  36%|███▌      | 173/484 [22:31<40:47,  7.87s/it, training_loss=0.113]\u001b[A\n",
            "Epoch 2:  36%|███▌      | 174/484 [22:31<38:40,  7.49s/it, training_loss=0.113]\u001b[A\n",
            "Epoch 2:  36%|███▌      | 174/484 [22:41<38:40,  7.49s/it, training_loss=0.414]\u001b[A\n",
            "Epoch 2:  36%|███▌      | 175/484 [22:41<41:59,  8.15s/it, training_loss=0.414]\u001b[A\n",
            "Epoch 2:  36%|███▌      | 175/484 [22:47<41:59,  8.15s/it, training_loss=0.027]\u001b[A\n",
            "Epoch 2:  36%|███▋      | 176/484 [22:47<39:26,  7.68s/it, training_loss=0.027]\u001b[A\n",
            "Epoch 2:  36%|███▋      | 176/484 [22:56<39:26,  7.68s/it, training_loss=0.014]\u001b[A\n",
            "Epoch 2:  37%|███▋      | 177/484 [22:56<41:25,  8.10s/it, training_loss=0.014]\u001b[A\n",
            "Epoch 2:  37%|███▋      | 177/484 [23:03<41:25,  8.10s/it, training_loss=0.102]\u001b[A\n",
            "Epoch 2:  37%|███▋      | 178/484 [23:03<39:44,  7.79s/it, training_loss=0.102]\u001b[A\n",
            "Epoch 2:  37%|███▋      | 178/484 [23:11<39:44,  7.79s/it, training_loss=0.026]\u001b[A\n",
            "Epoch 2:  37%|███▋      | 179/484 [23:11<39:08,  7.70s/it, training_loss=0.026]\u001b[A\n",
            "Epoch 2:  37%|███▋      | 179/484 [23:19<39:08,  7.70s/it, training_loss=0.011]\u001b[A\n",
            "Epoch 2:  37%|███▋      | 180/484 [23:19<40:03,  7.91s/it, training_loss=0.011]\u001b[A\n",
            "Epoch 2:  37%|███▋      | 180/484 [23:26<40:03,  7.91s/it, training_loss=0.213]\u001b[A\n",
            "Epoch 2:  37%|███▋      | 181/484 [23:26<37:46,  7.48s/it, training_loss=0.213]\u001b[A\n",
            "Epoch 2:  37%|███▋      | 181/484 [23:35<37:46,  7.48s/it, training_loss=0.158]\u001b[A\n",
            "Epoch 2:  38%|███▊      | 182/484 [23:35<40:56,  8.13s/it, training_loss=0.158]\u001b[A\n",
            "Epoch 2:  38%|███▊      | 182/484 [23:42<40:56,  8.13s/it, training_loss=0.029]\u001b[A\n",
            "Epoch 2:  38%|███▊      | 183/484 [23:42<38:21,  7.65s/it, training_loss=0.029]\u001b[A\n",
            "Epoch 2:  38%|███▊      | 183/484 [23:51<38:21,  7.65s/it, training_loss=0.010]\u001b[A\n",
            "Epoch 2:  38%|███▊      | 184/484 [23:51<40:00,  8.00s/it, training_loss=0.010]\u001b[A\n",
            "Epoch 2:  38%|███▊      | 184/484 [23:58<40:00,  8.00s/it, training_loss=0.026]\u001b[A\n",
            "Epoch 2:  38%|███▊      | 185/484 [23:58<38:48,  7.79s/it, training_loss=0.026]\u001b[A\n",
            "Epoch 2:  38%|███▊      | 185/484 [24:05<38:48,  7.79s/it, training_loss=0.135]\u001b[A\n",
            "Epoch 2:  38%|███▊      | 186/484 [24:05<37:52,  7.63s/it, training_loss=0.135]\u001b[A\n",
            "Epoch 2:  38%|███▊      | 186/484 [24:14<37:52,  7.63s/it, training_loss=0.014]\u001b[A\n",
            "Epoch 2:  39%|███▊      | 187/484 [24:14<39:19,  7.95s/it, training_loss=0.014]\u001b[A\n",
            "Epoch 2:  39%|███▊      | 187/484 [24:21<39:19,  7.95s/it, training_loss=0.182]\u001b[A\n",
            "Epoch 2:  39%|███▉      | 188/484 [24:21<37:05,  7.52s/it, training_loss=0.182]\u001b[A\n",
            "Epoch 2:  39%|███▉      | 188/484 [24:30<37:05,  7.52s/it, training_loss=0.031]\u001b[A\n",
            "Epoch 2:  39%|███▉      | 189/484 [24:30<40:10,  8.17s/it, training_loss=0.031]\u001b[A\n",
            "Epoch 2:  39%|███▉      | 189/484 [24:37<40:10,  8.17s/it, training_loss=0.070]\u001b[A\n",
            "Epoch 2:  39%|███▉      | 190/484 [24:37<37:41,  7.69s/it, training_loss=0.070]\u001b[A\n",
            "Epoch 2:  39%|███▉      | 190/484 [24:45<37:41,  7.69s/it, training_loss=0.112]\u001b[A\n",
            "Epoch 2:  39%|███▉      | 191/484 [24:45<38:59,  7.99s/it, training_loss=0.112]\u001b[A\n",
            "Epoch 2:  39%|███▉      | 191/484 [24:53<38:59,  7.99s/it, training_loss=0.116]\u001b[A\n",
            "Epoch 2:  40%|███▉      | 192/484 [24:53<38:04,  7.82s/it, training_loss=0.116]\u001b[A\n",
            "Epoch 2:  40%|███▉      | 192/484 [25:00<38:04,  7.82s/it, training_loss=0.154]\u001b[A\n",
            "Epoch 2:  40%|███▉      | 193/484 [25:00<36:47,  7.59s/it, training_loss=0.154]\u001b[A\n",
            "Epoch 2:  40%|███▉      | 193/484 [25:09<36:47,  7.59s/it, training_loss=0.039]\u001b[A\n",
            "Epoch 2:  40%|████      | 194/484 [25:09<38:31,  7.97s/it, training_loss=0.039]\u001b[A\n",
            "Epoch 2:  40%|████      | 194/484 [25:15<38:31,  7.97s/it, training_loss=0.104]\u001b[A\n",
            "Epoch 2:  40%|████      | 195/484 [25:15<36:18,  7.54s/it, training_loss=0.104]\u001b[A\n",
            "Epoch 2:  40%|████      | 195/484 [25:25<36:18,  7.54s/it, training_loss=0.053]\u001b[A\n",
            "Epoch 2:  40%|████      | 196/484 [25:25<39:10,  8.16s/it, training_loss=0.053]\u001b[A\n",
            "Epoch 2:  40%|████      | 196/484 [25:31<39:10,  8.16s/it, training_loss=0.283]\u001b[A\n",
            "Epoch 2:  41%|████      | 197/484 [25:31<36:44,  7.68s/it, training_loss=0.283]\u001b[A\n",
            "Epoch 2:  41%|████      | 197/484 [25:40<36:44,  7.68s/it, training_loss=0.078]\u001b[A\n",
            "Epoch 2:  41%|████      | 198/484 [25:40<37:39,  7.90s/it, training_loss=0.078]\u001b[A\n",
            "Epoch 2:  41%|████      | 198/484 [25:47<37:39,  7.90s/it, training_loss=0.105]\u001b[A\n",
            "Epoch 2:  41%|████      | 199/484 [25:48<37:05,  7.81s/it, training_loss=0.105]\u001b[A\n",
            "Epoch 2:  41%|████      | 199/484 [25:54<37:05,  7.81s/it, training_loss=0.022]\u001b[A\n",
            "Epoch 2:  41%|████▏     | 200/484 [25:54<35:33,  7.51s/it, training_loss=0.022]\u001b[A\n",
            "Epoch 2:  41%|████▏     | 200/484 [26:03<35:33,  7.51s/it, training_loss=0.259]\u001b[A\n",
            "Epoch 2:  42%|████▏     | 201/484 [26:03<37:46,  8.01s/it, training_loss=0.259]\u001b[A\n",
            "Epoch 2:  42%|████▏     | 201/484 [26:10<37:46,  8.01s/it, training_loss=0.097]\u001b[A\n",
            "Epoch 2:  42%|████▏     | 202/484 [26:10<35:29,  7.55s/it, training_loss=0.097]\u001b[A\n",
            "Epoch 2:  42%|████▏     | 202/484 [26:19<35:29,  7.55s/it, training_loss=0.030]\u001b[A\n",
            "Epoch 2:  42%|████▏     | 203/484 [26:19<38:07,  8.14s/it, training_loss=0.030]\u001b[A\n",
            "Epoch 2:  42%|████▏     | 203/484 [26:26<38:07,  8.14s/it, training_loss=0.064]\u001b[A\n",
            "Epoch 2:  42%|████▏     | 204/484 [26:26<35:56,  7.70s/it, training_loss=0.064]\u001b[A\n",
            "Epoch 2:  42%|████▏     | 204/484 [26:34<35:56,  7.70s/it, training_loss=0.148]\u001b[A\n",
            "Epoch 2:  42%|████▏     | 205/484 [26:34<36:19,  7.81s/it, training_loss=0.148]\u001b[A\n",
            "Epoch 2:  42%|████▏     | 205/484 [26:42<36:19,  7.81s/it, training_loss=0.012]\u001b[A\n",
            "Epoch 2:  43%|████▎     | 206/484 [26:42<36:17,  7.83s/it, training_loss=0.012]\u001b[A\n",
            "Epoch 2:  43%|████▎     | 206/484 [26:49<36:17,  7.83s/it, training_loss=0.166]\u001b[A\n",
            "Epoch 2:  43%|████▎     | 207/484 [26:49<34:28,  7.47s/it, training_loss=0.166]\u001b[A\n",
            "Epoch 2:  43%|████▎     | 207/484 [26:58<34:28,  7.47s/it, training_loss=0.028]\u001b[A\n",
            "Epoch 2:  43%|████▎     | 208/484 [26:58<37:13,  8.09s/it, training_loss=0.028]\u001b[A\n",
            "Epoch 2:  43%|████▎     | 208/484 [27:05<37:13,  8.09s/it, training_loss=0.009]\u001b[A\n",
            "Epoch 2:  43%|████▎     | 209/484 [27:05<34:59,  7.64s/it, training_loss=0.009]\u001b[A\n",
            "Epoch 2:  43%|████▎     | 209/484 [27:14<34:59,  7.64s/it, training_loss=0.125]\u001b[A\n",
            "Epoch 2:  43%|████▎     | 210/484 [27:14<36:50,  8.07s/it, training_loss=0.125]\u001b[A\n",
            "Epoch 2:  43%|████▎     | 210/484 [27:21<36:50,  8.07s/it, training_loss=0.355]\u001b[A\n",
            "Epoch 2:  44%|████▎     | 211/484 [27:21<35:06,  7.72s/it, training_loss=0.355]\u001b[A\n",
            "Epoch 2:  44%|████▎     | 211/484 [27:28<35:06,  7.72s/it, training_loss=0.008]\u001b[A\n",
            "Epoch 2:  44%|████▍     | 212/484 [27:28<34:49,  7.68s/it, training_loss=0.008]\u001b[A\n",
            "Epoch 2:  44%|████▍     | 212/484 [27:37<34:49,  7.68s/it, training_loss=0.053]\u001b[A\n",
            "Epoch 2:  44%|████▍     | 213/484 [27:37<35:32,  7.87s/it, training_loss=0.053]\u001b[A\n",
            "Epoch 2:  44%|████▍     | 213/484 [27:43<35:32,  7.87s/it, training_loss=0.035]\u001b[A\n",
            "Epoch 2:  44%|████▍     | 214/484 [27:43<33:32,  7.45s/it, training_loss=0.035]\u001b[A\n",
            "Epoch 2:  44%|████▍     | 214/484 [27:53<33:32,  7.45s/it, training_loss=0.050]\u001b[A\n",
            "Epoch 2:  44%|████▍     | 215/484 [27:53<36:18,  8.10s/it, training_loss=0.050]\u001b[A\n",
            "Epoch 2:  44%|████▍     | 215/484 [27:59<36:18,  8.10s/it, training_loss=0.011]\u001b[A\n",
            "Epoch 2:  45%|████▍     | 216/484 [27:59<34:01,  7.62s/it, training_loss=0.011]\u001b[A\n",
            "Epoch 2:  45%|████▍     | 216/484 [28:08<34:01,  7.62s/it, training_loss=0.008]\u001b[A\n",
            "Epoch 2:  45%|████▍     | 217/484 [28:08<35:39,  8.01s/it, training_loss=0.008]\u001b[A\n",
            "Epoch 2:  45%|████▍     | 217/484 [28:15<35:39,  8.01s/it, training_loss=0.149]\u001b[A\n",
            "Epoch 2:  45%|████▌     | 218/484 [28:15<34:22,  7.75s/it, training_loss=0.149]\u001b[A\n",
            "Epoch 2:  45%|████▌     | 218/484 [28:23<34:22,  7.75s/it, training_loss=0.007]\u001b[A\n",
            "Epoch 2:  45%|████▌     | 219/484 [28:23<33:38,  7.62s/it, training_loss=0.007]\u001b[A\n",
            "Epoch 2:  45%|████▌     | 219/484 [28:31<33:38,  7.62s/it, training_loss=0.008]\u001b[A\n",
            "Epoch 2:  45%|████▌     | 220/484 [28:31<34:42,  7.89s/it, training_loss=0.008]\u001b[A\n",
            "Epoch 2:  45%|████▌     | 220/484 [28:38<34:42,  7.89s/it, training_loss=0.099]\u001b[A\n",
            "Epoch 2:  46%|████▌     | 221/484 [28:38<32:44,  7.47s/it, training_loss=0.099]\u001b[A\n",
            "Epoch 2:  46%|████▌     | 221/484 [28:47<32:44,  7.47s/it, training_loss=0.161]\u001b[A\n",
            "Epoch 2:  46%|████▌     | 222/484 [28:47<35:28,  8.12s/it, training_loss=0.161]\u001b[A\n",
            "Epoch 2:  46%|████▌     | 222/484 [28:54<35:28,  8.12s/it, training_loss=0.007]\u001b[A\n",
            "Epoch 2:  46%|████▌     | 223/484 [28:54<33:11,  7.63s/it, training_loss=0.007]\u001b[A\n",
            "Epoch 2:  46%|████▌     | 223/484 [29:02<33:11,  7.63s/it, training_loss=0.010]\u001b[A\n",
            "Epoch 2:  46%|████▋     | 224/484 [29:02<34:21,  7.93s/it, training_loss=0.010]\u001b[A\n",
            "Epoch 2:  46%|████▋     | 224/484 [29:10<34:21,  7.93s/it, training_loss=0.007]\u001b[A\n",
            "Epoch 2:  46%|████▋     | 225/484 [29:10<33:28,  7.76s/it, training_loss=0.007]\u001b[A\n",
            "Epoch 2:  46%|████▋     | 225/484 [29:17<33:28,  7.76s/it, training_loss=0.006]\u001b[A\n",
            "Epoch 2:  47%|████▋     | 226/484 [29:17<32:19,  7.52s/it, training_loss=0.006]\u001b[A\n",
            "Epoch 2:  47%|████▋     | 226/484 [29:26<32:19,  7.52s/it, training_loss=0.009]\u001b[A\n",
            "Epoch 2:  47%|████▋     | 227/484 [29:26<33:58,  7.93s/it, training_loss=0.009]\u001b[A\n",
            "Epoch 2:  47%|████▋     | 227/484 [29:32<33:58,  7.93s/it, training_loss=0.140]\u001b[A\n",
            "Epoch 2:  47%|████▋     | 228/484 [29:32<32:01,  7.51s/it, training_loss=0.140]\u001b[A\n",
            "Epoch 2:  47%|████▋     | 228/484 [29:42<32:01,  7.51s/it, training_loss=0.019]\u001b[A\n",
            "Epoch 2:  47%|████▋     | 229/484 [29:42<34:20,  8.08s/it, training_loss=0.019]\u001b[A\n",
            "Epoch 2:  47%|████▋     | 229/484 [29:48<34:20,  8.08s/it, training_loss=0.032]\u001b[A\n",
            "Epoch 2:  48%|████▊     | 230/484 [29:48<32:21,  7.65s/it, training_loss=0.032]\u001b[A\n",
            "Epoch 2:  48%|████▊     | 230/484 [29:56<32:21,  7.65s/it, training_loss=0.265]\u001b[A\n",
            "Epoch 2:  48%|████▊     | 231/484 [29:56<32:38,  7.74s/it, training_loss=0.265]\u001b[A\n",
            "Epoch 2:  48%|████▊     | 231/484 [30:04<32:38,  7.74s/it, training_loss=0.175]\u001b[A\n",
            "Epoch 2:  48%|████▊     | 232/484 [30:04<32:50,  7.82s/it, training_loss=0.175]\u001b[A\n",
            "Epoch 2:  48%|████▊     | 232/484 [30:11<32:50,  7.82s/it, training_loss=0.261]\u001b[A\n",
            "Epoch 2:  48%|████▊     | 233/484 [30:11<31:07,  7.44s/it, training_loss=0.261]\u001b[A\n",
            "Epoch 2:  48%|████▊     | 233/484 [30:20<31:07,  7.44s/it, training_loss=0.029]\u001b[A\n",
            "Epoch 2:  48%|████▊     | 234/484 [30:20<33:47,  8.11s/it, training_loss=0.029]\u001b[A\n",
            "Epoch 2:  48%|████▊     | 234/484 [30:27<33:47,  8.11s/it, training_loss=0.099]\u001b[A\n",
            "Epoch 2:  49%|████▊     | 235/484 [30:27<31:44,  7.65s/it, training_loss=0.099]\u001b[A\n",
            "Epoch 2:  49%|████▊     | 235/484 [30:36<31:44,  7.65s/it, training_loss=0.169]\u001b[A\n",
            "Epoch 2:  49%|████▉     | 236/484 [30:36<33:34,  8.12s/it, training_loss=0.169]\u001b[A\n",
            "Epoch 2:  49%|████▉     | 236/484 [30:43<33:34,  8.12s/it, training_loss=0.333]\u001b[A\n",
            "Epoch 2:  49%|████▉     | 237/484 [30:43<32:04,  7.79s/it, training_loss=0.333]\u001b[A\n",
            "Epoch 2:  49%|████▉     | 237/484 [30:51<32:04,  7.79s/it, training_loss=0.028]\u001b[A\n",
            "Epoch 2:  49%|████▉     | 238/484 [30:51<31:46,  7.75s/it, training_loss=0.028]\u001b[A\n",
            "Epoch 2:  49%|████▉     | 238/484 [30:59<31:46,  7.75s/it, training_loss=0.011]\u001b[A\n",
            "Epoch 2:  49%|████▉     | 239/484 [30:59<32:17,  7.91s/it, training_loss=0.011]\u001b[A\n",
            "Epoch 2:  49%|████▉     | 239/484 [31:06<32:17,  7.91s/it, training_loss=0.283]\u001b[A\n",
            "Epoch 2:  50%|████▉     | 240/484 [31:06<30:30,  7.50s/it, training_loss=0.283]\u001b[A\n",
            "Epoch 2:  50%|████▉     | 240/484 [31:15<30:30,  7.50s/it, training_loss=0.102]\u001b[A\n",
            "Epoch 2:  50%|████▉     | 241/484 [31:15<33:01,  8.15s/it, training_loss=0.102]\u001b[A\n",
            "Epoch 2:  50%|████▉     | 241/484 [31:22<33:01,  8.15s/it, training_loss=0.173]\u001b[A\n",
            "Epoch 2:  50%|█████     | 242/484 [31:22<30:56,  7.67s/it, training_loss=0.173]\u001b[A\n",
            "Epoch 2:  50%|█████     | 242/484 [31:31<30:56,  7.67s/it, training_loss=0.010]\u001b[A\n",
            "Epoch 2:  50%|█████     | 243/484 [31:31<32:18,  8.04s/it, training_loss=0.010]\u001b[A\n",
            "Epoch 2:  50%|█████     | 243/484 [31:38<32:18,  8.04s/it, training_loss=0.279]\u001b[A\n",
            "Epoch 2:  50%|█████     | 244/484 [31:38<31:11,  7.80s/it, training_loss=0.279]\u001b[A\n",
            "Epoch 2:  50%|█████     | 244/484 [31:45<31:11,  7.80s/it, training_loss=0.089]\u001b[A\n",
            "Epoch 2:  51%|█████     | 245/484 [31:45<30:23,  7.63s/it, training_loss=0.089]\u001b[A\n",
            "Epoch 2:  51%|█████     | 245/484 [31:54<30:23,  7.63s/it, training_loss=0.215]\u001b[A\n",
            "Epoch 2:  51%|█████     | 246/484 [31:54<31:33,  7.95s/it, training_loss=0.215]\u001b[A\n",
            "Epoch 2:  51%|█████     | 246/484 [32:01<31:33,  7.95s/it, training_loss=0.026]\u001b[A\n",
            "Epoch 2:  51%|█████     | 247/484 [32:01<29:46,  7.54s/it, training_loss=0.026]\u001b[A\n",
            "Epoch 2:  51%|█████     | 247/484 [32:10<29:46,  7.54s/it, training_loss=0.007]\u001b[A\n",
            "Epoch 2:  51%|█████     | 248/484 [32:10<32:11,  8.18s/it, training_loss=0.007]\u001b[A\n",
            "Epoch 2:  51%|█████     | 248/484 [32:17<32:11,  8.18s/it, training_loss=0.141]\u001b[A\n",
            "Epoch 2:  51%|█████▏    | 249/484 [32:17<30:09,  7.70s/it, training_loss=0.141]\u001b[A\n",
            "Epoch 2:  51%|█████▏    | 249/484 [32:26<30:09,  7.70s/it, training_loss=0.034]\u001b[A\n",
            "Epoch 2:  52%|█████▏    | 250/484 [32:26<31:14,  8.01s/it, training_loss=0.034]\u001b[A\n",
            "Epoch 2:  52%|█████▏    | 250/484 [32:33<31:14,  8.01s/it, training_loss=0.272]\u001b[A\n",
            "Epoch 2:  52%|█████▏    | 251/484 [32:33<30:29,  7.85s/it, training_loss=0.272]\u001b[A\n",
            "Epoch 2:  52%|█████▏    | 251/484 [32:40<30:29,  7.85s/it, training_loss=0.045]\u001b[A\n",
            "Epoch 2:  52%|█████▏    | 252/484 [32:40<29:25,  7.61s/it, training_loss=0.045]\u001b[A\n",
            "Epoch 2:  52%|█████▏    | 252/484 [32:49<29:25,  7.61s/it, training_loss=0.131]\u001b[A\n",
            "Epoch 2:  52%|█████▏    | 253/484 [32:49<30:46,  7.99s/it, training_loss=0.131]\u001b[A\n",
            "Epoch 2:  52%|█████▏    | 253/484 [32:56<30:46,  7.99s/it, training_loss=0.010]\u001b[A\n",
            "Epoch 2:  52%|█████▏    | 254/484 [32:56<28:55,  7.55s/it, training_loss=0.010]\u001b[A\n",
            "Epoch 2:  52%|█████▏    | 254/484 [33:05<28:55,  7.55s/it, training_loss=0.150]\u001b[A\n",
            "Epoch 2:  53%|█████▎    | 255/484 [33:05<31:09,  8.16s/it, training_loss=0.150]\u001b[A\n",
            "Epoch 2:  53%|█████▎    | 255/484 [33:12<31:09,  8.16s/it, training_loss=0.057]\u001b[A\n",
            "Epoch 2:  53%|█████▎    | 256/484 [33:12<29:07,  7.67s/it, training_loss=0.057]\u001b[A\n",
            "Epoch 2:  53%|█████▎    | 256/484 [33:20<29:07,  7.67s/it, training_loss=0.030]\u001b[A\n",
            "Epoch 2:  53%|█████▎    | 257/484 [33:20<29:49,  7.88s/it, training_loss=0.030]\u001b[A\n",
            "Epoch 2:  53%|█████▎    | 257/484 [33:28<29:49,  7.88s/it, training_loss=0.230]\u001b[A\n",
            "Epoch 2:  53%|█████▎    | 258/484 [33:28<29:26,  7.82s/it, training_loss=0.230]\u001b[A\n",
            "Epoch 2:  53%|█████▎    | 258/484 [33:34<29:26,  7.82s/it, training_loss=0.026]\u001b[A\n",
            "Epoch 2:  54%|█████▎    | 259/484 [33:34<28:02,  7.48s/it, training_loss=0.026]\u001b[A\n",
            "Epoch 2:  54%|█████▎    | 259/484 [33:44<28:02,  7.48s/it, training_loss=0.072]\u001b[A\n",
            "Epoch 2:  54%|█████▎    | 260/484 [33:44<29:53,  8.00s/it, training_loss=0.072]\u001b[A\n",
            "Epoch 2:  54%|█████▎    | 260/484 [33:50<29:53,  8.00s/it, training_loss=0.163]\u001b[A\n",
            "Epoch 2:  54%|█████▍    | 261/484 [33:50<28:05,  7.56s/it, training_loss=0.163]\u001b[A\n",
            "Epoch 2:  54%|█████▍    | 261/484 [33:59<28:05,  7.56s/it, training_loss=0.112]\u001b[A\n",
            "Epoch 2:  54%|█████▍    | 262/484 [33:59<29:53,  8.08s/it, training_loss=0.112]\u001b[A\n",
            "Epoch 2:  54%|█████▍    | 262/484 [34:06<29:53,  8.08s/it, training_loss=0.090]\u001b[A\n",
            "Epoch 2:  54%|█████▍    | 263/484 [34:06<28:20,  7.69s/it, training_loss=0.090]\u001b[A\n",
            "Epoch 2:  54%|█████▍    | 263/484 [34:14<28:20,  7.69s/it, training_loss=0.422]\u001b[A\n",
            "Epoch 2:  55%|█████▍    | 264/484 [34:14<28:31,  7.78s/it, training_loss=0.422]\u001b[A\n",
            "Epoch 2:  55%|█████▍    | 264/484 [34:22<28:31,  7.78s/it, training_loss=0.305]\u001b[A\n",
            "Epoch 2:  55%|█████▍    | 265/484 [34:22<28:44,  7.87s/it, training_loss=0.305]\u001b[A\n",
            "Epoch 2:  55%|█████▍    | 265/484 [34:29<28:44,  7.87s/it, training_loss=0.292]\u001b[A\n",
            "Epoch 2:  55%|█████▍    | 266/484 [34:29<27:12,  7.49s/it, training_loss=0.292]\u001b[A\n",
            "Epoch 2:  55%|█████▍    | 266/484 [34:38<27:12,  7.49s/it, training_loss=0.038]\u001b[A\n",
            "Epoch 2:  55%|█████▌    | 267/484 [34:38<29:22,  8.12s/it, training_loss=0.038]\u001b[A\n",
            "Epoch 2:  55%|█████▌    | 267/484 [34:45<29:22,  8.12s/it, training_loss=0.012]\u001b[A\n",
            "Epoch 2:  55%|█████▌    | 268/484 [34:45<27:33,  7.65s/it, training_loss=0.012]\u001b[A\n",
            "Epoch 2:  55%|█████▌    | 268/484 [34:54<27:33,  7.65s/it, training_loss=0.071]\u001b[A\n",
            "Epoch 2:  56%|█████▌    | 269/484 [34:54<28:57,  8.08s/it, training_loss=0.071]\u001b[A\n",
            "Epoch 2:  56%|█████▌    | 269/484 [35:01<28:57,  8.08s/it, training_loss=0.019]\u001b[A\n",
            "Epoch 2:  56%|█████▌    | 270/484 [35:01<27:42,  7.77s/it, training_loss=0.019]\u001b[A\n",
            "Epoch 2:  56%|█████▌    | 270/484 [35:09<27:42,  7.77s/it, training_loss=0.020]\u001b[A\n",
            "Epoch 2:  56%|█████▌    | 271/484 [35:09<27:19,  7.70s/it, training_loss=0.020]\u001b[A\n",
            "Epoch 2:  56%|█████▌    | 271/484 [35:17<27:19,  7.70s/it, training_loss=0.201]\u001b[A\n",
            "Epoch 2:  56%|█████▌    | 272/484 [35:17<27:55,  7.90s/it, training_loss=0.201]\u001b[A\n",
            "Epoch 2:  56%|█████▌    | 272/484 [35:24<27:55,  7.90s/it, training_loss=0.016]\u001b[A\n",
            "Epoch 2:  56%|█████▋    | 273/484 [35:24<26:17,  7.48s/it, training_loss=0.016]\u001b[A\n",
            "Epoch 2:  56%|█████▋    | 273/484 [35:33<26:17,  7.48s/it, training_loss=0.083]\u001b[A\n",
            "Epoch 2:  57%|█████▋    | 274/484 [35:33<28:27,  8.13s/it, training_loss=0.083]\u001b[A\n",
            "Epoch 2:  57%|█████▋    | 274/484 [35:40<28:27,  8.13s/it, training_loss=0.022]\u001b[A\n",
            "Epoch 2:  57%|█████▋    | 275/484 [35:40<26:37,  7.64s/it, training_loss=0.022]\u001b[A\n",
            "Epoch 2:  57%|█████▋    | 275/484 [35:49<26:37,  7.64s/it, training_loss=0.018]\u001b[A\n",
            "Epoch 2:  57%|█████▋    | 276/484 [35:49<27:46,  8.01s/it, training_loss=0.018]\u001b[A\n",
            "Epoch 2:  57%|█████▋    | 276/484 [35:56<27:46,  8.01s/it, training_loss=0.063]\u001b[A\n",
            "Epoch 2:  57%|█████▋    | 277/484 [35:56<26:53,  7.79s/it, training_loss=0.063]\u001b[A\n",
            "Epoch 2:  57%|█████▋    | 277/484 [36:03<26:53,  7.79s/it, training_loss=0.155]\u001b[A\n",
            "Epoch 2:  57%|█████▋    | 278/484 [36:03<26:14,  7.64s/it, training_loss=0.155]\u001b[A\n",
            "Epoch 2:  57%|█████▋    | 278/484 [36:12<26:14,  7.64s/it, training_loss=0.014]\u001b[A\n",
            "Epoch 2:  58%|█████▊    | 279/484 [36:12<27:15,  7.98s/it, training_loss=0.014]\u001b[A\n",
            "Epoch 2:  58%|█████▊    | 279/484 [36:19<27:15,  7.98s/it, training_loss=0.103]\u001b[A\n",
            "Epoch 2:  58%|█████▊    | 280/484 [36:19<25:49,  7.59s/it, training_loss=0.103]\u001b[A\n",
            "Epoch 2:  58%|█████▊    | 280/484 [36:28<25:49,  7.59s/it, training_loss=0.018]\u001b[A\n",
            "Epoch 2:  58%|█████▊    | 281/484 [36:28<27:52,  8.24s/it, training_loss=0.018]\u001b[A\n",
            "Epoch 2:  58%|█████▊    | 281/484 [36:35<27:52,  8.24s/it, training_loss=0.211]\u001b[A\n",
            "Epoch 2:  58%|█████▊    | 282/484 [36:35<26:02,  7.73s/it, training_loss=0.211]\u001b[A\n",
            "Epoch 2:  58%|█████▊    | 282/484 [36:44<26:02,  7.73s/it, training_loss=0.122]\u001b[A\n",
            "Epoch 2:  58%|█████▊    | 283/484 [36:44<27:02,  8.07s/it, training_loss=0.122]\u001b[A\n",
            "Epoch 2:  58%|█████▊    | 283/484 [36:51<27:02,  8.07s/it, training_loss=0.017]\u001b[A\n",
            "Epoch 2:  59%|█████▊    | 284/484 [36:51<26:11,  7.86s/it, training_loss=0.017]\u001b[A\n",
            "Epoch 2:  59%|█████▊    | 284/484 [36:58<26:11,  7.86s/it, training_loss=0.011]\u001b[A\n",
            "Epoch 2:  59%|█████▉    | 285/484 [36:58<25:26,  7.67s/it, training_loss=0.011]\u001b[A\n",
            "Epoch 2:  59%|█████▉    | 285/484 [37:07<25:26,  7.67s/it, training_loss=0.083]\u001b[A\n",
            "Epoch 2:  59%|█████▉    | 286/484 [37:07<26:18,  7.97s/it, training_loss=0.083]\u001b[A\n",
            "Epoch 2:  59%|█████▉    | 286/484 [37:14<26:18,  7.97s/it, training_loss=0.012]\u001b[A\n",
            "Epoch 2:  59%|█████▉    | 287/484 [37:14<24:45,  7.54s/it, training_loss=0.012]\u001b[A\n",
            "Epoch 2:  59%|█████▉    | 287/484 [37:23<24:45,  7.54s/it, training_loss=0.169]\u001b[A\n",
            "Epoch 2:  60%|█████▉    | 288/484 [37:23<26:42,  8.17s/it, training_loss=0.169]\u001b[A\n",
            "Epoch 2:  60%|█████▉    | 288/484 [37:30<26:42,  8.17s/it, training_loss=0.185]\u001b[A\n",
            "Epoch 2:  60%|█████▉    | 289/484 [37:30<24:57,  7.68s/it, training_loss=0.185]\u001b[A\n",
            "Epoch 2:  60%|█████▉    | 289/484 [37:38<24:57,  7.68s/it, training_loss=0.141]\u001b[A\n",
            "Epoch 2:  60%|█████▉    | 290/484 [37:38<25:43,  7.96s/it, training_loss=0.141]\u001b[A\n",
            "Epoch 2:  60%|█████▉    | 290/484 [37:46<25:43,  7.96s/it, training_loss=0.309]\u001b[A\n",
            "Epoch 2:  60%|██████    | 291/484 [37:46<25:10,  7.83s/it, training_loss=0.309]\u001b[A\n",
            "Epoch 2:  60%|██████    | 291/484 [37:53<25:10,  7.83s/it, training_loss=0.009]\u001b[A\n",
            "Epoch 2:  60%|██████    | 292/484 [37:53<24:05,  7.53s/it, training_loss=0.009]\u001b[A\n",
            "Epoch 2:  60%|██████    | 292/484 [38:02<24:05,  7.53s/it, training_loss=0.172]\u001b[A\n",
            "Epoch 2:  61%|██████    | 293/484 [38:02<25:27,  8.00s/it, training_loss=0.172]\u001b[A\n",
            "Epoch 2:  61%|██████    | 293/484 [38:08<25:27,  8.00s/it, training_loss=0.179]\u001b[A\n",
            "Epoch 2:  61%|██████    | 294/484 [38:08<23:55,  7.56s/it, training_loss=0.179]\u001b[A\n",
            "Epoch 2:  61%|██████    | 294/484 [38:18<23:55,  7.56s/it, training_loss=0.265]\u001b[A\n",
            "Epoch 2:  61%|██████    | 295/484 [38:18<25:44,  8.17s/it, training_loss=0.265]\u001b[A\n",
            "Epoch 2:  61%|██████    | 295/484 [38:25<25:44,  8.17s/it, training_loss=0.313]\u001b[A\n",
            "Epoch 2:  61%|██████    | 296/484 [38:25<24:07,  7.70s/it, training_loss=0.313]\u001b[A\n",
            "Epoch 2:  61%|██████    | 296/484 [38:33<24:07,  7.70s/it, training_loss=0.086]\u001b[A\n",
            "Epoch 2:  61%|██████▏   | 297/484 [38:33<24:27,  7.85s/it, training_loss=0.086]\u001b[A\n",
            "Epoch 2:  61%|██████▏   | 297/484 [38:41<24:27,  7.85s/it, training_loss=0.031]\u001b[A\n",
            "Epoch 2:  62%|██████▏   | 298/484 [38:41<24:17,  7.84s/it, training_loss=0.031]\u001b[A\n",
            "Epoch 2:  62%|██████▏   | 298/484 [38:47<24:17,  7.84s/it, training_loss=0.162]\u001b[A\n",
            "Epoch 2:  62%|██████▏   | 299/484 [38:47<23:07,  7.50s/it, training_loss=0.162]\u001b[A\n",
            "Epoch 2:  62%|██████▏   | 299/484 [38:57<23:07,  7.50s/it, training_loss=0.181]\u001b[A\n",
            "Epoch 2:  62%|██████▏   | 300/484 [38:57<24:44,  8.07s/it, training_loss=0.181]\u001b[A\n",
            "Epoch 2:  62%|██████▏   | 300/484 [39:03<24:44,  8.07s/it, training_loss=0.086]\u001b[A\n",
            "Epoch 2:  62%|██████▏   | 301/484 [39:03<23:12,  7.61s/it, training_loss=0.086]\u001b[A\n",
            "Epoch 2:  62%|██████▏   | 301/484 [39:13<23:12,  7.61s/it, training_loss=0.102]\u001b[A\n",
            "Epoch 2:  62%|██████▏   | 302/484 [39:13<24:38,  8.12s/it, training_loss=0.102]\u001b[A\n",
            "Epoch 2:  62%|██████▏   | 302/484 [39:19<24:38,  8.12s/it, training_loss=0.045]\u001b[A\n",
            "Epoch 2:  63%|██████▎   | 303/484 [39:19<23:22,  7.75s/it, training_loss=0.045]\u001b[A\n",
            "Epoch 2:  63%|██████▎   | 303/484 [39:27<23:22,  7.75s/it, training_loss=0.218]\u001b[A\n",
            "Epoch 2:  63%|██████▎   | 304/484 [39:27<23:23,  7.80s/it, training_loss=0.218]\u001b[A\n",
            "Epoch 2:  63%|██████▎   | 304/484 [39:35<23:23,  7.80s/it, training_loss=0.151]\u001b[A\n",
            "Epoch 2:  63%|██████▎   | 305/484 [39:35<23:33,  7.90s/it, training_loss=0.151]\u001b[A\n",
            "Epoch 2:  63%|██████▎   | 305/484 [39:42<23:33,  7.90s/it, training_loss=0.228]\u001b[A\n",
            "Epoch 2:  63%|██████▎   | 306/484 [39:42<22:17,  7.51s/it, training_loss=0.228]\u001b[A\n",
            "Epoch 2:  63%|██████▎   | 306/484 [39:52<22:17,  7.51s/it, training_loss=0.025]\u001b[A\n",
            "Epoch 2:  63%|██████▎   | 307/484 [39:52<24:07,  8.18s/it, training_loss=0.025]\u001b[A\n",
            "Epoch 2:  63%|██████▎   | 307/484 [39:58<24:07,  8.18s/it, training_loss=0.097]\u001b[A\n",
            "Epoch 2:  64%|██████▎   | 308/484 [39:58<22:37,  7.71s/it, training_loss=0.097]\u001b[A\n",
            "Epoch 2:  64%|██████▎   | 308/484 [40:08<22:37,  7.71s/it, training_loss=0.300]\u001b[A\n",
            "Epoch 2:  64%|██████▍   | 309/484 [40:08<23:44,  8.14s/it, training_loss=0.300]\u001b[A\n",
            "Epoch 2:  64%|██████▍   | 309/484 [40:15<23:44,  8.14s/it, training_loss=0.191]\u001b[A\n",
            "Epoch 2:  64%|██████▍   | 310/484 [40:15<22:56,  7.91s/it, training_loss=0.191]\u001b[A\n",
            "Epoch 2:  64%|██████▍   | 310/484 [40:23<22:56,  7.91s/it, training_loss=0.024]\u001b[A\n",
            "Epoch 2:  64%|██████▍   | 311/484 [40:23<22:54,  7.95s/it, training_loss=0.024]\u001b[A\n",
            "Epoch 2:  64%|██████▍   | 311/484 [40:31<22:54,  7.95s/it, training_loss=0.274]\u001b[A\n",
            "Epoch 2:  64%|██████▍   | 312/484 [40:31<22:52,  7.98s/it, training_loss=0.274]\u001b[A\n",
            "Epoch 2:  64%|██████▍   | 312/484 [40:38<22:52,  7.98s/it, training_loss=0.043]\u001b[A\n",
            "Epoch 2:  65%|██████▍   | 313/484 [40:38<21:32,  7.56s/it, training_loss=0.043]\u001b[A\n",
            "Epoch 2:  65%|██████▍   | 313/484 [40:47<21:32,  7.56s/it, training_loss=0.224]\u001b[A\n",
            "Epoch 2:  65%|██████▍   | 314/484 [40:47<23:11,  8.19s/it, training_loss=0.224]\u001b[A\n",
            "Epoch 2:  65%|██████▍   | 314/484 [40:54<23:11,  8.19s/it, training_loss=0.063]\u001b[A\n",
            "Epoch 2:  65%|██████▌   | 315/484 [40:54<21:41,  7.70s/it, training_loss=0.063]\u001b[A\n",
            "Epoch 2:  65%|██████▌   | 315/484 [41:03<21:41,  7.70s/it, training_loss=0.194]\u001b[A\n",
            "Epoch 2:  65%|██████▌   | 316/484 [41:03<22:46,  8.13s/it, training_loss=0.194]\u001b[A\n",
            "Epoch 2:  65%|██████▌   | 316/484 [41:10<22:46,  8.13s/it, training_loss=0.197]\u001b[A\n",
            "Epoch 2:  65%|██████▌   | 317/484 [41:10<21:38,  7.77s/it, training_loss=0.197]\u001b[A\n",
            "Epoch 2:  65%|██████▌   | 317/484 [41:17<21:38,  7.77s/it, training_loss=0.018]\u001b[A\n",
            "Epoch 2:  66%|██████▌   | 318/484 [41:17<21:20,  7.72s/it, training_loss=0.018]\u001b[A\n",
            "Epoch 2:  66%|██████▌   | 318/484 [41:26<21:20,  7.72s/it, training_loss=0.051]\u001b[A\n",
            "Epoch 2:  66%|██████▌   | 319/484 [41:26<21:43,  7.90s/it, training_loss=0.051]\u001b[A\n",
            "Epoch 2:  66%|██████▌   | 319/484 [41:32<21:43,  7.90s/it, training_loss=0.028]\u001b[A\n",
            "Epoch 2:  66%|██████▌   | 320/484 [41:32<20:29,  7.50s/it, training_loss=0.028]\u001b[A\n",
            "Epoch 2:  66%|██████▌   | 320/484 [41:42<20:29,  7.50s/it, training_loss=0.101]\u001b[A\n",
            "Epoch 2:  66%|██████▋   | 321/484 [41:42<22:07,  8.14s/it, training_loss=0.101]\u001b[A\n",
            "Epoch 2:  66%|██████▋   | 321/484 [41:49<22:07,  8.14s/it, training_loss=0.078]\u001b[A\n",
            "Epoch 2:  67%|██████▋   | 322/484 [41:49<20:40,  7.66s/it, training_loss=0.078]\u001b[A\n",
            "Epoch 2:  67%|██████▋   | 322/484 [41:57<20:40,  7.66s/it, training_loss=0.103]\u001b[A\n",
            "Epoch 2:  67%|██████▋   | 323/484 [41:57<21:31,  8.02s/it, training_loss=0.103]\u001b[A\n",
            "Epoch 2:  67%|██████▋   | 323/484 [42:05<21:31,  8.02s/it, training_loss=0.011]\u001b[A\n",
            "Epoch 2:  67%|██████▋   | 324/484 [42:05<20:43,  7.77s/it, training_loss=0.011]\u001b[A\n",
            "Epoch 2:  67%|██████▋   | 324/484 [42:12<20:43,  7.77s/it, training_loss=0.028]\u001b[A\n",
            "Epoch 2:  67%|██████▋   | 325/484 [42:12<20:11,  7.62s/it, training_loss=0.028]\u001b[A\n",
            "Epoch 2:  67%|██████▋   | 325/484 [42:21<20:11,  7.62s/it, training_loss=0.066]\u001b[A\n",
            "Epoch 2:  67%|██████▋   | 326/484 [42:21<20:54,  7.94s/it, training_loss=0.066]\u001b[A\n",
            "Epoch 2:  67%|██████▋   | 326/484 [42:27<20:54,  7.94s/it, training_loss=0.064]\u001b[A\n",
            "Epoch 2:  68%|██████▊   | 327/484 [42:27<19:38,  7.51s/it, training_loss=0.064]\u001b[A\n",
            "Epoch 2:  68%|██████▊   | 327/484 [42:37<19:38,  7.51s/it, training_loss=0.016]\u001b[A\n",
            "Epoch 2:  68%|██████▊   | 328/484 [42:37<21:14,  8.17s/it, training_loss=0.016]\u001b[A\n",
            "Epoch 2:  68%|██████▊   | 328/484 [42:43<21:14,  8.17s/it, training_loss=0.076]\u001b[A\n",
            "Epoch 2:  68%|██████▊   | 329/484 [42:43<19:51,  7.69s/it, training_loss=0.076]\u001b[A\n",
            "Epoch 2:  68%|██████▊   | 329/484 [42:52<19:51,  7.69s/it, training_loss=0.061]\u001b[A\n",
            "Epoch 2:  68%|██████▊   | 330/484 [42:52<20:32,  8.00s/it, training_loss=0.061]\u001b[A\n",
            "Epoch 2:  68%|██████▊   | 330/484 [42:59<20:32,  8.00s/it, training_loss=0.029]\u001b[A\n",
            "Epoch 2:  68%|██████▊   | 331/484 [42:59<19:56,  7.82s/it, training_loss=0.029]\u001b[A\n",
            "Epoch 2:  68%|██████▊   | 331/484 [43:06<19:56,  7.82s/it, training_loss=0.094]\u001b[A\n",
            "Epoch 2:  69%|██████▊   | 332/484 [43:06<19:10,  7.57s/it, training_loss=0.094]\u001b[A\n",
            "Epoch 2:  69%|██████▊   | 332/484 [43:15<19:10,  7.57s/it, training_loss=0.150]\u001b[A\n",
            "Epoch 2:  69%|██████▉   | 333/484 [43:15<20:00,  7.95s/it, training_loss=0.150]\u001b[A\n",
            "Epoch 2:  69%|██████▉   | 333/484 [43:22<20:00,  7.95s/it, training_loss=0.149]\u001b[A\n",
            "Epoch 2:  69%|██████▉   | 334/484 [43:22<18:47,  7.51s/it, training_loss=0.149]\u001b[A\n",
            "Epoch 2:  69%|██████▉   | 334/484 [43:31<18:47,  7.51s/it, training_loss=0.039]\u001b[A\n",
            "Epoch 2:  69%|██████▉   | 335/484 [43:31<20:10,  8.12s/it, training_loss=0.039]\u001b[A\n",
            "Epoch 2:  69%|██████▉   | 335/484 [43:38<20:10,  8.12s/it, training_loss=0.278]\u001b[A\n",
            "Epoch 2:  69%|██████▉   | 336/484 [43:38<18:47,  7.62s/it, training_loss=0.278]\u001b[A\n",
            "Epoch 2:  69%|██████▉   | 336/484 [43:46<18:47,  7.62s/it, training_loss=0.135]\u001b[A\n",
            "Epoch 2:  70%|██████▉   | 337/484 [43:46<19:01,  7.77s/it, training_loss=0.135]\u001b[A\n",
            "Epoch 2:  70%|██████▉   | 337/484 [43:54<19:01,  7.77s/it, training_loss=0.177]\u001b[A\n",
            "Epoch 2:  70%|██████▉   | 338/484 [43:54<18:56,  7.79s/it, training_loss=0.177]\u001b[A\n",
            "Epoch 2:  70%|██████▉   | 338/484 [44:00<18:56,  7.79s/it, training_loss=0.084]\u001b[A\n",
            "Epoch 2:  70%|███████   | 339/484 [44:00<17:57,  7.43s/it, training_loss=0.084]\u001b[A\n",
            "Epoch 2:  70%|███████   | 339/484 [44:10<17:57,  7.43s/it, training_loss=0.021]\u001b[A\n",
            "Epoch 2:  70%|███████   | 340/484 [44:10<19:13,  8.01s/it, training_loss=0.021]\u001b[A\n",
            "Epoch 2:  70%|███████   | 340/484 [44:16<19:13,  8.01s/it, training_loss=0.110]\u001b[A\n",
            "Epoch 2:  70%|███████   | 341/484 [44:16<18:00,  7.55s/it, training_loss=0.110]\u001b[A\n",
            "Epoch 2:  70%|███████   | 341/484 [44:25<18:00,  7.55s/it, training_loss=0.020]\u001b[A\n",
            "Epoch 2:  71%|███████   | 342/484 [44:25<19:01,  8.04s/it, training_loss=0.020]\u001b[A\n",
            "Epoch 2:  71%|███████   | 342/484 [44:32<19:01,  8.04s/it, training_loss=0.196]\u001b[A\n",
            "Epoch 2:  71%|███████   | 343/484 [44:32<18:04,  7.69s/it, training_loss=0.196]\u001b[A\n",
            "Epoch 2:  71%|███████   | 343/484 [44:40<18:04,  7.69s/it, training_loss=0.007]\u001b[A\n",
            "Epoch 2:  71%|███████   | 344/484 [44:40<17:52,  7.66s/it, training_loss=0.007]\u001b[A\n",
            "Epoch 2:  71%|███████   | 344/484 [44:48<17:52,  7.66s/it, training_loss=0.015]\u001b[A\n",
            "Epoch 2:  71%|███████▏  | 345/484 [44:48<18:09,  7.84s/it, training_loss=0.015]\u001b[A\n",
            "Epoch 2:  71%|███████▏  | 345/484 [44:55<18:09,  7.84s/it, training_loss=0.134]\u001b[A\n",
            "Epoch 2:  71%|███████▏  | 346/484 [44:55<17:05,  7.43s/it, training_loss=0.134]\u001b[A\n",
            "Epoch 2:  71%|███████▏  | 346/484 [45:04<17:05,  7.43s/it, training_loss=0.076]\u001b[A\n",
            "Epoch 2:  72%|███████▏  | 347/484 [45:04<18:28,  8.09s/it, training_loss=0.076]\u001b[A\n",
            "Epoch 2:  72%|███████▏  | 347/484 [45:11<18:28,  8.09s/it, training_loss=0.160]\u001b[A\n",
            "Epoch 2:  72%|███████▏  | 348/484 [45:11<17:14,  7.61s/it, training_loss=0.160]\u001b[A\n",
            "Epoch 2:  72%|███████▏  | 348/484 [45:19<17:14,  7.61s/it, training_loss=0.065]\u001b[A\n",
            "Epoch 2:  72%|███████▏  | 349/484 [45:19<17:54,  7.96s/it, training_loss=0.065]\u001b[A\n",
            "Epoch 2:  72%|███████▏  | 349/484 [45:27<17:54,  7.96s/it, training_loss=0.005]\u001b[A\n",
            "Epoch 2:  72%|███████▏  | 350/484 [45:27<17:14,  7.72s/it, training_loss=0.005]\u001b[A\n",
            "Epoch 2:  72%|███████▏  | 350/484 [45:34<17:14,  7.72s/it, training_loss=0.070]\u001b[A\n",
            "Epoch 2:  73%|███████▎  | 351/484 [45:34<16:42,  7.54s/it, training_loss=0.070]\u001b[A\n",
            "Epoch 2:  73%|███████▎  | 351/484 [45:42<16:42,  7.54s/it, training_loss=0.012]\u001b[A\n",
            "Epoch 2:  73%|███████▎  | 352/484 [45:42<17:19,  7.87s/it, training_loss=0.012]\u001b[A\n",
            "Epoch 2:  73%|███████▎  | 352/484 [45:49<17:19,  7.87s/it, training_loss=0.358]\u001b[A\n",
            "Epoch 2:  73%|███████▎  | 353/484 [45:49<16:15,  7.45s/it, training_loss=0.358]\u001b[A\n",
            "Epoch 2:  73%|███████▎  | 353/484 [45:58<16:15,  7.45s/it, training_loss=0.018]\u001b[A\n",
            "Epoch 2:  73%|███████▎  | 354/484 [45:58<17:29,  8.07s/it, training_loss=0.018]\u001b[A\n",
            "Epoch 2:  73%|███████▎  | 354/484 [46:05<17:29,  8.07s/it, training_loss=0.146]\u001b[A\n",
            "Epoch 2:  73%|███████▎  | 355/484 [46:05<16:20,  7.60s/it, training_loss=0.146]\u001b[A\n",
            "Epoch 2:  73%|███████▎  | 355/484 [46:13<16:20,  7.60s/it, training_loss=0.150]\u001b[A\n",
            "Epoch 2:  74%|███████▎  | 356/484 [46:13<16:41,  7.83s/it, training_loss=0.150]\u001b[A\n",
            "Epoch 2:  74%|███████▎  | 356/484 [46:21<16:41,  7.83s/it, training_loss=0.020]\u001b[A\n",
            "Epoch 2:  74%|███████▍  | 357/484 [46:21<16:27,  7.77s/it, training_loss=0.020]\u001b[A\n",
            "Epoch 2:  74%|███████▍  | 357/484 [46:28<16:27,  7.77s/it, training_loss=0.013]\u001b[A\n",
            "Epoch 2:  74%|███████▍  | 358/484 [46:28<15:39,  7.46s/it, training_loss=0.013]\u001b[A\n",
            "Epoch 2:  74%|███████▍  | 358/484 [46:37<15:39,  7.46s/it, training_loss=0.144]\u001b[A\n",
            "Epoch 2:  74%|███████▍  | 359/484 [46:37<16:37,  7.98s/it, training_loss=0.144]\u001b[A\n",
            "Epoch 2:  74%|███████▍  | 359/484 [46:43<16:37,  7.98s/it, training_loss=0.011]\u001b[A\n",
            "Epoch 2:  74%|███████▍  | 360/484 [46:43<15:34,  7.54s/it, training_loss=0.011]\u001b[A\n",
            "Epoch 2:  74%|███████▍  | 360/484 [46:53<15:34,  7.54s/it, training_loss=0.010]\u001b[A\n",
            "Epoch 2:  75%|███████▍  | 361/484 [46:53<16:38,  8.12s/it, training_loss=0.010]\u001b[A\n",
            "Epoch 2:  75%|███████▍  | 361/484 [46:59<16:38,  8.12s/it, training_loss=0.072]\u001b[A\n",
            "Epoch 2:  75%|███████▍  | 362/484 [46:59<15:35,  7.67s/it, training_loss=0.072]\u001b[A\n",
            "Epoch 2:  75%|███████▍  | 362/484 [47:07<15:35,  7.67s/it, training_loss=0.006]\u001b[A\n",
            "Epoch 2:  75%|███████▌  | 363/484 [47:07<15:38,  7.75s/it, training_loss=0.006]\u001b[A\n",
            "Epoch 2:  75%|███████▌  | 363/484 [47:15<15:38,  7.75s/it, training_loss=0.144]\u001b[A\n",
            "Epoch 2:  75%|███████▌  | 364/484 [47:15<15:36,  7.80s/it, training_loss=0.144]\u001b[A\n",
            "Epoch 2:  75%|███████▌  | 364/484 [47:22<15:36,  7.80s/it, training_loss=0.117]\u001b[A\n",
            "Epoch 2:  75%|███████▌  | 365/484 [47:22<14:44,  7.43s/it, training_loss=0.117]\u001b[A\n",
            "Epoch 2:  75%|███████▌  | 365/484 [47:31<14:44,  7.43s/it, training_loss=0.024]\u001b[A\n",
            "Epoch 2:  76%|███████▌  | 366/484 [47:31<15:52,  8.08s/it, training_loss=0.024]\u001b[A\n",
            "Epoch 2:  76%|███████▌  | 366/484 [47:38<15:52,  8.08s/it, training_loss=0.015]\u001b[A\n",
            "Epoch 2:  76%|███████▌  | 367/484 [47:38<14:50,  7.61s/it, training_loss=0.015]\u001b[A\n",
            "Epoch 2:  76%|███████▌  | 367/484 [47:47<14:50,  7.61s/it, training_loss=0.189]\u001b[A\n",
            "Epoch 2:  76%|███████▌  | 368/484 [47:47<15:32,  8.03s/it, training_loss=0.189]\u001b[A\n",
            "Epoch 2:  76%|███████▌  | 368/484 [47:54<15:32,  8.03s/it, training_loss=0.179]\u001b[A\n",
            "Epoch 2:  76%|███████▌  | 369/484 [47:54<14:49,  7.74s/it, training_loss=0.179]\u001b[A\n",
            "Epoch 2:  76%|███████▌  | 369/484 [48:01<14:49,  7.74s/it, training_loss=0.015]\u001b[A\n",
            "Epoch 2:  76%|███████▋  | 370/484 [48:01<14:32,  7.65s/it, training_loss=0.015]\u001b[A\n",
            "Epoch 2:  76%|███████▋  | 370/484 [48:10<14:32,  7.65s/it, training_loss=0.025]\u001b[A\n",
            "Epoch 2:  77%|███████▋  | 371/484 [48:10<14:47,  7.86s/it, training_loss=0.025]\u001b[A\n",
            "Epoch 2:  77%|███████▋  | 371/484 [48:18<14:47,  7.86s/it, training_loss=0.092]\u001b[A\n",
            "Epoch 2:  77%|███████▋  | 372/484 [48:18<14:53,  7.97s/it, training_loss=0.092]\u001b[A\n",
            "Epoch 2:  77%|███████▋  | 372/484 [48:27<14:53,  7.97s/it, training_loss=0.046]\u001b[A\n",
            "Epoch 2:  77%|███████▋  | 373/484 [48:27<15:30,  8.38s/it, training_loss=0.046]\u001b[A\n",
            "Epoch 2:  77%|███████▋  | 373/484 [48:34<15:30,  8.38s/it, training_loss=0.029]\u001b[A\n",
            "Epoch 2:  77%|███████▋  | 374/484 [48:34<14:19,  7.82s/it, training_loss=0.029]\u001b[A\n",
            "Epoch 2:  77%|███████▋  | 374/484 [48:43<14:19,  7.82s/it, training_loss=0.046]\u001b[A\n",
            "Epoch 2:  77%|███████▋  | 375/484 [48:43<14:57,  8.24s/it, training_loss=0.046]\u001b[A\n",
            "Epoch 2:  77%|███████▋  | 375/484 [48:50<14:57,  8.24s/it, training_loss=0.007]\u001b[A\n",
            "Epoch 2:  78%|███████▊  | 376/484 [48:50<14:04,  7.82s/it, training_loss=0.007]\u001b[A\n",
            "Epoch 2:  78%|███████▊  | 376/484 [48:58<14:04,  7.82s/it, training_loss=0.196]\u001b[A\n",
            "Epoch 2:  78%|███████▊  | 377/484 [48:58<13:56,  7.82s/it, training_loss=0.196]\u001b[A\n",
            "Epoch 2:  78%|███████▊  | 377/484 [49:06<13:56,  7.82s/it, training_loss=0.146]\u001b[A\n",
            "Epoch 2:  78%|███████▊  | 378/484 [49:06<13:56,  7.89s/it, training_loss=0.146]\u001b[A\n",
            "Epoch 2:  78%|███████▊  | 378/484 [49:12<13:56,  7.89s/it, training_loss=0.144]\u001b[A\n",
            "Epoch 2:  78%|███████▊  | 379/484 [49:12<13:04,  7.47s/it, training_loss=0.144]\u001b[A\n",
            "Epoch 2:  78%|███████▊  | 379/484 [49:22<13:04,  7.47s/it, training_loss=0.527]\u001b[A\n",
            "Epoch 2:  79%|███████▊  | 380/484 [49:22<14:05,  8.13s/it, training_loss=0.527]\u001b[A\n",
            "Epoch 2:  79%|███████▊  | 380/484 [49:28<14:05,  8.13s/it, training_loss=0.176]\u001b[A\n",
            "Epoch 2:  79%|███████▊  | 381/484 [49:28<13:06,  7.64s/it, training_loss=0.176]\u001b[A\n",
            "Epoch 2:  79%|███████▊  | 381/484 [49:37<13:06,  7.64s/it, training_loss=0.196]\u001b[A\n",
            "Epoch 2:  79%|███████▉  | 382/484 [49:37<13:40,  8.04s/it, training_loss=0.196]\u001b[A\n",
            "Epoch 2:  79%|███████▉  | 382/484 [49:44<13:40,  8.04s/it, training_loss=0.039]\u001b[A\n",
            "Epoch 2:  79%|███████▉  | 383/484 [49:44<13:02,  7.75s/it, training_loss=0.039]\u001b[A\n",
            "Epoch 2:  79%|███████▉  | 383/484 [49:52<13:02,  7.75s/it, training_loss=0.181]\u001b[A\n",
            "Epoch 2:  79%|███████▉  | 384/484 [49:52<12:47,  7.67s/it, training_loss=0.181]\u001b[A\n",
            "Epoch 2:  79%|███████▉  | 384/484 [50:00<12:47,  7.67s/it, training_loss=0.087]\u001b[A\n",
            "Epoch 2:  80%|███████▉  | 385/484 [50:00<13:05,  7.93s/it, training_loss=0.087]\u001b[A\n",
            "Epoch 2:  80%|███████▉  | 385/484 [50:07<13:05,  7.93s/it, training_loss=0.009]\u001b[A\n",
            "Epoch 2:  80%|███████▉  | 386/484 [50:07<12:16,  7.51s/it, training_loss=0.009]\u001b[A\n",
            "Epoch 2:  80%|███████▉  | 386/484 [50:17<12:16,  7.51s/it, training_loss=0.008]\u001b[A\n",
            "Epoch 2:  80%|███████▉  | 387/484 [50:17<13:12,  8.17s/it, training_loss=0.008]\u001b[A\n",
            "Epoch 2:  80%|███████▉  | 387/484 [50:23<13:12,  8.17s/it, training_loss=0.015]\u001b[A\n",
            "Epoch 2:  80%|████████  | 388/484 [50:23<12:18,  7.70s/it, training_loss=0.015]\u001b[A\n",
            "Epoch 2:  80%|████████  | 388/484 [50:32<12:18,  7.70s/it, training_loss=0.216]\u001b[A\n",
            "Epoch 2:  80%|████████  | 389/484 [50:32<12:47,  8.08s/it, training_loss=0.216]\u001b[A\n",
            "Epoch 2:  80%|████████  | 389/484 [50:40<12:47,  8.08s/it, training_loss=0.040]\u001b[A\n",
            "Epoch 2:  81%|████████  | 390/484 [50:40<12:15,  7.83s/it, training_loss=0.040]\u001b[A\n",
            "Epoch 2:  81%|████████  | 390/484 [50:47<12:15,  7.83s/it, training_loss=0.124]\u001b[A\n",
            "Epoch 2:  81%|████████  | 391/484 [50:47<11:52,  7.67s/it, training_loss=0.124]\u001b[A\n",
            "Epoch 2:  81%|████████  | 391/484 [50:56<11:52,  7.67s/it, training_loss=0.173]\u001b[A\n",
            "Epoch 2:  81%|████████  | 392/484 [50:56<12:15,  8.00s/it, training_loss=0.173]\u001b[A\n",
            "Epoch 2:  81%|████████  | 392/484 [51:02<12:15,  8.00s/it, training_loss=0.051]\u001b[A\n",
            "Epoch 2:  81%|████████  | 393/484 [51:02<11:29,  7.57s/it, training_loss=0.051]\u001b[A\n",
            "Epoch 2:  81%|████████  | 393/484 [51:12<11:29,  7.57s/it, training_loss=0.184]\u001b[A\n",
            "Epoch 2:  81%|████████▏ | 394/484 [51:12<12:17,  8.19s/it, training_loss=0.184]\u001b[A\n",
            "Epoch 2:  81%|████████▏ | 394/484 [51:18<12:17,  8.19s/it, training_loss=0.058]\u001b[A\n",
            "Epoch 2:  82%|████████▏ | 395/484 [51:18<11:24,  7.70s/it, training_loss=0.058]\u001b[A\n",
            "Epoch 2:  82%|████████▏ | 395/484 [51:27<11:24,  7.70s/it, training_loss=0.189]\u001b[A\n",
            "Epoch 2:  82%|████████▏ | 396/484 [51:27<11:40,  7.96s/it, training_loss=0.189]\u001b[A\n",
            "Epoch 2:  82%|████████▏ | 396/484 [51:34<11:40,  7.96s/it, training_loss=0.042]\u001b[A\n",
            "Epoch 2:  82%|████████▏ | 397/484 [51:34<11:19,  7.81s/it, training_loss=0.042]\u001b[A\n",
            "Epoch 2:  82%|████████▏ | 397/484 [51:41<11:19,  7.81s/it, training_loss=0.025]\u001b[A\n",
            "Epoch 2:  82%|████████▏ | 398/484 [51:41<10:44,  7.49s/it, training_loss=0.025]\u001b[A\n",
            "Epoch 2:  82%|████████▏ | 398/484 [51:50<10:44,  7.49s/it, training_loss=0.176]\u001b[A\n",
            "Epoch 2:  82%|████████▏ | 399/484 [51:50<11:16,  7.96s/it, training_loss=0.176]\u001b[A\n",
            "Epoch 2:  82%|████████▏ | 399/484 [51:57<11:16,  7.96s/it, training_loss=0.129]\u001b[A\n",
            "Epoch 2:  83%|████████▎ | 400/484 [51:57<10:30,  7.50s/it, training_loss=0.129]\u001b[A\n",
            "Epoch 2:  83%|████████▎ | 400/484 [52:06<10:30,  7.50s/it, training_loss=0.049]\u001b[A\n",
            "Epoch 2:  83%|████████▎ | 401/484 [52:06<11:10,  8.08s/it, training_loss=0.049]\u001b[A\n",
            "Epoch 2:  83%|████████▎ | 401/484 [52:13<11:10,  8.08s/it, training_loss=0.142]\u001b[A\n",
            "Epoch 2:  83%|████████▎ | 402/484 [52:13<10:26,  7.65s/it, training_loss=0.142]\u001b[A\n",
            "Epoch 2:  83%|████████▎ | 402/484 [52:21<10:26,  7.65s/it, training_loss=0.025]\u001b[A\n",
            "Epoch 2:  83%|████████▎ | 403/484 [52:21<10:29,  7.78s/it, training_loss=0.025]\u001b[A\n",
            "Epoch 2:  83%|████████▎ | 403/484 [52:29<10:29,  7.78s/it, training_loss=0.011]\u001b[A\n",
            "Epoch 2:  83%|████████▎ | 404/484 [52:29<10:26,  7.83s/it, training_loss=0.011]\u001b[A\n",
            "Epoch 2:  83%|████████▎ | 404/484 [52:35<10:26,  7.83s/it, training_loss=0.109]\u001b[A\n",
            "Epoch 2:  84%|████████▎ | 405/484 [52:35<09:52,  7.51s/it, training_loss=0.109]\u001b[A\n",
            "Epoch 2:  84%|████████▎ | 405/484 [52:45<09:52,  7.51s/it, training_loss=0.171]\u001b[A\n",
            "Epoch 2:  84%|████████▍ | 406/484 [52:45<10:31,  8.10s/it, training_loss=0.171]\u001b[A\n",
            "Epoch 2:  84%|████████▍ | 406/484 [52:52<10:31,  8.10s/it, training_loss=0.050]\u001b[A\n",
            "Epoch 2:  84%|████████▍ | 407/484 [52:52<09:48,  7.64s/it, training_loss=0.050]\u001b[A\n",
            "Epoch 2:  84%|████████▍ | 407/484 [53:01<09:48,  7.64s/it, training_loss=0.129]\u001b[A\n",
            "Epoch 2:  84%|████████▍ | 408/484 [53:01<10:19,  8.16s/it, training_loss=0.129]\u001b[A\n",
            "Epoch 2:  84%|████████▍ | 408/484 [53:08<10:19,  8.16s/it, training_loss=0.007]\u001b[A\n",
            "Epoch 2:  85%|████████▍ | 409/484 [53:08<09:41,  7.75s/it, training_loss=0.007]\u001b[A\n",
            "Epoch 2:  85%|████████▍ | 409/484 [53:15<09:41,  7.75s/it, training_loss=0.033]\u001b[A\n",
            "Epoch 2:  85%|████████▍ | 410/484 [53:15<09:34,  7.76s/it, training_loss=0.033]\u001b[A\n",
            "Epoch 2:  85%|████████▍ | 410/484 [53:24<09:34,  7.76s/it, training_loss=0.029]\u001b[A\n",
            "Epoch 2:  85%|████████▍ | 411/484 [53:24<09:34,  7.87s/it, training_loss=0.029]\u001b[A\n",
            "Epoch 2:  85%|████████▍ | 411/484 [53:30<09:34,  7.87s/it, training_loss=0.024]\u001b[A\n",
            "Epoch 2:  85%|████████▌ | 412/484 [53:30<08:56,  7.45s/it, training_loss=0.024]\u001b[A\n",
            "Epoch 2:  85%|████████▌ | 412/484 [53:40<08:56,  7.45s/it, training_loss=0.045]\u001b[A\n",
            "Epoch 2:  85%|████████▌ | 413/484 [53:40<09:35,  8.11s/it, training_loss=0.045]\u001b[A\n",
            "Epoch 2:  85%|████████▌ | 413/484 [53:46<09:35,  8.11s/it, training_loss=0.138]\u001b[A\n",
            "Epoch 2:  86%|████████▌ | 414/484 [53:46<08:54,  7.63s/it, training_loss=0.138]\u001b[A\n",
            "Epoch 2:  86%|████████▌ | 414/484 [53:55<08:54,  7.63s/it, training_loss=0.128]\u001b[A\n",
            "Epoch 2:  86%|████████▌ | 415/484 [53:55<09:14,  8.03s/it, training_loss=0.128]\u001b[A\n",
            "Epoch 2:  86%|████████▌ | 415/484 [54:02<09:14,  8.03s/it, training_loss=0.015]\u001b[A\n",
            "Epoch 2:  86%|████████▌ | 416/484 [54:02<08:49,  7.78s/it, training_loss=0.015]\u001b[A\n",
            "Epoch 2:  86%|████████▌ | 416/484 [54:10<08:49,  7.78s/it, training_loss=0.080]\u001b[A\n",
            "Epoch 2:  86%|████████▌ | 417/484 [54:10<08:32,  7.64s/it, training_loss=0.080]\u001b[A\n",
            "Epoch 2:  86%|████████▌ | 417/484 [54:18<08:32,  7.64s/it, training_loss=0.250]\u001b[A\n",
            "Epoch 2:  86%|████████▋ | 418/484 [54:18<08:43,  7.94s/it, training_loss=0.250]\u001b[A\n",
            "Epoch 2:  86%|████████▋ | 418/484 [54:25<08:43,  7.94s/it, training_loss=0.244]\u001b[A\n",
            "Epoch 2:  87%|████████▋ | 419/484 [54:25<08:08,  7.51s/it, training_loss=0.244]\u001b[A\n",
            "Epoch 2:  87%|████████▋ | 419/484 [54:35<08:08,  7.51s/it, training_loss=0.133]\u001b[A\n",
            "Epoch 2:  87%|████████▋ | 420/484 [54:35<08:43,  8.19s/it, training_loss=0.133]\u001b[A\n",
            "Epoch 2:  87%|████████▋ | 420/484 [54:41<08:43,  8.19s/it, training_loss=0.025]\u001b[A\n",
            "Epoch 2:  87%|████████▋ | 421/484 [54:41<08:08,  7.75s/it, training_loss=0.025]\u001b[A\n",
            "Epoch 2:  87%|████████▋ | 421/484 [54:50<08:08,  7.75s/it, training_loss=0.193]\u001b[A\n",
            "Epoch 2:  87%|████████▋ | 422/484 [54:50<08:21,  8.09s/it, training_loss=0.193]\u001b[A\n",
            "Epoch 2:  87%|████████▋ | 422/484 [54:58<08:21,  8.09s/it, training_loss=0.008]\u001b[A\n",
            "Epoch 2:  87%|████████▋ | 423/484 [54:58<08:00,  7.88s/it, training_loss=0.008]\u001b[A\n",
            "Epoch 2:  87%|████████▋ | 423/484 [55:05<08:00,  7.88s/it, training_loss=0.245]\u001b[A\n",
            "Epoch 2:  88%|████████▊ | 424/484 [55:05<07:40,  7.67s/it, training_loss=0.245]\u001b[A\n",
            "Epoch 2:  88%|████████▊ | 424/484 [55:13<07:40,  7.67s/it, training_loss=0.186]\u001b[A\n",
            "Epoch 2:  88%|████████▊ | 425/484 [55:13<07:49,  7.95s/it, training_loss=0.186]\u001b[A\n",
            "Epoch 2:  88%|████████▊ | 425/484 [55:20<07:49,  7.95s/it, training_loss=0.072]\u001b[A\n",
            "Epoch 2:  88%|████████▊ | 426/484 [55:20<07:15,  7.50s/it, training_loss=0.072]\u001b[A\n",
            "Epoch 2:  88%|████████▊ | 426/484 [55:29<07:15,  7.50s/it, training_loss=0.018]\u001b[A\n",
            "Epoch 2:  88%|████████▊ | 427/484 [55:29<07:43,  8.13s/it, training_loss=0.018]\u001b[A\n",
            "Epoch 2:  88%|████████▊ | 427/484 [55:36<07:43,  8.13s/it, training_loss=0.130]\u001b[A\n",
            "Epoch 2:  88%|████████▊ | 428/484 [55:36<07:08,  7.64s/it, training_loss=0.130]\u001b[A\n",
            "Epoch 2:  88%|████████▊ | 428/484 [55:44<07:08,  7.64s/it, training_loss=0.142]\u001b[A\n",
            "Epoch 2:  89%|████████▊ | 429/484 [55:44<07:15,  7.91s/it, training_loss=0.142]\u001b[A\n",
            "Epoch 2:  89%|████████▊ | 429/484 [55:52<07:15,  7.91s/it, training_loss=0.113]\u001b[A\n",
            "Epoch 2:  89%|████████▉ | 430/484 [55:52<07:00,  7.79s/it, training_loss=0.113]\u001b[A\n",
            "Epoch 2:  89%|████████▉ | 430/484 [55:59<07:00,  7.79s/it, training_loss=0.010]\u001b[A\n",
            "Epoch 2:  89%|████████▉ | 431/484 [55:59<06:37,  7.49s/it, training_loss=0.010]\u001b[A\n",
            "Epoch 2:  89%|████████▉ | 431/484 [56:08<06:37,  7.49s/it, training_loss=0.011]\u001b[A\n",
            "Epoch 2:  89%|████████▉ | 432/484 [56:08<06:54,  7.97s/it, training_loss=0.011]\u001b[A\n",
            "Epoch 2:  89%|████████▉ | 432/484 [56:14<06:54,  7.97s/it, training_loss=0.122]\u001b[A\n",
            "Epoch 2:  89%|████████▉ | 433/484 [56:14<06:24,  7.53s/it, training_loss=0.122]\u001b[A\n",
            "Epoch 2:  89%|████████▉ | 433/484 [56:24<06:24,  7.53s/it, training_loss=0.018]\u001b[A\n",
            "Epoch 2:  90%|████████▉ | 434/484 [56:24<06:46,  8.14s/it, training_loss=0.018]\u001b[A\n",
            "Epoch 2:  90%|████████▉ | 434/484 [56:31<06:46,  8.14s/it, training_loss=0.041]\u001b[A\n",
            "Epoch 2:  90%|████████▉ | 435/484 [56:31<06:16,  7.69s/it, training_loss=0.041]\u001b[A\n",
            "Epoch 2:  90%|████████▉ | 435/484 [56:39<06:16,  7.69s/it, training_loss=0.207]\u001b[A\n",
            "Epoch 2:  90%|█████████ | 436/484 [56:39<06:13,  7.78s/it, training_loss=0.207]\u001b[A\n",
            "Epoch 2:  90%|█████████ | 436/484 [56:47<06:13,  7.78s/it, training_loss=0.213]\u001b[A\n",
            "Epoch 2:  90%|█████████ | 437/484 [56:47<06:08,  7.83s/it, training_loss=0.213]\u001b[A\n",
            "Epoch 2:  90%|█████████ | 437/484 [56:53<06:08,  7.83s/it, training_loss=0.016]\u001b[A\n",
            "Epoch 2:  90%|█████████ | 438/484 [56:53<05:43,  7.46s/it, training_loss=0.016]\u001b[A\n",
            "Epoch 2:  90%|█████████ | 438/484 [57:03<05:43,  7.46s/it, training_loss=0.008]\u001b[A\n",
            "Epoch 2:  91%|█████████ | 439/484 [57:03<06:03,  8.07s/it, training_loss=0.008]\u001b[A\n",
            "Epoch 2:  91%|█████████ | 439/484 [57:09<06:03,  8.07s/it, training_loss=0.070]\u001b[A\n",
            "Epoch 2:  91%|█████████ | 440/484 [57:09<05:34,  7.60s/it, training_loss=0.070]\u001b[A\n",
            "Epoch 2:  91%|█████████ | 440/484 [57:18<05:34,  7.60s/it, training_loss=0.191]\u001b[A\n",
            "Epoch 2:  91%|█████████ | 441/484 [57:18<05:45,  8.03s/it, training_loss=0.191]\u001b[A\n",
            "Epoch 2:  91%|█████████ | 441/484 [57:25<05:45,  8.03s/it, training_loss=0.377]\u001b[A\n",
            "Epoch 2:  91%|█████████▏| 442/484 [57:25<05:23,  7.71s/it, training_loss=0.377]\u001b[A\n",
            "Epoch 2:  91%|█████████▏| 442/484 [57:33<05:23,  7.71s/it, training_loss=0.151]\u001b[A\n",
            "Epoch 2:  92%|█████████▏| 443/484 [57:33<05:14,  7.67s/it, training_loss=0.151]\u001b[A\n",
            "Epoch 2:  92%|█████████▏| 443/484 [57:41<05:14,  7.67s/it, training_loss=0.047]\u001b[A\n",
            "Epoch 2:  92%|█████████▏| 444/484 [57:41<05:14,  7.86s/it, training_loss=0.047]\u001b[A\n",
            "Epoch 2:  92%|█████████▏| 444/484 [57:47<05:14,  7.86s/it, training_loss=0.005]\u001b[A\n",
            "Epoch 2:  92%|█████████▏| 445/484 [57:47<04:49,  7.43s/it, training_loss=0.005]\u001b[A\n",
            "Epoch 2:  92%|█████████▏| 445/484 [57:57<04:49,  7.43s/it, training_loss=0.073]\u001b[A\n",
            "Epoch 2:  92%|█████████▏| 446/484 [57:57<05:07,  8.09s/it, training_loss=0.073]\u001b[A\n",
            "Epoch 2:  92%|█████████▏| 446/484 [58:04<05:07,  8.09s/it, training_loss=0.049]\u001b[A\n",
            "Epoch 2:  92%|█████████▏| 447/484 [58:04<04:41,  7.61s/it, training_loss=0.049]\u001b[A\n",
            "Epoch 2:  92%|█████████▏| 447/484 [58:12<04:41,  7.61s/it, training_loss=0.247]\u001b[A\n",
            "Epoch 2:  93%|█████████▎| 448/484 [58:12<04:45,  7.94s/it, training_loss=0.247]\u001b[A\n",
            "Epoch 2:  93%|█████████▎| 448/484 [58:20<04:45,  7.94s/it, training_loss=0.032]\u001b[A\n",
            "Epoch 2:  93%|█████████▎| 449/484 [58:20<04:31,  7.75s/it, training_loss=0.032]\u001b[A\n",
            "Epoch 2:  93%|█████████▎| 449/484 [58:27<04:31,  7.75s/it, training_loss=0.094]\u001b[A\n",
            "Epoch 2:  93%|█████████▎| 450/484 [58:27<04:15,  7.51s/it, training_loss=0.094]\u001b[A\n",
            "Epoch 2:  93%|█████████▎| 450/484 [58:35<04:15,  7.51s/it, training_loss=0.220]\u001b[A\n",
            "Epoch 2:  93%|█████████▎| 451/484 [58:35<04:21,  7.92s/it, training_loss=0.220]\u001b[A\n",
            "Epoch 2:  93%|█████████▎| 451/484 [58:42<04:21,  7.92s/it, training_loss=0.094]\u001b[A\n",
            "Epoch 2:  93%|█████████▎| 452/484 [58:42<03:59,  7.49s/it, training_loss=0.094]\u001b[A\n",
            "Epoch 2:  93%|█████████▎| 452/484 [58:51<03:59,  7.49s/it, training_loss=0.022]\u001b[A\n",
            "Epoch 2:  94%|█████████▎| 453/484 [58:51<04:11,  8.10s/it, training_loss=0.022]\u001b[A\n",
            "Epoch 2:  94%|█████████▎| 453/484 [58:58<04:11,  8.10s/it, training_loss=0.019]\u001b[A\n",
            "Epoch 2:  94%|█████████▍| 454/484 [58:58<03:48,  7.61s/it, training_loss=0.019]\u001b[A\n",
            "Epoch 2:  94%|█████████▍| 454/484 [59:06<03:48,  7.61s/it, training_loss=0.052]\u001b[A\n",
            "Epoch 2:  94%|█████████▍| 455/484 [59:06<03:44,  7.76s/it, training_loss=0.052]\u001b[A\n",
            "Epoch 2:  94%|█████████▍| 455/484 [59:14<03:44,  7.76s/it, training_loss=0.148]\u001b[A\n",
            "Epoch 2:  94%|█████████▍| 456/484 [59:14<03:36,  7.75s/it, training_loss=0.148]\u001b[A\n",
            "Epoch 2:  94%|█████████▍| 456/484 [59:20<03:36,  7.75s/it, training_loss=0.008]\u001b[A\n",
            "Epoch 2:  94%|█████████▍| 457/484 [59:20<03:19,  7.39s/it, training_loss=0.008]\u001b[A\n",
            "Epoch 2:  94%|█████████▍| 457/484 [59:30<03:19,  7.39s/it, training_loss=0.172]\u001b[A\n",
            "Epoch 2:  95%|█████████▍| 458/484 [59:30<03:27,  7.99s/it, training_loss=0.172]\u001b[A\n",
            "Epoch 2:  95%|█████████▍| 458/484 [59:36<03:27,  7.99s/it, training_loss=0.204]\u001b[A\n",
            "Epoch 2:  95%|█████████▍| 459/484 [59:36<03:08,  7.53s/it, training_loss=0.204]\u001b[A\n",
            "Epoch 2:  95%|█████████▍| 459/484 [59:45<03:08,  7.53s/it, training_loss=0.023]\u001b[A\n",
            "Epoch 2:  95%|█████████▌| 460/484 [59:45<03:11,  7.98s/it, training_loss=0.023]\u001b[A\n",
            "Epoch 2:  95%|█████████▌| 460/484 [59:52<03:11,  7.98s/it, training_loss=0.033]\u001b[A\n",
            "Epoch 2:  95%|█████████▌| 461/484 [59:52<02:56,  7.69s/it, training_loss=0.033]\u001b[A\n",
            "Epoch 2:  95%|█████████▌| 461/484 [1:00:00<02:56,  7.69s/it, training_loss=0.156]\u001b[A\n",
            "Epoch 2:  95%|█████████▌| 462/484 [1:00:00<02:48,  7.64s/it, training_loss=0.156]\u001b[A\n",
            "Epoch 2:  95%|█████████▌| 462/484 [1:00:08<02:48,  7.64s/it, training_loss=0.017]\u001b[A\n",
            "Epoch 2:  96%|█████████▌| 463/484 [1:00:08<02:44,  7.85s/it, training_loss=0.017]\u001b[A\n",
            "Epoch 2:  96%|█████████▌| 463/484 [1:00:15<02:44,  7.85s/it, training_loss=0.199]\u001b[A\n",
            "Epoch 2:  96%|█████████▌| 464/484 [1:00:15<02:28,  7.45s/it, training_loss=0.199]\u001b[A\n",
            "Epoch 2:  96%|█████████▌| 464/484 [1:00:24<02:28,  7.45s/it, training_loss=0.140]\u001b[A\n",
            "Epoch 2:  96%|█████████▌| 465/484 [1:00:24<02:34,  8.12s/it, training_loss=0.140]\u001b[A\n",
            "Epoch 2:  96%|█████████▌| 465/484 [1:00:31<02:34,  8.12s/it, training_loss=0.130]\u001b[A\n",
            "Epoch 2:  96%|█████████▋| 466/484 [1:00:31<02:17,  7.63s/it, training_loss=0.130]\u001b[A\n",
            "Epoch 2:  96%|█████████▋| 466/484 [1:00:40<02:17,  7.63s/it, training_loss=0.006]\u001b[A\n",
            "Epoch 2:  96%|█████████▋| 467/484 [1:00:40<02:15,  7.99s/it, training_loss=0.006]\u001b[A\n",
            "Epoch 2:  96%|█████████▋| 467/484 [1:00:47<02:15,  7.99s/it, training_loss=0.063]\u001b[A\n",
            "Epoch 2:  97%|█████████▋| 468/484 [1:00:47<02:04,  7.76s/it, training_loss=0.063]\u001b[A\n",
            "Epoch 2:  97%|█████████▋| 468/484 [1:00:54<02:04,  7.76s/it, training_loss=0.004]\u001b[A\n",
            "Epoch 2:  97%|█████████▋| 469/484 [1:00:54<01:54,  7.62s/it, training_loss=0.004]\u001b[A\n",
            "Epoch 2:  97%|█████████▋| 469/484 [1:01:03<01:54,  7.62s/it, training_loss=0.035]\u001b[A\n",
            "Epoch 2:  97%|█████████▋| 470/484 [1:01:03<01:50,  7.91s/it, training_loss=0.035]\u001b[A\n",
            "Epoch 2:  97%|█████████▋| 470/484 [1:01:09<01:50,  7.91s/it, training_loss=0.100]\u001b[A\n",
            "Epoch 2:  97%|█████████▋| 471/484 [1:01:09<01:37,  7.47s/it, training_loss=0.100]\u001b[A\n",
            "Epoch 2:  97%|█████████▋| 471/484 [1:01:19<01:37,  7.47s/it, training_loss=0.009]\u001b[A\n",
            "Epoch 2:  98%|█████████▊| 472/484 [1:01:19<01:37,  8.11s/it, training_loss=0.009]\u001b[A\n",
            "Epoch 2:  98%|█████████▊| 472/484 [1:01:25<01:37,  8.11s/it, training_loss=0.025]\u001b[A\n",
            "Epoch 2:  98%|█████████▊| 473/484 [1:01:25<01:23,  7.61s/it, training_loss=0.025]\u001b[A\n",
            "Epoch 2:  98%|█████████▊| 473/484 [1:01:33<01:23,  7.61s/it, training_loss=0.047]\u001b[A\n",
            "Epoch 2:  98%|█████████▊| 474/484 [1:01:33<01:18,  7.84s/it, training_loss=0.047]\u001b[A\n",
            "Epoch 2:  98%|█████████▊| 474/484 [1:01:41<01:18,  7.84s/it, training_loss=0.206]\u001b[A\n",
            "Epoch 2:  98%|█████████▊| 475/484 [1:01:41<01:09,  7.75s/it, training_loss=0.206]\u001b[A\n",
            "Epoch 2:  98%|█████████▊| 475/484 [1:01:48<01:09,  7.75s/it, training_loss=0.277]\u001b[A\n",
            "Epoch 2:  98%|█████████▊| 476/484 [1:01:48<00:59,  7.41s/it, training_loss=0.277]\u001b[A\n",
            "Epoch 2:  98%|█████████▊| 476/484 [1:01:57<00:59,  7.41s/it, training_loss=0.012]\u001b[A\n",
            "Epoch 2:  99%|█████████▊| 477/484 [1:01:57<00:55,  7.94s/it, training_loss=0.012]\u001b[A\n",
            "Epoch 2:  99%|█████████▊| 477/484 [1:02:03<00:55,  7.94s/it, training_loss=0.212]\u001b[A\n",
            "Epoch 2:  99%|█████████▉| 478/484 [1:02:03<00:45,  7.51s/it, training_loss=0.212]\u001b[A\n",
            "Epoch 2:  99%|█████████▉| 478/484 [1:02:13<00:45,  7.51s/it, training_loss=0.303]\u001b[A\n",
            "Epoch 2:  99%|█████████▉| 479/484 [1:02:13<00:40,  8.06s/it, training_loss=0.303]\u001b[A\n",
            "Epoch 2:  99%|█████████▉| 479/484 [1:02:19<00:40,  8.06s/it, training_loss=0.017]\u001b[A\n",
            "Epoch 2:  99%|█████████▉| 480/484 [1:02:19<00:30,  7.67s/it, training_loss=0.017]\u001b[A\n",
            "Epoch 2:  99%|█████████▉| 480/484 [1:02:27<00:30,  7.67s/it, training_loss=0.019]\u001b[A\n",
            "Epoch 2:  99%|█████████▉| 481/484 [1:02:27<00:23,  7.73s/it, training_loss=0.019]\u001b[A\n",
            "Epoch 2:  99%|█████████▉| 481/484 [1:02:35<00:23,  7.73s/it, training_loss=0.296]\u001b[A\n",
            "Epoch 2: 100%|█████████▉| 482/484 [1:02:35<00:15,  7.82s/it, training_loss=0.296]\u001b[A\n",
            "Epoch 2: 100%|█████████▉| 482/484 [1:02:42<00:15,  7.82s/it, training_loss=0.138]\u001b[A\n",
            "Epoch 2: 100%|█████████▉| 483/484 [1:02:42<00:07,  7.44s/it, training_loss=0.138]\u001b[A\n",
            "Epoch 2: 100%|█████████▉| 483/484 [1:02:50<00:07,  7.44s/it, training_loss=0.014]\u001b[A\n",
            "Epoch 2: 100%|██████████| 484/484 [1:02:50<00:00,  7.59s/it, training_loss=0.014]\u001b[A\n",
            " 20%|██        | 1/5 [2:10:58<4:32:24, 4086.21s/it]"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            " Epoch {epoch}\n",
            "Training loss: {loss_train_avg}\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n",
            "  0%|          | 0/121 [00:00<?, ?it/s]\u001b[A\n",
            "  1%|          | 1/121 [00:01<03:54,  1.95s/it]\u001b[A\n",
            "  2%|▏         | 2/121 [00:03<03:49,  1.93s/it]\u001b[A\n",
            "  2%|▏         | 3/121 [00:05<03:50,  1.95s/it]\u001b[A\n",
            "  3%|▎         | 4/121 [00:07<03:47,  1.94s/it]\u001b[A\n",
            "  4%|▍         | 5/121 [00:12<05:41,  2.94s/it]\u001b[A\n",
            "  5%|▍         | 6/121 [00:15<05:40,  2.96s/it]\u001b[A\n",
            "  6%|▌         | 7/121 [00:17<05:18,  2.80s/it]\u001b[A\n",
            "  7%|▋         | 8/121 [00:19<04:45,  2.52s/it]\u001b[A\n",
            "  7%|▋         | 9/121 [00:22<04:47,  2.57s/it]\u001b[A\n",
            "  8%|▊         | 10/121 [00:24<04:30,  2.44s/it]\u001b[A\n",
            "  9%|▉         | 11/121 [00:28<05:04,  2.76s/it]\u001b[A\n",
            " 10%|▉         | 12/121 [00:31<05:20,  2.94s/it]\u001b[A\n",
            " 11%|█         | 13/121 [00:34<05:16,  2.93s/it]\u001b[A\n",
            " 12%|█▏        | 14/121 [00:36<04:59,  2.80s/it]\u001b[A\n",
            " 12%|█▏        | 15/121 [00:38<04:27,  2.53s/it]\u001b[A\n",
            " 13%|█▎        | 16/121 [00:40<04:05,  2.34s/it]\u001b[A\n",
            " 14%|█▍        | 17/121 [00:42<03:50,  2.21s/it]\u001b[A\n",
            " 15%|█▍        | 18/121 [00:44<03:39,  2.13s/it]\u001b[A\n",
            " 16%|█▌        | 19/121 [00:46<03:36,  2.12s/it]\u001b[A\n",
            " 17%|█▋        | 20/121 [00:49<04:06,  2.44s/it]\u001b[A\n",
            " 17%|█▋        | 21/121 [00:52<04:22,  2.63s/it]\u001b[A\n",
            " 18%|█▊        | 22/121 [00:55<04:16,  2.59s/it]\u001b[A\n",
            " 19%|█▉        | 23/121 [00:57<03:54,  2.40s/it]\u001b[A\n",
            " 20%|█▉        | 24/121 [00:59<03:38,  2.25s/it]\u001b[A\n",
            " 21%|██        | 25/121 [01:01<03:26,  2.15s/it]\u001b[A\n",
            " 21%|██▏       | 26/121 [01:03<03:17,  2.08s/it]\u001b[A\n",
            " 22%|██▏       | 27/121 [01:05<03:17,  2.10s/it]\u001b[A\n",
            " 23%|██▎       | 28/121 [01:08<03:46,  2.44s/it]\u001b[A\n",
            " 24%|██▍       | 29/121 [01:11<03:59,  2.61s/it]\u001b[A\n",
            " 25%|██▍       | 30/121 [01:13<03:52,  2.55s/it]\u001b[A\n",
            " 26%|██▌       | 31/121 [01:15<03:32,  2.36s/it]\u001b[A\n",
            " 26%|██▋       | 32/121 [01:17<03:18,  2.24s/it]\u001b[A\n",
            " 27%|██▋       | 33/121 [01:19<03:09,  2.15s/it]\u001b[A\n",
            " 28%|██▊       | 34/121 [01:21<03:01,  2.08s/it]\u001b[A\n",
            " 29%|██▉       | 35/121 [01:23<03:03,  2.14s/it]\u001b[A\n",
            " 30%|██▉       | 36/121 [01:27<03:29,  2.46s/it]\u001b[A\n",
            " 31%|███       | 37/121 [01:30<03:40,  2.62s/it]\u001b[A\n",
            " 31%|███▏      | 38/121 [01:32<03:32,  2.56s/it]\u001b[A\n",
            " 32%|███▏      | 39/121 [01:34<03:14,  2.37s/it]\u001b[A\n",
            " 33%|███▎      | 40/121 [01:36<03:01,  2.24s/it]\u001b[A\n",
            " 34%|███▍      | 41/121 [01:38<02:51,  2.14s/it]\u001b[A\n",
            " 35%|███▍      | 42/121 [01:40<02:44,  2.08s/it]\u001b[A\n",
            " 36%|███▌      | 43/121 [01:42<02:47,  2.15s/it]\u001b[A\n",
            " 36%|███▋      | 44/121 [01:45<03:09,  2.46s/it]\u001b[A\n",
            " 37%|███▋      | 45/121 [01:48<03:18,  2.62s/it]\u001b[A\n",
            " 38%|███▊      | 46/121 [01:51<03:11,  2.55s/it]\u001b[A\n",
            " 39%|███▉      | 47/121 [01:53<02:54,  2.36s/it]\u001b[A\n",
            " 40%|███▉      | 48/121 [01:55<02:43,  2.24s/it]\u001b[A\n",
            " 40%|████      | 49/121 [01:56<02:34,  2.14s/it]\u001b[A\n",
            " 41%|████▏     | 50/121 [01:58<02:27,  2.07s/it]\u001b[A\n",
            " 42%|████▏     | 51/121 [02:01<02:31,  2.17s/it]\u001b[A\n",
            " 43%|████▎     | 52/121 [02:04<02:50,  2.47s/it]\u001b[A\n",
            " 44%|████▍     | 53/121 [02:07<02:58,  2.62s/it]\u001b[A\n",
            " 45%|████▍     | 54/121 [02:09<02:49,  2.54s/it]\u001b[A\n",
            " 45%|████▌     | 55/121 [02:11<02:35,  2.36s/it]\u001b[A\n",
            " 46%|████▋     | 56/121 [02:13<02:24,  2.23s/it]\u001b[A\n",
            " 47%|████▋     | 57/121 [02:15<02:16,  2.13s/it]\u001b[A\n",
            " 48%|████▊     | 58/121 [02:17<02:10,  2.07s/it]\u001b[A\n",
            " 49%|████▉     | 59/121 [02:19<02:15,  2.18s/it]\u001b[A\n",
            " 50%|████▉     | 60/121 [02:23<02:32,  2.50s/it]\u001b[A\n",
            " 50%|█████     | 61/121 [02:26<02:38,  2.64s/it]\u001b[A\n",
            " 51%|█████     | 62/121 [02:28<02:28,  2.52s/it]\u001b[A\n",
            " 52%|█████▏    | 63/121 [02:30<02:16,  2.35s/it]\u001b[A\n",
            " 53%|█████▎    | 64/121 [02:32<02:06,  2.23s/it]\u001b[A\n",
            " 54%|█████▎    | 65/121 [02:34<01:59,  2.14s/it]\u001b[A\n",
            " 55%|█████▍    | 66/121 [02:36<01:54,  2.08s/it]\u001b[A\n",
            " 55%|█████▌    | 67/121 [02:38<01:59,  2.21s/it]\u001b[A\n",
            " 56%|█████▌    | 68/121 [02:41<02:13,  2.51s/it]\u001b[A\n",
            " 57%|█████▋    | 69/121 [02:44<02:17,  2.65s/it]\u001b[A\n",
            " 58%|█████▊    | 70/121 [02:46<02:07,  2.51s/it]\u001b[A\n",
            " 59%|█████▊    | 71/121 [02:48<01:56,  2.33s/it]\u001b[A\n",
            " 60%|█████▉    | 72/121 [02:50<01:48,  2.21s/it]\u001b[A\n",
            " 60%|██████    | 73/121 [02:52<01:42,  2.13s/it]\u001b[A\n",
            " 61%|██████    | 74/121 [02:54<01:38,  2.11s/it]\u001b[A\n",
            " 62%|██████▏   | 75/121 [02:57<01:45,  2.30s/it]\u001b[A\n",
            " 63%|██████▎   | 76/121 [03:00<01:55,  2.56s/it]\u001b[A\n",
            " 64%|██████▎   | 77/121 [03:03<01:58,  2.69s/it]\u001b[A\n",
            " 64%|██████▍   | 78/121 [03:05<01:47,  2.50s/it]\u001b[A\n",
            " 65%|██████▌   | 79/121 [03:07<01:38,  2.33s/it]\u001b[A\n",
            " 66%|██████▌   | 80/121 [03:09<01:30,  2.21s/it]\u001b[A\n",
            " 67%|██████▋   | 81/121 [03:11<01:24,  2.12s/it]\u001b[A\n",
            " 68%|██████▊   | 82/121 [03:13<01:20,  2.07s/it]\u001b[A\n",
            " 69%|██████▊   | 83/121 [03:16<01:27,  2.30s/it]\u001b[A\n",
            " 69%|██████▉   | 84/121 [03:19<01:34,  2.56s/it]\u001b[A\n",
            " 70%|███████   | 85/121 [03:22<01:36,  2.68s/it]\u001b[A\n",
            " 71%|███████   | 86/121 [03:24<01:26,  2.48s/it]\u001b[A\n",
            " 72%|███████▏  | 87/121 [03:26<01:19,  2.33s/it]\u001b[A\n",
            " 73%|███████▎  | 88/121 [03:28<01:12,  2.21s/it]\u001b[A\n",
            " 74%|███████▎  | 89/121 [03:30<01:08,  2.15s/it]\u001b[A\n",
            " 74%|███████▍  | 90/121 [03:32<01:04,  2.10s/it]\u001b[A\n",
            " 75%|███████▌  | 91/121 [03:35<01:11,  2.39s/it]\u001b[A\n",
            " 76%|███████▌  | 92/121 [03:38<01:15,  2.60s/it]\u001b[A\n",
            " 77%|███████▋  | 93/121 [03:41<01:15,  2.69s/it]\u001b[A\n",
            " 78%|███████▊  | 94/121 [03:43<01:06,  2.46s/it]\u001b[A\n",
            " 79%|███████▊  | 95/121 [03:45<01:00,  2.31s/it]\u001b[A\n",
            " 79%|███████▉  | 96/121 [03:47<00:54,  2.20s/it]\u001b[A\n",
            " 80%|████████  | 97/121 [03:49<00:50,  2.12s/it]\u001b[A\n",
            " 81%|████████  | 98/121 [03:51<00:47,  2.07s/it]\u001b[A\n",
            " 82%|████████▏ | 99/121 [03:54<00:52,  2.40s/it]\u001b[A\n",
            " 83%|████████▎ | 100/121 [03:57<00:54,  2.60s/it]\u001b[A\n",
            " 83%|████████▎ | 101/121 [04:00<00:52,  2.65s/it]\u001b[A\n",
            " 84%|████████▍ | 102/121 [04:02<00:46,  2.44s/it]\u001b[A\n",
            " 85%|████████▌ | 103/121 [04:04<00:41,  2.30s/it]\u001b[A\n",
            " 86%|████████▌ | 104/121 [04:06<00:37,  2.19s/it]\u001b[A\n",
            " 87%|████████▋ | 105/121 [04:07<00:33,  2.12s/it]\u001b[A\n",
            " 88%|████████▊ | 106/121 [04:10<00:31,  2.09s/it]\u001b[A\n",
            " 88%|████████▊ | 107/121 [04:13<00:34,  2.44s/it]\u001b[A\n",
            " 89%|████████▉ | 108/121 [04:16<00:34,  2.63s/it]\u001b[A\n",
            " 90%|█████████ | 109/121 [04:18<00:31,  2.61s/it]\u001b[A\n",
            " 91%|█████████ | 110/121 [04:20<00:26,  2.42s/it]\u001b[A\n",
            " 92%|█████████▏| 111/121 [04:22<00:22,  2.27s/it]\u001b[A\n",
            " 93%|█████████▎| 112/121 [04:24<00:19,  2.19s/it]\u001b[A\n",
            " 93%|█████████▎| 113/121 [04:26<00:17,  2.13s/it]\u001b[A\n",
            " 94%|█████████▍| 114/121 [04:29<00:15,  2.18s/it]\u001b[A\n",
            " 95%|█████████▌| 115/121 [04:32<00:14,  2.48s/it]\u001b[A\n",
            " 96%|█████████▌| 116/121 [04:35<00:13,  2.64s/it]\u001b[A\n",
            " 97%|█████████▋| 117/121 [04:37<00:10,  2.59s/it]\u001b[A\n",
            " 98%|█████████▊| 118/121 [04:39<00:07,  2.40s/it]\u001b[A\n",
            " 98%|█████████▊| 119/121 [04:41<00:04,  2.26s/it]\u001b[A\n",
            " 99%|█████████▉| 120/121 [04:43<00:02,  2.16s/it]\u001b[A\n",
            "100%|██████████| 121/121 [04:45<00:00,  2.36s/it]\n",
            " 40%|████      | 2/5 [2:15:44<3:23:29, 4069.76s/it]"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Validation loss: 0.5124791602350094\n",
            "F1 Score (weighted): 0.8431228280409429\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n",
            "Epoch 3:   0%|          | 0/484 [00:00<?, ?it/s]\u001b[A\n",
            "Epoch 3:   0%|          | 0/484 [00:09<?, ?it/s, training_loss=0.182]\u001b[A\n",
            "Epoch 3:   0%|          | 1/484 [00:09<1:19:12,  9.84s/it, training_loss=0.182]\u001b[A\n",
            "Epoch 3:   0%|          | 1/484 [00:16<1:19:12,  9.84s/it, training_loss=0.202]\u001b[A\n",
            "Epoch 3:   0%|          | 2/484 [00:16<1:03:34,  7.91s/it, training_loss=0.202]\u001b[A\n",
            "Epoch 3:   0%|          | 2/484 [00:24<1:03:34,  7.91s/it, training_loss=0.004]\u001b[A\n",
            "Epoch 3:   1%|          | 3/484 [00:24<1:05:10,  8.13s/it, training_loss=0.004]\u001b[A\n",
            "Epoch 3:   1%|          | 3/484 [00:32<1:05:10,  8.13s/it, training_loss=0.009]\u001b[A\n",
            "Epoch 3:   1%|          | 4/484 [00:32<1:03:24,  7.93s/it, training_loss=0.009]\u001b[A\n",
            "Epoch 3:   1%|          | 4/484 [00:39<1:03:24,  7.93s/it, training_loss=0.165]\u001b[A\n",
            "Epoch 3:   1%|          | 5/484 [00:39<59:40,  7.48s/it, training_loss=0.165]  \u001b[A\n",
            "Epoch 3:   1%|          | 5/484 [00:48<59:40,  7.48s/it, training_loss=0.083]\u001b[A\n",
            "Epoch 3:   1%|          | 6/484 [00:48<1:05:01,  8.16s/it, training_loss=0.083]\u001b[A\n",
            "Epoch 3:   1%|          | 6/484 [00:55<1:05:01,  8.16s/it, training_loss=0.040]\u001b[A\n",
            "Epoch 3:   1%|▏         | 7/484 [00:55<1:00:42,  7.64s/it, training_loss=0.040]\u001b[A\n",
            "Epoch 3:   1%|▏         | 7/484 [01:04<1:00:42,  7.64s/it, training_loss=0.005]\u001b[A\n",
            "Epoch 3:   2%|▏         | 8/484 [01:04<1:04:53,  8.18s/it, training_loss=0.005]\u001b[A\n",
            "Epoch 3:   2%|▏         | 8/484 [01:11<1:04:53,  8.18s/it, training_loss=0.264]\u001b[A\n",
            "Epoch 3:   2%|▏         | 9/484 [01:11<1:01:12,  7.73s/it, training_loss=0.264]\u001b[A\n",
            "Epoch 3:   2%|▏         | 9/484 [01:19<1:01:12,  7.73s/it, training_loss=0.024]\u001b[A\n",
            "Epoch 3:   2%|▏         | 10/484 [01:19<1:01:36,  7.80s/it, training_loss=0.024]\u001b[A\n",
            "Epoch 3:   2%|▏         | 10/484 [01:27<1:01:36,  7.80s/it, training_loss=0.009]\u001b[A\n",
            "Epoch 3:   2%|▏         | 11/484 [01:27<1:02:02,  7.87s/it, training_loss=0.009]\u001b[A\n",
            "Epoch 3:   2%|▏         | 11/484 [01:33<1:02:02,  7.87s/it, training_loss=0.119]\u001b[A\n",
            "Epoch 3:   2%|▏         | 12/484 [01:33<58:45,  7.47s/it, training_loss=0.119]  \u001b[A\n",
            "Epoch 3:   2%|▏         | 12/484 [01:43<58:45,  7.47s/it, training_loss=0.011]\u001b[A\n",
            "Epoch 3:   3%|▎         | 13/484 [01:43<1:03:43,  8.12s/it, training_loss=0.011]\u001b[A\n",
            "Epoch 3:   3%|▎         | 13/484 [01:49<1:03:43,  8.12s/it, training_loss=0.051]\u001b[A\n",
            "Epoch 3:   3%|▎         | 14/484 [01:49<59:46,  7.63s/it, training_loss=0.051]  \u001b[A\n",
            "Epoch 3:   3%|▎         | 14/484 [01:58<59:46,  7.63s/it, training_loss=0.004]\u001b[A\n",
            "Epoch 3:   3%|▎         | 15/484 [01:58<1:02:47,  8.03s/it, training_loss=0.004]\u001b[A\n",
            "Epoch 3:   3%|▎         | 15/484 [02:05<1:02:47,  8.03s/it, training_loss=0.156]\u001b[A\n",
            "Epoch 3:   3%|▎         | 16/484 [02:06<1:00:37,  7.77s/it, training_loss=0.156]\u001b[A\n",
            "Epoch 3:   3%|▎         | 16/484 [02:16<1:00:37,  7.77s/it, training_loss=0.039]\u001b[A\n",
            "Epoch 3:   4%|▎         | 17/484 [02:16<1:06:26,  8.54s/it, training_loss=0.039]\u001b[A\n",
            "Epoch 3:   4%|▎         | 17/484 [02:23<1:06:26,  8.54s/it, training_loss=0.186]\u001b[A\n",
            "Epoch 3:   4%|▎         | 18/484 [02:23<1:03:56,  8.23s/it, training_loss=0.186]\u001b[A\n",
            "Epoch 3:   4%|▎         | 18/484 [02:30<1:03:56,  8.23s/it, training_loss=0.062]\u001b[A\n",
            "Epoch 3:   4%|▍         | 19/484 [02:30<1:01:12,  7.90s/it, training_loss=0.062]\u001b[A\n",
            "Epoch 3:   4%|▍         | 19/484 [02:40<1:01:12,  7.90s/it, training_loss=0.053]\u001b[A\n",
            "Epoch 3:   4%|▍         | 20/484 [02:40<1:04:00,  8.28s/it, training_loss=0.053]\u001b[A\n",
            "Epoch 3:   4%|▍         | 20/484 [02:46<1:04:00,  8.28s/it, training_loss=0.004]\u001b[A\n",
            "Epoch 3:   4%|▍         | 21/484 [02:46<59:55,  7.77s/it, training_loss=0.004]  \u001b[A\n",
            "Epoch 3:   4%|▍         | 21/484 [02:56<59:55,  7.77s/it, training_loss=0.008]\u001b[A\n",
            "Epoch 3:   5%|▍         | 22/484 [02:56<1:04:16,  8.35s/it, training_loss=0.008]\u001b[A\n",
            "Epoch 3:   5%|▍         | 22/484 [03:02<1:04:16,  8.35s/it, training_loss=0.019]\u001b[A\n",
            "Epoch 3:   5%|▍         | 23/484 [03:02<59:58,  7.81s/it, training_loss=0.019]  \u001b[A\n",
            "Epoch 3:   5%|▍         | 23/484 [03:11<59:58,  7.81s/it, training_loss=0.012]\u001b[A\n",
            "Epoch 3:   5%|▍         | 24/484 [03:11<1:01:38,  8.04s/it, training_loss=0.012]\u001b[A\n",
            "Epoch 3:   5%|▍         | 24/484 [03:19<1:01:38,  8.04s/it, training_loss=0.019]\u001b[A\n",
            "Epoch 3:   5%|▌         | 25/484 [03:19<1:00:31,  7.91s/it, training_loss=0.019]\u001b[A\n",
            "Epoch 3:   5%|▌         | 25/484 [03:26<1:00:31,  7.91s/it, training_loss=0.016]\u001b[A\n",
            "Epoch 3:   5%|▌         | 26/484 [03:26<58:15,  7.63s/it, training_loss=0.016]  \u001b[A\n",
            "Epoch 3:   5%|▌         | 26/484 [03:35<58:15,  7.63s/it, training_loss=0.159]\u001b[A\n",
            "Epoch 3:   6%|▌         | 27/484 [03:35<1:01:18,  8.05s/it, training_loss=0.159]\u001b[A\n",
            "Epoch 3:   6%|▌         | 27/484 [03:41<1:01:18,  8.05s/it, training_loss=0.009]\u001b[A\n",
            "Epoch 3:   6%|▌         | 28/484 [03:41<57:42,  7.59s/it, training_loss=0.009]  \u001b[A\n",
            "Epoch 3:   6%|▌         | 28/484 [03:51<57:42,  7.59s/it, training_loss=0.013]\u001b[A\n",
            "Epoch 3:   6%|▌         | 29/484 [03:51<1:02:05,  8.19s/it, training_loss=0.013]\u001b[A\n",
            "Epoch 3:   6%|▌         | 29/484 [03:57<1:02:05,  8.19s/it, training_loss=0.008]\u001b[A\n",
            "Epoch 3:   6%|▌         | 30/484 [03:57<58:20,  7.71s/it, training_loss=0.008]  \u001b[A\n",
            "Epoch 3:   6%|▌         | 30/484 [04:06<58:20,  7.71s/it, training_loss=0.037]\u001b[A\n",
            "Epoch 3:   6%|▋         | 31/484 [04:06<59:45,  7.91s/it, training_loss=0.037]\u001b[A\n",
            "Epoch 3:   6%|▋         | 31/484 [04:14<59:45,  7.91s/it, training_loss=0.035]\u001b[A\n",
            "Epoch 3:   7%|▋         | 32/484 [04:14<59:25,  7.89s/it, training_loss=0.035]\u001b[A\n",
            "Epoch 3:   7%|▋         | 32/484 [04:20<59:25,  7.89s/it, training_loss=0.045]\u001b[A\n",
            "Epoch 3:   7%|▋         | 33/484 [04:20<56:42,  7.54s/it, training_loss=0.045]\u001b[A\n",
            "Epoch 3:   7%|▋         | 33/484 [04:30<56:42,  7.54s/it, training_loss=0.253]\u001b[A\n",
            "Epoch 3:   7%|▋         | 34/484 [04:30<1:00:34,  8.08s/it, training_loss=0.253]\u001b[A\n",
            "Epoch 3:   7%|▋         | 34/484 [04:36<1:00:34,  8.08s/it, training_loss=0.037]\u001b[A\n",
            "Epoch 3:   7%|▋         | 35/484 [04:36<56:56,  7.61s/it, training_loss=0.037]  \u001b[A\n",
            "Epoch 3:   7%|▋         | 35/484 [04:46<56:56,  7.61s/it, training_loss=0.030]\u001b[A\n",
            "Epoch 3:   7%|▋         | 36/484 [04:46<1:02:29,  8.37s/it, training_loss=0.030]\u001b[A\n",
            "Epoch 3:   7%|▋         | 36/484 [04:53<1:02:29,  8.37s/it, training_loss=0.005]\u001b[A\n",
            "Epoch 3:   8%|▊         | 37/484 [04:53<58:52,  7.90s/it, training_loss=0.005]  \u001b[A\n",
            "Epoch 3:   8%|▊         | 37/484 [05:01<58:52,  7.90s/it, training_loss=0.043]\u001b[A\n",
            "Epoch 3:   8%|▊         | 38/484 [05:01<58:58,  7.93s/it, training_loss=0.043]\u001b[A\n",
            "Epoch 3:   8%|▊         | 38/484 [05:09<58:58,  7.93s/it, training_loss=0.009]\u001b[A\n",
            "Epoch 3:   8%|▊         | 39/484 [05:09<59:06,  7.97s/it, training_loss=0.009]\u001b[A\n",
            "Epoch 3:   8%|▊         | 39/484 [05:16<59:06,  7.97s/it, training_loss=0.084]\u001b[A\n",
            "Epoch 3:   8%|▊         | 40/484 [05:16<55:54,  7.56s/it, training_loss=0.084]\u001b[A\n",
            "Epoch 3:   8%|▊         | 40/484 [05:25<55:54,  7.56s/it, training_loss=0.004]\u001b[A\n",
            "Epoch 3:   8%|▊         | 41/484 [05:25<1:00:09,  8.15s/it, training_loss=0.004]\u001b[A\n",
            "Epoch 3:   8%|▊         | 41/484 [05:32<1:00:09,  8.15s/it, training_loss=0.014]\u001b[A\n",
            "Epoch 3:   9%|▊         | 42/484 [05:32<56:27,  7.67s/it, training_loss=0.014]  \u001b[A\n",
            "Epoch 3:   9%|▊         | 42/484 [05:41<56:27,  7.67s/it, training_loss=0.071]\u001b[A\n",
            "Epoch 3:   9%|▉         | 43/484 [05:41<59:38,  8.11s/it, training_loss=0.071]\u001b[A\n",
            "Epoch 3:   9%|▉         | 43/484 [05:48<59:38,  8.11s/it, training_loss=0.174]\u001b[A\n",
            "Epoch 3:   9%|▉         | 44/484 [05:48<56:48,  7.75s/it, training_loss=0.174]\u001b[A\n",
            "Epoch 3:   9%|▉         | 44/484 [05:56<56:48,  7.75s/it, training_loss=0.179]\u001b[A\n",
            "Epoch 3:   9%|▉         | 45/484 [05:56<56:30,  7.72s/it, training_loss=0.179]\u001b[A\n",
            "Epoch 3:   9%|▉         | 45/484 [06:04<56:30,  7.72s/it, training_loss=0.106]\u001b[A\n",
            "Epoch 3:  10%|▉         | 46/484 [06:04<57:40,  7.90s/it, training_loss=0.106]\u001b[A\n",
            "Epoch 3:  10%|▉         | 46/484 [06:10<57:40,  7.90s/it, training_loss=0.003]\u001b[A\n",
            "Epoch 3:  10%|▉         | 47/484 [06:10<54:35,  7.50s/it, training_loss=0.003]\u001b[A\n",
            "Epoch 3:  10%|▉         | 47/484 [06:20<54:35,  7.50s/it, training_loss=0.020]\u001b[A\n",
            "Epoch 3:  10%|▉         | 48/484 [06:20<59:15,  8.16s/it, training_loss=0.020]\u001b[A\n",
            "Epoch 3:  10%|▉         | 48/484 [06:27<59:15,  8.16s/it, training_loss=0.013]\u001b[A\n",
            "Epoch 3:  10%|█         | 49/484 [06:27<55:33,  7.66s/it, training_loss=0.013]\u001b[A\n",
            "Epoch 3:  10%|█         | 49/484 [06:36<55:33,  7.66s/it, training_loss=0.070]\u001b[A\n",
            "Epoch 3:  10%|█         | 50/484 [06:36<58:33,  8.10s/it, training_loss=0.070]\u001b[A\n",
            "Epoch 3:  10%|█         | 50/484 [06:43<58:33,  8.10s/it, training_loss=0.189]\u001b[A\n",
            "Epoch 3:  11%|█         | 51/484 [06:43<56:11,  7.79s/it, training_loss=0.189]\u001b[A\n",
            "Epoch 3:  11%|█         | 51/484 [06:50<56:11,  7.79s/it, training_loss=0.005]\u001b[A\n",
            "Epoch 3:  11%|█         | 52/484 [06:50<55:34,  7.72s/it, training_loss=0.005]\u001b[A\n",
            "Epoch 3:  11%|█         | 52/484 [06:59<55:34,  7.72s/it, training_loss=0.026]\u001b[A\n",
            "Epoch 3:  11%|█         | 53/484 [06:59<56:58,  7.93s/it, training_loss=0.026]\u001b[A\n",
            "Epoch 3:  11%|█         | 53/484 [07:05<56:58,  7.93s/it, training_loss=0.005]\u001b[A\n",
            "Epoch 3:  11%|█         | 54/484 [07:05<53:48,  7.51s/it, training_loss=0.005]\u001b[A\n",
            "Epoch 3:  11%|█         | 54/484 [07:15<53:48,  7.51s/it, training_loss=0.007]\u001b[A\n",
            "Epoch 3:  11%|█▏        | 55/484 [07:15<58:25,  8.17s/it, training_loss=0.007]\u001b[A\n",
            "Epoch 3:  11%|█▏        | 55/484 [07:22<58:25,  8.17s/it, training_loss=0.029]\u001b[A\n",
            "Epoch 3:  12%|█▏        | 56/484 [07:22<54:46,  7.68s/it, training_loss=0.029]\u001b[A\n",
            "Epoch 3:  12%|█▏        | 56/484 [07:30<54:46,  7.68s/it, training_loss=0.028]\u001b[A\n",
            "Epoch 3:  12%|█▏        | 57/484 [07:30<57:09,  8.03s/it, training_loss=0.028]\u001b[A\n",
            "Epoch 3:  12%|█▏        | 57/484 [07:38<57:09,  8.03s/it, training_loss=0.004]\u001b[A\n",
            "Epoch 3:  12%|█▏        | 58/484 [07:38<55:10,  7.77s/it, training_loss=0.004]\u001b[A\n",
            "Epoch 3:  12%|█▏        | 58/484 [07:45<55:10,  7.77s/it, training_loss=0.030]\u001b[A\n",
            "Epoch 3:  12%|█▏        | 59/484 [07:45<53:57,  7.62s/it, training_loss=0.030]\u001b[A\n",
            "Epoch 3:  12%|█▏        | 59/484 [07:54<53:57,  7.62s/it, training_loss=0.011]\u001b[A\n",
            "Epoch 3:  12%|█▏        | 60/484 [07:54<56:09,  7.95s/it, training_loss=0.011]\u001b[A\n",
            "Epoch 3:  12%|█▏        | 60/484 [08:00<56:09,  7.95s/it, training_loss=0.011]\u001b[A\n",
            "Epoch 3:  13%|█▎        | 61/484 [08:00<53:08,  7.54s/it, training_loss=0.011]\u001b[A\n",
            "Epoch 3:  13%|█▎        | 61/484 [08:10<53:08,  7.54s/it, training_loss=0.104]\u001b[A\n",
            "Epoch 3:  13%|█▎        | 62/484 [08:10<57:28,  8.17s/it, training_loss=0.104]\u001b[A\n",
            "Epoch 3:  13%|█▎        | 62/484 [08:16<57:28,  8.17s/it, training_loss=0.202]\u001b[A\n",
            "Epoch 3:  13%|█▎        | 63/484 [08:16<53:51,  7.68s/it, training_loss=0.202]\u001b[A\n",
            "Epoch 3:  13%|█▎        | 63/484 [08:25<53:51,  7.68s/it, training_loss=0.004]\u001b[A\n",
            "Epoch 3:  13%|█▎        | 64/484 [08:25<55:45,  7.97s/it, training_loss=0.004]\u001b[A\n",
            "Epoch 3:  13%|█▎        | 64/484 [08:32<55:45,  7.97s/it, training_loss=0.187]\u001b[A\n",
            "Epoch 3:  13%|█▎        | 65/484 [08:32<54:25,  7.79s/it, training_loss=0.187]\u001b[A\n",
            "Epoch 3:  13%|█▎        | 65/484 [08:39<54:25,  7.79s/it, training_loss=0.216]\u001b[A\n",
            "Epoch 3:  14%|█▎        | 66/484 [08:39<52:44,  7.57s/it, training_loss=0.216]\u001b[A\n",
            "Epoch 3:  14%|█▎        | 66/484 [08:49<52:44,  7.57s/it, training_loss=0.126]\u001b[A\n",
            "Epoch 3:  14%|█▍        | 67/484 [08:49<56:55,  8.19s/it, training_loss=0.126]\u001b[A\n",
            "Epoch 3:  14%|█▍        | 67/484 [08:56<56:55,  8.19s/it, training_loss=0.071]\u001b[A\n",
            "Epoch 3:  14%|█▍        | 68/484 [08:56<53:29,  7.72s/it, training_loss=0.071]\u001b[A\n",
            "Epoch 3:  14%|█▍        | 68/484 [09:05<53:29,  7.72s/it, training_loss=0.218]\u001b[A\n",
            "Epoch 3:  14%|█▍        | 69/484 [09:05<57:20,  8.29s/it, training_loss=0.218]\u001b[A\n",
            "Epoch 3:  14%|█▍        | 69/484 [09:12<57:20,  8.29s/it, training_loss=0.010]\u001b[A\n",
            "Epoch 3:  14%|█▍        | 70/484 [09:12<53:33,  7.76s/it, training_loss=0.010]\u001b[A\n",
            "Epoch 3:  14%|█▍        | 70/484 [09:20<53:33,  7.76s/it, training_loss=0.056]\u001b[A\n",
            "Epoch 3:  15%|█▍        | 71/484 [09:20<54:52,  7.97s/it, training_loss=0.056]\u001b[A\n",
            "Epoch 3:  15%|█▍        | 71/484 [09:28<54:52,  7.97s/it, training_loss=0.123]\u001b[A\n",
            "Epoch 3:  15%|█▍        | 72/484 [09:28<54:02,  7.87s/it, training_loss=0.123]\u001b[A\n",
            "Epoch 3:  15%|█▍        | 72/484 [09:35<54:02,  7.87s/it, training_loss=0.173]\u001b[A\n",
            "Epoch 3:  15%|█▌        | 73/484 [09:35<51:26,  7.51s/it, training_loss=0.173]\u001b[A\n",
            "Epoch 3:  15%|█▌        | 73/484 [09:44<51:26,  7.51s/it, training_loss=0.006]\u001b[A\n",
            "Epoch 3:  15%|█▌        | 74/484 [09:44<54:52,  8.03s/it, training_loss=0.006]\u001b[A\n",
            "Epoch 3:  15%|█▌        | 74/484 [09:50<54:52,  8.03s/it, training_loss=0.031]\u001b[A\n",
            "Epoch 3:  15%|█▌        | 75/484 [09:50<51:42,  7.59s/it, training_loss=0.031]\u001b[A\n",
            "Epoch 3:  15%|█▌        | 75/484 [10:00<51:42,  7.59s/it, training_loss=0.129]\u001b[A\n",
            "Epoch 3:  16%|█▌        | 76/484 [10:00<55:12,  8.12s/it, training_loss=0.129]\u001b[A\n",
            "Epoch 3:  16%|█▌        | 76/484 [10:06<55:12,  8.12s/it, training_loss=0.007]\u001b[A\n",
            "Epoch 3:  16%|█▌        | 77/484 [10:06<52:18,  7.71s/it, training_loss=0.007]\u001b[A\n",
            "Epoch 3:  16%|█▌        | 77/484 [10:14<52:18,  7.71s/it, training_loss=0.008]\u001b[A\n",
            "Epoch 3:  16%|█▌        | 78/484 [10:14<52:25,  7.75s/it, training_loss=0.008]\u001b[A\n",
            "Epoch 3:  16%|█▌        | 78/484 [10:22<52:25,  7.75s/it, training_loss=0.184]\u001b[A\n",
            "Epoch 3:  16%|█▋        | 79/484 [10:22<52:55,  7.84s/it, training_loss=0.184]\u001b[A\n",
            "Epoch 3:  16%|█▋        | 79/484 [10:29<52:55,  7.84s/it, training_loss=0.179]\u001b[A\n",
            "Epoch 3:  17%|█▋        | 80/484 [10:29<50:16,  7.47s/it, training_loss=0.179]\u001b[A\n",
            "Epoch 3:  17%|█▋        | 80/484 [10:39<50:16,  7.47s/it, training_loss=0.126]\u001b[A\n",
            "Epoch 3:  17%|█▋        | 81/484 [10:39<54:29,  8.11s/it, training_loss=0.126]\u001b[A\n",
            "Epoch 3:  17%|█▋        | 81/484 [10:45<54:29,  8.11s/it, training_loss=0.122]\u001b[A\n",
            "Epoch 3:  17%|█▋        | 82/484 [10:45<51:10,  7.64s/it, training_loss=0.122]\u001b[A\n",
            "Epoch 3:  17%|█▋        | 82/484 [10:54<51:10,  7.64s/it, training_loss=0.012]\u001b[A\n",
            "Epoch 3:  17%|█▋        | 83/484 [10:54<54:10,  8.11s/it, training_loss=0.012]\u001b[A\n",
            "Epoch 3:  17%|█▋        | 83/484 [11:01<54:10,  8.11s/it, training_loss=0.007]\u001b[A\n",
            "Epoch 3:  17%|█▋        | 84/484 [11:01<51:49,  7.77s/it, training_loss=0.007]\u001b[A\n",
            "Epoch 3:  17%|█▋        | 84/484 [11:09<51:49,  7.77s/it, training_loss=0.140]\u001b[A\n",
            "Epoch 3:  18%|█▊        | 85/484 [11:09<51:30,  7.74s/it, training_loss=0.140]\u001b[A\n",
            "Epoch 3:  18%|█▊        | 85/484 [11:17<51:30,  7.74s/it, training_loss=0.034]\u001b[A\n",
            "Epoch 3:  18%|█▊        | 86/484 [11:17<52:25,  7.90s/it, training_loss=0.034]\u001b[A\n",
            "Epoch 3:  18%|█▊        | 86/484 [11:24<52:25,  7.90s/it, training_loss=0.010]\u001b[A\n",
            "Epoch 3:  18%|█▊        | 87/484 [11:24<49:26,  7.47s/it, training_loss=0.010]\u001b[A\n",
            "Epoch 3:  18%|█▊        | 87/484 [11:33<49:26,  7.47s/it, training_loss=0.015]\u001b[A\n",
            "Epoch 3:  18%|█▊        | 88/484 [11:33<53:36,  8.12s/it, training_loss=0.015]\u001b[A\n",
            "Epoch 3:  18%|█▊        | 88/484 [11:40<53:36,  8.12s/it, training_loss=0.061]\u001b[A\n",
            "Epoch 3:  18%|█▊        | 89/484 [11:40<50:14,  7.63s/it, training_loss=0.061]\u001b[A\n",
            "Epoch 3:  18%|█▊        | 89/484 [11:49<50:14,  7.63s/it, training_loss=0.003]\u001b[A\n",
            "Epoch 3:  19%|█▊        | 90/484 [11:49<52:38,  8.02s/it, training_loss=0.003]\u001b[A\n",
            "Epoch 3:  19%|█▊        | 90/484 [11:56<52:38,  8.02s/it, training_loss=0.150]\u001b[A\n",
            "Epoch 3:  19%|█▉        | 91/484 [11:56<50:41,  7.74s/it, training_loss=0.150]\u001b[A\n",
            "Epoch 3:  19%|█▉        | 91/484 [12:03<50:41,  7.74s/it, training_loss=0.006]\u001b[A\n",
            "Epoch 3:  19%|█▉        | 92/484 [12:03<49:38,  7.60s/it, training_loss=0.006]\u001b[A\n",
            "Epoch 3:  19%|█▉        | 92/484 [12:12<49:38,  7.60s/it, training_loss=0.086]\u001b[A\n",
            "Epoch 3:  19%|█▉        | 93/484 [12:12<51:30,  7.90s/it, training_loss=0.086]\u001b[A\n",
            "Epoch 3:  19%|█▉        | 93/484 [12:18<51:30,  7.90s/it, training_loss=0.064]\u001b[A\n",
            "Epoch 3:  19%|█▉        | 94/484 [12:18<48:39,  7.49s/it, training_loss=0.064]\u001b[A\n",
            "Epoch 3:  19%|█▉        | 94/484 [12:28<48:39,  7.49s/it, training_loss=0.091]\u001b[A\n",
            "Epoch 3:  20%|█▉        | 95/484 [12:28<52:47,  8.14s/it, training_loss=0.091]\u001b[A\n",
            "Epoch 3:  20%|█▉        | 95/484 [12:34<52:47,  8.14s/it, training_loss=0.195]\u001b[A\n",
            "Epoch 3:  20%|█▉        | 96/484 [12:34<49:32,  7.66s/it, training_loss=0.195]\u001b[A\n",
            "Epoch 3:  20%|█▉        | 96/484 [12:43<49:32,  7.66s/it, training_loss=0.240]\u001b[A\n",
            "Epoch 3:  20%|██        | 97/484 [12:43<51:25,  7.97s/it, training_loss=0.240]\u001b[A\n",
            "Epoch 3:  20%|██        | 97/484 [12:51<51:25,  7.97s/it, training_loss=0.003]\u001b[A\n",
            "Epoch 3:  20%|██        | 98/484 [12:51<50:16,  7.81s/it, training_loss=0.003]\u001b[A\n",
            "Epoch 3:  20%|██        | 98/484 [12:58<50:16,  7.81s/it, training_loss=0.004]\u001b[A\n",
            "Epoch 3:  20%|██        | 99/484 [12:58<48:39,  7.58s/it, training_loss=0.004]\u001b[A\n",
            "Epoch 3:  20%|██        | 99/484 [13:07<48:39,  7.58s/it, training_loss=0.275]\u001b[A\n",
            "Epoch 3:  21%|██        | 100/484 [13:07<51:17,  8.01s/it, training_loss=0.275]\u001b[A\n",
            "Epoch 3:  21%|██        | 100/484 [13:13<51:17,  8.01s/it, training_loss=0.005]\u001b[A\n",
            "Epoch 3:  21%|██        | 101/484 [13:13<48:26,  7.59s/it, training_loss=0.005]\u001b[A\n",
            "Epoch 3:  21%|██        | 101/484 [13:23<48:26,  7.59s/it, training_loss=0.134]\u001b[A\n",
            "Epoch 3:  21%|██        | 102/484 [13:23<52:14,  8.20s/it, training_loss=0.134]\u001b[A\n",
            "Epoch 3:  21%|██        | 102/484 [13:29<52:14,  8.20s/it, training_loss=0.245]\u001b[A\n",
            "Epoch 3:  21%|██▏       | 103/484 [13:29<48:56,  7.71s/it, training_loss=0.245]\u001b[A\n",
            "Epoch 3:  21%|██▏       | 103/484 [13:38<48:56,  7.71s/it, training_loss=0.116]\u001b[A\n",
            "Epoch 3:  21%|██▏       | 104/484 [13:38<50:02,  7.90s/it, training_loss=0.116]\u001b[A\n",
            "Epoch 3:  21%|██▏       | 104/484 [13:46<50:02,  7.90s/it, training_loss=0.098]\u001b[A\n",
            "Epoch 3:  22%|██▏       | 105/484 [13:46<49:33,  7.84s/it, training_loss=0.098]\u001b[A\n",
            "Epoch 3:  22%|██▏       | 105/484 [13:52<49:33,  7.84s/it, training_loss=0.005]\u001b[A\n",
            "Epoch 3:  22%|██▏       | 106/484 [13:52<47:07,  7.48s/it, training_loss=0.005]\u001b[A\n",
            "Epoch 3:  22%|██▏       | 106/484 [14:01<47:07,  7.48s/it, training_loss=0.004]\u001b[A\n",
            "Epoch 3:  22%|██▏       | 107/484 [14:01<50:21,  8.02s/it, training_loss=0.004]\u001b[A\n",
            "Epoch 3:  22%|██▏       | 107/484 [14:08<50:21,  8.02s/it, training_loss=0.004]\u001b[A\n",
            "Epoch 3:  22%|██▏       | 108/484 [14:08<47:22,  7.56s/it, training_loss=0.004]\u001b[A\n",
            "Epoch 3:  22%|██▏       | 108/484 [14:17<47:22,  7.56s/it, training_loss=0.152]\u001b[A\n",
            "Epoch 3:  23%|██▎       | 109/484 [14:17<50:32,  8.09s/it, training_loss=0.152]\u001b[A\n",
            "Epoch 3:  23%|██▎       | 109/484 [14:24<50:32,  8.09s/it, training_loss=0.003]\u001b[A\n",
            "Epoch 3:  23%|██▎       | 110/484 [14:24<48:02,  7.71s/it, training_loss=0.003]\u001b[A\n",
            "Epoch 3:  23%|██▎       | 110/484 [14:32<48:02,  7.71s/it, training_loss=0.243]\u001b[A\n",
            "Epoch 3:  23%|██▎       | 111/484 [14:32<48:23,  7.78s/it, training_loss=0.243]\u001b[A\n",
            "Epoch 3:  23%|██▎       | 111/484 [14:40<48:23,  7.78s/it, training_loss=0.294]\u001b[A\n",
            "Epoch 3:  23%|██▎       | 112/484 [14:40<48:47,  7.87s/it, training_loss=0.294]\u001b[A\n",
            "Epoch 3:  23%|██▎       | 112/484 [14:47<48:47,  7.87s/it, training_loss=0.004]\u001b[A\n",
            "Epoch 3:  23%|██▎       | 113/484 [14:47<46:18,  7.49s/it, training_loss=0.004]\u001b[A\n",
            "Epoch 3:  23%|██▎       | 113/484 [14:56<46:18,  7.49s/it, training_loss=0.018]\u001b[A\n",
            "Epoch 3:  24%|██▎       | 114/484 [14:56<50:04,  8.12s/it, training_loss=0.018]\u001b[A\n",
            "Epoch 3:  24%|██▎       | 114/484 [15:03<50:04,  8.12s/it, training_loss=0.005]\u001b[A\n",
            "Epoch 3:  24%|██▍       | 115/484 [15:03<47:04,  7.65s/it, training_loss=0.005]\u001b[A\n",
            "Epoch 3:  24%|██▍       | 115/484 [15:12<47:04,  7.65s/it, training_loss=0.043]\u001b[A\n",
            "Epoch 3:  24%|██▍       | 116/484 [15:12<49:49,  8.12s/it, training_loss=0.043]\u001b[A\n",
            "Epoch 3:  24%|██▍       | 116/484 [15:19<49:49,  8.12s/it, training_loss=0.067]\u001b[A\n",
            "Epoch 3:  24%|██▍       | 117/484 [15:19<47:32,  7.77s/it, training_loss=0.067]\u001b[A\n",
            "Epoch 3:  24%|██▍       | 117/484 [15:27<47:32,  7.77s/it, training_loss=0.073]\u001b[A\n",
            "Epoch 3:  24%|██▍       | 118/484 [15:27<47:13,  7.74s/it, training_loss=0.073]\u001b[A\n",
            "Epoch 3:  24%|██▍       | 118/484 [15:35<47:13,  7.74s/it, training_loss=0.003]\u001b[A\n",
            "Epoch 3:  25%|██▍       | 119/484 [15:35<47:48,  7.86s/it, training_loss=0.003]\u001b[A\n",
            "Epoch 3:  25%|██▍       | 119/484 [15:41<47:48,  7.86s/it, training_loss=0.002]\u001b[A\n",
            "Epoch 3:  25%|██▍       | 120/484 [15:41<45:17,  7.46s/it, training_loss=0.002]\u001b[A\n",
            "Epoch 3:  25%|██▍       | 120/484 [15:51<45:17,  7.46s/it, training_loss=0.041]\u001b[A\n",
            "Epoch 3:  25%|██▌       | 121/484 [15:51<49:08,  8.12s/it, training_loss=0.041]\u001b[A\n",
            "Epoch 3:  25%|██▌       | 121/484 [15:58<49:08,  8.12s/it, training_loss=0.006]\u001b[A\n",
            "Epoch 3:  25%|██▌       | 122/484 [15:58<46:05,  7.64s/it, training_loss=0.006]\u001b[A\n",
            "Epoch 3:  25%|██▌       | 122/484 [16:07<46:05,  7.64s/it, training_loss=0.010]\u001b[A\n",
            "Epoch 3:  25%|██▌       | 123/484 [16:07<48:23,  8.04s/it, training_loss=0.010]\u001b[A\n",
            "Epoch 3:  25%|██▌       | 123/484 [16:14<48:23,  8.04s/it, training_loss=0.025]\u001b[A\n",
            "Epoch 3:  26%|██▌       | 124/484 [16:14<46:42,  7.79s/it, training_loss=0.025]\u001b[A\n",
            "Epoch 3:  26%|██▌       | 124/484 [16:21<46:42,  7.79s/it, training_loss=0.356]\u001b[A\n",
            "Epoch 3:  26%|██▌       | 125/484 [16:21<45:57,  7.68s/it, training_loss=0.356]\u001b[A\n",
            "Epoch 3:  26%|██▌       | 125/484 [16:30<45:57,  7.68s/it, training_loss=0.005]\u001b[A\n",
            "Epoch 3:  26%|██▌       | 126/484 [16:30<47:21,  7.94s/it, training_loss=0.005]\u001b[A\n",
            "Epoch 3:  26%|██▌       | 126/484 [16:36<47:21,  7.94s/it, training_loss=0.105]\u001b[A\n",
            "Epoch 3:  26%|██▌       | 127/484 [16:36<44:49,  7.53s/it, training_loss=0.105]\u001b[A\n",
            "Epoch 3:  26%|██▌       | 127/484 [16:46<44:49,  7.53s/it, training_loss=0.013]\u001b[A\n",
            "Epoch 3:  26%|██▋       | 128/484 [16:46<48:42,  8.21s/it, training_loss=0.013]\u001b[A\n",
            "Epoch 3:  26%|██▋       | 128/484 [16:53<48:42,  8.21s/it, training_loss=0.010]\u001b[A\n",
            "Epoch 3:  27%|██▋       | 129/484 [16:53<45:37,  7.71s/it, training_loss=0.010]\u001b[A\n",
            "Epoch 3:  27%|██▋       | 129/484 [17:01<45:37,  7.71s/it, training_loss=0.003]\u001b[A\n",
            "Epoch 3:  27%|██▋       | 130/484 [17:01<47:32,  8.06s/it, training_loss=0.003]\u001b[A\n",
            "Epoch 3:  27%|██▋       | 130/484 [17:09<47:32,  8.06s/it, training_loss=0.009]\u001b[A\n",
            "Epoch 3:  27%|██▋       | 131/484 [17:09<46:02,  7.83s/it, training_loss=0.009]\u001b[A\n",
            "Epoch 3:  27%|██▋       | 131/484 [17:16<46:02,  7.83s/it, training_loss=0.211]\u001b[A\n",
            "Epoch 3:  27%|██▋       | 132/484 [17:16<44:59,  7.67s/it, training_loss=0.211]\u001b[A\n",
            "Epoch 3:  27%|██▋       | 132/484 [17:25<44:59,  7.67s/it, training_loss=0.003]\u001b[A\n",
            "Epoch 3:  27%|██▋       | 133/484 [17:25<46:30,  7.95s/it, training_loss=0.003]\u001b[A\n",
            "Epoch 3:  27%|██▋       | 133/484 [17:31<46:30,  7.95s/it, training_loss=0.070]\u001b[A\n",
            "Epoch 3:  28%|██▊       | 134/484 [17:31<43:52,  7.52s/it, training_loss=0.070]\u001b[A\n",
            "Epoch 3:  28%|██▊       | 134/484 [17:41<43:52,  7.52s/it, training_loss=0.004]\u001b[A\n",
            "Epoch 3:  28%|██▊       | 135/484 [17:41<47:32,  8.17s/it, training_loss=0.004]\u001b[A\n",
            "Epoch 3:  28%|██▊       | 135/484 [17:47<47:32,  8.17s/it, training_loss=0.004]\u001b[A\n",
            "Epoch 3:  28%|██▊       | 136/484 [17:47<44:30,  7.68s/it, training_loss=0.004]\u001b[A\n",
            "Epoch 3:  28%|██▊       | 136/484 [17:56<44:30,  7.68s/it, training_loss=0.189]\u001b[A\n",
            "Epoch 3:  28%|██▊       | 137/484 [17:56<46:03,  7.96s/it, training_loss=0.189]\u001b[A\n",
            "Epoch 3:  28%|██▊       | 137/484 [18:03<46:03,  7.96s/it, training_loss=0.162]\u001b[A\n",
            "Epoch 3:  29%|██▊       | 138/484 [18:03<45:04,  7.82s/it, training_loss=0.162]\u001b[A\n",
            "Epoch 3:  29%|██▊       | 138/484 [18:11<45:04,  7.82s/it, training_loss=0.123]\u001b[A\n",
            "Epoch 3:  29%|██▊       | 139/484 [18:11<43:46,  7.61s/it, training_loss=0.123]\u001b[A\n",
            "Epoch 3:  29%|██▊       | 139/484 [18:20<43:46,  7.61s/it, training_loss=0.003]\u001b[A\n",
            "Epoch 3:  29%|██▉       | 140/484 [18:20<45:50,  8.00s/it, training_loss=0.003]\u001b[A\n",
            "Epoch 3:  29%|██▉       | 140/484 [18:26<45:50,  8.00s/it, training_loss=0.007]\u001b[A\n",
            "Epoch 3:  29%|██▉       | 141/484 [18:26<43:16,  7.57s/it, training_loss=0.007]\u001b[A\n",
            "Epoch 3:  29%|██▉       | 141/484 [18:36<43:16,  7.57s/it, training_loss=0.005]\u001b[A\n",
            "Epoch 3:  29%|██▉       | 142/484 [18:36<46:42,  8.19s/it, training_loss=0.005]\u001b[A\n",
            "Epoch 3:  29%|██▉       | 142/484 [18:42<46:42,  8.19s/it, training_loss=0.012]\u001b[A\n",
            "Epoch 3:  30%|██▉       | 143/484 [18:42<43:54,  7.73s/it, training_loss=0.012]\u001b[A\n",
            "Epoch 3:  30%|██▉       | 143/484 [18:51<43:54,  7.73s/it, training_loss=0.004]\u001b[A\n",
            "Epoch 3:  30%|██▉       | 144/484 [18:51<45:24,  8.01s/it, training_loss=0.004]\u001b[A\n",
            "Epoch 3:  30%|██▉       | 144/484 [18:59<45:24,  8.01s/it, training_loss=0.017]\u001b[A\n",
            "Epoch 3:  30%|██▉       | 145/484 [18:59<44:38,  7.90s/it, training_loss=0.017]\u001b[A\n",
            "Epoch 3:  30%|██▉       | 145/484 [19:06<44:38,  7.90s/it, training_loss=0.010]\u001b[A\n",
            "Epoch 3:  30%|███       | 146/484 [19:06<43:05,  7.65s/it, training_loss=0.010]\u001b[A\n",
            "Epoch 3:  30%|███       | 146/484 [19:15<43:05,  7.65s/it, training_loss=0.003]\u001b[A\n",
            "Epoch 3:  30%|███       | 147/484 [19:15<45:23,  8.08s/it, training_loss=0.003]\u001b[A\n",
            "Epoch 3:  30%|███       | 147/484 [19:21<45:23,  8.08s/it, training_loss=0.045]\u001b[A\n",
            "Epoch 3:  31%|███       | 148/484 [19:22<42:50,  7.65s/it, training_loss=0.045]\u001b[A\n",
            "Epoch 3:  31%|███       | 148/484 [19:31<42:50,  7.65s/it, training_loss=0.040]\u001b[A\n",
            "Epoch 3:  31%|███       | 149/484 [19:31<46:00,  8.24s/it, training_loss=0.040]\u001b[A\n",
            "Epoch 3:  31%|███       | 149/484 [19:38<46:00,  8.24s/it, training_loss=0.008]\u001b[A\n",
            "Epoch 3:  31%|███       | 150/484 [19:38<43:06,  7.75s/it, training_loss=0.008]\u001b[A\n",
            "Epoch 3:  31%|███       | 150/484 [19:46<43:06,  7.75s/it, training_loss=0.003]\u001b[A\n",
            "Epoch 3:  31%|███       | 151/484 [19:46<44:27,  8.01s/it, training_loss=0.003]\u001b[A\n",
            "Epoch 3:  31%|███       | 151/484 [19:54<44:27,  8.01s/it, training_loss=0.003]\u001b[A\n",
            "Epoch 3:  31%|███▏      | 152/484 [19:54<43:48,  7.92s/it, training_loss=0.003]\u001b[A\n",
            "Epoch 3:  31%|███▏      | 152/484 [20:01<43:48,  7.92s/it, training_loss=0.015]\u001b[A\n",
            "Epoch 3:  32%|███▏      | 153/484 [20:01<42:01,  7.62s/it, training_loss=0.015]\u001b[A\n",
            "Epoch 3:  32%|███▏      | 153/484 [20:10<42:01,  7.62s/it, training_loss=0.067]\u001b[A\n",
            "Epoch 3:  32%|███▏      | 154/484 [20:10<44:30,  8.09s/it, training_loss=0.067]\u001b[A\n",
            "Epoch 3:  32%|███▏      | 154/484 [20:17<44:30,  8.09s/it, training_loss=0.006]\u001b[A\n",
            "Epoch 3:  32%|███▏      | 155/484 [20:17<41:52,  7.64s/it, training_loss=0.006]\u001b[A\n",
            "Epoch 3:  32%|███▏      | 155/484 [20:26<41:52,  7.64s/it, training_loss=0.025]\u001b[A\n",
            "Epoch 3:  32%|███▏      | 156/484 [20:26<44:55,  8.22s/it, training_loss=0.025]\u001b[A\n",
            "Epoch 3:  32%|███▏      | 156/484 [20:33<44:55,  8.22s/it, training_loss=0.005]\u001b[A\n",
            "Epoch 3:  32%|███▏      | 157/484 [20:33<42:23,  7.78s/it, training_loss=0.005]\u001b[A\n",
            "Epoch 3:  32%|███▏      | 157/484 [20:41<42:23,  7.78s/it, training_loss=0.063]\u001b[A\n",
            "Epoch 3:  33%|███▎      | 158/484 [20:41<42:56,  7.90s/it, training_loss=0.063]\u001b[A\n",
            "Epoch 3:  33%|███▎      | 158/484 [20:49<42:56,  7.90s/it, training_loss=0.078]\u001b[A\n",
            "Epoch 3:  33%|███▎      | 159/484 [20:49<42:48,  7.90s/it, training_loss=0.078]\u001b[A\n",
            "Epoch 3:  33%|███▎      | 159/484 [20:56<42:48,  7.90s/it, training_loss=0.160]\u001b[A\n",
            "Epoch 3:  33%|███▎      | 160/484 [20:56<40:47,  7.55s/it, training_loss=0.160]\u001b[A\n",
            "Epoch 3:  33%|███▎      | 160/484 [21:05<40:47,  7.55s/it, training_loss=0.203]\u001b[A\n",
            "Epoch 3:  33%|███▎      | 161/484 [21:05<43:41,  8.11s/it, training_loss=0.203]\u001b[A\n",
            "Epoch 3:  33%|███▎      | 161/484 [21:12<43:41,  8.11s/it, training_loss=0.170]\u001b[A\n",
            "Epoch 3:  33%|███▎      | 162/484 [21:12<41:09,  7.67s/it, training_loss=0.170]\u001b[A\n",
            "Epoch 3:  33%|███▎      | 162/484 [21:21<41:09,  7.67s/it, training_loss=0.016]\u001b[A\n",
            "Epoch 3:  34%|███▎      | 163/484 [21:21<43:42,  8.17s/it, training_loss=0.016]\u001b[A\n",
            "Epoch 3:  34%|███▎      | 163/484 [21:28<43:42,  8.17s/it, training_loss=0.004]\u001b[A\n",
            "Epoch 3:  34%|███▍      | 164/484 [21:28<41:25,  7.77s/it, training_loss=0.004]\u001b[A\n",
            "Epoch 3:  34%|███▍      | 164/484 [21:36<41:25,  7.77s/it, training_loss=0.034]\u001b[A\n",
            "Epoch 3:  34%|███▍      | 165/484 [21:36<41:25,  7.79s/it, training_loss=0.034]\u001b[A\n",
            "Epoch 3:  34%|███▍      | 165/484 [21:44<41:25,  7.79s/it, training_loss=0.003]\u001b[A\n",
            "Epoch 3:  34%|███▍      | 166/484 [21:44<41:47,  7.88s/it, training_loss=0.003]\u001b[A\n",
            "Epoch 3:  34%|███▍      | 166/484 [21:51<41:47,  7.88s/it, training_loss=0.004]\u001b[A\n",
            "Epoch 3:  35%|███▍      | 167/484 [21:51<39:36,  7.50s/it, training_loss=0.004]\u001b[A\n",
            "Epoch 3:  35%|███▍      | 167/484 [22:00<39:36,  7.50s/it, training_loss=0.201]\u001b[A\n",
            "Epoch 3:  35%|███▍      | 168/484 [22:00<42:53,  8.14s/it, training_loss=0.201]\u001b[A\n",
            "Epoch 3:  35%|███▍      | 168/484 [22:07<42:53,  8.14s/it, training_loss=0.089]\u001b[A\n",
            "Epoch 3:  35%|███▍      | 169/484 [22:07<40:11,  7.65s/it, training_loss=0.089]\u001b[A\n",
            "Epoch 3:  35%|███▍      | 169/484 [22:16<40:11,  7.65s/it, training_loss=0.004]\u001b[A\n",
            "Epoch 3:  35%|███▌      | 170/484 [22:16<42:16,  8.08s/it, training_loss=0.004]\u001b[A\n",
            "Epoch 3:  35%|███▌      | 170/484 [22:23<42:16,  8.08s/it, training_loss=0.002]\u001b[A\n",
            "Epoch 3:  35%|███▌      | 171/484 [22:23<40:37,  7.79s/it, training_loss=0.002]\u001b[A\n",
            "Epoch 3:  35%|███▌      | 171/484 [22:31<40:37,  7.79s/it, training_loss=0.189]\u001b[A\n",
            "Epoch 3:  36%|███▌      | 172/484 [22:31<40:04,  7.71s/it, training_loss=0.189]\u001b[A\n",
            "Epoch 3:  36%|███▌      | 172/484 [22:39<40:04,  7.71s/it, training_loss=0.162]\u001b[A\n",
            "Epoch 3:  36%|███▌      | 173/484 [22:39<41:05,  7.93s/it, training_loss=0.162]\u001b[A\n",
            "Epoch 3:  36%|███▌      | 173/484 [22:46<41:05,  7.93s/it, training_loss=0.003]\u001b[A\n",
            "Epoch 3:  36%|███▌      | 174/484 [22:46<39:00,  7.55s/it, training_loss=0.003]\u001b[A\n",
            "Epoch 3:  36%|███▌      | 174/484 [22:55<39:00,  7.55s/it, training_loss=0.242]\u001b[A\n",
            "Epoch 3:  36%|███▌      | 175/484 [22:55<42:22,  8.23s/it, training_loss=0.242]\u001b[A\n",
            "Epoch 3:  36%|███▌      | 175/484 [23:02<42:22,  8.23s/it, training_loss=0.042]\u001b[A\n",
            "Epoch 3:  36%|███▋      | 176/484 [23:02<39:39,  7.73s/it, training_loss=0.042]\u001b[A\n",
            "Epoch 3:  36%|███▋      | 176/484 [23:11<39:39,  7.73s/it, training_loss=0.047]\u001b[A\n",
            "Epoch 3:  37%|███▋      | 177/484 [23:11<41:26,  8.10s/it, training_loss=0.047]\u001b[A\n",
            "Epoch 3:  37%|███▋      | 177/484 [23:18<41:26,  8.10s/it, training_loss=0.014]\u001b[A\n",
            "Epoch 3:  37%|███▋      | 178/484 [23:18<40:03,  7.85s/it, training_loss=0.014]\u001b[A\n",
            "Epoch 3:  37%|███▋      | 178/484 [23:26<40:03,  7.85s/it, training_loss=0.018]\u001b[A\n",
            "Epoch 3:  37%|███▋      | 179/484 [23:26<39:10,  7.71s/it, training_loss=0.018]\u001b[A\n",
            "Epoch 3:  37%|███▋      | 179/484 [23:34<39:10,  7.71s/it, training_loss=0.242]\u001b[A\n",
            "Epoch 3:  37%|███▋      | 180/484 [23:34<40:28,  7.99s/it, training_loss=0.242]\u001b[A\n",
            "Epoch 3:  37%|███▋      | 180/484 [23:41<40:28,  7.99s/it, training_loss=0.045]\u001b[A\n",
            "Epoch 3:  37%|███▋      | 181/484 [23:41<38:08,  7.55s/it, training_loss=0.045]\u001b[A\n",
            "Epoch 3:  37%|███▋      | 181/484 [23:51<38:08,  7.55s/it, training_loss=0.010]\u001b[A\n",
            "Epoch 3:  38%|███▊      | 182/484 [23:51<41:19,  8.21s/it, training_loss=0.010]\u001b[A\n",
            "Epoch 3:  38%|███▊      | 182/484 [23:57<41:19,  8.21s/it, training_loss=0.044]\u001b[A\n",
            "Epoch 3:  38%|███▊      | 183/484 [23:57<38:42,  7.72s/it, training_loss=0.044]\u001b[A\n",
            "Epoch 3:  38%|███▊      | 183/484 [24:06<38:42,  7.72s/it, training_loss=0.004]\u001b[A\n",
            "Epoch 3:  38%|███▊      | 184/484 [24:06<40:06,  8.02s/it, training_loss=0.004]\u001b[A\n",
            "Epoch 3:  38%|███▊      | 184/484 [24:13<40:06,  8.02s/it, training_loss=0.002]\u001b[A\n",
            "Epoch 3:  38%|███▊      | 185/484 [24:13<39:11,  7.87s/it, training_loss=0.002]\u001b[A\n",
            "Epoch 3:  38%|███▊      | 185/484 [24:20<39:11,  7.87s/it, training_loss=0.021]\u001b[A\n",
            "Epoch 3:  38%|███▊      | 186/484 [24:21<38:02,  7.66s/it, training_loss=0.021]\u001b[A\n",
            "Epoch 3:  38%|███▊      | 186/484 [24:29<38:02,  7.66s/it, training_loss=0.005]\u001b[A\n",
            "Epoch 3:  39%|███▊      | 187/484 [24:29<39:40,  8.02s/it, training_loss=0.005]\u001b[A\n",
            "Epoch 3:  39%|███▊      | 187/484 [24:36<39:40,  8.02s/it, training_loss=0.260]\u001b[A\n",
            "Epoch 3:  39%|███▉      | 188/484 [24:36<37:24,  7.58s/it, training_loss=0.260]\u001b[A\n",
            "Epoch 3:  39%|███▉      | 188/484 [24:46<37:24,  7.58s/it, training_loss=0.003]\u001b[A\n",
            "Epoch 3:  39%|███▉      | 189/484 [24:46<40:23,  8.22s/it, training_loss=0.003]\u001b[A\n",
            "Epoch 3:  39%|███▉      | 189/484 [24:52<40:23,  8.22s/it, training_loss=0.009]\u001b[A\n",
            "Epoch 3:  39%|███▉      | 190/484 [24:52<37:45,  7.71s/it, training_loss=0.009]\u001b[A\n",
            "Epoch 3:  39%|███▉      | 190/484 [25:01<37:45,  7.71s/it, training_loss=0.266]\u001b[A\n",
            "Epoch 3:  39%|███▉      | 191/484 [25:01<38:50,  7.95s/it, training_loss=0.266]\u001b[A\n",
            "Epoch 3:  39%|███▉      | 191/484 [25:08<38:50,  7.95s/it, training_loss=0.005]\u001b[A\n",
            "Epoch 3:  40%|███▉      | 192/484 [25:08<38:10,  7.84s/it, training_loss=0.005]\u001b[A\n",
            "Epoch 3:  40%|███▉      | 192/484 [25:15<38:10,  7.84s/it, training_loss=0.283]\u001b[A\n",
            "Epoch 3:  40%|███▉      | 193/484 [25:15<36:46,  7.58s/it, training_loss=0.283]\u001b[A\n",
            "Epoch 3:  40%|███▉      | 193/484 [25:24<36:46,  7.58s/it, training_loss=0.003]\u001b[A\n",
            "Epoch 3:  40%|████      | 194/484 [25:24<38:43,  8.01s/it, training_loss=0.003]\u001b[A\n",
            "Epoch 3:  40%|████      | 194/484 [25:31<38:43,  8.01s/it, training_loss=0.011]\u001b[A\n",
            "Epoch 3:  40%|████      | 195/484 [25:31<36:24,  7.56s/it, training_loss=0.011]\u001b[A\n",
            "Epoch 3:  40%|████      | 195/484 [25:40<36:24,  7.56s/it, training_loss=0.027]\u001b[A\n",
            "Epoch 3:  40%|████      | 196/484 [25:40<39:05,  8.14s/it, training_loss=0.027]\u001b[A\n",
            "Epoch 3:  40%|████      | 196/484 [25:47<39:05,  8.14s/it, training_loss=0.004]\u001b[A\n",
            "Epoch 3:  41%|████      | 197/484 [25:47<36:43,  7.68s/it, training_loss=0.004]\u001b[A\n",
            "Epoch 3:  41%|████      | 197/484 [25:55<36:43,  7.68s/it, training_loss=0.003]\u001b[A\n",
            "Epoch 3:  41%|████      | 198/484 [25:55<37:08,  7.79s/it, training_loss=0.003]\u001b[A\n",
            "Epoch 3:  41%|████      | 198/484 [26:03<37:08,  7.79s/it, training_loss=0.280]\u001b[A\n",
            "Epoch 3:  41%|████      | 199/484 [26:03<37:10,  7.83s/it, training_loss=0.280]\u001b[A\n",
            "Epoch 3:  41%|████      | 199/484 [26:10<37:10,  7.83s/it, training_loss=0.047]\u001b[A\n",
            "Epoch 3:  41%|████▏     | 200/484 [26:10<35:27,  7.49s/it, training_loss=0.047]\u001b[A\n",
            "Epoch 3:  41%|████▏     | 200/484 [26:19<35:27,  7.49s/it, training_loss=0.003]\u001b[A\n",
            "Epoch 3:  42%|████▏     | 201/484 [26:19<38:09,  8.09s/it, training_loss=0.003]\u001b[A\n",
            "Epoch 3:  42%|████▏     | 201/484 [26:26<38:09,  8.09s/it, training_loss=0.010]\u001b[A\n",
            "Epoch 3:  42%|████▏     | 202/484 [26:26<35:50,  7.63s/it, training_loss=0.010]\u001b[A\n",
            "Epoch 3:  42%|████▏     | 202/484 [26:35<35:50,  7.63s/it, training_loss=0.126]\u001b[A\n",
            "Epoch 3:  42%|████▏     | 203/484 [26:35<38:05,  8.13s/it, training_loss=0.126]\u001b[A\n",
            "Epoch 3:  42%|████▏     | 203/484 [26:42<38:05,  8.13s/it, training_loss=0.200]\u001b[A\n",
            "Epoch 3:  42%|████▏     | 204/484 [26:42<36:16,  7.77s/it, training_loss=0.200]\u001b[A\n",
            "Epoch 3:  42%|████▏     | 204/484 [26:50<36:16,  7.77s/it, training_loss=0.002]\u001b[A\n",
            "Epoch 3:  42%|████▏     | 205/484 [26:50<36:17,  7.81s/it, training_loss=0.002]\u001b[A\n",
            "Epoch 3:  42%|████▏     | 205/484 [26:58<36:17,  7.81s/it, training_loss=0.024]\u001b[A\n",
            "Epoch 3:  43%|████▎     | 206/484 [26:58<36:45,  7.94s/it, training_loss=0.024]\u001b[A\n",
            "Epoch 3:  43%|████▎     | 206/484 [27:05<36:45,  7.94s/it, training_loss=0.004]\u001b[A\n",
            "Epoch 3:  43%|████▎     | 207/484 [27:05<34:47,  7.54s/it, training_loss=0.004]\u001b[A\n",
            "Epoch 3:  43%|████▎     | 207/484 [27:14<34:47,  7.54s/it, training_loss=0.154]\u001b[A\n",
            "Epoch 3:  43%|████▎     | 208/484 [27:14<37:38,  8.18s/it, training_loss=0.154]\u001b[A\n",
            "Epoch 3:  43%|████▎     | 208/484 [27:21<37:38,  8.18s/it, training_loss=0.010]\u001b[A\n",
            "Epoch 3:  43%|████▎     | 209/484 [27:21<35:19,  7.71s/it, training_loss=0.010]\u001b[A\n",
            "Epoch 3:  43%|████▎     | 209/484 [27:30<35:19,  7.71s/it, training_loss=0.004]\u001b[A\n",
            "Epoch 3:  43%|████▎     | 210/484 [27:30<37:02,  8.11s/it, training_loss=0.004]\u001b[A\n",
            "Epoch 3:  43%|████▎     | 210/484 [27:37<37:02,  8.11s/it, training_loss=0.094]\u001b[A\n",
            "Epoch 3:  44%|████▎     | 211/484 [27:37<35:19,  7.76s/it, training_loss=0.094]\u001b[A\n",
            "Epoch 3:  44%|████▎     | 211/484 [27:44<35:19,  7.76s/it, training_loss=0.296]\u001b[A\n",
            "Epoch 3:  44%|████▍     | 212/484 [27:44<34:55,  7.70s/it, training_loss=0.296]\u001b[A\n",
            "Epoch 3:  44%|████▍     | 212/484 [27:53<34:55,  7.70s/it, training_loss=0.006]\u001b[A\n",
            "Epoch 3:  44%|████▍     | 213/484 [27:53<35:42,  7.90s/it, training_loss=0.006]\u001b[A\n",
            "Epoch 3:  44%|████▍     | 213/484 [27:59<35:42,  7.90s/it, training_loss=0.153]\u001b[A\n",
            "Epoch 3:  44%|████▍     | 214/484 [27:59<33:37,  7.47s/it, training_loss=0.153]\u001b[A\n",
            "Epoch 3:  44%|████▍     | 214/484 [28:09<33:37,  7.47s/it, training_loss=0.005]\u001b[A\n",
            "Epoch 3:  44%|████▍     | 215/484 [28:09<36:33,  8.16s/it, training_loss=0.005]\u001b[A\n",
            "Epoch 3:  44%|████▍     | 215/484 [28:16<36:33,  8.16s/it, training_loss=0.291]\u001b[A\n",
            "Epoch 3:  45%|████▍     | 216/484 [28:16<34:24,  7.70s/it, training_loss=0.291]\u001b[A\n",
            "Epoch 3:  45%|████▍     | 216/484 [28:25<34:24,  7.70s/it, training_loss=0.003]\u001b[A\n",
            "Epoch 3:  45%|████▍     | 217/484 [28:25<35:55,  8.07s/it, training_loss=0.003]\u001b[A\n",
            "Epoch 3:  45%|████▍     | 217/484 [28:32<35:55,  8.07s/it, training_loss=0.002]\u001b[A\n",
            "Epoch 3:  45%|████▌     | 218/484 [28:32<34:42,  7.83s/it, training_loss=0.002]\u001b[A\n",
            "Epoch 3:  45%|████▌     | 218/484 [28:39<34:42,  7.83s/it, training_loss=0.014]\u001b[A\n",
            "Epoch 3:  45%|████▌     | 219/484 [28:39<34:03,  7.71s/it, training_loss=0.014]\u001b[A\n",
            "Epoch 3:  45%|████▌     | 219/484 [28:48<34:03,  7.71s/it, training_loss=0.328]\u001b[A\n",
            "Epoch 3:  45%|████▌     | 220/484 [28:48<35:40,  8.11s/it, training_loss=0.328]\u001b[A\n",
            "Epoch 3:  45%|████▌     | 220/484 [28:55<35:40,  8.11s/it, training_loss=0.006]\u001b[A\n",
            "Epoch 3:  46%|████▌     | 221/484 [28:55<33:41,  7.69s/it, training_loss=0.006]\u001b[A\n",
            "Epoch 3:  46%|████▌     | 221/484 [29:05<33:41,  7.69s/it, training_loss=0.002]\u001b[A\n",
            "Epoch 3:  46%|████▌     | 222/484 [29:05<36:17,  8.31s/it, training_loss=0.002]\u001b[A\n",
            "Epoch 3:  46%|████▌     | 222/484 [29:11<36:17,  8.31s/it, training_loss=0.012]\u001b[A\n",
            "Epoch 3:  46%|████▌     | 223/484 [29:11<34:03,  7.83s/it, training_loss=0.012]\u001b[A\n",
            "Epoch 3:  46%|████▌     | 223/484 [29:21<34:03,  7.83s/it, training_loss=0.002]\u001b[A\n",
            "Epoch 3:  46%|████▋     | 224/484 [29:21<35:34,  8.21s/it, training_loss=0.002]\u001b[A\n",
            "Epoch 3:  46%|████▋     | 224/484 [29:28<35:34,  8.21s/it, training_loss=0.002]\u001b[A\n",
            "Epoch 3:  46%|████▋     | 225/484 [29:28<34:11,  7.92s/it, training_loss=0.002]\u001b[A\n",
            "Epoch 3:  46%|████▋     | 225/484 [29:35<34:11,  7.92s/it, training_loss=0.018]\u001b[A\n",
            "Epoch 3:  47%|████▋     | 226/484 [29:35<33:22,  7.76s/it, training_loss=0.018]\u001b[A\n",
            "Epoch 3:  47%|████▋     | 226/484 [29:44<33:22,  7.76s/it, training_loss=0.015]\u001b[A\n",
            "Epoch 3:  47%|████▋     | 227/484 [29:44<34:19,  8.01s/it, training_loss=0.015]\u001b[A\n",
            "Epoch 3:  47%|████▋     | 227/484 [29:50<34:19,  8.01s/it, training_loss=0.005]\u001b[A\n",
            "Epoch 3:  47%|████▋     | 228/484 [29:50<32:20,  7.58s/it, training_loss=0.005]\u001b[A\n",
            "Epoch 3:  47%|████▋     | 228/484 [30:00<32:20,  7.58s/it, training_loss=0.002]\u001b[A\n",
            "Epoch 3:  47%|████▋     | 229/484 [30:00<34:56,  8.22s/it, training_loss=0.002]\u001b[A\n",
            "Epoch 3:  47%|████▋     | 229/484 [30:07<34:56,  8.22s/it, training_loss=0.007]\u001b[A\n",
            "Epoch 3:  48%|████▊     | 230/484 [30:07<32:41,  7.72s/it, training_loss=0.007]\u001b[A\n",
            "Epoch 3:  48%|████▊     | 230/484 [30:15<32:41,  7.72s/it, training_loss=0.012]\u001b[A\n",
            "Epoch 3:  48%|████▊     | 231/484 [30:15<33:59,  8.06s/it, training_loss=0.012]\u001b[A\n",
            "Epoch 3:  48%|████▊     | 231/484 [30:23<33:59,  8.06s/it, training_loss=0.003]\u001b[A\n",
            "Epoch 3:  48%|████▊     | 232/484 [30:23<32:54,  7.84s/it, training_loss=0.003]\u001b[A\n",
            "Epoch 3:  48%|████▊     | 232/484 [30:30<32:54,  7.84s/it, training_loss=0.047]\u001b[A\n",
            "Epoch 3:  48%|████▊     | 233/484 [30:30<32:04,  7.67s/it, training_loss=0.047]\u001b[A\n",
            "Epoch 3:  48%|████▊     | 233/484 [30:39<32:04,  7.67s/it, training_loss=0.166]\u001b[A\n",
            "Epoch 3:  48%|████▊     | 234/484 [30:39<33:24,  8.02s/it, training_loss=0.166]\u001b[A\n",
            "Epoch 3:  48%|████▊     | 234/484 [30:46<33:24,  8.02s/it, training_loss=0.034]\u001b[A\n",
            "Epoch 3:  49%|████▊     | 235/484 [30:46<31:31,  7.60s/it, training_loss=0.034]\u001b[A\n",
            "Epoch 3:  49%|████▊     | 235/484 [30:55<31:31,  7.60s/it, training_loss=0.259]\u001b[A\n",
            "Epoch 3:  49%|████▉     | 236/484 [30:55<34:02,  8.24s/it, training_loss=0.259]\u001b[A\n",
            "Epoch 3:  49%|████▉     | 236/484 [31:02<34:02,  8.24s/it, training_loss=0.006]\u001b[A\n",
            "Epoch 3:  49%|████▉     | 237/484 [31:02<31:46,  7.72s/it, training_loss=0.006]\u001b[A\n",
            "Epoch 3:  49%|████▉     | 237/484 [31:11<31:46,  7.72s/it, training_loss=0.131]\u001b[A\n",
            "Epoch 3:  49%|████▉     | 238/484 [31:11<32:56,  8.03s/it, training_loss=0.131]\u001b[A\n",
            "Epoch 3:  49%|████▉     | 238/484 [31:18<32:56,  8.03s/it, training_loss=0.002]\u001b[A\n",
            "Epoch 3:  49%|████▉     | 239/484 [31:18<32:04,  7.85s/it, training_loss=0.002]\u001b[A\n",
            "Epoch 3:  49%|████▉     | 239/484 [31:25<32:04,  7.85s/it, training_loss=0.232]\u001b[A\n",
            "Epoch 3:  50%|████▉     | 240/484 [31:25<31:01,  7.63s/it, training_loss=0.232]\u001b[A\n",
            "Epoch 3:  50%|████▉     | 240/484 [31:34<31:01,  7.63s/it, training_loss=0.014]\u001b[A\n",
            "Epoch 3:  50%|████▉     | 241/484 [31:34<32:19,  7.98s/it, training_loss=0.014]\u001b[A\n",
            "Epoch 3:  50%|████▉     | 241/484 [31:40<32:19,  7.98s/it, training_loss=0.011]\u001b[A\n",
            "Epoch 3:  50%|█████     | 242/484 [31:40<30:28,  7.55s/it, training_loss=0.011]\u001b[A\n",
            "Epoch 3:  50%|█████     | 242/484 [31:50<30:28,  7.55s/it, training_loss=0.046]\u001b[A\n",
            "Epoch 3:  50%|█████     | 243/484 [31:50<32:50,  8.17s/it, training_loss=0.046]\u001b[A\n",
            "Epoch 3:  50%|█████     | 243/484 [31:57<32:50,  8.17s/it, training_loss=0.002]\u001b[A\n",
            "Epoch 3:  50%|█████     | 244/484 [31:57<30:42,  7.68s/it, training_loss=0.002]\u001b[A\n",
            "Epoch 3:  50%|█████     | 244/484 [32:05<30:42,  7.68s/it, training_loss=0.117]\u001b[A\n",
            "Epoch 3:  51%|█████     | 245/484 [32:05<31:35,  7.93s/it, training_loss=0.117]\u001b[A\n",
            "Epoch 3:  51%|█████     | 245/484 [32:13<31:35,  7.93s/it, training_loss=0.009]\u001b[A\n",
            "Epoch 3:  51%|█████     | 246/484 [32:13<31:05,  7.84s/it, training_loss=0.009]\u001b[A\n",
            "Epoch 3:  51%|█████     | 246/484 [32:20<31:05,  7.84s/it, training_loss=0.004]\u001b[A\n",
            "Epoch 3:  51%|█████     | 247/484 [32:20<29:45,  7.53s/it, training_loss=0.004]\u001b[A\n",
            "Epoch 3:  51%|█████     | 247/484 [32:29<29:45,  7.53s/it, training_loss=0.006]\u001b[A\n",
            "Epoch 3:  51%|█████     | 248/484 [32:29<31:30,  8.01s/it, training_loss=0.006]\u001b[A\n",
            "Epoch 3:  51%|█████     | 248/484 [32:35<31:30,  8.01s/it, training_loss=0.182]\u001b[A\n",
            "Epoch 3:  51%|█████▏    | 249/484 [32:35<29:39,  7.57s/it, training_loss=0.182]\u001b[A\n",
            "Epoch 3:  51%|█████▏    | 249/484 [32:45<29:39,  7.57s/it, training_loss=0.175]\u001b[A\n",
            "Epoch 3:  52%|█████▏    | 250/484 [32:45<32:19,  8.29s/it, training_loss=0.175]\u001b[A\n",
            "Epoch 3:  52%|█████▏    | 250/484 [32:52<32:19,  8.29s/it, training_loss=0.005]\u001b[A\n",
            "Epoch 3:  52%|█████▏    | 251/484 [32:52<31:01,  7.99s/it, training_loss=0.005]\u001b[A\n",
            "Epoch 3:  52%|█████▏    | 251/484 [33:01<31:01,  7.99s/it, training_loss=0.007]\u001b[A\n",
            "Epoch 3:  52%|█████▏    | 252/484 [33:01<31:21,  8.11s/it, training_loss=0.007]\u001b[A\n",
            "Epoch 3:  52%|█████▏    | 252/484 [33:09<31:21,  8.11s/it, training_loss=0.056]\u001b[A\n",
            "Epoch 3:  52%|█████▏    | 253/484 [33:09<30:42,  7.98s/it, training_loss=0.056]\u001b[A\n",
            "Epoch 3:  52%|█████▏    | 253/484 [33:15<30:42,  7.98s/it, training_loss=0.240]\u001b[A\n",
            "Epoch 3:  52%|█████▏    | 254/484 [33:15<29:10,  7.61s/it, training_loss=0.240]\u001b[A\n",
            "Epoch 3:  52%|█████▏    | 254/484 [33:24<29:10,  7.61s/it, training_loss=0.003]\u001b[A\n",
            "Epoch 3:  53%|█████▎    | 255/484 [33:24<30:49,  8.08s/it, training_loss=0.003]\u001b[A\n",
            "Epoch 3:  53%|█████▎    | 255/484 [33:31<30:49,  8.08s/it, training_loss=0.002]\u001b[A\n",
            "Epoch 3:  53%|█████▎    | 256/484 [33:31<28:51,  7.59s/it, training_loss=0.002]\u001b[A\n",
            "Epoch 3:  53%|█████▎    | 256/484 [33:40<28:51,  7.59s/it, training_loss=0.158]\u001b[A\n",
            "Epoch 3:  53%|█████▎    | 257/484 [33:40<30:41,  8.11s/it, training_loss=0.158]\u001b[A\n",
            "Epoch 3:  53%|█████▎    | 257/484 [33:47<30:41,  8.11s/it, training_loss=0.248]\u001b[A\n",
            "Epoch 3:  53%|█████▎    | 258/484 [33:47<29:02,  7.71s/it, training_loss=0.248]\u001b[A\n",
            "Epoch 3:  53%|█████▎    | 258/484 [33:55<29:02,  7.71s/it, training_loss=0.002]\u001b[A\n",
            "Epoch 3:  54%|█████▎    | 259/484 [33:55<29:04,  7.75s/it, training_loss=0.002]\u001b[A\n",
            "Epoch 3:  54%|█████▎    | 259/484 [34:03<29:04,  7.75s/it, training_loss=0.004]\u001b[A\n",
            "Epoch 3:  54%|█████▎    | 260/484 [34:03<29:16,  7.84s/it, training_loss=0.004]\u001b[A\n",
            "Epoch 3:  54%|█████▎    | 260/484 [34:09<29:16,  7.84s/it, training_loss=0.002]\u001b[A\n",
            "Epoch 3:  54%|█████▍    | 261/484 [34:09<27:43,  7.46s/it, training_loss=0.002]\u001b[A\n",
            "Epoch 3:  54%|█████▍    | 261/484 [34:19<27:43,  7.46s/it, training_loss=0.004]\u001b[A\n",
            "Epoch 3:  54%|█████▍    | 262/484 [34:19<30:02,  8.12s/it, training_loss=0.004]\u001b[A\n",
            "Epoch 3:  54%|█████▍    | 262/484 [34:26<30:02,  8.12s/it, training_loss=0.058]\u001b[A\n",
            "Epoch 3:  54%|█████▍    | 263/484 [34:26<28:12,  7.66s/it, training_loss=0.058]\u001b[A\n",
            "Epoch 3:  54%|█████▍    | 263/484 [34:35<28:12,  7.66s/it, training_loss=0.005]\u001b[A\n",
            "Epoch 3:  55%|█████▍    | 264/484 [34:35<29:41,  8.10s/it, training_loss=0.005]\u001b[A\n",
            "Epoch 3:  55%|█████▍    | 264/484 [34:42<29:41,  8.10s/it, training_loss=0.010]\u001b[A\n",
            "Epoch 3:  55%|█████▍    | 265/484 [34:42<28:29,  7.81s/it, training_loss=0.010]\u001b[A\n",
            "Epoch 3:  55%|█████▍    | 265/484 [34:50<28:29,  7.81s/it, training_loss=0.003]\u001b[A\n",
            "Epoch 3:  55%|█████▍    | 266/484 [34:50<28:11,  7.76s/it, training_loss=0.003]\u001b[A\n",
            "Epoch 3:  55%|█████▍    | 266/484 [34:58<28:11,  7.76s/it, training_loss=0.002]\u001b[A\n",
            "Epoch 3:  55%|█████▌    | 267/484 [34:58<28:46,  7.96s/it, training_loss=0.002]\u001b[A\n",
            "Epoch 3:  55%|█████▌    | 267/484 [35:05<28:46,  7.96s/it, training_loss=0.216]\u001b[A\n",
            "Epoch 3:  55%|█████▌    | 268/484 [35:05<27:05,  7.52s/it, training_loss=0.216]\u001b[A\n",
            "Epoch 3:  55%|█████▌    | 268/484 [35:14<27:05,  7.52s/it, training_loss=0.008]\u001b[A\n",
            "Epoch 3:  56%|█████▌    | 269/484 [35:14<29:21,  8.19s/it, training_loss=0.008]\u001b[A\n",
            "Epoch 3:  56%|█████▌    | 269/484 [35:21<29:21,  8.19s/it, training_loss=0.006]\u001b[A\n",
            "Epoch 3:  56%|█████▌    | 270/484 [35:21<27:27,  7.70s/it, training_loss=0.006]\u001b[A\n",
            "Epoch 3:  56%|█████▌    | 270/484 [35:30<27:27,  7.70s/it, training_loss=0.169]\u001b[A\n",
            "Epoch 3:  56%|█████▌    | 271/484 [35:30<28:43,  8.09s/it, training_loss=0.169]\u001b[A\n",
            "Epoch 3:  56%|█████▌    | 271/484 [35:37<28:43,  8.09s/it, training_loss=0.003]\u001b[A\n",
            "Epoch 3:  56%|█████▌    | 272/484 [35:37<27:27,  7.77s/it, training_loss=0.003]\u001b[A\n",
            "Epoch 3:  56%|█████▌    | 272/484 [35:44<27:27,  7.77s/it, training_loss=0.053]\u001b[A\n",
            "Epoch 3:  56%|█████▋    | 273/484 [35:44<26:53,  7.64s/it, training_loss=0.053]\u001b[A\n",
            "Epoch 3:  56%|█████▋    | 273/484 [35:53<26:53,  7.64s/it, training_loss=0.002]\u001b[A\n",
            "Epoch 3:  57%|█████▋    | 274/484 [35:53<27:38,  7.90s/it, training_loss=0.002]\u001b[A\n",
            "Epoch 3:  57%|█████▋    | 274/484 [35:59<27:38,  7.90s/it, training_loss=0.003]\u001b[A\n",
            "Epoch 3:  57%|█████▋    | 275/484 [35:59<26:04,  7.49s/it, training_loss=0.003]\u001b[A\n",
            "Epoch 3:  57%|█████▋    | 275/484 [36:09<26:04,  7.49s/it, training_loss=0.177]\u001b[A\n",
            "Epoch 3:  57%|█████▋    | 276/484 [36:09<28:14,  8.14s/it, training_loss=0.177]\u001b[A\n",
            "Epoch 3:  57%|█████▋    | 276/484 [36:15<28:14,  8.14s/it, training_loss=0.232]\u001b[A\n",
            "Epoch 3:  57%|█████▋    | 277/484 [36:15<26:21,  7.64s/it, training_loss=0.232]\u001b[A\n",
            "Epoch 3:  57%|█████▋    | 277/484 [36:24<26:21,  7.64s/it, training_loss=0.003]\u001b[A\n",
            "Epoch 3:  57%|█████▋    | 278/484 [36:24<27:17,  7.95s/it, training_loss=0.003]\u001b[A\n",
            "Epoch 3:  57%|█████▋    | 278/484 [36:31<27:17,  7.95s/it, training_loss=0.302]\u001b[A\n",
            "Epoch 3:  58%|█████▊    | 279/484 [36:31<26:34,  7.78s/it, training_loss=0.302]\u001b[A\n",
            "Epoch 3:  58%|█████▊    | 279/484 [36:38<26:34,  7.78s/it, training_loss=0.179]\u001b[A\n",
            "Epoch 3:  58%|█████▊    | 280/484 [36:38<25:41,  7.56s/it, training_loss=0.179]\u001b[A\n",
            "Epoch 3:  58%|█████▊    | 280/484 [36:47<25:41,  7.56s/it, training_loss=0.002]\u001b[A\n",
            "Epoch 3:  58%|█████▊    | 281/484 [36:47<26:57,  7.97s/it, training_loss=0.002]\u001b[A\n",
            "Epoch 3:  58%|█████▊    | 281/484 [36:54<26:57,  7.97s/it, training_loss=0.320]\u001b[A\n",
            "Epoch 3:  58%|█████▊    | 282/484 [36:54<25:28,  7.56s/it, training_loss=0.320]\u001b[A\n",
            "Epoch 3:  58%|█████▊    | 282/484 [37:04<25:28,  7.56s/it, training_loss=0.162]\u001b[A\n",
            "Epoch 3:  58%|█████▊    | 283/484 [37:04<27:23,  8.18s/it, training_loss=0.162]\u001b[A\n",
            "Epoch 3:  58%|█████▊    | 283/484 [37:10<27:23,  8.18s/it, training_loss=0.037]\u001b[A\n",
            "Epoch 3:  59%|█████▊    | 284/484 [37:10<25:39,  7.70s/it, training_loss=0.037]\u001b[A\n",
            "Epoch 3:  59%|█████▊    | 284/484 [37:19<25:39,  7.70s/it, training_loss=0.162]\u001b[A\n",
            "Epoch 3:  59%|█████▉    | 285/484 [37:19<26:26,  7.97s/it, training_loss=0.162]\u001b[A\n",
            "Epoch 3:  59%|█████▉    | 285/484 [37:26<26:26,  7.97s/it, training_loss=0.120]\u001b[A\n",
            "Epoch 3:  59%|█████▉    | 286/484 [37:26<25:50,  7.83s/it, training_loss=0.120]\u001b[A\n",
            "Epoch 3:  59%|█████▉    | 286/484 [37:33<25:50,  7.83s/it, training_loss=0.002]\u001b[A\n",
            "Epoch 3:  59%|█████▉    | 287/484 [37:33<24:37,  7.50s/it, training_loss=0.002]\u001b[A\n",
            "Epoch 3:  59%|█████▉    | 287/484 [37:42<24:37,  7.50s/it, training_loss=0.136]\u001b[A\n",
            "Epoch 3:  60%|█████▉    | 288/484 [37:42<26:02,  7.97s/it, training_loss=0.136]\u001b[A\n",
            "Epoch 3:  60%|█████▉    | 288/484 [37:49<26:02,  7.97s/it, training_loss=0.255]\u001b[A\n",
            "Epoch 3:  60%|█████▉    | 289/484 [37:49<24:29,  7.54s/it, training_loss=0.255]\u001b[A\n",
            "Epoch 3:  60%|█████▉    | 289/484 [37:58<24:29,  7.54s/it, training_loss=0.003]\u001b[A\n",
            "Epoch 3:  60%|█████▉    | 290/484 [37:58<26:08,  8.08s/it, training_loss=0.003]\u001b[A\n",
            "Epoch 3:  60%|█████▉    | 290/484 [38:05<26:08,  8.08s/it, training_loss=0.002]\u001b[A\n",
            "Epoch 3:  60%|██████    | 291/484 [38:05<24:36,  7.65s/it, training_loss=0.002]\u001b[A\n",
            "Epoch 3:  60%|██████    | 291/484 [38:13<24:36,  7.65s/it, training_loss=0.013]\u001b[A\n",
            "Epoch 3:  60%|██████    | 292/484 [38:13<24:41,  7.72s/it, training_loss=0.013]\u001b[A\n",
            "Epoch 3:  60%|██████    | 292/484 [38:21<24:41,  7.72s/it, training_loss=0.002]\u001b[A\n",
            "Epoch 3:  61%|██████    | 293/484 [38:21<24:52,  7.81s/it, training_loss=0.002]\u001b[A\n",
            "Epoch 3:  61%|██████    | 293/484 [38:27<24:52,  7.81s/it, training_loss=0.208]\u001b[A\n",
            "Epoch 3:  61%|██████    | 294/484 [38:27<23:32,  7.43s/it, training_loss=0.208]\u001b[A\n",
            "Epoch 3:  61%|██████    | 294/484 [38:37<23:32,  7.43s/it, training_loss=0.171]\u001b[A\n",
            "Epoch 3:  61%|██████    | 295/484 [38:37<25:25,  8.07s/it, training_loss=0.171]\u001b[A\n",
            "Epoch 3:  61%|██████    | 295/484 [38:43<25:25,  8.07s/it, training_loss=0.043]\u001b[A\n",
            "Epoch 3:  61%|██████    | 296/484 [38:43<23:54,  7.63s/it, training_loss=0.043]\u001b[A\n",
            "Epoch 3:  61%|██████    | 296/484 [38:52<23:54,  7.63s/it, training_loss=0.075]\u001b[A\n",
            "Epoch 3:  61%|██████▏   | 297/484 [38:52<25:15,  8.10s/it, training_loss=0.075]\u001b[A\n",
            "Epoch 3:  61%|██████▏   | 297/484 [38:59<25:15,  8.10s/it, training_loss=0.025]\u001b[A\n",
            "Epoch 3:  62%|██████▏   | 298/484 [38:59<24:00,  7.75s/it, training_loss=0.025]\u001b[A\n",
            "Epoch 3:  62%|██████▏   | 298/484 [39:07<24:00,  7.75s/it, training_loss=0.004]\u001b[A\n",
            "Epoch 3:  62%|██████▏   | 299/484 [39:07<23:45,  7.70s/it, training_loss=0.004]\u001b[A\n",
            "Epoch 3:  62%|██████▏   | 299/484 [39:15<23:45,  7.70s/it, training_loss=0.002]\u001b[A\n",
            "Epoch 3:  62%|██████▏   | 300/484 [39:15<24:08,  7.87s/it, training_loss=0.002]\u001b[A\n",
            "Epoch 3:  62%|██████▏   | 300/484 [39:22<24:08,  7.87s/it, training_loss=0.009]\u001b[A\n",
            "Epoch 3:  62%|██████▏   | 301/484 [39:22<22:44,  7.45s/it, training_loss=0.009]\u001b[A\n",
            "Epoch 3:  62%|██████▏   | 301/484 [39:31<22:44,  7.45s/it, training_loss=0.103]\u001b[A\n",
            "Epoch 3:  62%|██████▏   | 302/484 [39:31<24:37,  8.12s/it, training_loss=0.103]\u001b[A\n",
            "Epoch 3:  62%|██████▏   | 302/484 [39:38<24:37,  8.12s/it, training_loss=0.002]\u001b[A\n",
            "Epoch 3:  63%|██████▎   | 303/484 [39:38<23:00,  7.63s/it, training_loss=0.002]\u001b[A\n",
            "Epoch 3:  63%|██████▎   | 303/484 [39:47<23:00,  7.63s/it, training_loss=0.221]\u001b[A\n",
            "Epoch 3:  63%|██████▎   | 304/484 [39:47<23:57,  7.99s/it, training_loss=0.221]\u001b[A\n",
            "Epoch 3:  63%|██████▎   | 304/484 [39:54<23:57,  7.99s/it, training_loss=0.252]\u001b[A\n",
            "Epoch 3:  63%|██████▎   | 305/484 [39:54<23:08,  7.75s/it, training_loss=0.252]\u001b[A\n",
            "Epoch 3:  63%|██████▎   | 305/484 [40:01<23:08,  7.75s/it, training_loss=0.227]\u001b[A\n",
            "Epoch 3:  63%|██████▎   | 306/484 [40:01<22:37,  7.63s/it, training_loss=0.227]\u001b[A\n",
            "Epoch 3:  63%|██████▎   | 306/484 [40:10<22:37,  7.63s/it, training_loss=0.005]\u001b[A\n",
            "Epoch 3:  63%|██████▎   | 307/484 [40:10<23:22,  7.92s/it, training_loss=0.005]\u001b[A\n",
            "Epoch 3:  63%|██████▎   | 307/484 [40:16<23:22,  7.92s/it, training_loss=0.244]\u001b[A\n",
            "Epoch 3:  64%|██████▎   | 308/484 [40:16<21:58,  7.49s/it, training_loss=0.244]\u001b[A\n",
            "Epoch 3:  64%|██████▎   | 308/484 [40:26<21:58,  7.49s/it, training_loss=0.010]\u001b[A\n",
            "Epoch 3:  64%|██████▍   | 309/484 [40:26<23:47,  8.15s/it, training_loss=0.010]\u001b[A\n",
            "Epoch 3:  64%|██████▍   | 309/484 [40:33<23:47,  8.15s/it, training_loss=0.283]\u001b[A\n",
            "Epoch 3:  64%|██████▍   | 310/484 [40:33<22:11,  7.65s/it, training_loss=0.283]\u001b[A\n",
            "Epoch 3:  64%|██████▍   | 310/484 [40:41<22:11,  7.65s/it, training_loss=0.319]\u001b[A\n",
            "Epoch 3:  64%|██████▍   | 311/484 [40:41<23:01,  7.99s/it, training_loss=0.319]\u001b[A\n",
            "Epoch 3:  64%|██████▍   | 311/484 [40:49<23:01,  7.99s/it, training_loss=0.101]\u001b[A\n",
            "Epoch 3:  64%|██████▍   | 312/484 [40:49<22:24,  7.82s/it, training_loss=0.101]\u001b[A\n",
            "Epoch 3:  64%|██████▍   | 312/484 [40:56<22:24,  7.82s/it, training_loss=0.035]\u001b[A\n",
            "Epoch 3:  65%|██████▍   | 313/484 [40:56<21:37,  7.59s/it, training_loss=0.035]\u001b[A\n",
            "Epoch 3:  65%|██████▍   | 313/484 [41:05<21:37,  7.59s/it, training_loss=0.011]\u001b[A\n",
            "Epoch 3:  65%|██████▍   | 314/484 [41:05<22:35,  7.98s/it, training_loss=0.011]\u001b[A\n",
            "Epoch 3:  65%|██████▍   | 314/484 [41:11<22:35,  7.98s/it, training_loss=0.002]\u001b[A\n",
            "Epoch 3:  65%|██████▌   | 315/484 [41:11<21:13,  7.53s/it, training_loss=0.002]\u001b[A\n",
            "Epoch 3:  65%|██████▌   | 315/484 [41:21<21:13,  7.53s/it, training_loss=0.105]\u001b[A\n",
            "Epoch 3:  65%|██████▌   | 316/484 [41:21<22:49,  8.15s/it, training_loss=0.105]\u001b[A\n",
            "Epoch 3:  65%|██████▌   | 316/484 [41:27<22:49,  8.15s/it, training_loss=0.004]\u001b[A\n",
            "Epoch 3:  65%|██████▌   | 317/484 [41:27<21:19,  7.66s/it, training_loss=0.004]\u001b[A\n",
            "Epoch 3:  65%|██████▌   | 317/484 [41:36<21:19,  7.66s/it, training_loss=0.053]\u001b[A\n",
            "Epoch 3:  66%|██████▌   | 318/484 [41:36<21:44,  7.86s/it, training_loss=0.053]\u001b[A\n",
            "Epoch 3:  66%|██████▌   | 318/484 [41:43<21:44,  7.86s/it, training_loss=0.002]\u001b[A\n",
            "Epoch 3:  66%|██████▌   | 319/484 [41:43<21:23,  7.78s/it, training_loss=0.002]\u001b[A\n",
            "Epoch 3:  66%|██████▌   | 319/484 [41:50<21:23,  7.78s/it, training_loss=0.004]\u001b[A\n",
            "Epoch 3:  66%|██████▌   | 320/484 [41:50<20:20,  7.44s/it, training_loss=0.004]\u001b[A\n",
            "Epoch 3:  66%|██████▌   | 320/484 [41:59<20:20,  7.44s/it, training_loss=0.028]\u001b[A\n",
            "Epoch 3:  66%|██████▋   | 321/484 [41:59<21:40,  7.98s/it, training_loss=0.028]\u001b[A\n",
            "Epoch 3:  66%|██████▋   | 321/484 [42:06<21:40,  7.98s/it, training_loss=0.005]\u001b[A\n",
            "Epoch 3:  67%|██████▋   | 322/484 [42:06<20:20,  7.53s/it, training_loss=0.005]\u001b[A\n",
            "Epoch 3:  67%|██████▋   | 322/484 [42:15<20:20,  7.53s/it, training_loss=0.228]\u001b[A\n",
            "Epoch 3:  67%|██████▋   | 323/484 [42:15<21:35,  8.05s/it, training_loss=0.228]\u001b[A\n",
            "Epoch 3:  67%|██████▋   | 323/484 [42:22<21:35,  8.05s/it, training_loss=0.003]\u001b[A\n",
            "Epoch 3:  67%|██████▋   | 324/484 [42:22<20:26,  7.66s/it, training_loss=0.003]\u001b[A\n",
            "Epoch 3:  67%|██████▋   | 324/484 [42:29<20:26,  7.66s/it, training_loss=0.413]\u001b[A\n",
            "Epoch 3:  67%|██████▋   | 325/484 [42:29<20:20,  7.68s/it, training_loss=0.413]\u001b[A\n",
            "Epoch 3:  67%|██████▋   | 325/484 [42:37<20:20,  7.68s/it, training_loss=0.030]\u001b[A\n",
            "Epoch 3:  67%|██████▋   | 326/484 [42:37<20:37,  7.83s/it, training_loss=0.030]\u001b[A\n",
            "Epoch 3:  67%|██████▋   | 326/484 [42:44<20:37,  7.83s/it, training_loss=0.002]\u001b[A\n",
            "Epoch 3:  68%|██████▊   | 327/484 [42:44<19:29,  7.45s/it, training_loss=0.002]\u001b[A\n",
            "Epoch 3:  68%|██████▊   | 327/484 [42:54<19:29,  7.45s/it, training_loss=0.004]\u001b[A\n",
            "Epoch 3:  68%|██████▊   | 328/484 [42:54<21:04,  8.11s/it, training_loss=0.004]\u001b[A\n",
            "Epoch 3:  68%|██████▊   | 328/484 [43:00<21:04,  8.11s/it, training_loss=0.004]\u001b[A\n",
            "Epoch 3:  68%|██████▊   | 329/484 [43:00<19:42,  7.63s/it, training_loss=0.004]\u001b[A\n",
            "Epoch 3:  68%|██████▊   | 329/484 [43:09<19:42,  7.63s/it, training_loss=0.004]\u001b[A\n",
            "Epoch 3:  68%|██████▊   | 330/484 [43:09<20:41,  8.06s/it, training_loss=0.004]\u001b[A\n",
            "Epoch 3:  68%|██████▊   | 330/484 [43:16<20:41,  8.06s/it, training_loss=0.002]\u001b[A\n",
            "Epoch 3:  68%|██████▊   | 331/484 [43:16<19:49,  7.77s/it, training_loss=0.002]\u001b[A\n",
            "Epoch 3:  68%|██████▊   | 331/484 [43:24<19:49,  7.77s/it, training_loss=0.478]\u001b[A\n",
            "Epoch 3:  69%|██████▊   | 332/484 [43:24<19:31,  7.71s/it, training_loss=0.478]\u001b[A\n",
            "Epoch 3:  69%|██████▊   | 332/484 [43:32<19:31,  7.71s/it, training_loss=0.197]\u001b[A\n",
            "Epoch 3:  69%|██████▉   | 333/484 [43:32<19:52,  7.90s/it, training_loss=0.197]\u001b[A\n",
            "Epoch 3:  69%|██████▉   | 333/484 [43:39<19:52,  7.90s/it, training_loss=0.002]\u001b[A\n",
            "Epoch 3:  69%|██████▉   | 334/484 [43:39<18:44,  7.49s/it, training_loss=0.002]\u001b[A\n",
            "Epoch 3:  69%|██████▉   | 334/484 [43:49<18:44,  7.49s/it, training_loss=0.002]\u001b[A\n",
            "Epoch 3:  69%|██████▉   | 335/484 [43:49<20:14,  8.15s/it, training_loss=0.002]\u001b[A\n",
            "Epoch 3:  69%|██████▉   | 335/484 [43:55<20:14,  8.15s/it, training_loss=0.189]\u001b[A\n",
            "Epoch 3:  69%|██████▉   | 336/484 [43:55<18:53,  7.66s/it, training_loss=0.189]\u001b[A\n",
            "Epoch 3:  69%|██████▉   | 336/484 [44:04<18:53,  7.66s/it, training_loss=0.005]\u001b[A\n",
            "Epoch 3:  70%|██████▉   | 337/484 [44:04<19:41,  8.04s/it, training_loss=0.005]\u001b[A\n",
            "Epoch 3:  70%|██████▉   | 337/484 [44:11<19:41,  8.04s/it, training_loss=0.098]\u001b[A\n",
            "Epoch 3:  70%|██████▉   | 338/484 [44:11<18:58,  7.80s/it, training_loss=0.098]\u001b[A\n",
            "Epoch 3:  70%|██████▉   | 338/484 [44:18<18:58,  7.80s/it, training_loss=0.012]\u001b[A\n",
            "Epoch 3:  70%|███████   | 339/484 [44:18<18:26,  7.63s/it, training_loss=0.012]\u001b[A\n",
            "Epoch 3:  70%|███████   | 339/484 [44:27<18:26,  7.63s/it, training_loss=0.055]\u001b[A\n",
            "Epoch 3:  70%|███████   | 340/484 [44:27<19:02,  7.93s/it, training_loss=0.055]\u001b[A\n",
            "Epoch 3:  70%|███████   | 340/484 [44:34<19:02,  7.93s/it, training_loss=0.026]\u001b[A\n",
            "Epoch 3:  70%|███████   | 341/484 [44:34<17:55,  7.52s/it, training_loss=0.026]\u001b[A\n",
            "Epoch 3:  70%|███████   | 341/484 [44:43<17:55,  7.52s/it, training_loss=0.133]\u001b[A\n",
            "Epoch 3:  71%|███████   | 342/484 [44:43<19:23,  8.19s/it, training_loss=0.133]\u001b[A\n",
            "Epoch 3:  71%|███████   | 342/484 [44:50<19:23,  8.19s/it, training_loss=0.207]\u001b[A\n",
            "Epoch 3:  71%|███████   | 343/484 [44:50<18:07,  7.72s/it, training_loss=0.207]\u001b[A\n",
            "Epoch 3:  71%|███████   | 343/484 [44:59<18:07,  7.72s/it, training_loss=0.061]\u001b[A\n",
            "Epoch 3:  71%|███████   | 344/484 [44:59<18:44,  8.04s/it, training_loss=0.061]\u001b[A\n",
            "Epoch 3:  71%|███████   | 344/484 [45:06<18:44,  8.04s/it, training_loss=0.001]\u001b[A\n",
            "Epoch 3:  71%|███████▏  | 345/484 [45:06<18:11,  7.85s/it, training_loss=0.001]\u001b[A\n",
            "Epoch 3:  71%|███████▏  | 345/484 [45:13<18:11,  7.85s/it, training_loss=0.049]\u001b[A\n",
            "Epoch 3:  71%|███████▏  | 346/484 [45:13<17:34,  7.64s/it, training_loss=0.049]\u001b[A\n",
            "Epoch 3:  71%|███████▏  | 346/484 [45:22<17:34,  7.64s/it, training_loss=0.054]\u001b[A\n",
            "Epoch 3:  72%|███████▏  | 347/484 [45:22<18:13,  7.98s/it, training_loss=0.054]\u001b[A\n",
            "Epoch 3:  72%|███████▏  | 347/484 [45:29<18:13,  7.98s/it, training_loss=0.006]\u001b[A\n",
            "Epoch 3:  72%|███████▏  | 348/484 [45:29<17:04,  7.53s/it, training_loss=0.006]\u001b[A\n",
            "Epoch 3:  72%|███████▏  | 348/484 [45:38<17:04,  7.53s/it, training_loss=0.143]\u001b[A\n",
            "Epoch 3:  72%|███████▏  | 349/484 [45:38<18:17,  8.13s/it, training_loss=0.143]\u001b[A\n",
            "Epoch 3:  72%|███████▏  | 349/484 [45:45<18:17,  8.13s/it, training_loss=0.028]\u001b[A\n",
            "Epoch 3:  72%|███████▏  | 350/484 [45:45<17:04,  7.64s/it, training_loss=0.028]\u001b[A\n",
            "Epoch 3:  72%|███████▏  | 350/484 [45:53<17:04,  7.64s/it, training_loss=0.006]\u001b[A\n",
            "Epoch 3:  73%|███████▎  | 351/484 [45:53<17:26,  7.87s/it, training_loss=0.006]\u001b[A\n",
            "Epoch 3:  73%|███████▎  | 351/484 [46:01<17:26,  7.87s/it, training_loss=0.084]\u001b[A\n",
            "Epoch 3:  73%|███████▎  | 352/484 [46:01<17:08,  7.79s/it, training_loss=0.084]\u001b[A\n",
            "Epoch 3:  73%|███████▎  | 352/484 [46:07<17:08,  7.79s/it, training_loss=0.019]\u001b[A\n",
            "Epoch 3:  73%|███████▎  | 353/484 [46:07<16:17,  7.47s/it, training_loss=0.019]\u001b[A\n",
            "Epoch 3:  73%|███████▎  | 353/484 [46:16<16:17,  7.47s/it, training_loss=0.002]\u001b[A\n",
            "Epoch 3:  73%|███████▎  | 354/484 [46:16<17:14,  7.96s/it, training_loss=0.002]\u001b[A\n",
            "Epoch 3:  73%|███████▎  | 354/484 [46:23<17:14,  7.96s/it, training_loss=0.193]\u001b[A\n",
            "Epoch 3:  73%|███████▎  | 355/484 [46:23<16:11,  7.53s/it, training_loss=0.193]\u001b[A\n",
            "Epoch 3:  73%|███████▎  | 355/484 [46:32<16:11,  7.53s/it, training_loss=0.001]\u001b[A\n",
            "Epoch 3:  74%|███████▎  | 356/484 [46:32<17:18,  8.11s/it, training_loss=0.001]\u001b[A\n",
            "Epoch 3:  74%|███████▎  | 356/484 [46:39<17:18,  8.11s/it, training_loss=0.012]\u001b[A\n",
            "Epoch 3:  74%|███████▍  | 357/484 [46:39<16:16,  7.69s/it, training_loss=0.012]\u001b[A\n",
            "Epoch 3:  74%|███████▍  | 357/484 [46:47<16:16,  7.69s/it, training_loss=0.010]\u001b[A\n",
            "Epoch 3:  74%|███████▍  | 358/484 [46:47<16:21,  7.79s/it, training_loss=0.010]\u001b[A\n",
            "Epoch 3:  74%|███████▍  | 358/484 [46:55<16:21,  7.79s/it, training_loss=0.211]\u001b[A\n",
            "Epoch 3:  74%|███████▍  | 359/484 [46:55<16:17,  7.82s/it, training_loss=0.211]\u001b[A\n",
            "Epoch 3:  74%|███████▍  | 359/484 [47:02<16:17,  7.82s/it, training_loss=0.029]\u001b[A\n",
            "Epoch 3:  74%|███████▍  | 360/484 [47:02<15:23,  7.45s/it, training_loss=0.029]\u001b[A\n",
            "Epoch 3:  74%|███████▍  | 360/484 [47:11<15:23,  7.45s/it, training_loss=0.253]\u001b[A\n",
            "Epoch 3:  75%|███████▍  | 361/484 [47:11<16:33,  8.07s/it, training_loss=0.253]\u001b[A\n",
            "Epoch 3:  75%|███████▍  | 361/484 [47:18<16:33,  8.07s/it, training_loss=0.137]\u001b[A\n",
            "Epoch 3:  75%|███████▍  | 362/484 [47:18<15:28,  7.61s/it, training_loss=0.137]\u001b[A\n",
            "Epoch 3:  75%|███████▍  | 362/484 [47:27<15:28,  7.61s/it, training_loss=0.287]\u001b[A\n",
            "Epoch 3:  75%|███████▌  | 363/484 [47:27<16:18,  8.08s/it, training_loss=0.287]\u001b[A\n",
            "Epoch 3:  75%|███████▌  | 363/484 [47:34<16:18,  8.08s/it, training_loss=0.002]\u001b[A\n",
            "Epoch 3:  75%|███████▌  | 364/484 [47:34<15:26,  7.72s/it, training_loss=0.002]\u001b[A\n",
            "Epoch 3:  75%|███████▌  | 364/484 [47:41<15:26,  7.72s/it, training_loss=0.022]\u001b[A\n",
            "Epoch 3:  75%|███████▌  | 365/484 [47:41<15:17,  7.71s/it, training_loss=0.022]\u001b[A\n",
            "Epoch 3:  75%|███████▌  | 365/484 [47:50<15:17,  7.71s/it, training_loss=0.002]\u001b[A\n",
            "Epoch 3:  76%|███████▌  | 366/484 [47:50<15:26,  7.85s/it, training_loss=0.002]\u001b[A\n",
            "Epoch 3:  76%|███████▌  | 366/484 [47:56<15:26,  7.85s/it, training_loss=0.002]\u001b[A\n",
            "Epoch 3:  76%|███████▌  | 367/484 [47:56<14:29,  7.43s/it, training_loss=0.002]\u001b[A\n",
            "Epoch 3:  76%|███████▌  | 367/484 [48:06<14:29,  7.43s/it, training_loss=0.384]\u001b[A\n",
            "Epoch 3:  76%|███████▌  | 368/484 [48:06<15:38,  8.09s/it, training_loss=0.384]\u001b[A\n",
            "Epoch 3:  76%|███████▌  | 368/484 [48:12<15:38,  8.09s/it, training_loss=0.293]\u001b[A\n",
            "Epoch 3:  76%|███████▌  | 369/484 [48:12<14:35,  7.62s/it, training_loss=0.293]\u001b[A\n",
            "Epoch 3:  76%|███████▌  | 369/484 [48:21<14:35,  7.62s/it, training_loss=0.033]\u001b[A\n",
            "Epoch 3:  76%|███████▋  | 370/484 [48:21<15:14,  8.02s/it, training_loss=0.033]\u001b[A\n",
            "Epoch 3:  76%|███████▋  | 370/484 [48:28<15:14,  8.02s/it, training_loss=0.002]\u001b[A\n",
            "Epoch 3:  77%|███████▋  | 371/484 [48:28<14:36,  7.76s/it, training_loss=0.002]\u001b[A\n",
            "Epoch 3:  77%|███████▋  | 371/484 [48:36<14:36,  7.76s/it, training_loss=0.393]\u001b[A\n",
            "Epoch 3:  77%|███████▋  | 372/484 [48:36<14:16,  7.65s/it, training_loss=0.393]\u001b[A\n",
            "Epoch 3:  77%|███████▋  | 372/484 [48:44<14:16,  7.65s/it, training_loss=0.002]\u001b[A\n",
            "Epoch 3:  77%|███████▋  | 373/484 [48:44<14:39,  7.93s/it, training_loss=0.002]\u001b[A\n",
            "Epoch 3:  77%|███████▋  | 373/484 [48:51<14:39,  7.93s/it, training_loss=0.002]\u001b[A\n",
            "Epoch 3:  77%|███████▋  | 374/484 [48:51<13:46,  7.51s/it, training_loss=0.002]\u001b[A\n",
            "Epoch 3:  77%|███████▋  | 374/484 [49:01<13:46,  7.51s/it, training_loss=0.173]\u001b[A\n",
            "Epoch 3:  77%|███████▋  | 375/484 [49:01<14:50,  8.17s/it, training_loss=0.173]\u001b[A\n",
            "Epoch 3:  77%|███████▋  | 375/484 [49:07<14:50,  8.17s/it, training_loss=0.052]\u001b[A\n",
            "Epoch 3:  78%|███████▊  | 376/484 [49:07<13:48,  7.68s/it, training_loss=0.052]\u001b[A\n",
            "Epoch 3:  78%|███████▊  | 376/484 [49:16<13:48,  7.68s/it, training_loss=0.330]\u001b[A\n",
            "Epoch 3:  78%|███████▊  | 377/484 [49:16<14:20,  8.04s/it, training_loss=0.330]\u001b[A\n",
            "Epoch 3:  78%|███████▊  | 377/484 [49:23<14:20,  8.04s/it, training_loss=0.130]\u001b[A\n",
            "Epoch 3:  78%|███████▊  | 378/484 [49:23<13:45,  7.79s/it, training_loss=0.130]\u001b[A\n",
            "Epoch 3:  78%|███████▊  | 378/484 [49:30<13:45,  7.79s/it, training_loss=0.018]\u001b[A\n",
            "Epoch 3:  78%|███████▊  | 379/484 [49:30<13:21,  7.63s/it, training_loss=0.018]\u001b[A\n",
            "Epoch 3:  78%|███████▊  | 379/484 [49:39<13:21,  7.63s/it, training_loss=0.019]\u001b[A\n",
            "Epoch 3:  79%|███████▊  | 380/484 [49:39<13:46,  7.95s/it, training_loss=0.019]\u001b[A\n",
            "Epoch 3:  79%|███████▊  | 380/484 [49:46<13:46,  7.95s/it, training_loss=0.249]\u001b[A\n",
            "Epoch 3:  79%|███████▊  | 381/484 [49:46<12:57,  7.55s/it, training_loss=0.249]\u001b[A\n",
            "Epoch 3:  79%|███████▊  | 381/484 [49:56<12:57,  7.55s/it, training_loss=0.049]\u001b[A\n",
            "Epoch 3:  79%|███████▉  | 382/484 [49:56<13:58,  8.22s/it, training_loss=0.049]\u001b[A\n",
            "Epoch 3:  79%|███████▉  | 382/484 [50:02<13:58,  8.22s/it, training_loss=0.009]\u001b[A\n",
            "Epoch 3:  79%|███████▉  | 383/484 [50:02<13:00,  7.73s/it, training_loss=0.009]\u001b[A\n",
            "Epoch 3:  79%|███████▉  | 383/484 [50:11<13:00,  7.73s/it, training_loss=0.046]\u001b[A\n",
            "Epoch 3:  79%|███████▉  | 384/484 [50:11<13:22,  8.02s/it, training_loss=0.046]\u001b[A\n",
            "Epoch 3:  79%|███████▉  | 384/484 [50:18<13:22,  8.02s/it, training_loss=0.006]\u001b[A\n",
            "Epoch 3:  80%|███████▉  | 385/484 [50:18<12:56,  7.85s/it, training_loss=0.006]\u001b[A\n",
            "Epoch 3:  80%|███████▉  | 385/484 [50:25<12:56,  7.85s/it, training_loss=0.007]\u001b[A\n",
            "Epoch 3:  80%|███████▉  | 386/484 [50:25<12:24,  7.60s/it, training_loss=0.007]\u001b[A\n",
            "Epoch 3:  80%|███████▉  | 386/484 [50:34<12:24,  7.60s/it, training_loss=0.181]\u001b[A\n",
            "Epoch 3:  80%|███████▉  | 387/484 [50:34<12:56,  8.01s/it, training_loss=0.181]\u001b[A\n",
            "Epoch 3:  80%|███████▉  | 387/484 [50:41<12:56,  8.01s/it, training_loss=0.002]\u001b[A\n",
            "Epoch 3:  80%|████████  | 388/484 [50:41<12:06,  7.57s/it, training_loss=0.002]\u001b[A\n",
            "Epoch 3:  80%|████████  | 388/484 [50:51<12:06,  7.57s/it, training_loss=0.010]\u001b[A\n",
            "Epoch 3:  80%|████████  | 389/484 [50:51<13:01,  8.23s/it, training_loss=0.010]\u001b[A\n",
            "Epoch 3:  80%|████████  | 389/484 [50:57<13:01,  8.23s/it, training_loss=0.001]\u001b[A\n",
            "Epoch 3:  81%|████████  | 390/484 [50:57<12:06,  7.72s/it, training_loss=0.001]\u001b[A\n",
            "Epoch 3:  81%|████████  | 390/484 [51:06<12:06,  7.72s/it, training_loss=0.003]\u001b[A\n",
            "Epoch 3:  81%|████████  | 391/484 [51:06<12:20,  7.97s/it, training_loss=0.003]\u001b[A\n",
            "Epoch 3:  81%|████████  | 391/484 [51:13<12:20,  7.97s/it, training_loss=0.131]\u001b[A\n",
            "Epoch 3:  81%|████████  | 392/484 [51:13<12:03,  7.87s/it, training_loss=0.131]\u001b[A\n",
            "Epoch 3:  81%|████████  | 392/484 [51:20<12:03,  7.87s/it, training_loss=0.088]\u001b[A\n",
            "Epoch 3:  81%|████████  | 393/484 [51:20<11:26,  7.54s/it, training_loss=0.088]\u001b[A\n",
            "Epoch 3:  81%|████████  | 393/484 [51:29<11:26,  7.54s/it, training_loss=0.130]\u001b[A\n",
            "Epoch 3:  81%|████████▏ | 394/484 [51:29<12:03,  8.04s/it, training_loss=0.130]\u001b[A\n",
            "Epoch 3:  81%|████████▏ | 394/484 [51:36<12:03,  8.04s/it, training_loss=0.003]\u001b[A\n",
            "Epoch 3:  82%|████████▏ | 395/484 [51:36<11:18,  7.63s/it, training_loss=0.003]\u001b[A\n",
            "Epoch 3:  82%|████████▏ | 395/484 [51:45<11:18,  7.63s/it, training_loss=0.004]\u001b[A\n",
            "Epoch 3:  82%|████████▏ | 396/484 [51:45<12:02,  8.21s/it, training_loss=0.004]\u001b[A\n",
            "Epoch 3:  82%|████████▏ | 396/484 [51:52<12:02,  8.21s/it, training_loss=0.027]\u001b[A\n",
            "Epoch 3:  82%|████████▏ | 397/484 [51:52<11:11,  7.71s/it, training_loss=0.027]\u001b[A\n",
            "Epoch 3:  82%|████████▏ | 397/484 [52:00<11:11,  7.71s/it, training_loss=0.004]\u001b[A\n",
            "Epoch 3:  82%|████████▏ | 398/484 [52:00<11:16,  7.87s/it, training_loss=0.004]\u001b[A\n",
            "Epoch 3:  82%|████████▏ | 398/484 [52:08<11:16,  7.87s/it, training_loss=0.003]\u001b[A\n",
            "Epoch 3:  82%|████████▏ | 399/484 [52:08<11:06,  7.84s/it, training_loss=0.003]\u001b[A\n",
            "Epoch 3:  82%|████████▏ | 399/484 [52:15<11:06,  7.84s/it, training_loss=0.002]\u001b[A\n",
            "Epoch 3:  83%|████████▎ | 400/484 [52:15<10:27,  7.47s/it, training_loss=0.002]\u001b[A\n",
            "Epoch 3:  83%|████████▎ | 400/484 [52:24<10:27,  7.47s/it, training_loss=0.070]\u001b[A\n",
            "Epoch 3:  83%|████████▎ | 401/484 [52:24<11:08,  8.05s/it, training_loss=0.070]\u001b[A\n",
            "Epoch 3:  83%|████████▎ | 401/484 [52:31<11:08,  8.05s/it, training_loss=0.179]\u001b[A\n",
            "Epoch 3:  83%|████████▎ | 402/484 [52:31<10:23,  7.60s/it, training_loss=0.179]\u001b[A\n",
            "Epoch 3:  83%|████████▎ | 402/484 [52:40<10:23,  7.60s/it, training_loss=0.003]\u001b[A\n",
            "Epoch 3:  83%|████████▎ | 403/484 [52:40<10:54,  8.08s/it, training_loss=0.003]\u001b[A\n",
            "Epoch 3:  83%|████████▎ | 403/484 [52:47<10:54,  8.08s/it, training_loss=0.003]\u001b[A\n",
            "Epoch 3:  83%|████████▎ | 404/484 [52:47<10:20,  7.75s/it, training_loss=0.003]\u001b[A\n",
            "Epoch 3:  83%|████████▎ | 404/484 [52:55<10:20,  7.75s/it, training_loss=0.005]\u001b[A\n",
            "Epoch 3:  84%|████████▎ | 405/484 [52:55<10:13,  7.77s/it, training_loss=0.005]\u001b[A\n",
            "Epoch 3:  84%|████████▎ | 405/484 [53:03<10:13,  7.77s/it, training_loss=0.112]\u001b[A\n",
            "Epoch 3:  84%|████████▍ | 406/484 [53:03<10:15,  7.89s/it, training_loss=0.112]\u001b[A\n",
            "Epoch 3:  84%|████████▍ | 406/484 [53:09<10:15,  7.89s/it, training_loss=0.030]\u001b[A\n",
            "Epoch 3:  84%|████████▍ | 407/484 [53:09<09:39,  7.53s/it, training_loss=0.030]\u001b[A\n",
            "Epoch 3:  84%|████████▍ | 407/484 [53:19<09:39,  7.53s/it, training_loss=0.046]\u001b[A\n",
            "Epoch 3:  84%|████████▍ | 408/484 [53:19<10:21,  8.17s/it, training_loss=0.046]\u001b[A\n",
            "Epoch 3:  84%|████████▍ | 408/484 [53:26<10:21,  8.17s/it, training_loss=0.001]\u001b[A\n",
            "Epoch 3:  85%|████████▍ | 409/484 [53:26<09:36,  7.69s/it, training_loss=0.001]\u001b[A\n",
            "Epoch 3:  85%|████████▍ | 409/484 [53:35<09:36,  7.69s/it, training_loss=0.002]\u001b[A\n",
            "Epoch 3:  85%|████████▍ | 410/484 [53:35<09:59,  8.10s/it, training_loss=0.002]\u001b[A\n",
            "Epoch 3:  85%|████████▍ | 410/484 [53:42<09:59,  8.10s/it, training_loss=0.011]\u001b[A\n",
            "Epoch 3:  85%|████████▍ | 411/484 [53:42<09:27,  7.77s/it, training_loss=0.011]\u001b[A\n",
            "Epoch 3:  85%|████████▍ | 411/484 [53:49<09:27,  7.77s/it, training_loss=0.002]\u001b[A\n",
            "Epoch 3:  85%|████████▌ | 412/484 [53:49<09:14,  7.71s/it, training_loss=0.002]\u001b[A\n",
            "Epoch 3:  85%|████████▌ | 412/484 [53:58<09:14,  7.71s/it, training_loss=0.002]\u001b[A\n",
            "Epoch 3:  85%|████████▌ | 413/484 [53:58<09:21,  7.91s/it, training_loss=0.002]\u001b[A\n",
            "Epoch 3:  85%|████████▌ | 413/484 [54:04<09:21,  7.91s/it, training_loss=0.003]\u001b[A\n",
            "Epoch 3:  86%|████████▌ | 414/484 [54:04<08:44,  7.50s/it, training_loss=0.003]\u001b[A\n",
            "Epoch 3:  86%|████████▌ | 414/484 [54:14<08:44,  7.50s/it, training_loss=0.002]\u001b[A\n",
            "Epoch 3:  86%|████████▌ | 415/484 [54:14<09:24,  8.18s/it, training_loss=0.002]\u001b[A\n",
            "Epoch 3:  86%|████████▌ | 415/484 [54:21<09:24,  8.18s/it, training_loss=0.154]\u001b[A\n",
            "Epoch 3:  86%|████████▌ | 416/484 [54:21<08:42,  7.69s/it, training_loss=0.154]\u001b[A\n",
            "Epoch 3:  86%|████████▌ | 416/484 [54:29<08:42,  7.69s/it, training_loss=0.015]\u001b[A\n",
            "Epoch 3:  86%|████████▌ | 417/484 [54:29<08:59,  8.06s/it, training_loss=0.015]\u001b[A\n",
            "Epoch 3:  86%|████████▌ | 417/484 [54:37<08:59,  8.06s/it, training_loss=0.070]\u001b[A\n",
            "Epoch 3:  86%|████████▋ | 418/484 [54:37<08:35,  7.81s/it, training_loss=0.070]\u001b[A\n",
            "Epoch 3:  86%|████████▋ | 418/484 [54:44<08:35,  7.81s/it, training_loss=0.002]\u001b[A\n",
            "Epoch 3:  87%|████████▋ | 419/484 [54:44<08:21,  7.72s/it, training_loss=0.002]\u001b[A\n",
            "Epoch 3:  87%|████████▋ | 419/484 [54:53<08:21,  7.72s/it, training_loss=0.075]\u001b[A\n",
            "Epoch 3:  87%|████████▋ | 420/484 [54:53<08:29,  7.97s/it, training_loss=0.075]\u001b[A\n",
            "Epoch 3:  87%|████████▋ | 420/484 [54:59<08:29,  7.97s/it, training_loss=0.199]\u001b[A\n",
            "Epoch 3:  87%|████████▋ | 421/484 [54:59<07:54,  7.54s/it, training_loss=0.199]\u001b[A\n",
            "Epoch 3:  87%|████████▋ | 421/484 [55:09<07:54,  7.54s/it, training_loss=0.016]\u001b[A\n",
            "Epoch 3:  87%|████████▋ | 422/484 [55:09<08:28,  8.20s/it, training_loss=0.016]\u001b[A\n",
            "Epoch 3:  87%|████████▋ | 422/484 [55:16<08:28,  8.20s/it, training_loss=0.259]\u001b[A\n",
            "Epoch 3:  87%|████████▋ | 423/484 [55:16<07:49,  7.70s/it, training_loss=0.259]\u001b[A\n",
            "Epoch 3:  87%|████████▋ | 423/484 [55:24<07:49,  7.70s/it, training_loss=0.148]\u001b[A\n",
            "Epoch 3:  88%|████████▊ | 424/484 [55:24<08:01,  8.02s/it, training_loss=0.148]\u001b[A\n",
            "Epoch 3:  88%|████████▊ | 424/484 [55:32<08:01,  8.02s/it, training_loss=0.035]\u001b[A\n",
            "Epoch 3:  88%|████████▊ | 425/484 [55:32<07:39,  7.80s/it, training_loss=0.035]\u001b[A\n",
            "Epoch 3:  88%|████████▊ | 425/484 [55:39<07:39,  7.80s/it, training_loss=0.002]\u001b[A\n",
            "Epoch 3:  88%|████████▊ | 426/484 [55:39<07:21,  7.62s/it, training_loss=0.002]\u001b[A\n",
            "Epoch 3:  88%|████████▊ | 426/484 [55:48<07:21,  7.62s/it, training_loss=0.002]\u001b[A\n",
            "Epoch 3:  88%|████████▊ | 427/484 [55:48<07:34,  7.97s/it, training_loss=0.002]\u001b[A\n",
            "Epoch 3:  88%|████████▊ | 427/484 [55:54<07:34,  7.97s/it, training_loss=0.002]\u001b[A\n",
            "Epoch 3:  88%|████████▊ | 428/484 [55:54<07:02,  7.54s/it, training_loss=0.002]\u001b[A\n",
            "Epoch 3:  88%|████████▊ | 428/484 [56:04<07:02,  7.54s/it, training_loss=0.002]\u001b[A\n",
            "Epoch 3:  89%|████████▊ | 429/484 [56:04<07:29,  8.17s/it, training_loss=0.002]\u001b[A\n",
            "Epoch 3:  89%|████████▊ | 429/484 [56:10<07:29,  8.17s/it, training_loss=0.063]\u001b[A\n",
            "Epoch 3:  89%|████████▉ | 430/484 [56:10<06:54,  7.67s/it, training_loss=0.063]\u001b[A\n",
            "Epoch 3:  89%|████████▉ | 430/484 [56:19<06:54,  7.67s/it, training_loss=0.008]\u001b[A\n",
            "Epoch 3:  89%|████████▉ | 431/484 [56:19<07:01,  7.94s/it, training_loss=0.008]\u001b[A\n",
            "Epoch 3:  89%|████████▉ | 431/484 [56:26<07:01,  7.94s/it, training_loss=0.030]\u001b[A\n",
            "Epoch 3:  89%|████████▉ | 432/484 [56:26<06:46,  7.82s/it, training_loss=0.030]\u001b[A\n",
            "Epoch 3:  89%|████████▉ | 432/484 [56:33<06:46,  7.82s/it, training_loss=0.066]\u001b[A\n",
            "Epoch 3:  89%|████████▉ | 433/484 [56:33<06:25,  7.56s/it, training_loss=0.066]\u001b[A\n",
            "Epoch 3:  89%|████████▉ | 433/484 [56:42<06:25,  7.56s/it, training_loss=0.313]\u001b[A\n",
            "Epoch 3:  90%|████████▉ | 434/484 [56:42<06:39,  8.00s/it, training_loss=0.313]\u001b[A\n",
            "Epoch 3:  90%|████████▉ | 434/484 [56:49<06:39,  8.00s/it, training_loss=0.010]\u001b[A\n",
            "Epoch 3:  90%|████████▉ | 435/484 [56:49<06:10,  7.56s/it, training_loss=0.010]\u001b[A\n",
            "Epoch 3:  90%|████████▉ | 435/484 [56:58<06:10,  7.56s/it, training_loss=0.002]\u001b[A\n",
            "Epoch 3:  90%|█████████ | 436/484 [56:58<06:32,  8.17s/it, training_loss=0.002]\u001b[A\n",
            "Epoch 3:  90%|█████████ | 436/484 [57:05<06:32,  8.17s/it, training_loss=0.013]\u001b[A\n",
            "Epoch 3:  90%|█████████ | 437/484 [57:05<06:01,  7.68s/it, training_loss=0.013]\u001b[A\n",
            "Epoch 3:  90%|█████████ | 437/484 [57:13<06:01,  7.68s/it, training_loss=0.002]\u001b[A\n",
            "Epoch 3:  90%|█████████ | 438/484 [57:13<06:02,  7.88s/it, training_loss=0.002]\u001b[A\n",
            "Epoch 3:  90%|█████████ | 438/484 [57:21<06:02,  7.88s/it, training_loss=0.002]\u001b[A\n",
            "Epoch 3:  91%|█████████ | 439/484 [57:21<05:52,  7.83s/it, training_loss=0.002]\u001b[A\n",
            "Epoch 3:  91%|█████████ | 439/484 [57:28<05:52,  7.83s/it, training_loss=0.003]\u001b[A\n",
            "Epoch 3:  91%|█████████ | 440/484 [57:28<05:28,  7.47s/it, training_loss=0.003]\u001b[A\n",
            "Epoch 3:  91%|█████████ | 440/484 [57:37<05:28,  7.47s/it, training_loss=0.002]\u001b[A\n",
            "Epoch 3:  91%|█████████ | 441/484 [57:37<05:44,  8.02s/it, training_loss=0.002]\u001b[A\n",
            "Epoch 3:  91%|█████████ | 441/484 [57:44<05:44,  8.02s/it, training_loss=0.213]\u001b[A\n",
            "Epoch 3:  91%|█████████▏| 442/484 [57:44<05:17,  7.56s/it, training_loss=0.213]\u001b[A\n",
            "Epoch 3:  91%|█████████▏| 442/484 [57:53<05:17,  7.56s/it, training_loss=0.198]\u001b[A\n",
            "Epoch 3:  92%|█████████▏| 443/484 [57:53<05:31,  8.07s/it, training_loss=0.198]\u001b[A\n",
            "Epoch 3:  92%|█████████▏| 443/484 [58:00<05:31,  8.07s/it, training_loss=0.020]\u001b[A\n",
            "Epoch 3:  92%|█████████▏| 444/484 [58:00<05:06,  7.67s/it, training_loss=0.020]\u001b[A\n",
            "Epoch 3:  92%|█████████▏| 444/484 [58:07<05:06,  7.67s/it, training_loss=0.003]\u001b[A\n",
            "Epoch 3:  92%|█████████▏| 445/484 [58:07<05:00,  7.70s/it, training_loss=0.003]\u001b[A\n",
            "Epoch 3:  92%|█████████▏| 445/484 [58:15<05:00,  7.70s/it, training_loss=0.002]\u001b[A\n",
            "Epoch 3:  92%|█████████▏| 446/484 [58:15<04:58,  7.85s/it, training_loss=0.002]\u001b[A\n",
            "Epoch 3:  92%|█████████▏| 446/484 [58:22<04:58,  7.85s/it, training_loss=0.002]\u001b[A\n",
            "Epoch 3:  92%|█████████▏| 447/484 [58:22<04:35,  7.46s/it, training_loss=0.002]\u001b[A\n",
            "Epoch 3:  92%|█████████▏| 447/484 [58:32<04:35,  7.46s/it, training_loss=0.097]\u001b[A\n",
            "Epoch 3:  93%|█████████▎| 448/484 [58:32<04:52,  8.13s/it, training_loss=0.097]\u001b[A\n",
            "Epoch 3:  93%|█████████▎| 448/484 [58:38<04:52,  8.13s/it, training_loss=0.003]\u001b[A\n",
            "Epoch 3:  93%|█████████▎| 449/484 [58:38<04:28,  7.67s/it, training_loss=0.003]\u001b[A\n",
            "Epoch 3:  93%|█████████▎| 449/484 [58:47<04:28,  7.67s/it, training_loss=0.112]\u001b[A\n",
            "Epoch 3:  93%|█████████▎| 450/484 [58:47<04:36,  8.12s/it, training_loss=0.112]\u001b[A\n",
            "Epoch 3:  93%|█████████▎| 450/484 [58:55<04:36,  8.12s/it, training_loss=0.001]\u001b[A\n",
            "Epoch 3:  93%|█████████▎| 451/484 [58:55<04:17,  7.81s/it, training_loss=0.001]\u001b[A\n",
            "Epoch 3:  93%|█████████▎| 451/484 [59:02<04:17,  7.81s/it, training_loss=0.003]\u001b[A\n",
            "Epoch 3:  93%|█████████▎| 452/484 [59:02<04:08,  7.76s/it, training_loss=0.003]\u001b[A\n",
            "Epoch 3:  93%|█████████▎| 452/484 [59:11<04:08,  7.76s/it, training_loss=0.001]\u001b[A\n",
            "Epoch 3:  94%|█████████▎| 453/484 [59:11<04:07,  7.98s/it, training_loss=0.001]\u001b[A\n",
            "Epoch 3:  94%|█████████▎| 453/484 [59:17<04:07,  7.98s/it, training_loss=0.002]\u001b[A\n",
            "Epoch 3:  94%|█████████▍| 454/484 [59:17<03:46,  7.56s/it, training_loss=0.002]\u001b[A\n",
            "Epoch 3:  94%|█████████▍| 454/484 [59:27<03:46,  7.56s/it, training_loss=0.002]\u001b[A\n",
            "Epoch 3:  94%|█████████▍| 455/484 [59:27<03:58,  8.21s/it, training_loss=0.002]\u001b[A\n",
            "Epoch 3:  94%|█████████▍| 455/484 [59:34<03:58,  8.21s/it, training_loss=0.005]\u001b[A\n",
            "Epoch 3:  94%|█████████▍| 456/484 [59:34<03:35,  7.71s/it, training_loss=0.005]\u001b[A\n",
            "Epoch 3:  94%|█████████▍| 456/484 [59:43<03:35,  7.71s/it, training_loss=0.106]\u001b[A\n",
            "Epoch 3:  94%|█████████▍| 457/484 [59:43<03:38,  8.09s/it, training_loss=0.106]\u001b[A\n",
            "Epoch 3:  94%|█████████▍| 457/484 [59:50<03:38,  8.09s/it, training_loss=0.238]\u001b[A\n",
            "Epoch 3:  95%|█████████▍| 458/484 [59:50<03:23,  7.83s/it, training_loss=0.238]\u001b[A\n",
            "Epoch 3:  95%|█████████▍| 458/484 [59:57<03:23,  7.83s/it, training_loss=0.004]\u001b[A\n",
            "Epoch 3:  95%|█████████▍| 459/484 [59:57<03:12,  7.71s/it, training_loss=0.004]\u001b[A\n",
            "Epoch 3:  95%|█████████▍| 459/484 [1:00:06<03:12,  7.71s/it, training_loss=0.066]\u001b[A\n",
            "Epoch 3:  95%|█████████▌| 460/484 [1:00:06<03:11,  7.98s/it, training_loss=0.066]\u001b[A\n",
            "Epoch 3:  95%|█████████▌| 460/484 [1:00:12<03:11,  7.98s/it, training_loss=0.002]\u001b[A\n",
            "Epoch 3:  95%|█████████▌| 461/484 [1:00:12<02:53,  7.56s/it, training_loss=0.002]\u001b[A\n",
            "Epoch 3:  95%|█████████▌| 461/484 [1:00:22<02:53,  7.56s/it, training_loss=0.002]\u001b[A\n",
            "Epoch 3:  95%|█████████▌| 462/484 [1:00:22<03:00,  8.22s/it, training_loss=0.002]\u001b[A\n",
            "Epoch 3:  95%|█████████▌| 462/484 [1:00:29<03:00,  8.22s/it, training_loss=0.061]\u001b[A\n",
            "Epoch 3:  96%|█████████▌| 463/484 [1:00:29<02:42,  7.72s/it, training_loss=0.061]\u001b[A\n",
            "Epoch 3:  96%|█████████▌| 463/484 [1:00:38<02:42,  7.72s/it, training_loss=0.007]\u001b[A\n",
            "Epoch 3:  96%|█████████▌| 464/484 [1:00:38<02:41,  8.06s/it, training_loss=0.007]\u001b[A\n",
            "Epoch 3:  96%|█████████▌| 464/484 [1:00:45<02:41,  8.06s/it, training_loss=0.233]\u001b[A\n",
            "Epoch 3:  96%|█████████▌| 465/484 [1:00:45<02:29,  7.85s/it, training_loss=0.233]\u001b[A\n",
            "Epoch 3:  96%|█████████▌| 465/484 [1:00:52<02:29,  7.85s/it, training_loss=0.269]\u001b[A\n",
            "Epoch 3:  96%|█████████▋| 466/484 [1:00:52<02:18,  7.67s/it, training_loss=0.269]\u001b[A\n",
            "Epoch 3:  96%|█████████▋| 466/484 [1:01:01<02:18,  7.67s/it, training_loss=0.252]\u001b[A\n",
            "Epoch 3:  96%|█████████▋| 467/484 [1:01:01<02:15,  7.98s/it, training_loss=0.252]\u001b[A\n",
            "Epoch 3:  96%|█████████▋| 467/484 [1:01:07<02:15,  7.98s/it, training_loss=0.002]\u001b[A\n",
            "Epoch 3:  97%|█████████▋| 468/484 [1:01:07<02:00,  7.56s/it, training_loss=0.002]\u001b[A\n",
            "Epoch 3:  97%|█████████▋| 468/484 [1:01:17<02:00,  7.56s/it, training_loss=0.003]\u001b[A\n",
            "Epoch 3:  97%|█████████▋| 469/484 [1:01:17<02:03,  8.22s/it, training_loss=0.003]\u001b[A\n",
            "Epoch 3:  97%|█████████▋| 469/484 [1:01:24<02:03,  8.22s/it, training_loss=0.001]\u001b[A\n",
            "Epoch 3:  97%|█████████▋| 470/484 [1:01:24<01:48,  7.71s/it, training_loss=0.001]\u001b[A\n",
            "Epoch 3:  97%|█████████▋| 470/484 [1:01:32<01:48,  7.71s/it, training_loss=0.002]\u001b[A\n",
            "Epoch 3:  97%|█████████▋| 471/484 [1:01:32<01:44,  8.01s/it, training_loss=0.002]\u001b[A\n",
            "Epoch 3:  97%|█████████▋| 471/484 [1:01:40<01:44,  8.01s/it, training_loss=0.007]\u001b[A\n",
            "Epoch 3:  98%|█████████▊| 472/484 [1:01:40<01:33,  7.82s/it, training_loss=0.007]\u001b[A\n",
            "Epoch 3:  98%|█████████▊| 472/484 [1:01:47<01:33,  7.82s/it, training_loss=0.003]\u001b[A\n",
            "Epoch 3:  98%|█████████▊| 473/484 [1:01:47<01:23,  7.60s/it, training_loss=0.003]\u001b[A\n",
            "Epoch 3:  98%|█████████▊| 473/484 [1:01:56<01:23,  7.60s/it, training_loss=0.279]\u001b[A\n",
            "Epoch 3:  98%|█████████▊| 474/484 [1:01:56<01:19,  7.99s/it, training_loss=0.279]\u001b[A\n",
            "Epoch 3:  98%|█████████▊| 474/484 [1:02:02<01:19,  7.99s/it, training_loss=0.004]\u001b[A\n",
            "Epoch 3:  98%|█████████▊| 475/484 [1:02:02<01:08,  7.56s/it, training_loss=0.004]\u001b[A\n",
            "Epoch 3:  98%|█████████▊| 475/484 [1:02:12<01:08,  7.56s/it, training_loss=0.030]\u001b[A\n",
            "Epoch 3:  98%|█████████▊| 476/484 [1:02:12<01:05,  8.16s/it, training_loss=0.030]\u001b[A\n",
            "Epoch 3:  98%|█████████▊| 476/484 [1:02:18<01:05,  8.16s/it, training_loss=0.052]\u001b[A\n",
            "Epoch 3:  99%|█████████▊| 477/484 [1:02:18<00:53,  7.68s/it, training_loss=0.052]\u001b[A\n",
            "Epoch 3:  99%|█████████▊| 477/484 [1:02:27<00:53,  7.68s/it, training_loss=0.002]\u001b[A\n",
            "Epoch 3:  99%|█████████▉| 478/484 [1:02:27<00:47,  7.89s/it, training_loss=0.002]\u001b[A\n",
            "Epoch 3:  99%|█████████▉| 478/484 [1:02:35<00:47,  7.89s/it, training_loss=0.002]\u001b[A\n",
            "Epoch 3:  99%|█████████▉| 479/484 [1:02:35<00:39,  7.85s/it, training_loss=0.002]\u001b[A\n",
            "Epoch 3:  99%|█████████▉| 479/484 [1:02:41<00:39,  7.85s/it, training_loss=0.002]\u001b[A\n",
            "Epoch 3:  99%|█████████▉| 480/484 [1:02:41<00:30,  7.54s/it, training_loss=0.002]\u001b[A\n",
            "Epoch 3:  99%|█████████▉| 480/484 [1:02:51<00:30,  7.54s/it, training_loss=0.001]\u001b[A\n",
            "Epoch 3:  99%|█████████▉| 481/484 [1:02:51<00:24,  8.05s/it, training_loss=0.001]\u001b[A\n",
            "Epoch 3:  99%|█████████▉| 481/484 [1:02:57<00:24,  8.05s/it, training_loss=0.029]\u001b[A\n",
            "Epoch 3: 100%|█████████▉| 482/484 [1:02:57<00:15,  7.60s/it, training_loss=0.029]\u001b[A\n",
            "Epoch 3: 100%|█████████▉| 482/484 [1:03:07<00:15,  7.60s/it, training_loss=0.077]\u001b[A\n",
            "Epoch 3: 100%|█████████▉| 483/484 [1:03:07<00:08,  8.14s/it, training_loss=0.077]\u001b[A\n",
            "Epoch 3: 100%|█████████▉| 483/484 [1:03:12<00:08,  8.14s/it, training_loss=0.098]\u001b[A\n",
            "Epoch 3: 100%|██████████| 484/484 [1:03:12<00:00,  7.29s/it, training_loss=0.098]\u001b[A\n",
            " 40%|████      | 2/5 [3:18:59<3:23:29, 4069.76s/it]"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            " Epoch {epoch}\n",
            "Training loss: {loss_train_avg}\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n",
            "  0%|          | 0/121 [00:00<?, ?it/s]\u001b[A\n",
            "  1%|          | 1/121 [00:02<04:01,  2.01s/it]\u001b[A\n",
            "  2%|▏         | 2/121 [00:04<04:49,  2.44s/it]\u001b[A\n",
            "  2%|▏         | 3/121 [00:08<05:30,  2.80s/it]\u001b[A\n",
            "  3%|▎         | 4/121 [00:12<07:02,  3.61s/it]\u001b[A\n",
            "  4%|▍         | 5/121 [00:14<05:47,  3.00s/it]\u001b[A\n",
            "  5%|▍         | 6/121 [00:16<05:02,  2.63s/it]\u001b[A\n",
            "  6%|▌         | 7/121 [00:18<04:32,  2.39s/it]\u001b[A\n",
            "  7%|▋         | 8/121 [00:20<04:14,  2.25s/it]\u001b[A\n",
            "  7%|▋         | 9/121 [00:24<05:09,  2.76s/it]\u001b[A\n",
            "  8%|▊         | 10/121 [00:28<06:03,  3.27s/it]\u001b[A\n",
            "  9%|▉         | 11/121 [00:31<05:49,  3.18s/it]\u001b[A\n",
            " 10%|▉         | 12/121 [00:33<05:11,  2.85s/it]\u001b[A\n",
            " 11%|█         | 13/121 [00:35<04:37,  2.57s/it]\u001b[A\n",
            " 12%|█▏        | 14/121 [00:37<04:13,  2.37s/it]\u001b[A\n",
            " 12%|█▏        | 15/121 [00:39<03:56,  2.23s/it]\u001b[A\n",
            " 13%|█▎        | 16/121 [00:41<03:44,  2.14s/it]\u001b[A\n",
            " 14%|█▍        | 17/121 [00:44<03:55,  2.27s/it]\u001b[A\n",
            " 15%|█▍        | 18/121 [00:47<04:21,  2.54s/it]\u001b[A\n",
            " 16%|█▌        | 19/121 [00:50<04:30,  2.66s/it]\u001b[A\n",
            " 17%|█▋        | 20/121 [00:52<04:14,  2.52s/it]\u001b[A\n",
            " 17%|█▋        | 21/121 [00:54<03:53,  2.34s/it]\u001b[A\n",
            " 18%|█▊        | 22/121 [00:56<03:39,  2.22s/it]\u001b[A\n",
            " 19%|█▉        | 23/121 [00:58<03:28,  2.13s/it]\u001b[A\n",
            " 20%|█▉        | 24/121 [01:00<03:20,  2.07s/it]\u001b[A\n",
            " 21%|██        | 25/121 [01:02<03:33,  2.23s/it]\u001b[A\n",
            " 21%|██▏       | 26/121 [01:05<03:59,  2.52s/it]\u001b[A\n",
            " 22%|██▏       | 27/121 [01:08<04:09,  2.65s/it]\u001b[A\n",
            " 23%|██▎       | 28/121 [01:11<03:53,  2.51s/it]\u001b[A\n",
            " 24%|██▍       | 29/121 [01:12<03:34,  2.33s/it]\u001b[A\n",
            " 25%|██▍       | 30/121 [01:14<03:21,  2.22s/it]\u001b[A\n",
            " 26%|██▌       | 31/121 [01:16<03:11,  2.12s/it]\u001b[A\n",
            " 26%|██▋       | 32/121 [01:18<03:03,  2.07s/it]\u001b[A\n",
            " 27%|██▋       | 33/121 [01:21<03:15,  2.23s/it]\u001b[A\n",
            " 28%|██▊       | 34/121 [01:24<03:38,  2.51s/it]\u001b[A\n",
            " 29%|██▉       | 35/121 [01:27<03:47,  2.65s/it]\u001b[A\n",
            " 30%|██▉       | 36/121 [01:29<03:33,  2.51s/it]\u001b[A\n",
            " 31%|███       | 37/121 [01:31<03:16,  2.34s/it]\u001b[A\n",
            " 31%|███▏      | 38/121 [01:33<03:04,  2.22s/it]\u001b[A\n",
            " 32%|███▏      | 39/121 [01:35<02:55,  2.14s/it]\u001b[A\n",
            " 33%|███▎      | 40/121 [01:37<02:48,  2.08s/it]\u001b[A\n",
            " 34%|███▍      | 41/121 [01:40<03:00,  2.26s/it]\u001b[A\n",
            " 35%|███▍      | 42/121 [01:43<03:20,  2.53s/it]\u001b[A\n",
            " 36%|███▌      | 43/121 [01:46<03:27,  2.66s/it]\u001b[A\n",
            " 36%|███▋      | 44/121 [01:48<03:11,  2.49s/it]\u001b[A\n",
            " 37%|███▋      | 45/121 [01:50<02:56,  2.32s/it]\u001b[A\n",
            " 38%|███▊      | 46/121 [01:52<02:45,  2.20s/it]\u001b[A\n",
            " 39%|███▉      | 47/121 [01:54<02:37,  2.13s/it]\u001b[A\n",
            " 40%|███▉      | 48/121 [01:56<02:31,  2.07s/it]\u001b[A\n",
            " 40%|████      | 49/121 [01:58<02:43,  2.27s/it]\u001b[A\n",
            " 41%|████▏     | 50/121 [02:01<03:00,  2.54s/it]\u001b[A\n",
            " 42%|████▏     | 51/121 [02:04<03:05,  2.66s/it]\u001b[A\n",
            " 43%|████▎     | 52/121 [02:06<02:51,  2.48s/it]\u001b[A\n",
            " 44%|████▍     | 53/121 [02:08<02:37,  2.32s/it]\u001b[A\n",
            " 45%|████▍     | 54/121 [02:10<02:27,  2.20s/it]\u001b[A\n",
            " 45%|████▌     | 55/121 [02:12<02:19,  2.12s/it]\u001b[A\n",
            " 46%|████▋     | 56/121 [02:14<02:13,  2.06s/it]\u001b[A\n",
            " 47%|████▋     | 57/121 [02:17<02:25,  2.27s/it]\u001b[A\n",
            " 48%|████▊     | 58/121 [02:20<02:40,  2.54s/it]\u001b[A\n",
            " 49%|████▉     | 59/121 [02:23<02:45,  2.67s/it]\u001b[A\n",
            " 50%|████▉     | 60/121 [02:25<02:30,  2.47s/it]\u001b[A\n",
            " 50%|█████     | 61/121 [02:27<02:18,  2.31s/it]\u001b[A\n",
            " 51%|█████     | 62/121 [02:29<02:10,  2.20s/it]\u001b[A\n",
            " 52%|█████▏    | 63/121 [02:31<02:03,  2.13s/it]\u001b[A\n",
            " 53%|█████▎    | 64/121 [02:33<01:58,  2.07s/it]\u001b[A\n",
            " 54%|█████▎    | 65/121 [02:36<02:10,  2.33s/it]\u001b[A\n",
            " 55%|█████▍    | 66/121 [02:39<02:21,  2.57s/it]\u001b[A\n",
            " 55%|█████▌    | 67/121 [02:42<02:24,  2.67s/it]\u001b[A\n",
            " 56%|█████▌    | 68/121 [02:44<02:10,  2.46s/it]\u001b[A\n",
            " 57%|█████▋    | 69/121 [02:46<01:59,  2.31s/it]\u001b[A\n",
            " 58%|█████▊    | 70/121 [02:48<01:52,  2.20s/it]\u001b[A\n",
            " 59%|█████▊    | 71/121 [02:50<01:45,  2.12s/it]\u001b[A\n",
            " 60%|█████▉    | 72/121 [02:52<01:41,  2.07s/it]\u001b[A\n",
            " 60%|██████    | 73/121 [02:55<01:53,  2.36s/it]\u001b[A\n",
            " 61%|██████    | 74/121 [02:58<02:01,  2.59s/it]\u001b[A\n",
            " 62%|██████▏   | 75/121 [03:01<02:02,  2.67s/it]\u001b[A\n",
            " 63%|██████▎   | 76/121 [03:03<01:50,  2.46s/it]\u001b[A\n",
            " 64%|██████▎   | 77/121 [03:05<01:41,  2.30s/it]\u001b[A\n",
            " 64%|██████▍   | 78/121 [03:06<01:34,  2.20s/it]\u001b[A\n",
            " 65%|██████▌   | 79/121 [03:08<01:29,  2.12s/it]\u001b[A\n",
            " 66%|██████▌   | 80/121 [03:10<01:25,  2.08s/it]\u001b[A\n",
            " 67%|██████▋   | 81/121 [03:14<01:36,  2.40s/it]\u001b[A\n",
            " 68%|██████▊   | 82/121 [03:17<01:41,  2.60s/it]\u001b[A\n",
            " 69%|██████▊   | 83/121 [03:19<01:40,  2.64s/it]\u001b[A\n",
            " 69%|██████▉   | 84/121 [03:21<01:29,  2.43s/it]\u001b[A\n",
            " 70%|███████   | 85/121 [03:23<01:22,  2.29s/it]\u001b[A\n",
            " 71%|███████   | 86/121 [03:25<01:16,  2.19s/it]\u001b[A\n",
            " 72%|███████▏  | 87/121 [03:27<01:11,  2.11s/it]\u001b[A\n",
            " 73%|███████▎  | 88/121 [03:29<01:09,  2.10s/it]\u001b[A\n",
            " 74%|███████▎  | 89/121 [03:32<01:17,  2.43s/it]\u001b[A\n",
            " 74%|███████▍  | 90/121 [03:35<01:21,  2.62s/it]\u001b[A\n",
            " 75%|███████▌  | 91/121 [03:38<01:18,  2.62s/it]\u001b[A\n",
            " 76%|███████▌  | 92/121 [03:40<01:10,  2.42s/it]\u001b[A\n",
            " 77%|███████▋  | 93/121 [03:42<01:03,  2.27s/it]\u001b[A\n",
            " 78%|███████▊  | 94/121 [03:44<00:58,  2.17s/it]\u001b[A\n",
            " 79%|███████▊  | 95/121 [03:46<00:54,  2.10s/it]\u001b[A\n",
            " 79%|███████▉  | 96/121 [03:48<00:52,  2.09s/it]\u001b[A\n",
            " 80%|████████  | 97/121 [03:51<00:58,  2.43s/it]\u001b[A\n",
            " 81%|████████  | 98/121 [03:54<01:00,  2.61s/it]\u001b[A\n",
            " 82%|████████▏ | 99/121 [03:57<00:57,  2.60s/it]\u001b[A\n",
            " 83%|████████▎ | 100/121 [03:59<00:50,  2.40s/it]\u001b[A\n",
            " 83%|████████▎ | 101/121 [04:01<00:45,  2.26s/it]\u001b[A\n",
            " 84%|████████▍ | 102/121 [04:03<00:41,  2.17s/it]\u001b[A\n",
            " 85%|████████▌ | 103/121 [04:05<00:37,  2.10s/it]\u001b[A\n",
            " 86%|████████▌ | 104/121 [04:07<00:35,  2.11s/it]\u001b[A\n",
            " 87%|████████▋ | 105/121 [04:10<00:39,  2.45s/it]\u001b[A\n",
            " 88%|████████▊ | 106/121 [04:13<00:39,  2.62s/it]\u001b[A\n",
            " 88%|████████▊ | 107/121 [04:15<00:36,  2.57s/it]\u001b[A\n",
            " 89%|████████▉ | 108/121 [04:17<00:30,  2.38s/it]\u001b[A\n",
            " 90%|█████████ | 109/121 [04:19<00:26,  2.25s/it]\u001b[A\n",
            " 91%|█████████ | 110/121 [04:21<00:23,  2.15s/it]\u001b[A\n",
            " 92%|█████████▏| 111/121 [04:23<00:20,  2.09s/it]\u001b[A\n",
            " 93%|█████████▎| 112/121 [04:25<00:19,  2.15s/it]\u001b[A\n",
            " 93%|█████████▎| 113/121 [04:29<00:19,  2.47s/it]\u001b[A\n",
            " 94%|█████████▍| 114/121 [04:32<00:18,  2.63s/it]\u001b[A\n",
            " 95%|█████████▌| 115/121 [04:34<00:15,  2.59s/it]\u001b[A\n",
            " 96%|█████████▌| 116/121 [04:36<00:11,  2.40s/it]\u001b[A\n",
            " 97%|█████████▋| 117/121 [04:38<00:09,  2.26s/it]\u001b[A\n",
            " 98%|█████████▊| 118/121 [04:40<00:06,  2.16s/it]\u001b[A\n",
            " 98%|█████████▊| 119/121 [04:42<00:04,  2.09s/it]\u001b[A\n",
            " 99%|█████████▉| 120/121 [04:44<00:02,  2.17s/it]\u001b[A\n",
            "100%|██████████| 121/121 [04:47<00:00,  2.38s/it]\n",
            " 60%|██████    | 3/5 [3:23:47<2:15:51, 4075.81s/it]"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Validation loss: 0.6267791452879193\n",
            "F1 Score (weighted): 0.8543480667060214\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n",
            "Epoch 4:   0%|          | 0/484 [00:00<?, ?it/s]\u001b[A\n",
            "Epoch 4:   0%|          | 0/484 [00:08<?, ?it/s, training_loss=0.003]\u001b[A\n",
            "Epoch 4:   0%|          | 1/484 [00:08<1:07:16,  8.36s/it, training_loss=0.003]\u001b[A\n",
            "Epoch 4:   0%|          | 1/484 [00:14<1:07:16,  8.36s/it, training_loss=0.114]\u001b[A\n",
            "Epoch 4:   0%|          | 2/484 [00:15<59:03,  7.35s/it, training_loss=0.114]  \u001b[A\n",
            "Epoch 4:   0%|          | 2/484 [00:24<59:03,  7.35s/it, training_loss=0.001]\u001b[A\n",
            "Epoch 4:   1%|          | 3/484 [00:24<1:06:13,  8.26s/it, training_loss=0.001]\u001b[A\n",
            "Epoch 4:   1%|          | 3/484 [00:30<1:06:13,  8.26s/it, training_loss=0.002]\u001b[A\n",
            "Epoch 4:   1%|          | 4/484 [00:30<1:00:22,  7.55s/it, training_loss=0.002]\u001b[A\n",
            "Epoch 4:   1%|          | 4/484 [00:40<1:00:22,  7.55s/it, training_loss=0.003]\u001b[A\n",
            "Epoch 4:   1%|          | 5/484 [00:40<1:05:12,  8.17s/it, training_loss=0.003]\u001b[A\n",
            "Epoch 4:   1%|          | 5/484 [00:47<1:05:12,  8.17s/it, training_loss=0.084]\u001b[A\n",
            "Epoch 4:   1%|          | 6/484 [00:47<1:01:49,  7.76s/it, training_loss=0.084]\u001b[A\n",
            "Epoch 4:   1%|          | 6/484 [00:54<1:01:49,  7.76s/it, training_loss=0.002]\u001b[A\n",
            "Epoch 4:   1%|▏         | 7/484 [00:54<1:01:37,  7.75s/it, training_loss=0.002]\u001b[A\n",
            "Epoch 4:   1%|▏         | 7/484 [01:03<1:01:37,  7.75s/it, training_loss=0.002]\u001b[A\n",
            "Epoch 4:   2%|▏         | 8/484 [01:03<1:03:32,  8.01s/it, training_loss=0.002]\u001b[A\n",
            "Epoch 4:   2%|▏         | 8/484 [01:09<1:03:32,  8.01s/it, training_loss=0.003]\u001b[A\n",
            "Epoch 4:   2%|▏         | 9/484 [01:09<59:53,  7.57s/it, training_loss=0.003]  \u001b[A\n",
            "Epoch 4:   2%|▏         | 9/484 [01:19<59:53,  7.57s/it, training_loss=0.013]\u001b[A\n",
            "Epoch 4:   2%|▏         | 10/484 [01:19<1:04:36,  8.18s/it, training_loss=0.013]\u001b[A\n",
            "Epoch 4:   2%|▏         | 10/484 [01:25<1:04:36,  8.18s/it, training_loss=0.011]\u001b[A\n",
            "Epoch 4:   2%|▏         | 11/484 [01:25<1:00:21,  7.66s/it, training_loss=0.011]\u001b[A\n",
            "Epoch 4:   2%|▏         | 11/484 [01:34<1:00:21,  7.66s/it, training_loss=0.261]\u001b[A\n",
            "Epoch 4:   2%|▏         | 12/484 [01:34<1:03:23,  8.06s/it, training_loss=0.261]\u001b[A\n",
            "Epoch 4:   2%|▏         | 12/484 [01:41<1:03:23,  8.06s/it, training_loss=0.004]\u001b[A\n",
            "Epoch 4:   3%|▎         | 13/484 [01:42<1:00:55,  7.76s/it, training_loss=0.004]\u001b[A\n",
            "Epoch 4:   3%|▎         | 13/484 [01:49<1:00:55,  7.76s/it, training_loss=0.004]\u001b[A\n",
            "Epoch 4:   3%|▎         | 14/484 [01:49<1:00:16,  7.69s/it, training_loss=0.004]\u001b[A\n",
            "Epoch 4:   3%|▎         | 14/484 [01:57<1:00:16,  7.69s/it, training_loss=0.002]\u001b[A\n",
            "Epoch 4:   3%|▎         | 15/484 [01:57<1:01:46,  7.90s/it, training_loss=0.002]\u001b[A\n",
            "Epoch 4:   3%|▎         | 15/484 [02:04<1:01:46,  7.90s/it, training_loss=0.001]\u001b[A\n",
            "Epoch 4:   3%|▎         | 16/484 [02:04<58:14,  7.47s/it, training_loss=0.001]  \u001b[A\n",
            "Epoch 4:   3%|▎         | 16/484 [02:14<58:14,  7.47s/it, training_loss=0.001]\u001b[A\n",
            "Epoch 4:   4%|▎         | 17/484 [02:14<1:03:16,  8.13s/it, training_loss=0.001]\u001b[A\n",
            "Epoch 4:   4%|▎         | 17/484 [02:20<1:03:16,  8.13s/it, training_loss=0.005]\u001b[A\n",
            "Epoch 4:   4%|▎         | 18/484 [02:20<59:22,  7.65s/it, training_loss=0.005]  \u001b[A\n",
            "Epoch 4:   4%|▎         | 18/484 [02:29<59:22,  7.65s/it, training_loss=0.001]\u001b[A\n",
            "Epoch 4:   4%|▍         | 19/484 [02:29<1:01:52,  7.98s/it, training_loss=0.001]\u001b[A\n",
            "Epoch 4:   4%|▍         | 19/484 [02:36<1:01:52,  7.98s/it, training_loss=0.001]\u001b[A\n",
            "Epoch 4:   4%|▍         | 20/484 [02:36<1:00:14,  7.79s/it, training_loss=0.001]\u001b[A\n",
            "Epoch 4:   4%|▍         | 20/484 [02:43<1:00:14,  7.79s/it, training_loss=0.013]\u001b[A\n",
            "Epoch 4:   4%|▍         | 21/484 [02:43<58:43,  7.61s/it, training_loss=0.013]  \u001b[A\n",
            "Epoch 4:   4%|▍         | 21/484 [02:52<58:43,  7.61s/it, training_loss=0.002]\u001b[A\n",
            "Epoch 4:   5%|▍         | 22/484 [02:52<1:01:04,  7.93s/it, training_loss=0.002]\u001b[A\n",
            "Epoch 4:   5%|▍         | 22/484 [02:59<1:01:04,  7.93s/it, training_loss=0.019]\u001b[A\n",
            "Epoch 4:   5%|▍         | 23/484 [02:59<57:37,  7.50s/it, training_loss=0.019]  \u001b[A\n",
            "Epoch 4:   5%|▍         | 23/484 [03:08<57:37,  7.50s/it, training_loss=0.125]\u001b[A\n",
            "Epoch 4:   5%|▍         | 24/484 [03:08<1:02:17,  8.13s/it, training_loss=0.125]\u001b[A\n",
            "Epoch 4:   5%|▍         | 24/484 [03:15<1:02:17,  8.13s/it, training_loss=0.003]\u001b[A\n",
            "Epoch 4:   5%|▌         | 25/484 [03:15<58:26,  7.64s/it, training_loss=0.003]  \u001b[A\n",
            "Epoch 4:   5%|▌         | 25/484 [03:23<58:26,  7.64s/it, training_loss=0.097]\u001b[A\n",
            "Epoch 4:   5%|▌         | 26/484 [03:23<1:00:00,  7.86s/it, training_loss=0.097]\u001b[A\n",
            "Epoch 4:   5%|▌         | 26/484 [03:31<1:00:00,  7.86s/it, training_loss=0.001]\u001b[A\n",
            "Epoch 4:   6%|▌         | 27/484 [03:31<59:11,  7.77s/it, training_loss=0.001]  \u001b[A\n",
            "Epoch 4:   6%|▌         | 27/484 [03:37<59:11,  7.77s/it, training_loss=0.001]\u001b[A\n",
            "Epoch 4:   6%|▌         | 28/484 [03:37<56:41,  7.46s/it, training_loss=0.001]\u001b[A\n",
            "Epoch 4:   6%|▌         | 28/484 [03:46<56:41,  7.46s/it, training_loss=0.002]\u001b[A\n",
            "Epoch 4:   6%|▌         | 29/484 [03:46<1:00:26,  7.97s/it, training_loss=0.002]\u001b[A\n",
            "Epoch 4:   6%|▌         | 29/484 [03:53<1:00:26,  7.97s/it, training_loss=0.071]\u001b[A\n",
            "Epoch 4:   6%|▌         | 30/484 [03:53<57:01,  7.54s/it, training_loss=0.071]  \u001b[A\n",
            "Epoch 4:   6%|▌         | 30/484 [04:02<57:01,  7.54s/it, training_loss=0.001]\u001b[A\n",
            "Epoch 4:   6%|▋         | 31/484 [04:02<1:00:59,  8.08s/it, training_loss=0.001]\u001b[A\n",
            "Epoch 4:   6%|▋         | 31/484 [04:09<1:00:59,  8.08s/it, training_loss=0.001]\u001b[A\n",
            "Epoch 4:   7%|▋         | 32/484 [04:09<57:54,  7.69s/it, training_loss=0.001]  \u001b[A\n",
            "Epoch 4:   7%|▋         | 32/484 [04:17<57:54,  7.69s/it, training_loss=0.001]\u001b[A\n",
            "Epoch 4:   7%|▋         | 33/484 [04:17<58:07,  7.73s/it, training_loss=0.001]\u001b[A\n",
            "Epoch 4:   7%|▋         | 33/484 [04:25<58:07,  7.73s/it, training_loss=0.002]\u001b[A\n",
            "Epoch 4:   7%|▋         | 34/484 [04:25<58:41,  7.83s/it, training_loss=0.002]\u001b[A\n",
            "Epoch 4:   7%|▋         | 34/484 [04:32<58:41,  7.83s/it, training_loss=0.198]\u001b[A\n",
            "Epoch 4:   7%|▋         | 35/484 [04:32<55:43,  7.45s/it, training_loss=0.198]\u001b[A\n",
            "Epoch 4:   7%|▋         | 35/484 [04:41<55:43,  7.45s/it, training_loss=0.012]\u001b[A\n",
            "Epoch 4:   7%|▋         | 36/484 [04:41<1:00:30,  8.10s/it, training_loss=0.012]\u001b[A\n",
            "Epoch 4:   7%|▋         | 36/484 [04:48<1:00:30,  8.10s/it, training_loss=0.283]\u001b[A\n",
            "Epoch 4:   8%|▊         | 37/484 [04:48<56:53,  7.64s/it, training_loss=0.283]  \u001b[A\n",
            "Epoch 4:   8%|▊         | 37/484 [04:57<56:53,  7.64s/it, training_loss=0.008]\u001b[A\n",
            "Epoch 4:   8%|▊         | 38/484 [04:57<1:00:03,  8.08s/it, training_loss=0.008]\u001b[A\n",
            "Epoch 4:   8%|▊         | 38/484 [05:04<1:00:03,  8.08s/it, training_loss=0.001]\u001b[A\n",
            "Epoch 4:   8%|▊         | 39/484 [05:04<57:58,  7.82s/it, training_loss=0.001]  \u001b[A\n",
            "Epoch 4:   8%|▊         | 39/484 [05:12<57:58,  7.82s/it, training_loss=0.005]\u001b[A\n",
            "Epoch 4:   8%|▊         | 40/484 [05:12<57:54,  7.83s/it, training_loss=0.005]\u001b[A\n",
            "Epoch 4:   8%|▊         | 40/484 [05:20<57:54,  7.83s/it, training_loss=0.002]\u001b[A\n",
            "Epoch 4:   8%|▊         | 41/484 [05:20<58:33,  7.93s/it, training_loss=0.002]\u001b[A\n",
            "Epoch 4:   8%|▊         | 41/484 [05:27<58:33,  7.93s/it, training_loss=0.005]\u001b[A\n",
            "Epoch 4:   9%|▊         | 42/484 [05:27<55:29,  7.53s/it, training_loss=0.005]\u001b[A\n",
            "Epoch 4:   9%|▊         | 42/484 [05:36<55:29,  7.53s/it, training_loss=0.158]\u001b[A\n",
            "Epoch 4:   9%|▉         | 43/484 [05:36<59:59,  8.16s/it, training_loss=0.158]\u001b[A\n",
            "Epoch 4:   9%|▉         | 43/484 [05:43<59:59,  8.16s/it, training_loss=0.001]\u001b[A\n",
            "Epoch 4:   9%|▉         | 44/484 [05:43<56:18,  7.68s/it, training_loss=0.001]\u001b[A\n",
            "Epoch 4:   9%|▉         | 44/484 [05:52<56:18,  7.68s/it, training_loss=0.163]\u001b[A\n",
            "Epoch 4:   9%|▉         | 45/484 [05:52<59:02,  8.07s/it, training_loss=0.163]\u001b[A\n",
            "Epoch 4:   9%|▉         | 45/484 [05:59<59:02,  8.07s/it, training_loss=0.003]\u001b[A\n",
            "Epoch 4:  10%|▉         | 46/484 [05:59<56:51,  7.79s/it, training_loss=0.003]\u001b[A\n",
            "Epoch 4:  10%|▉         | 46/484 [06:06<56:51,  7.79s/it, training_loss=0.038]\u001b[A\n",
            "Epoch 4:  10%|▉         | 47/484 [06:06<56:03,  7.70s/it, training_loss=0.038]\u001b[A\n",
            "Epoch 4:  10%|▉         | 47/484 [06:15<56:03,  7.70s/it, training_loss=0.216]\u001b[A\n",
            "Epoch 4:  10%|▉         | 48/484 [06:15<57:34,  7.92s/it, training_loss=0.216]\u001b[A\n",
            "Epoch 4:  10%|▉         | 48/484 [06:21<57:34,  7.92s/it, training_loss=0.004]\u001b[A\n",
            "Epoch 4:  10%|█         | 49/484 [06:21<54:29,  7.52s/it, training_loss=0.004]\u001b[A\n",
            "Epoch 4:  10%|█         | 49/484 [06:31<54:29,  7.52s/it, training_loss=0.001]\u001b[A\n",
            "Epoch 4:  10%|█         | 50/484 [06:31<59:09,  8.18s/it, training_loss=0.001]\u001b[A\n",
            "Epoch 4:  10%|█         | 50/484 [06:38<59:09,  8.18s/it, training_loss=0.001]\u001b[A\n",
            "Epoch 4:  11%|█         | 51/484 [06:38<55:34,  7.70s/it, training_loss=0.001]\u001b[A\n",
            "Epoch 4:  11%|█         | 51/484 [06:47<55:34,  7.70s/it, training_loss=0.069]\u001b[A\n",
            "Epoch 4:  11%|█         | 52/484 [06:47<58:19,  8.10s/it, training_loss=0.069]\u001b[A\n",
            "Epoch 4:  11%|█         | 52/484 [06:54<58:19,  8.10s/it, training_loss=0.004]\u001b[A\n",
            "Epoch 4:  11%|█         | 53/484 [06:54<56:14,  7.83s/it, training_loss=0.004]\u001b[A\n",
            "Epoch 4:  11%|█         | 53/484 [07:01<56:14,  7.83s/it, training_loss=0.093]\u001b[A\n",
            "Epoch 4:  11%|█         | 54/484 [07:01<55:00,  7.68s/it, training_loss=0.093]\u001b[A\n",
            "Epoch 4:  11%|█         | 54/484 [07:10<55:00,  7.68s/it, training_loss=0.161]\u001b[A\n",
            "Epoch 4:  11%|█▏        | 55/484 [07:10<56:41,  7.93s/it, training_loss=0.161]\u001b[A\n",
            "Epoch 4:  11%|█▏        | 55/484 [07:16<56:41,  7.93s/it, training_loss=0.001]\u001b[A\n",
            "Epoch 4:  12%|█▏        | 56/484 [07:16<53:34,  7.51s/it, training_loss=0.001]\u001b[A\n",
            "Epoch 4:  12%|█▏        | 56/484 [07:26<53:34,  7.51s/it, training_loss=0.011]\u001b[A\n",
            "Epoch 4:  12%|█▏        | 57/484 [07:26<57:59,  8.15s/it, training_loss=0.011]\u001b[A\n",
            "Epoch 4:  12%|█▏        | 57/484 [07:32<57:59,  8.15s/it, training_loss=0.001]\u001b[A\n",
            "Epoch 4:  12%|█▏        | 58/484 [07:32<54:13,  7.64s/it, training_loss=0.001]\u001b[A\n",
            "Epoch 4:  12%|█▏        | 58/484 [07:41<54:13,  7.64s/it, training_loss=0.001]\u001b[A\n",
            "Epoch 4:  12%|█▏        | 59/484 [07:41<56:23,  7.96s/it, training_loss=0.001]\u001b[A\n",
            "Epoch 4:  12%|█▏        | 59/484 [07:49<56:23,  7.96s/it, training_loss=0.498]\u001b[A\n",
            "Epoch 4:  12%|█▏        | 60/484 [07:49<54:54,  7.77s/it, training_loss=0.498]\u001b[A\n",
            "Epoch 4:  12%|█▏        | 60/484 [07:56<54:54,  7.77s/it, training_loss=0.055]\u001b[A\n",
            "Epoch 4:  13%|█▎        | 61/484 [07:56<53:13,  7.55s/it, training_loss=0.055]\u001b[A\n",
            "Epoch 4:  13%|█▎        | 61/484 [08:04<53:13,  7.55s/it, training_loss=0.002]\u001b[A\n",
            "Epoch 4:  13%|█▎        | 62/484 [08:04<55:46,  7.93s/it, training_loss=0.002]\u001b[A\n",
            "Epoch 4:  13%|█▎        | 62/484 [08:11<55:46,  7.93s/it, training_loss=0.003]\u001b[A\n",
            "Epoch 4:  13%|█▎        | 63/484 [08:11<52:34,  7.49s/it, training_loss=0.003]\u001b[A\n",
            "Epoch 4:  13%|█▎        | 63/484 [08:20<52:34,  7.49s/it, training_loss=0.002]\u001b[A\n",
            "Epoch 4:  13%|█▎        | 64/484 [08:20<56:50,  8.12s/it, training_loss=0.002]\u001b[A\n",
            "Epoch 4:  13%|█▎        | 64/484 [08:27<56:50,  8.12s/it, training_loss=0.002]\u001b[A\n",
            "Epoch 4:  13%|█▎        | 65/484 [08:27<53:25,  7.65s/it, training_loss=0.002]\u001b[A\n",
            "Epoch 4:  13%|█▎        | 65/484 [08:36<53:25,  7.65s/it, training_loss=0.102]\u001b[A\n",
            "Epoch 4:  14%|█▎        | 66/484 [08:36<55:12,  7.92s/it, training_loss=0.102]\u001b[A\n",
            "Epoch 4:  14%|█▎        | 66/484 [08:43<55:12,  7.92s/it, training_loss=0.002]\u001b[A\n",
            "Epoch 4:  14%|█▍        | 67/484 [08:43<54:25,  7.83s/it, training_loss=0.002]\u001b[A\n",
            "Epoch 4:  14%|█▍        | 67/484 [08:50<54:25,  7.83s/it, training_loss=0.085]\u001b[A\n",
            "Epoch 4:  14%|█▍        | 68/484 [08:50<52:03,  7.51s/it, training_loss=0.085]\u001b[A\n",
            "Epoch 4:  14%|█▍        | 68/484 [08:59<52:03,  7.51s/it, training_loss=0.004]\u001b[A\n",
            "Epoch 4:  14%|█▍        | 69/484 [08:59<55:24,  8.01s/it, training_loss=0.004]\u001b[A\n",
            "Epoch 4:  14%|█▍        | 69/484 [09:06<55:24,  8.01s/it, training_loss=0.001]\u001b[A\n",
            "Epoch 4:  14%|█▍        | 70/484 [09:06<53:29,  7.75s/it, training_loss=0.001]\u001b[A\n",
            "Epoch 4:  14%|█▍        | 70/484 [09:16<53:29,  7.75s/it, training_loss=0.007]\u001b[A\n",
            "Epoch 4:  15%|█▍        | 71/484 [09:16<57:19,  8.33s/it, training_loss=0.007]\u001b[A\n",
            "Epoch 4:  15%|█▍        | 71/484 [09:22<57:19,  8.33s/it, training_loss=0.198]\u001b[A\n",
            "Epoch 4:  15%|█▍        | 72/484 [09:22<53:24,  7.78s/it, training_loss=0.198]\u001b[A\n",
            "Epoch 4:  15%|█▍        | 72/484 [09:31<53:24,  7.78s/it, training_loss=0.004]\u001b[A\n",
            "Epoch 4:  15%|█▌        | 73/484 [09:31<54:49,  8.00s/it, training_loss=0.004]\u001b[A\n",
            "Epoch 4:  15%|█▌        | 73/484 [09:38<54:49,  8.00s/it, training_loss=0.004]\u001b[A\n",
            "Epoch 4:  15%|█▌        | 74/484 [09:38<53:38,  7.85s/it, training_loss=0.004]\u001b[A\n",
            "Epoch 4:  15%|█▌        | 74/484 [09:45<53:38,  7.85s/it, training_loss=0.256]\u001b[A\n",
            "Epoch 4:  15%|█▌        | 75/484 [09:45<51:25,  7.54s/it, training_loss=0.256]\u001b[A\n",
            "Epoch 4:  15%|█▌        | 75/484 [09:54<51:25,  7.54s/it, training_loss=0.001]\u001b[A\n",
            "Epoch 4:  16%|█▌        | 76/484 [09:54<54:25,  8.00s/it, training_loss=0.001]\u001b[A\n",
            "Epoch 4:  16%|█▌        | 76/484 [10:01<54:25,  8.00s/it, training_loss=0.004]\u001b[A\n",
            "Epoch 4:  16%|█▌        | 77/484 [10:01<51:09,  7.54s/it, training_loss=0.004]\u001b[A\n",
            "Epoch 4:  16%|█▌        | 77/484 [10:10<51:09,  7.54s/it, training_loss=0.237]\u001b[A\n",
            "Epoch 4:  16%|█▌        | 78/484 [10:10<54:50,  8.11s/it, training_loss=0.237]\u001b[A\n",
            "Epoch 4:  16%|█▌        | 78/484 [10:17<54:50,  8.11s/it, training_loss=0.024]\u001b[A\n",
            "Epoch 4:  16%|█▋        | 79/484 [10:17<51:42,  7.66s/it, training_loss=0.024]\u001b[A\n",
            "Epoch 4:  16%|█▋        | 79/484 [10:25<51:42,  7.66s/it, training_loss=0.001]\u001b[A\n",
            "Epoch 4:  17%|█▋        | 80/484 [10:25<52:18,  7.77s/it, training_loss=0.001]\u001b[A\n",
            "Epoch 4:  17%|█▋        | 80/484 [10:33<52:18,  7.77s/it, training_loss=0.100]\u001b[A\n",
            "Epoch 4:  17%|█▋        | 81/484 [10:33<52:27,  7.81s/it, training_loss=0.100]\u001b[A\n",
            "Epoch 4:  17%|█▋        | 81/484 [10:39<52:27,  7.81s/it, training_loss=0.001]\u001b[A\n",
            "Epoch 4:  17%|█▋        | 82/484 [10:39<49:57,  7.46s/it, training_loss=0.001]\u001b[A\n",
            "Epoch 4:  17%|█▋        | 82/484 [10:49<49:57,  7.46s/it, training_loss=0.001]\u001b[A\n",
            "Epoch 4:  17%|█▋        | 83/484 [10:49<54:03,  8.09s/it, training_loss=0.001]\u001b[A\n",
            "Epoch 4:  17%|█▋        | 83/484 [10:55<54:03,  8.09s/it, training_loss=0.047]\u001b[A\n",
            "Epoch 4:  17%|█▋        | 84/484 [10:55<50:43,  7.61s/it, training_loss=0.047]\u001b[A\n",
            "Epoch 4:  17%|█▋        | 84/484 [11:05<50:43,  7.61s/it, training_loss=0.006]\u001b[A\n",
            "Epoch 4:  18%|█▊        | 85/484 [11:05<53:31,  8.05s/it, training_loss=0.006]\u001b[A\n",
            "Epoch 4:  18%|█▊        | 85/484 [11:11<53:31,  8.05s/it, training_loss=0.001]\u001b[A\n",
            "Epoch 4:  18%|█▊        | 86/484 [11:11<51:12,  7.72s/it, training_loss=0.001]\u001b[A\n",
            "Epoch 4:  18%|█▊        | 86/484 [11:19<51:12,  7.72s/it, training_loss=0.002]\u001b[A\n",
            "Epoch 4:  18%|█▊        | 87/484 [11:19<50:35,  7.65s/it, training_loss=0.002]\u001b[A\n",
            "Epoch 4:  18%|█▊        | 87/484 [11:27<50:35,  7.65s/it, training_loss=0.084]\u001b[A\n",
            "Epoch 4:  18%|█▊        | 88/484 [11:27<51:55,  7.87s/it, training_loss=0.084]\u001b[A\n",
            "Epoch 4:  18%|█▊        | 88/484 [11:34<51:55,  7.87s/it, training_loss=0.208]\u001b[A\n",
            "Epoch 4:  18%|█▊        | 89/484 [11:34<48:55,  7.43s/it, training_loss=0.208]\u001b[A\n",
            "Epoch 4:  18%|█▊        | 89/484 [11:43<48:55,  7.43s/it, training_loss=0.011]\u001b[A\n",
            "Epoch 4:  19%|█▊        | 90/484 [11:43<53:08,  8.09s/it, training_loss=0.011]\u001b[A\n",
            "Epoch 4:  19%|█▊        | 90/484 [11:50<53:08,  8.09s/it, training_loss=0.002]\u001b[A\n",
            "Epoch 4:  19%|█▉        | 91/484 [11:50<49:49,  7.61s/it, training_loss=0.002]\u001b[A\n",
            "Epoch 4:  19%|█▉        | 91/484 [11:59<49:49,  7.61s/it, training_loss=0.001]\u001b[A\n",
            "Epoch 4:  19%|█▉        | 92/484 [11:59<51:49,  7.93s/it, training_loss=0.001]\u001b[A\n",
            "Epoch 4:  19%|█▉        | 92/484 [12:06<51:49,  7.93s/it, training_loss=0.002]\u001b[A\n",
            "Epoch 4:  19%|█▉        | 93/484 [12:06<50:30,  7.75s/it, training_loss=0.002]\u001b[A\n",
            "Epoch 4:  19%|█▉        | 93/484 [12:13<50:30,  7.75s/it, training_loss=0.005]\u001b[A\n",
            "Epoch 4:  19%|█▉        | 94/484 [12:13<48:51,  7.52s/it, training_loss=0.005]\u001b[A\n",
            "Epoch 4:  19%|█▉        | 94/484 [12:22<48:51,  7.52s/it, training_loss=0.004]\u001b[A\n",
            "Epoch 4:  20%|█▉        | 95/484 [12:22<51:16,  7.91s/it, training_loss=0.004]\u001b[A\n",
            "Epoch 4:  20%|█▉        | 95/484 [12:28<51:16,  7.91s/it, training_loss=0.001]\u001b[A\n",
            "Epoch 4:  20%|█▉        | 96/484 [12:28<48:22,  7.48s/it, training_loss=0.001]\u001b[A\n",
            "Epoch 4:  20%|█▉        | 96/484 [12:38<48:22,  7.48s/it, training_loss=0.002]\u001b[A\n",
            "Epoch 4:  20%|██        | 97/484 [12:38<52:13,  8.10s/it, training_loss=0.002]\u001b[A\n",
            "Epoch 4:  20%|██        | 97/484 [12:44<52:13,  8.10s/it, training_loss=0.085]\u001b[A\n",
            "Epoch 4:  20%|██        | 98/484 [12:44<48:59,  7.62s/it, training_loss=0.085]\u001b[A\n",
            "Epoch 4:  20%|██        | 98/484 [12:52<48:59,  7.62s/it, training_loss=0.064]\u001b[A\n",
            "Epoch 4:  20%|██        | 99/484 [12:52<50:11,  7.82s/it, training_loss=0.064]\u001b[A\n",
            "Epoch 4:  20%|██        | 99/484 [13:00<50:11,  7.82s/it, training_loss=0.002]\u001b[A\n",
            "Epoch 4:  21%|██        | 100/484 [13:00<49:50,  7.79s/it, training_loss=0.002]\u001b[A\n",
            "Epoch 4:  21%|██        | 100/484 [13:07<49:50,  7.79s/it, training_loss=0.001]\u001b[A\n",
            "Epoch 4:  21%|██        | 101/484 [13:07<47:34,  7.45s/it, training_loss=0.001]\u001b[A\n",
            "Epoch 4:  21%|██        | 101/484 [13:16<47:34,  7.45s/it, training_loss=0.001]\u001b[A\n",
            "Epoch 4:  21%|██        | 102/484 [13:16<50:47,  7.98s/it, training_loss=0.001]\u001b[A\n",
            "Epoch 4:  21%|██        | 102/484 [13:23<50:47,  7.98s/it, training_loss=0.008]\u001b[A\n",
            "Epoch 4:  21%|██▏       | 103/484 [13:23<47:48,  7.53s/it, training_loss=0.008]\u001b[A\n",
            "Epoch 4:  21%|██▏       | 103/484 [13:32<47:48,  7.53s/it, training_loss=0.002]\u001b[A\n",
            "Epoch 4:  21%|██▏       | 104/484 [13:32<50:52,  8.03s/it, training_loss=0.002]\u001b[A\n",
            "Epoch 4:  21%|██▏       | 104/484 [13:39<50:52,  8.03s/it, training_loss=0.007]\u001b[A\n",
            "Epoch 4:  22%|██▏       | 105/484 [13:39<48:30,  7.68s/it, training_loss=0.007]\u001b[A\n",
            "Epoch 4:  22%|██▏       | 105/484 [13:46<48:30,  7.68s/it, training_loss=0.009]\u001b[A\n",
            "Epoch 4:  22%|██▏       | 106/484 [13:46<48:26,  7.69s/it, training_loss=0.009]\u001b[A\n",
            "Epoch 4:  22%|██▏       | 106/484 [13:54<48:26,  7.69s/it, training_loss=0.036]\u001b[A\n",
            "Epoch 4:  22%|██▏       | 107/484 [13:54<49:09,  7.82s/it, training_loss=0.036]\u001b[A\n",
            "Epoch 4:  22%|██▏       | 107/484 [14:01<49:09,  7.82s/it, training_loss=0.003]\u001b[A\n",
            "Epoch 4:  22%|██▏       | 108/484 [14:01<46:32,  7.43s/it, training_loss=0.003]\u001b[A\n",
            "Epoch 4:  22%|██▏       | 108/484 [14:11<46:32,  7.43s/it, training_loss=0.002]\u001b[A\n",
            "Epoch 4:  23%|██▎       | 109/484 [14:11<50:33,  8.09s/it, training_loss=0.002]\u001b[A\n",
            "Epoch 4:  23%|██▎       | 109/484 [14:17<50:33,  8.09s/it, training_loss=0.001]\u001b[A\n",
            "Epoch 4:  23%|██▎       | 110/484 [14:17<47:34,  7.63s/it, training_loss=0.001]\u001b[A\n",
            "Epoch 4:  23%|██▎       | 110/484 [14:26<47:34,  7.63s/it, training_loss=0.008]\u001b[A\n",
            "Epoch 4:  23%|██▎       | 111/484 [14:26<50:03,  8.05s/it, training_loss=0.008]\u001b[A\n",
            "Epoch 4:  23%|██▎       | 111/484 [14:33<50:03,  8.05s/it, training_loss=0.001]\u001b[A\n",
            "Epoch 4:  23%|██▎       | 112/484 [14:33<48:09,  7.77s/it, training_loss=0.001]\u001b[A\n",
            "Epoch 4:  23%|██▎       | 112/484 [14:41<48:09,  7.77s/it, training_loss=0.102]\u001b[A\n",
            "Epoch 4:  23%|██▎       | 113/484 [14:41<47:43,  7.72s/it, training_loss=0.102]\u001b[A\n",
            "Epoch 4:  23%|██▎       | 113/484 [14:49<47:43,  7.72s/it, training_loss=0.002]\u001b[A\n",
            "Epoch 4:  24%|██▎       | 114/484 [14:49<48:55,  7.94s/it, training_loss=0.002]\u001b[A\n",
            "Epoch 4:  24%|██▎       | 114/484 [14:56<48:55,  7.94s/it, training_loss=0.141]\u001b[A\n",
            "Epoch 4:  24%|██▍       | 115/484 [14:56<46:12,  7.51s/it, training_loss=0.141]\u001b[A\n",
            "Epoch 4:  24%|██▍       | 115/484 [15:06<46:12,  7.51s/it, training_loss=0.264]\u001b[A\n",
            "Epoch 4:  24%|██▍       | 116/484 [15:06<50:05,  8.17s/it, training_loss=0.264]\u001b[A\n",
            "Epoch 4:  24%|██▍       | 116/484 [15:12<50:05,  8.17s/it, training_loss=0.001]\u001b[A\n",
            "Epoch 4:  24%|██▍       | 117/484 [15:12<46:59,  7.68s/it, training_loss=0.001]\u001b[A\n",
            "Epoch 4:  24%|██▍       | 117/484 [15:21<46:59,  7.68s/it, training_loss=0.013]\u001b[A\n",
            "Epoch 4:  24%|██▍       | 118/484 [15:21<48:57,  8.03s/it, training_loss=0.013]\u001b[A\n",
            "Epoch 4:  24%|██▍       | 118/484 [15:28<48:57,  8.03s/it, training_loss=0.001]\u001b[A\n",
            "Epoch 4:  25%|██▍       | 119/484 [15:28<47:16,  7.77s/it, training_loss=0.001]\u001b[A\n",
            "Epoch 4:  25%|██▍       | 119/484 [15:35<47:16,  7.77s/it, training_loss=0.012]\u001b[A\n",
            "Epoch 4:  25%|██▍       | 120/484 [15:35<46:09,  7.61s/it, training_loss=0.012]\u001b[A\n",
            "Epoch 4:  25%|██▍       | 120/484 [15:44<46:09,  7.61s/it, training_loss=0.001]\u001b[A\n",
            "Epoch 4:  25%|██▌       | 121/484 [15:44<47:57,  7.93s/it, training_loss=0.001]\u001b[A\n",
            "Epoch 4:  25%|██▌       | 121/484 [15:51<47:57,  7.93s/it, training_loss=0.001]\u001b[A\n",
            "Epoch 4:  25%|██▌       | 122/484 [15:51<45:13,  7.50s/it, training_loss=0.001]\u001b[A\n",
            "Epoch 4:  25%|██▌       | 122/484 [16:00<45:13,  7.50s/it, training_loss=0.003]\u001b[A\n",
            "Epoch 4:  25%|██▌       | 123/484 [16:00<49:02,  8.15s/it, training_loss=0.003]\u001b[A\n",
            "Epoch 4:  25%|██▌       | 123/484 [16:07<49:02,  8.15s/it, training_loss=0.003]\u001b[A\n",
            "Epoch 4:  26%|██▌       | 124/484 [16:07<45:52,  7.64s/it, training_loss=0.003]\u001b[A\n",
            "Epoch 4:  26%|██▌       | 124/484 [16:15<45:52,  7.64s/it, training_loss=0.001]\u001b[A\n",
            "Epoch 4:  26%|██▌       | 125/484 [16:15<47:13,  7.89s/it, training_loss=0.001]\u001b[A\n",
            "Epoch 4:  26%|██▌       | 125/484 [16:23<47:13,  7.89s/it, training_loss=0.020]\u001b[A\n",
            "Epoch 4:  26%|██▌       | 126/484 [16:23<46:21,  7.77s/it, training_loss=0.020]\u001b[A\n",
            "Epoch 4:  26%|██▌       | 126/484 [16:29<46:21,  7.77s/it, training_loss=0.002]\u001b[A\n",
            "Epoch 4:  26%|██▌       | 127/484 [16:29<44:29,  7.48s/it, training_loss=0.002]\u001b[A\n",
            "Epoch 4:  26%|██▌       | 127/484 [16:38<44:29,  7.48s/it, training_loss=0.002]\u001b[A\n",
            "Epoch 4:  26%|██▋       | 128/484 [16:38<47:11,  7.95s/it, training_loss=0.002]\u001b[A\n",
            "Epoch 4:  26%|██▋       | 128/484 [16:45<47:11,  7.95s/it, training_loss=0.009]\u001b[A\n",
            "Epoch 4:  27%|██▋       | 129/484 [16:45<44:34,  7.53s/it, training_loss=0.009]\u001b[A\n",
            "Epoch 4:  27%|██▋       | 129/484 [16:55<44:34,  7.53s/it, training_loss=0.001]\u001b[A\n",
            "Epoch 4:  27%|██▋       | 130/484 [16:55<48:00,  8.14s/it, training_loss=0.001]\u001b[A\n",
            "Epoch 4:  27%|██▋       | 130/484 [17:01<48:00,  8.14s/it, training_loss=0.001]\u001b[A\n",
            "Epoch 4:  27%|██▋       | 131/484 [17:01<45:06,  7.67s/it, training_loss=0.001]\u001b[A\n",
            "Epoch 4:  27%|██▋       | 131/484 [17:11<45:06,  7.67s/it, training_loss=0.004]\u001b[A\n",
            "Epoch 4:  27%|██▋       | 132/484 [17:11<48:36,  8.28s/it, training_loss=0.004]\u001b[A\n",
            "Epoch 4:  27%|██▋       | 132/484 [17:18<48:36,  8.28s/it, training_loss=0.002]\u001b[A\n",
            "Epoch 4:  27%|██▋       | 133/484 [17:18<46:39,  7.98s/it, training_loss=0.002]\u001b[A\n",
            "Epoch 4:  27%|██▋       | 133/484 [17:25<46:39,  7.98s/it, training_loss=0.001]\u001b[A\n",
            "Epoch 4:  28%|██▊       | 134/484 [17:25<45:04,  7.73s/it, training_loss=0.001]\u001b[A\n",
            "Epoch 4:  28%|██▊       | 134/484 [17:34<45:04,  7.73s/it, training_loss=0.227]\u001b[A\n",
            "Epoch 4:  28%|██▊       | 135/484 [17:34<46:34,  8.01s/it, training_loss=0.227]\u001b[A\n",
            "Epoch 4:  28%|██▊       | 135/484 [17:40<46:34,  8.01s/it, training_loss=0.002]\u001b[A\n",
            "Epoch 4:  28%|██▊       | 136/484 [17:40<43:45,  7.55s/it, training_loss=0.002]\u001b[A\n",
            "Epoch 4:  28%|██▊       | 136/484 [17:50<43:45,  7.55s/it, training_loss=0.126]\u001b[A\n",
            "Epoch 4:  28%|██▊       | 137/484 [17:50<47:08,  8.15s/it, training_loss=0.126]\u001b[A\n",
            "Epoch 4:  28%|██▊       | 137/484 [17:56<47:08,  8.15s/it, training_loss=0.113]\u001b[A\n",
            "Epoch 4:  29%|██▊       | 138/484 [17:56<44:05,  7.65s/it, training_loss=0.113]\u001b[A\n",
            "Epoch 4:  29%|██▊       | 138/484 [18:05<44:05,  7.65s/it, training_loss=0.281]\u001b[A\n",
            "Epoch 4:  29%|██▊       | 139/484 [18:05<45:10,  7.86s/it, training_loss=0.281]\u001b[A\n",
            "Epoch 4:  29%|██▊       | 139/484 [18:12<45:10,  7.86s/it, training_loss=0.103]\u001b[A\n",
            "Epoch 4:  29%|██▉       | 140/484 [18:12<44:34,  7.77s/it, training_loss=0.103]\u001b[A\n",
            "Epoch 4:  29%|██▉       | 140/484 [18:19<44:34,  7.77s/it, training_loss=0.002]\u001b[A\n",
            "Epoch 4:  29%|██▉       | 141/484 [18:19<42:28,  7.43s/it, training_loss=0.002]\u001b[A\n",
            "Epoch 4:  29%|██▉       | 141/484 [18:28<42:28,  7.43s/it, training_loss=0.008]\u001b[A\n",
            "Epoch 4:  29%|██▉       | 142/484 [18:28<45:28,  7.98s/it, training_loss=0.008]\u001b[A\n",
            "Epoch 4:  29%|██▉       | 142/484 [18:35<45:28,  7.98s/it, training_loss=0.042]\u001b[A\n",
            "Epoch 4:  30%|██▉       | 143/484 [18:35<42:54,  7.55s/it, training_loss=0.042]\u001b[A\n",
            "Epoch 4:  30%|██▉       | 143/484 [18:44<42:54,  7.55s/it, training_loss=0.001]\u001b[A\n",
            "Epoch 4:  30%|██▉       | 144/484 [18:44<45:49,  8.09s/it, training_loss=0.001]\u001b[A\n",
            "Epoch 4:  30%|██▉       | 144/484 [18:51<45:49,  8.09s/it, training_loss=0.263]\u001b[A\n",
            "Epoch 4:  30%|██▉       | 145/484 [18:51<43:18,  7.67s/it, training_loss=0.263]\u001b[A\n",
            "Epoch 4:  30%|██▉       | 145/484 [18:59<43:18,  7.67s/it, training_loss=0.009]\u001b[A\n",
            "Epoch 4:  30%|███       | 146/484 [18:59<43:25,  7.71s/it, training_loss=0.009]\u001b[A\n",
            "Epoch 4:  30%|███       | 146/484 [19:07<43:25,  7.71s/it, training_loss=0.002]\u001b[A\n",
            "Epoch 4:  30%|███       | 147/484 [19:07<43:57,  7.82s/it, training_loss=0.002]\u001b[A\n",
            "Epoch 4:  30%|███       | 147/484 [19:13<43:57,  7.82s/it, training_loss=0.001]\u001b[A\n",
            "Epoch 4:  31%|███       | 148/484 [19:13<41:41,  7.44s/it, training_loss=0.001]\u001b[A\n",
            "Epoch 4:  31%|███       | 148/484 [19:23<41:41,  7.44s/it, training_loss=0.011]\u001b[A\n",
            "Epoch 4:  31%|███       | 149/484 [19:23<45:03,  8.07s/it, training_loss=0.011]\u001b[A\n",
            "Epoch 4:  31%|███       | 149/484 [19:29<45:03,  8.07s/it, training_loss=0.003]\u001b[A\n",
            "Epoch 4:  31%|███       | 150/484 [19:29<42:09,  7.57s/it, training_loss=0.003]\u001b[A\n",
            "Epoch 4:  31%|███       | 150/484 [19:38<42:09,  7.57s/it, training_loss=0.002]\u001b[A\n",
            "Epoch 4:  31%|███       | 151/484 [19:38<44:11,  7.96s/it, training_loss=0.002]\u001b[A\n",
            "Epoch 4:  31%|███       | 151/484 [19:45<44:11,  7.96s/it, training_loss=0.001]\u001b[A\n",
            "Epoch 4:  31%|███▏      | 152/484 [19:45<42:37,  7.70s/it, training_loss=0.001]\u001b[A\n",
            "Epoch 4:  31%|███▏      | 152/484 [19:52<42:37,  7.70s/it, training_loss=0.013]\u001b[A\n",
            "Epoch 4:  32%|███▏      | 153/484 [19:52<41:42,  7.56s/it, training_loss=0.013]\u001b[A\n",
            "Epoch 4:  32%|███▏      | 153/484 [20:01<41:42,  7.56s/it, training_loss=0.005]\u001b[A\n",
            "Epoch 4:  32%|███▏      | 154/484 [20:01<43:13,  7.86s/it, training_loss=0.005]\u001b[A\n",
            "Epoch 4:  32%|███▏      | 154/484 [20:07<43:13,  7.86s/it, training_loss=0.001]\u001b[A\n",
            "Epoch 4:  32%|███▏      | 155/484 [20:07<40:53,  7.46s/it, training_loss=0.001]\u001b[A\n",
            "Epoch 4:  32%|███▏      | 155/484 [20:17<40:53,  7.46s/it, training_loss=0.065]\u001b[A\n",
            "Epoch 4:  32%|███▏      | 156/484 [20:17<44:25,  8.13s/it, training_loss=0.065]\u001b[A\n",
            "Epoch 4:  32%|███▏      | 156/484 [20:24<44:25,  8.13s/it, training_loss=0.003]\u001b[A\n",
            "Epoch 4:  32%|███▏      | 157/484 [20:24<41:38,  7.64s/it, training_loss=0.003]\u001b[A\n",
            "Epoch 4:  32%|███▏      | 157/484 [20:32<41:38,  7.64s/it, training_loss=0.001]\u001b[A\n",
            "Epoch 4:  33%|███▎      | 158/484 [20:32<43:11,  7.95s/it, training_loss=0.001]\u001b[A\n",
            "Epoch 4:  33%|███▎      | 158/484 [20:40<43:11,  7.95s/it, training_loss=0.002]\u001b[A\n",
            "Epoch 4:  33%|███▎      | 159/484 [20:40<42:21,  7.82s/it, training_loss=0.002]\u001b[A\n",
            "Epoch 4:  33%|███▎      | 159/484 [20:47<42:21,  7.82s/it, training_loss=0.002]\u001b[A\n",
            "Epoch 4:  33%|███▎      | 160/484 [20:47<41:23,  7.67s/it, training_loss=0.002]\u001b[A\n",
            "Epoch 4:  33%|███▎      | 160/484 [20:56<41:23,  7.67s/it, training_loss=0.061]\u001b[A\n",
            "Epoch 4:  33%|███▎      | 161/484 [20:56<43:16,  8.04s/it, training_loss=0.061]\u001b[A\n",
            "Epoch 4:  33%|███▎      | 161/484 [21:03<43:16,  8.04s/it, training_loss=0.221]\u001b[A\n",
            "Epoch 4:  33%|███▎      | 162/484 [21:03<40:50,  7.61s/it, training_loss=0.221]\u001b[A\n",
            "Epoch 4:  33%|███▎      | 162/484 [21:14<40:50,  7.61s/it, training_loss=0.001]\u001b[A\n",
            "Epoch 4:  34%|███▎      | 163/484 [21:14<46:18,  8.66s/it, training_loss=0.001]\u001b[A\n",
            "Epoch 4:  34%|███▎      | 163/484 [21:20<46:18,  8.66s/it, training_loss=0.011]\u001b[A\n",
            "Epoch 4:  34%|███▍      | 164/484 [21:20<42:47,  8.02s/it, training_loss=0.011]\u001b[A\n",
            "Epoch 4:  34%|███▍      | 164/484 [21:29<42:47,  8.02s/it, training_loss=0.002]\u001b[A\n",
            "Epoch 4:  34%|███▍      | 165/484 [21:29<43:38,  8.21s/it, training_loss=0.002]\u001b[A\n",
            "Epoch 4:  34%|███▍      | 165/484 [21:36<43:38,  8.21s/it, training_loss=0.001]\u001b[A\n",
            "Epoch 4:  34%|███▍      | 166/484 [21:36<42:19,  7.98s/it, training_loss=0.001]\u001b[A\n",
            "Epoch 4:  34%|███▍      | 166/484 [21:43<42:19,  7.98s/it, training_loss=0.004]\u001b[A\n",
            "Epoch 4:  35%|███▍      | 167/484 [21:43<40:29,  7.66s/it, training_loss=0.004]\u001b[A\n",
            "Epoch 4:  35%|███▍      | 167/484 [21:52<40:29,  7.66s/it, training_loss=0.001]\u001b[A\n",
            "Epoch 4:  35%|███▍      | 168/484 [21:52<42:24,  8.05s/it, training_loss=0.001]\u001b[A\n",
            "Epoch 4:  35%|███▍      | 168/484 [21:59<42:24,  8.05s/it, training_loss=0.010]\u001b[A\n",
            "Epoch 4:  35%|███▍      | 169/484 [21:59<39:48,  7.58s/it, training_loss=0.010]\u001b[A\n",
            "Epoch 4:  35%|███▍      | 169/484 [22:08<39:48,  7.58s/it, training_loss=0.215]\u001b[A\n",
            "Epoch 4:  35%|███▌      | 170/484 [22:08<42:41,  8.16s/it, training_loss=0.215]\u001b[A\n",
            "Epoch 4:  35%|███▌      | 170/484 [22:15<42:41,  8.16s/it, training_loss=0.066]\u001b[A\n",
            "Epoch 4:  35%|███▌      | 171/484 [22:15<40:01,  7.67s/it, training_loss=0.066]\u001b[A\n",
            "Epoch 4:  35%|███▌      | 171/484 [22:23<40:01,  7.67s/it, training_loss=0.001]\u001b[A\n",
            "Epoch 4:  36%|███▌      | 172/484 [22:23<40:30,  7.79s/it, training_loss=0.001]\u001b[A\n",
            "Epoch 4:  36%|███▌      | 172/484 [22:31<40:30,  7.79s/it, training_loss=0.029]\u001b[A\n",
            "Epoch 4:  36%|███▌      | 173/484 [22:31<40:27,  7.80s/it, training_loss=0.029]\u001b[A\n",
            "Epoch 4:  36%|███▌      | 173/484 [22:37<40:27,  7.80s/it, training_loss=0.004]\u001b[A\n",
            "Epoch 4:  36%|███▌      | 174/484 [22:37<38:34,  7.47s/it, training_loss=0.004]\u001b[A\n",
            "Epoch 4:  36%|███▌      | 174/484 [22:47<38:34,  7.47s/it, training_loss=0.050]\u001b[A\n",
            "Epoch 4:  36%|███▌      | 175/484 [22:47<41:29,  8.06s/it, training_loss=0.050]\u001b[A\n",
            "Epoch 4:  36%|███▌      | 175/484 [22:53<41:29,  8.06s/it, training_loss=0.003]\u001b[A\n",
            "Epoch 4:  36%|███▋      | 176/484 [22:53<39:02,  7.61s/it, training_loss=0.003]\u001b[A\n",
            "Epoch 4:  36%|███▋      | 176/484 [23:03<39:02,  7.61s/it, training_loss=0.002]\u001b[A\n",
            "Epoch 4:  37%|███▋      | 177/484 [23:03<41:31,  8.12s/it, training_loss=0.002]\u001b[A\n",
            "Epoch 4:  37%|███▋      | 177/484 [23:10<41:31,  8.12s/it, training_loss=0.257]\u001b[A\n",
            "Epoch 4:  37%|███▋      | 178/484 [23:10<39:26,  7.73s/it, training_loss=0.257]\u001b[A\n",
            "Epoch 4:  37%|███▋      | 178/484 [23:17<39:26,  7.73s/it, training_loss=0.003]\u001b[A\n",
            "Epoch 4:  37%|███▋      | 179/484 [23:17<39:20,  7.74s/it, training_loss=0.003]\u001b[A\n",
            "Epoch 4:  37%|███▋      | 179/484 [23:25<39:20,  7.74s/it, training_loss=0.179]\u001b[A\n",
            "Epoch 4:  37%|███▋      | 180/484 [23:25<39:45,  7.85s/it, training_loss=0.179]\u001b[A\n",
            "Epoch 4:  37%|███▋      | 180/484 [23:32<39:45,  7.85s/it, training_loss=0.002]\u001b[A\n",
            "Epoch 4:  37%|███▋      | 181/484 [23:32<37:36,  7.45s/it, training_loss=0.002]\u001b[A\n",
            "Epoch 4:  37%|███▋      | 181/484 [23:42<37:36,  7.45s/it, training_loss=0.082]\u001b[A\n",
            "Epoch 4:  38%|███▊      | 182/484 [23:42<40:50,  8.11s/it, training_loss=0.082]\u001b[A\n",
            "Epoch 4:  38%|███▊      | 182/484 [23:48<40:50,  8.11s/it, training_loss=0.001]\u001b[A\n",
            "Epoch 4:  38%|███▊      | 183/484 [23:48<38:21,  7.65s/it, training_loss=0.001]\u001b[A\n",
            "Epoch 4:  38%|███▊      | 183/484 [23:57<38:21,  7.65s/it, training_loss=0.001]\u001b[A\n",
            "Epoch 4:  38%|███▊      | 184/484 [23:57<40:16,  8.05s/it, training_loss=0.001]\u001b[A\n",
            "Epoch 4:  38%|███▊      | 184/484 [24:04<40:16,  8.05s/it, training_loss=0.081]\u001b[A\n",
            "Epoch 4:  38%|███▊      | 185/484 [24:04<38:43,  7.77s/it, training_loss=0.081]\u001b[A\n",
            "Epoch 4:  38%|███▊      | 185/484 [24:12<38:43,  7.77s/it, training_loss=0.002]\u001b[A\n",
            "Epoch 4:  38%|███▊      | 186/484 [24:12<38:11,  7.69s/it, training_loss=0.002]\u001b[A\n",
            "Epoch 4:  38%|███▊      | 186/484 [24:20<38:11,  7.69s/it, training_loss=0.002]\u001b[A\n",
            "Epoch 4:  39%|███▊      | 187/484 [24:20<39:11,  7.92s/it, training_loss=0.002]\u001b[A\n",
            "Epoch 4:  39%|███▊      | 187/484 [24:27<39:11,  7.92s/it, training_loss=0.001]\u001b[A\n",
            "Epoch 4:  39%|███▉      | 188/484 [24:27<37:04,  7.52s/it, training_loss=0.001]\u001b[A\n",
            "Epoch 4:  39%|███▉      | 188/484 [24:37<37:04,  7.52s/it, training_loss=0.001]\u001b[A\n",
            "Epoch 4:  39%|███▉      | 189/484 [24:37<40:13,  8.18s/it, training_loss=0.001]\u001b[A\n",
            "Epoch 4:  39%|███▉      | 189/484 [24:43<40:13,  8.18s/it, training_loss=0.001]\u001b[A\n",
            "Epoch 4:  39%|███▉      | 190/484 [24:43<37:43,  7.70s/it, training_loss=0.001]\u001b[A\n",
            "Epoch 4:  39%|███▉      | 190/484 [24:52<37:43,  7.70s/it, training_loss=0.079]\u001b[A\n",
            "Epoch 4:  39%|███▉      | 191/484 [24:52<39:09,  8.02s/it, training_loss=0.079]\u001b[A\n",
            "Epoch 4:  39%|███▉      | 191/484 [24:59<39:09,  8.02s/it, training_loss=0.007]\u001b[A\n",
            "Epoch 4:  40%|███▉      | 192/484 [24:59<37:54,  7.79s/it, training_loss=0.007]\u001b[A\n",
            "Epoch 4:  40%|███▉      | 192/484 [25:06<37:54,  7.79s/it, training_loss=0.001]\u001b[A\n",
            "Epoch 4:  40%|███▉      | 193/484 [25:06<36:57,  7.62s/it, training_loss=0.001]\u001b[A\n",
            "Epoch 4:  40%|███▉      | 193/484 [25:15<36:57,  7.62s/it, training_loss=0.238]\u001b[A\n",
            "Epoch 4:  40%|████      | 194/484 [25:15<38:26,  7.95s/it, training_loss=0.238]\u001b[A\n",
            "Epoch 4:  40%|████      | 194/484 [25:22<38:26,  7.95s/it, training_loss=0.002]\u001b[A\n",
            "Epoch 4:  40%|████      | 195/484 [25:22<36:11,  7.52s/it, training_loss=0.002]\u001b[A\n",
            "Epoch 4:  40%|████      | 195/484 [25:31<36:11,  7.52s/it, training_loss=0.417]\u001b[A\n",
            "Epoch 4:  40%|████      | 196/484 [25:31<38:59,  8.12s/it, training_loss=0.417]\u001b[A\n",
            "Epoch 4:  40%|████      | 196/484 [25:38<38:59,  8.12s/it, training_loss=0.009]\u001b[A\n",
            "Epoch 4:  41%|████      | 197/484 [25:38<36:30,  7.63s/it, training_loss=0.009]\u001b[A\n",
            "Epoch 4:  41%|████      | 197/484 [25:46<36:30,  7.63s/it, training_loss=0.001]\u001b[A\n",
            "Epoch 4:  41%|████      | 198/484 [25:46<37:21,  7.84s/it, training_loss=0.001]\u001b[A\n",
            "Epoch 4:  41%|████      | 198/484 [25:54<37:21,  7.84s/it, training_loss=0.003]\u001b[A\n",
            "Epoch 4:  41%|████      | 199/484 [25:54<36:55,  7.77s/it, training_loss=0.003]\u001b[A\n",
            "Epoch 4:  41%|████      | 199/484 [26:00<36:55,  7.77s/it, training_loss=0.220]\u001b[A\n",
            "Epoch 4:  41%|████▏     | 200/484 [26:00<35:05,  7.42s/it, training_loss=0.220]\u001b[A\n",
            "Epoch 4:  41%|████▏     | 200/484 [26:09<35:05,  7.42s/it, training_loss=0.085]\u001b[A\n",
            "Epoch 4:  42%|████▏     | 201/484 [26:09<37:41,  7.99s/it, training_loss=0.085]\u001b[A\n",
            "Epoch 4:  42%|████▏     | 201/484 [26:16<37:41,  7.99s/it, training_loss=0.282]\u001b[A\n",
            "Epoch 4:  42%|████▏     | 202/484 [26:16<35:29,  7.55s/it, training_loss=0.282]\u001b[A\n",
            "Epoch 4:  42%|████▏     | 202/484 [26:25<35:29,  7.55s/it, training_loss=0.003]\u001b[A\n",
            "Epoch 4:  42%|████▏     | 203/484 [26:25<37:45,  8.06s/it, training_loss=0.003]\u001b[A\n",
            "Epoch 4:  42%|████▏     | 203/484 [26:32<37:45,  8.06s/it, training_loss=0.016]\u001b[A\n",
            "Epoch 4:  42%|████▏     | 204/484 [26:32<35:48,  7.67s/it, training_loss=0.016]\u001b[A\n",
            "Epoch 4:  42%|████▏     | 204/484 [26:40<35:48,  7.67s/it, training_loss=0.080]\u001b[A\n",
            "Epoch 4:  42%|████▏     | 205/484 [26:40<35:58,  7.74s/it, training_loss=0.080]\u001b[A\n",
            "Epoch 4:  42%|████▏     | 205/484 [26:48<35:58,  7.74s/it, training_loss=0.005]\u001b[A\n",
            "Epoch 4:  43%|████▎     | 206/484 [26:48<36:20,  7.84s/it, training_loss=0.005]\u001b[A\n",
            "Epoch 4:  43%|████▎     | 206/484 [26:55<36:20,  7.84s/it, training_loss=0.233]\u001b[A\n",
            "Epoch 4:  43%|████▎     | 207/484 [26:55<34:27,  7.47s/it, training_loss=0.233]\u001b[A\n",
            "Epoch 4:  43%|████▎     | 207/484 [27:04<34:27,  7.47s/it, training_loss=0.020]\u001b[A\n",
            "Epoch 4:  43%|████▎     | 208/484 [27:04<37:15,  8.10s/it, training_loss=0.020]\u001b[A\n",
            "Epoch 4:  43%|████▎     | 208/484 [27:11<37:15,  8.10s/it, training_loss=0.042]\u001b[A\n",
            "Epoch 4:  43%|████▎     | 209/484 [27:11<35:00,  7.64s/it, training_loss=0.042]\u001b[A\n",
            "Epoch 4:  43%|████▎     | 209/484 [27:20<35:00,  7.64s/it, training_loss=0.001]\u001b[A\n",
            "Epoch 4:  43%|████▎     | 210/484 [27:20<36:53,  8.08s/it, training_loss=0.001]\u001b[A\n",
            "Epoch 4:  43%|████▎     | 210/484 [27:27<36:53,  8.08s/it, training_loss=0.002]\u001b[A\n",
            "Epoch 4:  44%|████▎     | 211/484 [27:27<35:07,  7.72s/it, training_loss=0.002]\u001b[A\n",
            "Epoch 4:  44%|████▎     | 211/484 [27:34<35:07,  7.72s/it, training_loss=0.244]\u001b[A\n",
            "Epoch 4:  44%|████▍     | 212/484 [27:34<34:46,  7.67s/it, training_loss=0.244]\u001b[A\n",
            "Epoch 4:  44%|████▍     | 212/484 [27:43<34:46,  7.67s/it, training_loss=0.233]\u001b[A\n",
            "Epoch 4:  44%|████▍     | 213/484 [27:43<35:30,  7.86s/it, training_loss=0.233]\u001b[A\n",
            "Epoch 4:  44%|████▍     | 213/484 [27:49<35:30,  7.86s/it, training_loss=0.098]\u001b[A\n",
            "Epoch 4:  44%|████▍     | 214/484 [27:49<33:26,  7.43s/it, training_loss=0.098]\u001b[A\n",
            "Epoch 4:  44%|████▍     | 214/484 [27:59<33:26,  7.43s/it, training_loss=0.008]\u001b[A\n",
            "Epoch 4:  44%|████▍     | 215/484 [27:59<36:11,  8.07s/it, training_loss=0.008]\u001b[A\n",
            "Epoch 4:  44%|████▍     | 215/484 [28:05<36:11,  8.07s/it, training_loss=0.002]\u001b[A\n",
            "Epoch 4:  45%|████▍     | 216/484 [28:05<33:55,  7.59s/it, training_loss=0.002]\u001b[A\n",
            "Epoch 4:  45%|████▍     | 216/484 [28:14<33:55,  7.59s/it, training_loss=0.002]\u001b[A\n",
            "Epoch 4:  45%|████▍     | 217/484 [28:14<35:20,  7.94s/it, training_loss=0.002]\u001b[A\n",
            "Epoch 4:  45%|████▍     | 217/484 [28:21<35:20,  7.94s/it, training_loss=0.021]\u001b[A\n",
            "Epoch 4:  45%|████▌     | 218/484 [28:21<34:23,  7.76s/it, training_loss=0.021]\u001b[A\n",
            "Epoch 4:  45%|████▌     | 218/484 [28:28<34:23,  7.76s/it, training_loss=0.007]\u001b[A\n",
            "Epoch 4:  45%|████▌     | 219/484 [28:28<33:20,  7.55s/it, training_loss=0.007]\u001b[A\n",
            "Epoch 4:  45%|████▌     | 219/484 [28:37<33:20,  7.55s/it, training_loss=0.022]\u001b[A\n",
            "Epoch 4:  45%|████▌     | 220/484 [28:37<34:55,  7.94s/it, training_loss=0.022]\u001b[A\n",
            "Epoch 4:  45%|████▌     | 220/484 [28:44<34:55,  7.94s/it, training_loss=0.002]\u001b[A\n",
            "Epoch 4:  46%|████▌     | 221/484 [28:44<32:56,  7.52s/it, training_loss=0.002]\u001b[A\n",
            "Epoch 4:  46%|████▌     | 221/484 [28:53<32:56,  7.52s/it, training_loss=0.002]\u001b[A\n",
            "Epoch 4:  46%|████▌     | 222/484 [28:53<35:29,  8.13s/it, training_loss=0.002]\u001b[A\n",
            "Epoch 4:  46%|████▌     | 222/484 [29:00<35:29,  8.13s/it, training_loss=0.004]\u001b[A\n",
            "Epoch 4:  46%|████▌     | 223/484 [29:00<33:19,  7.66s/it, training_loss=0.004]\u001b[A\n",
            "Epoch 4:  46%|████▌     | 223/484 [29:08<33:19,  7.66s/it, training_loss=0.002]\u001b[A\n",
            "Epoch 4:  46%|████▋     | 224/484 [29:08<34:17,  7.91s/it, training_loss=0.002]\u001b[A\n",
            "Epoch 4:  46%|████▋     | 224/484 [29:16<34:17,  7.91s/it, training_loss=0.008]\u001b[A\n",
            "Epoch 4:  46%|████▋     | 225/484 [29:16<33:44,  7.82s/it, training_loss=0.008]\u001b[A\n",
            "Epoch 4:  46%|████▋     | 225/484 [29:22<33:44,  7.82s/it, training_loss=0.171]\u001b[A\n",
            "Epoch 4:  47%|████▋     | 226/484 [29:22<32:11,  7.49s/it, training_loss=0.171]\u001b[A\n",
            "Epoch 4:  47%|████▋     | 226/484 [29:32<32:11,  7.49s/it, training_loss=0.043]\u001b[A\n",
            "Epoch 4:  47%|████▋     | 227/484 [29:32<34:08,  7.97s/it, training_loss=0.043]\u001b[A\n",
            "Epoch 4:  47%|████▋     | 227/484 [29:38<34:08,  7.97s/it, training_loss=0.018]\u001b[A\n",
            "Epoch 4:  47%|████▋     | 228/484 [29:38<32:04,  7.52s/it, training_loss=0.018]\u001b[A\n",
            "Epoch 4:  47%|████▋     | 228/484 [29:47<32:04,  7.52s/it, training_loss=0.001]\u001b[A\n",
            "Epoch 4:  47%|████▋     | 229/484 [29:47<34:17,  8.07s/it, training_loss=0.001]\u001b[A\n",
            "Epoch 4:  47%|████▋     | 229/484 [29:54<34:17,  8.07s/it, training_loss=0.122]\u001b[A\n",
            "Epoch 4:  48%|████▊     | 230/484 [29:54<32:25,  7.66s/it, training_loss=0.122]\u001b[A\n",
            "Epoch 4:  48%|████▊     | 230/484 [30:02<32:25,  7.66s/it, training_loss=0.002]\u001b[A\n",
            "Epoch 4:  48%|████▊     | 231/484 [30:02<32:29,  7.70s/it, training_loss=0.002]\u001b[A\n",
            "Epoch 4:  48%|████▊     | 231/484 [30:10<32:29,  7.70s/it, training_loss=0.025]\u001b[A\n",
            "Epoch 4:  48%|████▊     | 232/484 [30:10<32:50,  7.82s/it, training_loss=0.025]\u001b[A\n",
            "Epoch 4:  48%|████▊     | 232/484 [30:17<32:50,  7.82s/it, training_loss=0.003]\u001b[A\n",
            "Epoch 4:  48%|████▊     | 233/484 [30:17<31:11,  7.46s/it, training_loss=0.003]\u001b[A\n",
            "Epoch 4:  48%|████▊     | 233/484 [30:26<31:11,  7.46s/it, training_loss=0.153]\u001b[A\n",
            "Epoch 4:  48%|████▊     | 234/484 [30:26<33:42,  8.09s/it, training_loss=0.153]\u001b[A\n",
            "Epoch 4:  48%|████▊     | 234/484 [30:33<33:42,  8.09s/it, training_loss=0.001]\u001b[A\n",
            "Epoch 4:  49%|████▊     | 235/484 [30:33<31:36,  7.62s/it, training_loss=0.001]\u001b[A\n",
            "Epoch 4:  49%|████▊     | 235/484 [30:42<31:36,  7.62s/it, training_loss=0.003]\u001b[A\n",
            "Epoch 4:  49%|████▉     | 236/484 [30:42<33:16,  8.05s/it, training_loss=0.003]\u001b[A\n",
            "Epoch 4:  49%|████▉     | 236/484 [30:49<33:16,  8.05s/it, training_loss=0.007]\u001b[A\n",
            "Epoch 4:  49%|████▉     | 237/484 [30:49<31:52,  7.74s/it, training_loss=0.007]\u001b[A\n",
            "Epoch 4:  49%|████▉     | 237/484 [30:56<31:52,  7.74s/it, training_loss=0.001]\u001b[A\n",
            "Epoch 4:  49%|████▉     | 238/484 [30:56<31:28,  7.68s/it, training_loss=0.001]\u001b[A\n",
            "Epoch 4:  49%|████▉     | 238/484 [31:05<31:28,  7.68s/it, training_loss=0.186]\u001b[A\n",
            "Epoch 4:  49%|████▉     | 239/484 [31:05<32:07,  7.87s/it, training_loss=0.186]\u001b[A\n",
            "Epoch 4:  49%|████▉     | 239/484 [31:11<32:07,  7.87s/it, training_loss=0.001]\u001b[A\n",
            "Epoch 4:  50%|████▉     | 240/484 [31:11<30:26,  7.49s/it, training_loss=0.001]\u001b[A\n",
            "Epoch 4:  50%|████▉     | 240/484 [31:21<30:26,  7.49s/it, training_loss=0.115]\u001b[A\n",
            "Epoch 4:  50%|████▉     | 241/484 [31:21<32:59,  8.14s/it, training_loss=0.115]\u001b[A\n",
            "Epoch 4:  50%|████▉     | 241/484 [31:27<32:59,  8.14s/it, training_loss=0.002]\u001b[A\n",
            "Epoch 4:  50%|█████     | 242/484 [31:27<30:48,  7.64s/it, training_loss=0.002]\u001b[A\n",
            "Epoch 4:  50%|█████     | 242/484 [31:36<30:48,  7.64s/it, training_loss=0.027]\u001b[A\n",
            "Epoch 4:  50%|█████     | 243/484 [31:36<32:03,  7.98s/it, training_loss=0.027]\u001b[A\n",
            "Epoch 4:  50%|█████     | 243/484 [31:43<32:03,  7.98s/it, training_loss=0.003]\u001b[A\n",
            "Epoch 4:  50%|█████     | 244/484 [31:43<31:03,  7.77s/it, training_loss=0.003]\u001b[A\n",
            "Epoch 4:  50%|█████     | 244/484 [31:51<31:03,  7.77s/it, training_loss=0.019]\u001b[A\n",
            "Epoch 4:  51%|█████     | 245/484 [31:51<30:15,  7.59s/it, training_loss=0.019]\u001b[A\n",
            "Epoch 4:  51%|█████     | 245/484 [31:59<30:15,  7.59s/it, training_loss=0.001]\u001b[A\n",
            "Epoch 4:  51%|█████     | 246/484 [31:59<31:24,  7.92s/it, training_loss=0.001]\u001b[A\n",
            "Epoch 4:  51%|█████     | 246/484 [32:06<31:24,  7.92s/it, training_loss=0.202]\u001b[A\n",
            "Epoch 4:  51%|█████     | 247/484 [32:06<29:39,  7.51s/it, training_loss=0.202]\u001b[A\n",
            "Epoch 4:  51%|█████     | 247/484 [32:15<29:39,  7.51s/it, training_loss=0.003]\u001b[A\n",
            "Epoch 4:  51%|█████     | 248/484 [32:15<32:04,  8.15s/it, training_loss=0.003]\u001b[A\n",
            "Epoch 4:  51%|█████     | 248/484 [32:22<32:04,  8.15s/it, training_loss=0.001]\u001b[A\n",
            "Epoch 4:  51%|█████▏    | 249/484 [32:22<30:01,  7.66s/it, training_loss=0.001]\u001b[A\n",
            "Epoch 4:  51%|█████▏    | 249/484 [32:31<30:01,  7.66s/it, training_loss=0.001]\u001b[A\n",
            "Epoch 4:  52%|█████▏    | 250/484 [32:31<30:59,  7.95s/it, training_loss=0.001]\u001b[A\n",
            "Epoch 4:  52%|█████▏    | 250/484 [32:38<30:59,  7.95s/it, training_loss=0.002]\u001b[A\n",
            "Epoch 4:  52%|█████▏    | 251/484 [32:38<30:19,  7.81s/it, training_loss=0.002]\u001b[A\n",
            "Epoch 4:  52%|█████▏    | 251/484 [32:45<30:19,  7.81s/it, training_loss=0.001]\u001b[A\n",
            "Epoch 4:  52%|█████▏    | 252/484 [32:45<29:17,  7.57s/it, training_loss=0.001]\u001b[A\n",
            "Epoch 4:  52%|█████▏    | 252/484 [32:54<29:17,  7.57s/it, training_loss=0.001]\u001b[A\n",
            "Epoch 4:  52%|█████▏    | 253/484 [32:54<30:38,  7.96s/it, training_loss=0.001]\u001b[A\n",
            "Epoch 4:  52%|█████▏    | 253/484 [33:00<30:38,  7.96s/it, training_loss=0.001]\u001b[A\n",
            "Epoch 4:  52%|█████▏    | 254/484 [33:00<28:46,  7.51s/it, training_loss=0.001]\u001b[A\n",
            "Epoch 4:  52%|█████▏    | 254/484 [33:10<28:46,  7.51s/it, training_loss=0.002]\u001b[A\n",
            "Epoch 4:  53%|█████▎    | 255/484 [33:10<31:03,  8.14s/it, training_loss=0.002]\u001b[A\n",
            "Epoch 4:  53%|█████▎    | 255/484 [33:17<31:03,  8.14s/it, training_loss=0.004]\u001b[A\n",
            "Epoch 4:  53%|█████▎    | 256/484 [33:17<29:05,  7.66s/it, training_loss=0.004]\u001b[A\n",
            "Epoch 4:  53%|█████▎    | 256/484 [33:25<29:05,  7.66s/it, training_loss=0.002]\u001b[A\n",
            "Epoch 4:  53%|█████▎    | 257/484 [33:25<29:26,  7.78s/it, training_loss=0.002]\u001b[A\n",
            "Epoch 4:  53%|█████▎    | 257/484 [33:32<29:26,  7.78s/it, training_loss=0.001]\u001b[A\n",
            "Epoch 4:  53%|█████▎    | 258/484 [33:32<29:16,  7.77s/it, training_loss=0.001]\u001b[A\n",
            "Epoch 4:  53%|█████▎    | 258/484 [33:39<29:16,  7.77s/it, training_loss=0.001]\u001b[A\n",
            "Epoch 4:  54%|█████▎    | 259/484 [33:39<27:51,  7.43s/it, training_loss=0.001]\u001b[A\n",
            "Epoch 4:  54%|█████▎    | 259/484 [33:48<27:51,  7.43s/it, training_loss=0.001]\u001b[A\n",
            "Epoch 4:  54%|█████▎    | 260/484 [33:48<29:57,  8.02s/it, training_loss=0.001]\u001b[A\n",
            "Epoch 4:  54%|█████▎    | 260/484 [33:55<29:57,  8.02s/it, training_loss=0.170]\u001b[A\n",
            "Epoch 4:  54%|█████▍    | 261/484 [33:55<28:08,  7.57s/it, training_loss=0.170]\u001b[A\n",
            "Epoch 4:  54%|█████▍    | 261/484 [34:04<28:08,  7.57s/it, training_loss=0.092]\u001b[A\n",
            "Epoch 4:  54%|█████▍    | 262/484 [34:04<29:41,  8.02s/it, training_loss=0.092]\u001b[A\n",
            "Epoch 4:  54%|█████▍    | 262/484 [34:11<29:41,  8.02s/it, training_loss=0.001]\u001b[A\n",
            "Epoch 4:  54%|█████▍    | 263/484 [34:11<28:24,  7.71s/it, training_loss=0.001]\u001b[A\n",
            "Epoch 4:  54%|█████▍    | 263/484 [34:19<28:24,  7.71s/it, training_loss=0.002]\u001b[A\n",
            "Epoch 4:  55%|█████▍    | 264/484 [34:19<28:07,  7.67s/it, training_loss=0.002]\u001b[A\n",
            "Epoch 4:  55%|█████▍    | 264/484 [34:27<28:07,  7.67s/it, training_loss=0.431]\u001b[A\n",
            "Epoch 4:  55%|█████▍    | 265/484 [34:27<28:44,  7.88s/it, training_loss=0.431]\u001b[A\n",
            "Epoch 4:  55%|█████▍    | 265/484 [34:34<28:44,  7.88s/it, training_loss=0.002]\u001b[A\n",
            "Epoch 4:  55%|█████▍    | 266/484 [34:34<27:11,  7.48s/it, training_loss=0.002]\u001b[A\n",
            "Epoch 4:  55%|█████▍    | 266/484 [34:43<27:11,  7.48s/it, training_loss=0.001]\u001b[A\n",
            "Epoch 4:  55%|█████▌    | 267/484 [34:43<29:29,  8.15s/it, training_loss=0.001]\u001b[A\n",
            "Epoch 4:  55%|█████▌    | 267/484 [34:50<29:29,  8.15s/it, training_loss=0.001]\u001b[A\n",
            "Epoch 4:  55%|█████▌    | 268/484 [34:50<27:35,  7.66s/it, training_loss=0.001]\u001b[A\n",
            "Epoch 4:  55%|█████▌    | 268/484 [34:59<27:35,  7.66s/it, training_loss=0.001]\u001b[A\n",
            "Epoch 4:  56%|█████▌    | 269/484 [34:59<28:50,  8.05s/it, training_loss=0.001]\u001b[A\n",
            "Epoch 4:  56%|█████▌    | 269/484 [35:06<28:50,  8.05s/it, training_loss=0.004]\u001b[A\n",
            "Epoch 4:  56%|█████▌    | 270/484 [35:06<27:46,  7.79s/it, training_loss=0.004]\u001b[A\n",
            "Epoch 4:  56%|█████▌    | 270/484 [35:13<27:46,  7.79s/it, training_loss=0.001]\u001b[A\n",
            "Epoch 4:  56%|█████▌    | 271/484 [35:13<27:17,  7.69s/it, training_loss=0.001]\u001b[A\n",
            "Epoch 4:  56%|█████▌    | 271/484 [35:22<27:17,  7.69s/it, training_loss=0.004]\u001b[A\n",
            "Epoch 4:  56%|█████▌    | 272/484 [35:22<28:02,  7.93s/it, training_loss=0.004]\u001b[A\n",
            "Epoch 4:  56%|█████▌    | 272/484 [35:28<28:02,  7.93s/it, training_loss=0.001]\u001b[A\n",
            "Epoch 4:  56%|█████▋    | 273/484 [35:28<26:26,  7.52s/it, training_loss=0.001]\u001b[A\n",
            "Epoch 4:  56%|█████▋    | 273/484 [35:38<26:26,  7.52s/it, training_loss=0.170]\u001b[A\n",
            "Epoch 4:  57%|█████▋    | 274/484 [35:38<28:35,  8.17s/it, training_loss=0.170]\u001b[A\n",
            "Epoch 4:  57%|█████▋    | 274/484 [35:45<28:35,  8.17s/it, training_loss=0.227]\u001b[A\n",
            "Epoch 4:  57%|█████▋    | 275/484 [35:45<26:50,  7.71s/it, training_loss=0.227]\u001b[A\n",
            "Epoch 4:  57%|█████▋    | 275/484 [35:53<26:50,  7.71s/it, training_loss=0.003]\u001b[A\n",
            "Epoch 4:  57%|█████▋    | 276/484 [35:53<27:48,  8.02s/it, training_loss=0.003]\u001b[A\n",
            "Epoch 4:  57%|█████▋    | 276/484 [36:01<27:48,  8.02s/it, training_loss=0.232]\u001b[A\n",
            "Epoch 4:  57%|█████▋    | 277/484 [36:01<27:01,  7.84s/it, training_loss=0.232]\u001b[A\n",
            "Epoch 4:  57%|█████▋    | 277/484 [36:08<27:01,  7.84s/it, training_loss=0.163]\u001b[A\n",
            "Epoch 4:  57%|█████▋    | 278/484 [36:08<26:07,  7.61s/it, training_loss=0.163]\u001b[A\n",
            "Epoch 4:  57%|█████▋    | 278/484 [36:17<26:07,  7.61s/it, training_loss=0.001]\u001b[A\n",
            "Epoch 4:  58%|█████▊    | 279/484 [36:17<27:21,  8.01s/it, training_loss=0.001]\u001b[A\n",
            "Epoch 4:  58%|█████▊    | 279/484 [36:23<27:21,  8.01s/it, training_loss=0.001]\u001b[A\n",
            "Epoch 4:  58%|█████▊    | 280/484 [36:23<25:43,  7.57s/it, training_loss=0.001]\u001b[A\n",
            "Epoch 4:  58%|█████▊    | 280/484 [36:33<25:43,  7.57s/it, training_loss=0.001]\u001b[A\n",
            "Epoch 4:  58%|█████▊    | 281/484 [36:33<27:40,  8.18s/it, training_loss=0.001]\u001b[A\n",
            "Epoch 4:  58%|█████▊    | 281/484 [36:40<27:40,  8.18s/it, training_loss=0.248]\u001b[A\n",
            "Epoch 4:  58%|█████▊    | 282/484 [36:40<25:54,  7.69s/it, training_loss=0.248]\u001b[A\n",
            "Epoch 4:  58%|█████▊    | 282/484 [36:48<25:54,  7.69s/it, training_loss=0.001]\u001b[A\n",
            "Epoch 4:  58%|█████▊    | 283/484 [36:48<26:37,  7.95s/it, training_loss=0.001]\u001b[A\n",
            "Epoch 4:  58%|█████▊    | 283/484 [36:56<26:37,  7.95s/it, training_loss=0.377]\u001b[A\n",
            "Epoch 4:  59%|█████▊    | 284/484 [36:56<26:14,  7.87s/it, training_loss=0.377]\u001b[A\n",
            "Epoch 4:  59%|█████▊    | 284/484 [37:03<26:14,  7.87s/it, training_loss=0.002]\u001b[A\n",
            "Epoch 4:  59%|█████▉    | 285/484 [37:03<25:07,  7.57s/it, training_loss=0.002]\u001b[A\n",
            "Epoch 4:  59%|█████▉    | 285/484 [37:12<25:07,  7.57s/it, training_loss=0.043]\u001b[A\n",
            "Epoch 4:  59%|█████▉    | 286/484 [37:12<26:34,  8.05s/it, training_loss=0.043]\u001b[A\n",
            "Epoch 4:  59%|█████▉    | 286/484 [37:18<26:34,  8.05s/it, training_loss=0.220]\u001b[A\n",
            "Epoch 4:  59%|█████▉    | 287/484 [37:18<25:00,  7.62s/it, training_loss=0.220]\u001b[A\n",
            "Epoch 4:  59%|█████▉    | 287/484 [37:28<25:00,  7.62s/it, training_loss=0.001]\u001b[A\n",
            "Epoch 4:  60%|█████▉    | 288/484 [37:28<26:46,  8.20s/it, training_loss=0.001]\u001b[A\n",
            "Epoch 4:  60%|█████▉    | 288/484 [37:35<26:46,  8.20s/it, training_loss=0.016]\u001b[A\n",
            "Epoch 4:  60%|█████▉    | 289/484 [37:35<25:08,  7.74s/it, training_loss=0.016]\u001b[A\n",
            "Epoch 4:  60%|█████▉    | 289/484 [37:43<25:08,  7.74s/it, training_loss=0.048]\u001b[A\n",
            "Epoch 4:  60%|█████▉    | 290/484 [37:43<25:25,  7.86s/it, training_loss=0.048]\u001b[A\n",
            "Epoch 4:  60%|█████▉    | 290/484 [37:51<25:25,  7.86s/it, training_loss=0.032]\u001b[A\n",
            "Epoch 4:  60%|██████    | 291/484 [37:51<25:16,  7.86s/it, training_loss=0.032]\u001b[A\n",
            "Epoch 4:  60%|██████    | 291/484 [37:57<25:16,  7.86s/it, training_loss=0.001]\u001b[A\n",
            "Epoch 4:  60%|██████    | 292/484 [37:57<23:55,  7.47s/it, training_loss=0.001]\u001b[A\n",
            "Epoch 4:  60%|██████    | 292/484 [38:07<23:55,  7.47s/it, training_loss=0.001]\u001b[A\n",
            "Epoch 4:  61%|██████    | 293/484 [38:07<25:42,  8.08s/it, training_loss=0.001]\u001b[A\n",
            "Epoch 4:  61%|██████    | 293/484 [38:13<25:42,  8.08s/it, training_loss=0.003]\u001b[A\n",
            "Epoch 4:  61%|██████    | 294/484 [38:13<24:09,  7.63s/it, training_loss=0.003]\u001b[A\n",
            "Epoch 4:  61%|██████    | 294/484 [38:22<24:09,  7.63s/it, training_loss=0.003]\u001b[A\n",
            "Epoch 4:  61%|██████    | 295/484 [38:23<25:29,  8.09s/it, training_loss=0.003]\u001b[A\n",
            "Epoch 4:  61%|██████    | 295/484 [38:29<25:29,  8.09s/it, training_loss=0.001]\u001b[A\n",
            "Epoch 4:  61%|██████    | 296/484 [38:29<24:17,  7.75s/it, training_loss=0.001]\u001b[A\n",
            "Epoch 4:  61%|██████    | 296/484 [38:37<24:17,  7.75s/it, training_loss=0.001]\u001b[A\n",
            "Epoch 4:  61%|██████▏   | 297/484 [38:37<23:59,  7.70s/it, training_loss=0.001]\u001b[A\n",
            "Epoch 4:  61%|██████▏   | 297/484 [38:45<23:59,  7.70s/it, training_loss=0.070]\u001b[A\n",
            "Epoch 4:  62%|██████▏   | 298/484 [38:45<24:31,  7.91s/it, training_loss=0.070]\u001b[A\n",
            "Epoch 4:  62%|██████▏   | 298/484 [38:52<24:31,  7.91s/it, training_loss=0.001]\u001b[A\n",
            "Epoch 4:  62%|██████▏   | 299/484 [38:52<23:07,  7.50s/it, training_loss=0.001]\u001b[A\n",
            "Epoch 4:  62%|██████▏   | 299/484 [39:02<23:07,  7.50s/it, training_loss=0.001]\u001b[A\n",
            "Epoch 4:  62%|██████▏   | 300/484 [39:02<24:58,  8.14s/it, training_loss=0.001]\u001b[A\n",
            "Epoch 4:  62%|██████▏   | 300/484 [39:08<24:58,  8.14s/it, training_loss=0.001]\u001b[A\n",
            "Epoch 4:  62%|██████▏   | 301/484 [39:08<23:21,  7.66s/it, training_loss=0.001]\u001b[A\n",
            "Epoch 4:  62%|██████▏   | 301/484 [39:17<23:21,  7.66s/it, training_loss=0.001]\u001b[A\n",
            "Epoch 4:  62%|██████▏   | 302/484 [39:17<24:27,  8.06s/it, training_loss=0.001]\u001b[A\n",
            "Epoch 4:  62%|██████▏   | 302/484 [39:24<24:27,  8.06s/it, training_loss=0.002]\u001b[A\n",
            "Epoch 4:  63%|██████▎   | 303/484 [39:24<23:31,  7.80s/it, training_loss=0.002]\u001b[A\n",
            "Epoch 4:  63%|██████▎   | 303/484 [39:32<23:31,  7.80s/it, training_loss=0.031]\u001b[A\n",
            "Epoch 4:  63%|██████▎   | 304/484 [39:32<22:51,  7.62s/it, training_loss=0.031]\u001b[A\n",
            "Epoch 4:  63%|██████▎   | 304/484 [39:40<22:51,  7.62s/it, training_loss=0.001]\u001b[A\n",
            "Epoch 4:  63%|██████▎   | 305/484 [39:40<23:37,  7.92s/it, training_loss=0.001]\u001b[A\n",
            "Epoch 4:  63%|██████▎   | 305/484 [39:47<23:37,  7.92s/it, training_loss=0.001]\u001b[A\n",
            "Epoch 4:  63%|██████▎   | 306/484 [39:47<22:18,  7.52s/it, training_loss=0.001]\u001b[A\n",
            "Epoch 4:  63%|██████▎   | 306/484 [39:56<22:18,  7.52s/it, training_loss=0.001]\u001b[A\n",
            "Epoch 4:  63%|██████▎   | 307/484 [39:56<24:03,  8.15s/it, training_loss=0.001]\u001b[A\n",
            "Epoch 4:  63%|██████▎   | 307/484 [40:03<24:03,  8.15s/it, training_loss=0.001]\u001b[A\n",
            "Epoch 4:  64%|██████▎   | 308/484 [40:03<22:27,  7.66s/it, training_loss=0.001]\u001b[A\n",
            "Epoch 4:  64%|██████▎   | 308/484 [40:11<22:27,  7.66s/it, training_loss=0.001]\u001b[A\n",
            "Epoch 4:  64%|██████▍   | 309/484 [40:11<23:09,  7.94s/it, training_loss=0.001]\u001b[A\n",
            "Epoch 4:  64%|██████▍   | 309/484 [40:19<23:09,  7.94s/it, training_loss=0.031]\u001b[A\n",
            "Epoch 4:  64%|██████▍   | 310/484 [40:19<22:43,  7.84s/it, training_loss=0.031]\u001b[A\n",
            "Epoch 4:  64%|██████▍   | 310/484 [40:26<22:43,  7.84s/it, training_loss=0.407]\u001b[A\n",
            "Epoch 4:  64%|██████▍   | 311/484 [40:26<21:45,  7.55s/it, training_loss=0.407]\u001b[A\n",
            "Epoch 4:  64%|██████▍   | 311/484 [40:35<21:45,  7.55s/it, training_loss=0.154]\u001b[A\n",
            "Epoch 4:  64%|██████▍   | 312/484 [40:35<22:54,  7.99s/it, training_loss=0.154]\u001b[A\n",
            "Epoch 4:  64%|██████▍   | 312/484 [40:42<22:54,  7.99s/it, training_loss=0.112]\u001b[A\n",
            "Epoch 4:  65%|██████▍   | 313/484 [40:42<21:32,  7.56s/it, training_loss=0.112]\u001b[A\n",
            "Epoch 4:  65%|██████▍   | 313/484 [40:51<21:32,  7.56s/it, training_loss=0.017]\u001b[A\n",
            "Epoch 4:  65%|██████▍   | 314/484 [40:51<23:05,  8.15s/it, training_loss=0.017]\u001b[A\n",
            "Epoch 4:  65%|██████▍   | 314/484 [40:58<23:05,  8.15s/it, training_loss=0.001]\u001b[A\n",
            "Epoch 4:  65%|██████▌   | 315/484 [40:58<21:38,  7.68s/it, training_loss=0.001]\u001b[A\n",
            "Epoch 4:  65%|██████▌   | 315/484 [41:06<21:38,  7.68s/it, training_loss=0.083]\u001b[A\n",
            "Epoch 4:  65%|██████▌   | 316/484 [41:06<21:47,  7.78s/it, training_loss=0.083]\u001b[A\n",
            "Epoch 4:  65%|██████▌   | 316/484 [41:14<21:47,  7.78s/it, training_loss=0.001]\u001b[A\n",
            "Epoch 4:  65%|██████▌   | 317/484 [41:14<21:44,  7.81s/it, training_loss=0.001]\u001b[A\n",
            "Epoch 4:  65%|██████▌   | 317/484 [41:20<21:44,  7.81s/it, training_loss=0.001]\u001b[A\n",
            "Epoch 4:  66%|██████▌   | 318/484 [41:20<20:35,  7.44s/it, training_loss=0.001]\u001b[A\n",
            "Epoch 4:  66%|██████▌   | 318/484 [41:30<20:35,  7.44s/it, training_loss=0.001]\u001b[A\n",
            "Epoch 4:  66%|██████▌   | 319/484 [41:30<22:06,  8.04s/it, training_loss=0.001]\u001b[A\n",
            "Epoch 4:  66%|██████▌   | 319/484 [41:36<22:06,  8.04s/it, training_loss=0.038]\u001b[A\n",
            "Epoch 4:  66%|██████▌   | 320/484 [41:36<20:41,  7.57s/it, training_loss=0.038]\u001b[A\n",
            "Epoch 4:  66%|██████▌   | 320/484 [41:45<20:41,  7.57s/it, training_loss=0.001]\u001b[A\n",
            "Epoch 4:  66%|██████▋   | 321/484 [41:45<21:49,  8.04s/it, training_loss=0.001]\u001b[A\n",
            "Epoch 4:  66%|██████▋   | 321/484 [41:52<21:49,  8.04s/it, training_loss=0.064]\u001b[A\n",
            "Epoch 4:  67%|██████▋   | 322/484 [41:52<21:00,  7.78s/it, training_loss=0.064]\u001b[A\n",
            "Epoch 4:  67%|██████▋   | 322/484 [42:00<21:00,  7.78s/it, training_loss=0.005]\u001b[A\n",
            "Epoch 4:  67%|██████▋   | 323/484 [42:00<20:50,  7.76s/it, training_loss=0.005]\u001b[A\n",
            "Epoch 4:  67%|██████▋   | 323/484 [42:08<20:50,  7.76s/it, training_loss=0.001]\u001b[A\n",
            "Epoch 4:  67%|██████▋   | 324/484 [42:08<21:11,  7.94s/it, training_loss=0.001]\u001b[A\n",
            "Epoch 4:  67%|██████▋   | 324/484 [42:15<21:11,  7.94s/it, training_loss=0.001]\u001b[A\n",
            "Epoch 4:  67%|██████▋   | 325/484 [42:15<20:02,  7.56s/it, training_loss=0.001]\u001b[A\n",
            "Epoch 4:  67%|██████▋   | 325/484 [42:25<20:02,  7.56s/it, training_loss=0.001]\u001b[A\n",
            "Epoch 4:  67%|██████▋   | 326/484 [42:25<21:51,  8.30s/it, training_loss=0.001]\u001b[A\n",
            "Epoch 4:  67%|██████▋   | 326/484 [42:32<21:51,  8.30s/it, training_loss=0.092]\u001b[A\n",
            "Epoch 4:  68%|██████▊   | 327/484 [42:32<20:18,  7.76s/it, training_loss=0.092]\u001b[A\n",
            "Epoch 4:  68%|██████▊   | 327/484 [42:41<20:18,  7.76s/it, training_loss=0.001]\u001b[A\n",
            "Epoch 4:  68%|██████▊   | 328/484 [42:41<21:06,  8.12s/it, training_loss=0.001]\u001b[A\n",
            "Epoch 4:  68%|██████▊   | 328/484 [42:48<21:06,  8.12s/it, training_loss=0.004]\u001b[A\n",
            "Epoch 4:  68%|██████▊   | 329/484 [42:48<20:11,  7.82s/it, training_loss=0.004]\u001b[A\n",
            "Epoch 4:  68%|██████▊   | 329/484 [42:55<20:11,  7.82s/it, training_loss=0.006]\u001b[A\n",
            "Epoch 4:  68%|██████▊   | 330/484 [42:55<19:47,  7.71s/it, training_loss=0.006]\u001b[A\n",
            "Epoch 4:  68%|██████▊   | 330/484 [43:04<19:47,  7.71s/it, training_loss=0.124]\u001b[A\n",
            "Epoch 4:  68%|██████▊   | 331/484 [43:04<20:12,  7.92s/it, training_loss=0.124]\u001b[A\n",
            "Epoch 4:  68%|██████▊   | 331/484 [43:10<20:12,  7.92s/it, training_loss=0.001]\u001b[A\n",
            "Epoch 4:  69%|██████▊   | 332/484 [43:10<19:00,  7.51s/it, training_loss=0.001]\u001b[A\n",
            "Epoch 4:  69%|██████▊   | 332/484 [43:20<19:00,  7.51s/it, training_loss=0.001]\u001b[A\n",
            "Epoch 4:  69%|██████▉   | 333/484 [43:20<20:30,  8.15s/it, training_loss=0.001]\u001b[A\n",
            "Epoch 4:  69%|██████▉   | 333/484 [43:26<20:30,  8.15s/it, training_loss=0.002]\u001b[A\n",
            "Epoch 4:  69%|██████▉   | 334/484 [43:26<19:07,  7.65s/it, training_loss=0.002]\u001b[A\n",
            "Epoch 4:  69%|██████▉   | 334/484 [43:35<19:07,  7.65s/it, training_loss=0.001]\u001b[A\n",
            "Epoch 4:  69%|██████▉   | 335/484 [43:35<19:44,  7.95s/it, training_loss=0.001]\u001b[A\n",
            "Epoch 4:  69%|██████▉   | 335/484 [43:42<19:44,  7.95s/it, training_loss=0.066]\u001b[A\n",
            "Epoch 4:  69%|██████▉   | 336/484 [43:42<19:11,  7.78s/it, training_loss=0.066]\u001b[A\n",
            "Epoch 4:  69%|██████▉   | 336/484 [43:49<19:11,  7.78s/it, training_loss=0.001]\u001b[A\n",
            "Epoch 4:  70%|██████▉   | 337/484 [43:49<18:27,  7.53s/it, training_loss=0.001]\u001b[A\n",
            "Epoch 4:  70%|██████▉   | 337/484 [43:58<18:27,  7.53s/it, training_loss=0.010]\u001b[A\n",
            "Epoch 4:  70%|██████▉   | 338/484 [43:58<19:19,  7.94s/it, training_loss=0.010]\u001b[A\n",
            "Epoch 4:  70%|██████▉   | 338/484 [44:05<19:19,  7.94s/it, training_loss=0.091]\u001b[A\n",
            "Epoch 4:  70%|███████   | 339/484 [44:05<18:08,  7.50s/it, training_loss=0.091]\u001b[A\n",
            "Epoch 4:  70%|███████   | 339/484 [44:14<18:08,  7.50s/it, training_loss=0.001]\u001b[A\n",
            "Epoch 4:  70%|███████   | 340/484 [44:14<19:26,  8.10s/it, training_loss=0.001]\u001b[A\n",
            "Epoch 4:  70%|███████   | 340/484 [44:21<19:26,  8.10s/it, training_loss=0.061]\u001b[A\n",
            "Epoch 4:  70%|███████   | 341/484 [44:21<18:16,  7.67s/it, training_loss=0.061]\u001b[A\n",
            "Epoch 4:  70%|███████   | 341/484 [44:29<18:16,  7.67s/it, training_loss=0.001]\u001b[A\n",
            "Epoch 4:  71%|███████   | 342/484 [44:29<18:27,  7.80s/it, training_loss=0.001]\u001b[A\n",
            "Epoch 4:  71%|███████   | 342/484 [44:37<18:27,  7.80s/it, training_loss=0.005]\u001b[A\n",
            "Epoch 4:  71%|███████   | 343/484 [44:37<18:22,  7.82s/it, training_loss=0.005]\u001b[A\n",
            "Epoch 4:  71%|███████   | 343/484 [44:43<18:22,  7.82s/it, training_loss=0.001]\u001b[A\n",
            "Epoch 4:  71%|███████   | 344/484 [44:43<17:28,  7.49s/it, training_loss=0.001]\u001b[A\n",
            "Epoch 4:  71%|███████   | 344/484 [44:53<17:28,  7.49s/it, training_loss=0.004]\u001b[A\n",
            "Epoch 4:  71%|███████▏  | 345/484 [44:53<18:40,  8.06s/it, training_loss=0.004]\u001b[A\n",
            "Epoch 4:  71%|███████▏  | 345/484 [44:59<18:40,  8.06s/it, training_loss=0.003]\u001b[A\n",
            "Epoch 4:  71%|███████▏  | 346/484 [44:59<17:28,  7.60s/it, training_loss=0.003]\u001b[A\n",
            "Epoch 4:  71%|███████▏  | 346/484 [45:09<17:28,  7.60s/it, training_loss=0.142]\u001b[A\n",
            "Epoch 4:  72%|███████▏  | 347/484 [45:09<18:29,  8.10s/it, training_loss=0.142]\u001b[A\n",
            "Epoch 4:  72%|███████▏  | 347/484 [45:16<18:29,  8.10s/it, training_loss=0.002]\u001b[A\n",
            "Epoch 4:  72%|███████▏  | 348/484 [45:16<17:33,  7.74s/it, training_loss=0.002]\u001b[A\n",
            "Epoch 4:  72%|███████▏  | 348/484 [45:23<17:33,  7.74s/it, training_loss=0.002]\u001b[A\n",
            "Epoch 4:  72%|███████▏  | 349/484 [45:23<17:26,  7.75s/it, training_loss=0.002]\u001b[A\n",
            "Epoch 4:  72%|███████▏  | 349/484 [45:31<17:26,  7.75s/it, training_loss=0.010]\u001b[A\n",
            "Epoch 4:  72%|███████▏  | 350/484 [45:31<17:32,  7.86s/it, training_loss=0.010]\u001b[A\n",
            "Epoch 4:  72%|███████▏  | 350/484 [45:38<17:32,  7.86s/it, training_loss=0.479]\u001b[A\n",
            "Epoch 4:  73%|███████▎  | 351/484 [45:38<16:29,  7.44s/it, training_loss=0.479]\u001b[A\n",
            "Epoch 4:  73%|███████▎  | 351/484 [45:48<16:29,  7.44s/it, training_loss=0.001]\u001b[A\n",
            "Epoch 4:  73%|███████▎  | 352/484 [45:48<17:50,  8.11s/it, training_loss=0.001]\u001b[A\n",
            "Epoch 4:  73%|███████▎  | 352/484 [45:54<17:50,  8.11s/it, training_loss=0.001]\u001b[A\n",
            "Epoch 4:  73%|███████▎  | 353/484 [45:54<16:37,  7.61s/it, training_loss=0.001]\u001b[A\n",
            "Epoch 4:  73%|███████▎  | 353/484 [46:03<16:37,  7.61s/it, training_loss=0.001]\u001b[A\n",
            "Epoch 4:  73%|███████▎  | 354/484 [46:03<17:20,  8.00s/it, training_loss=0.001]\u001b[A\n",
            "Epoch 4:  73%|███████▎  | 354/484 [46:10<17:20,  8.00s/it, training_loss=0.001]\u001b[A\n",
            "Epoch 4:  73%|███████▎  | 355/484 [46:10<16:40,  7.76s/it, training_loss=0.001]\u001b[A\n",
            "Epoch 4:  73%|███████▎  | 355/484 [46:17<16:40,  7.76s/it, training_loss=0.001]\u001b[A\n",
            "Epoch 4:  74%|███████▎  | 356/484 [46:17<16:16,  7.63s/it, training_loss=0.001]\u001b[A\n",
            "Epoch 4:  74%|███████▎  | 356/484 [46:26<16:16,  7.63s/it, training_loss=0.209]\u001b[A\n",
            "Epoch 4:  74%|███████▍  | 357/484 [46:26<16:49,  7.95s/it, training_loss=0.209]\u001b[A\n",
            "Epoch 4:  74%|███████▍  | 357/484 [46:33<16:49,  7.95s/it, training_loss=0.001]\u001b[A\n",
            "Epoch 4:  74%|███████▍  | 358/484 [46:33<15:48,  7.52s/it, training_loss=0.001]\u001b[A\n",
            "Epoch 4:  74%|███████▍  | 358/484 [46:42<15:48,  7.52s/it, training_loss=0.002]\u001b[A\n",
            "Epoch 4:  74%|███████▍  | 359/484 [46:42<17:03,  8.19s/it, training_loss=0.002]\u001b[A\n",
            "Epoch 4:  74%|███████▍  | 359/484 [46:49<17:03,  8.19s/it, training_loss=0.004]\u001b[A\n",
            "Epoch 4:  74%|███████▍  | 360/484 [46:49<15:57,  7.72s/it, training_loss=0.004]\u001b[A\n",
            "Epoch 4:  74%|███████▍  | 360/484 [46:58<15:57,  7.72s/it, training_loss=0.003]\u001b[A\n",
            "Epoch 4:  75%|███████▍  | 361/484 [46:58<16:31,  8.06s/it, training_loss=0.003]\u001b[A\n",
            "Epoch 4:  75%|███████▍  | 361/484 [47:05<16:31,  8.06s/it, training_loss=0.001]\u001b[A\n",
            "Epoch 4:  75%|███████▍  | 362/484 [47:05<15:55,  7.83s/it, training_loss=0.001]\u001b[A\n",
            "Epoch 4:  75%|███████▍  | 362/484 [47:12<15:55,  7.83s/it, training_loss=0.001]\u001b[A\n",
            "Epoch 4:  75%|███████▌  | 363/484 [47:12<15:27,  7.66s/it, training_loss=0.001]\u001b[A\n",
            "Epoch 4:  75%|███████▌  | 363/484 [47:21<15:27,  7.66s/it, training_loss=0.002]\u001b[A\n",
            "Epoch 4:  75%|███████▌  | 364/484 [47:21<16:00,  8.01s/it, training_loss=0.002]\u001b[A\n",
            "Epoch 4:  75%|███████▌  | 364/484 [47:28<16:00,  8.01s/it, training_loss=0.001]\u001b[A\n",
            "Epoch 4:  75%|███████▌  | 365/484 [47:28<14:59,  7.56s/it, training_loss=0.001]\u001b[A\n",
            "Epoch 4:  75%|███████▌  | 365/484 [47:37<14:59,  7.56s/it, training_loss=0.002]\u001b[A\n",
            "Epoch 4:  76%|███████▌  | 366/484 [47:37<16:05,  8.18s/it, training_loss=0.002]\u001b[A\n",
            "Epoch 4:  76%|███████▌  | 366/484 [47:44<16:05,  8.18s/it, training_loss=0.002]\u001b[A\n",
            "Epoch 4:  76%|███████▌  | 367/484 [47:44<14:58,  7.68s/it, training_loss=0.002]\u001b[A\n",
            "Epoch 4:  76%|███████▌  | 367/484 [47:52<14:58,  7.68s/it, training_loss=0.001]\u001b[A\n",
            "Epoch 4:  76%|███████▌  | 368/484 [47:52<15:20,  7.94s/it, training_loss=0.001]\u001b[A\n",
            "Epoch 4:  76%|███████▌  | 368/484 [48:00<15:20,  7.94s/it, training_loss=0.001]\u001b[A\n",
            "Epoch 4:  76%|███████▌  | 369/484 [48:00<14:57,  7.81s/it, training_loss=0.001]\u001b[A\n",
            "Epoch 4:  76%|███████▌  | 369/484 [48:07<14:57,  7.81s/it, training_loss=0.012]\u001b[A\n",
            "Epoch 4:  76%|███████▋  | 370/484 [48:07<14:15,  7.51s/it, training_loss=0.012]\u001b[A\n",
            "Epoch 4:  76%|███████▋  | 370/484 [48:16<14:15,  7.51s/it, training_loss=0.276]\u001b[A\n",
            "Epoch 4:  77%|███████▋  | 371/484 [48:16<15:01,  7.98s/it, training_loss=0.276]\u001b[A\n",
            "Epoch 4:  77%|███████▋  | 371/484 [48:22<15:01,  7.98s/it, training_loss=0.076]\u001b[A\n",
            "Epoch 4:  77%|███████▋  | 372/484 [48:22<14:05,  7.55s/it, training_loss=0.076]\u001b[A\n",
            "Epoch 4:  77%|███████▋  | 372/484 [48:32<14:05,  7.55s/it, training_loss=0.199]\u001b[A\n",
            "Epoch 4:  77%|███████▋  | 373/484 [48:32<15:03,  8.14s/it, training_loss=0.199]\u001b[A\n",
            "Epoch 4:  77%|███████▋  | 373/484 [48:38<15:03,  8.14s/it, training_loss=0.001]\u001b[A\n",
            "Epoch 4:  77%|███████▋  | 374/484 [48:38<14:02,  7.66s/it, training_loss=0.001]\u001b[A\n",
            "Epoch 4:  77%|███████▋  | 374/484 [48:47<14:02,  7.66s/it, training_loss=0.224]\u001b[A\n",
            "Epoch 4:  77%|███████▋  | 375/484 [48:47<14:08,  7.79s/it, training_loss=0.224]\u001b[A\n",
            "Epoch 4:  77%|███████▋  | 375/484 [48:54<14:08,  7.79s/it, training_loss=0.321]\u001b[A\n",
            "Epoch 4:  78%|███████▊  | 376/484 [48:54<14:05,  7.83s/it, training_loss=0.321]\u001b[A\n",
            "Epoch 4:  78%|███████▊  | 376/484 [49:01<14:05,  7.83s/it, training_loss=0.097]\u001b[A\n",
            "Epoch 4:  78%|███████▊  | 377/484 [49:01<13:18,  7.47s/it, training_loss=0.097]\u001b[A\n",
            "Epoch 4:  78%|███████▊  | 377/484 [49:11<13:18,  7.47s/it, training_loss=0.002]\u001b[A\n",
            "Epoch 4:  78%|███████▊  | 378/484 [49:11<14:14,  8.06s/it, training_loss=0.002]\u001b[A\n",
            "Epoch 4:  78%|███████▊  | 378/484 [49:17<14:14,  8.06s/it, training_loss=0.082]\u001b[A\n",
            "Epoch 4:  78%|███████▊  | 379/484 [49:17<13:17,  7.59s/it, training_loss=0.082]\u001b[A\n",
            "Epoch 4:  78%|███████▊  | 379/484 [49:26<13:17,  7.59s/it, training_loss=0.003]\u001b[A\n",
            "Epoch 4:  79%|███████▊  | 380/484 [49:26<14:04,  8.12s/it, training_loss=0.003]\u001b[A\n",
            "Epoch 4:  79%|███████▊  | 380/484 [49:33<14:04,  8.12s/it, training_loss=0.036]\u001b[A\n",
            "Epoch 4:  79%|███████▊  | 381/484 [49:33<13:18,  7.76s/it, training_loss=0.036]\u001b[A\n",
            "Epoch 4:  79%|███████▊  | 381/484 [49:41<13:18,  7.76s/it, training_loss=0.001]\u001b[A\n",
            "Epoch 4:  79%|███████▉  | 382/484 [49:41<13:04,  7.69s/it, training_loss=0.001]\u001b[A\n",
            "Epoch 4:  79%|███████▉  | 382/484 [49:49<13:04,  7.69s/it, training_loss=0.003]\u001b[A\n",
            "Epoch 4:  79%|███████▉  | 383/484 [49:49<13:16,  7.89s/it, training_loss=0.003]\u001b[A\n",
            "Epoch 4:  79%|███████▉  | 383/484 [49:56<13:16,  7.89s/it, training_loss=0.208]\u001b[A\n",
            "Epoch 4:  79%|███████▉  | 384/484 [49:56<12:27,  7.47s/it, training_loss=0.208]\u001b[A\n",
            "Epoch 4:  79%|███████▉  | 384/484 [50:05<12:27,  7.47s/it, training_loss=0.003]\u001b[A\n",
            "Epoch 4:  80%|███████▉  | 385/484 [50:05<13:27,  8.15s/it, training_loss=0.003]\u001b[A\n",
            "Epoch 4:  80%|███████▉  | 385/484 [50:12<13:27,  8.15s/it, training_loss=0.099]\u001b[A\n",
            "Epoch 4:  80%|███████▉  | 386/484 [50:12<12:30,  7.66s/it, training_loss=0.099]\u001b[A\n",
            "Epoch 4:  80%|███████▉  | 386/484 [50:21<12:30,  7.66s/it, training_loss=0.081]\u001b[A\n",
            "Epoch 4:  80%|███████▉  | 387/484 [50:21<12:57,  8.02s/it, training_loss=0.081]\u001b[A\n",
            "Epoch 4:  80%|███████▉  | 387/484 [50:28<12:57,  8.02s/it, training_loss=0.259]\u001b[A\n",
            "Epoch 4:  80%|████████  | 388/484 [50:28<12:29,  7.81s/it, training_loss=0.259]\u001b[A\n",
            "Epoch 4:  80%|████████  | 388/484 [50:35<12:29,  7.81s/it, training_loss=0.001]\u001b[A\n",
            "Epoch 4:  80%|████████  | 389/484 [50:35<12:04,  7.63s/it, training_loss=0.001]\u001b[A\n",
            "Epoch 4:  80%|████████  | 389/484 [50:44<12:04,  7.63s/it, training_loss=0.001]\u001b[A\n",
            "Epoch 4:  81%|████████  | 390/484 [50:44<12:30,  7.98s/it, training_loss=0.001]\u001b[A\n",
            "Epoch 4:  81%|████████  | 390/484 [50:51<12:30,  7.98s/it, training_loss=0.026]\u001b[A\n",
            "Epoch 4:  81%|████████  | 391/484 [50:51<11:41,  7.55s/it, training_loss=0.026]\u001b[A\n",
            "Epoch 4:  81%|████████  | 391/484 [51:00<11:41,  7.55s/it, training_loss=0.001]\u001b[A\n",
            "Epoch 4:  81%|████████  | 392/484 [51:00<12:33,  8.19s/it, training_loss=0.001]\u001b[A\n",
            "Epoch 4:  81%|████████  | 392/484 [51:07<12:33,  8.19s/it, training_loss=0.001]\u001b[A\n",
            "Epoch 4:  81%|████████  | 393/484 [51:07<11:40,  7.70s/it, training_loss=0.001]\u001b[A\n",
            "Epoch 4:  81%|████████  | 393/484 [51:16<11:40,  7.70s/it, training_loss=0.001]\u001b[A\n",
            "Epoch 4:  81%|████████▏ | 394/484 [51:16<11:58,  7.98s/it, training_loss=0.001]\u001b[A\n",
            "Epoch 4:  81%|████████▏ | 394/484 [51:23<11:58,  7.98s/it, training_loss=0.001]\u001b[A\n",
            "Epoch 4:  82%|████████▏ | 395/484 [51:23<11:36,  7.82s/it, training_loss=0.001]\u001b[A\n",
            "Epoch 4:  82%|████████▏ | 395/484 [51:30<11:36,  7.82s/it, training_loss=0.184]\u001b[A\n",
            "Epoch 4:  82%|████████▏ | 396/484 [51:30<11:02,  7.52s/it, training_loss=0.184]\u001b[A\n",
            "Epoch 4:  82%|████████▏ | 396/484 [51:39<11:02,  7.52s/it, training_loss=0.001]\u001b[A\n",
            "Epoch 4:  82%|████████▏ | 397/484 [51:39<11:33,  7.97s/it, training_loss=0.001]\u001b[A\n",
            "Epoch 4:  82%|████████▏ | 397/484 [51:45<11:33,  7.97s/it, training_loss=0.001]\u001b[A\n",
            "Epoch 4:  82%|████████▏ | 398/484 [51:45<10:46,  7.52s/it, training_loss=0.001]\u001b[A\n",
            "Epoch 4:  82%|████████▏ | 398/484 [51:55<10:46,  7.52s/it, training_loss=0.097]\u001b[A\n",
            "Epoch 4:  82%|████████▏ | 399/484 [51:55<11:29,  8.11s/it, training_loss=0.097]\u001b[A\n",
            "Epoch 4:  82%|████████▏ | 399/484 [52:01<11:29,  8.11s/it, training_loss=0.001]\u001b[A\n",
            "Epoch 4:  83%|████████▎ | 400/484 [52:01<10:43,  7.66s/it, training_loss=0.001]\u001b[A\n",
            "Epoch 4:  83%|████████▎ | 400/484 [52:09<10:43,  7.66s/it, training_loss=0.001]\u001b[A\n",
            "Epoch 4:  83%|████████▎ | 401/484 [52:09<10:44,  7.77s/it, training_loss=0.001]\u001b[A\n",
            "Epoch 4:  83%|████████▎ | 401/484 [52:17<10:44,  7.77s/it, training_loss=0.040]\u001b[A\n",
            "Epoch 4:  83%|████████▎ | 402/484 [52:17<10:41,  7.82s/it, training_loss=0.040]\u001b[A\n",
            "Epoch 4:  83%|████████▎ | 402/484 [52:24<10:41,  7.82s/it, training_loss=0.003]\u001b[A\n",
            "Epoch 4:  83%|████████▎ | 403/484 [52:24<10:04,  7.47s/it, training_loss=0.003]\u001b[A\n",
            "Epoch 4:  83%|████████▎ | 403/484 [52:34<10:04,  7.47s/it, training_loss=0.001]\u001b[A\n",
            "Epoch 4:  83%|████████▎ | 404/484 [52:34<10:46,  8.08s/it, training_loss=0.001]\u001b[A\n",
            "Epoch 4:  83%|████████▎ | 404/484 [52:40<10:46,  8.08s/it, training_loss=0.103]\u001b[A\n",
            "Epoch 4:  84%|████████▎ | 405/484 [52:40<10:02,  7.63s/it, training_loss=0.103]\u001b[A\n",
            "Epoch 4:  84%|████████▎ | 405/484 [52:49<10:02,  7.63s/it, training_loss=0.197]\u001b[A\n",
            "Epoch 4:  84%|████████▍ | 406/484 [52:49<10:31,  8.10s/it, training_loss=0.197]\u001b[A\n",
            "Epoch 4:  84%|████████▍ | 406/484 [52:56<10:31,  8.10s/it, training_loss=0.006]\u001b[A\n",
            "Epoch 4:  84%|████████▍ | 407/484 [52:56<09:56,  7.74s/it, training_loss=0.006]\u001b[A\n",
            "Epoch 4:  84%|████████▍ | 407/484 [53:04<09:56,  7.74s/it, training_loss=0.002]\u001b[A\n",
            "Epoch 4:  84%|████████▍ | 408/484 [53:04<09:46,  7.71s/it, training_loss=0.002]\u001b[A\n",
            "Epoch 4:  84%|████████▍ | 408/484 [53:12<09:46,  7.71s/it, training_loss=0.001]\u001b[A\n",
            "Epoch 4:  85%|████████▍ | 409/484 [53:12<09:50,  7.87s/it, training_loss=0.001]\u001b[A\n",
            "Epoch 4:  85%|████████▍ | 409/484 [53:19<09:50,  7.87s/it, training_loss=0.001]\u001b[A\n",
            "Epoch 4:  85%|████████▍ | 410/484 [53:19<09:12,  7.46s/it, training_loss=0.001]\u001b[A\n",
            "Epoch 4:  85%|████████▍ | 410/484 [53:29<09:12,  7.46s/it, training_loss=0.003]\u001b[A\n",
            "Epoch 4:  85%|████████▍ | 411/484 [53:29<10:07,  8.33s/it, training_loss=0.003]\u001b[A\n",
            "Epoch 4:  85%|████████▍ | 411/484 [53:35<10:07,  8.33s/it, training_loss=0.001]\u001b[A\n",
            "Epoch 4:  85%|████████▌ | 412/484 [53:35<09:19,  7.77s/it, training_loss=0.001]\u001b[A\n",
            "Epoch 4:  85%|████████▌ | 412/484 [53:44<09:19,  7.77s/it, training_loss=0.002]\u001b[A\n",
            "Epoch 4:  85%|████████▌ | 413/484 [53:44<09:36,  8.11s/it, training_loss=0.002]\u001b[A\n",
            "Epoch 4:  85%|████████▌ | 413/484 [53:52<09:36,  8.11s/it, training_loss=0.001]\u001b[A\n",
            "Epoch 4:  86%|████████▌ | 414/484 [53:52<09:08,  7.84s/it, training_loss=0.001]\u001b[A\n",
            "Epoch 4:  86%|████████▌ | 414/484 [53:59<09:08,  7.84s/it, training_loss=0.127]\u001b[A\n",
            "Epoch 4:  86%|████████▌ | 415/484 [53:59<08:47,  7.65s/it, training_loss=0.127]\u001b[A\n",
            "Epoch 4:  86%|████████▌ | 415/484 [54:07<08:47,  7.65s/it, training_loss=0.425]\u001b[A\n",
            "Epoch 4:  86%|████████▌ | 416/484 [54:07<08:59,  7.93s/it, training_loss=0.425]\u001b[A\n",
            "Epoch 4:  86%|████████▌ | 416/484 [54:14<08:59,  7.93s/it, training_loss=0.001]\u001b[A\n",
            "Epoch 4:  86%|████████▌ | 417/484 [54:14<08:23,  7.52s/it, training_loss=0.001]\u001b[A\n",
            "Epoch 4:  86%|████████▌ | 417/484 [54:24<08:23,  7.52s/it, training_loss=0.002]\u001b[A\n",
            "Epoch 4:  86%|████████▋ | 418/484 [54:24<08:59,  8.18s/it, training_loss=0.002]\u001b[A\n",
            "Epoch 4:  86%|████████▋ | 418/484 [54:30<08:59,  8.18s/it, training_loss=0.004]\u001b[A\n",
            "Epoch 4:  87%|████████▋ | 419/484 [54:30<08:20,  7.69s/it, training_loss=0.004]\u001b[A\n",
            "Epoch 4:  87%|████████▋ | 419/484 [54:39<08:20,  7.69s/it, training_loss=0.001]\u001b[A\n",
            "Epoch 4:  87%|████████▋ | 420/484 [54:39<08:33,  8.02s/it, training_loss=0.001]\u001b[A\n",
            "Epoch 4:  87%|████████▋ | 420/484 [54:46<08:33,  8.02s/it, training_loss=0.001]\u001b[A\n",
            "Epoch 4:  87%|████████▋ | 421/484 [54:46<08:14,  7.85s/it, training_loss=0.001]\u001b[A\n",
            "Epoch 4:  87%|████████▋ | 421/484 [54:54<08:14,  7.85s/it, training_loss=0.006]\u001b[A\n",
            "Epoch 4:  87%|████████▋ | 422/484 [54:54<07:53,  7.64s/it, training_loss=0.006]\u001b[A\n",
            "Epoch 4:  87%|████████▋ | 422/484 [55:02<07:53,  7.64s/it, training_loss=0.001]\u001b[A\n",
            "Epoch 4:  87%|████████▋ | 423/484 [55:02<08:07,  7.99s/it, training_loss=0.001]\u001b[A\n",
            "Epoch 4:  87%|████████▋ | 423/484 [55:09<08:07,  7.99s/it, training_loss=0.002]\u001b[A\n",
            "Epoch 4:  88%|████████▊ | 424/484 [55:09<07:33,  7.55s/it, training_loss=0.002]\u001b[A\n",
            "Epoch 4:  88%|████████▊ | 424/484 [55:19<07:33,  7.55s/it, training_loss=0.001]\u001b[A\n",
            "Epoch 4:  88%|████████▊ | 425/484 [55:19<08:02,  8.18s/it, training_loss=0.001]\u001b[A\n",
            "Epoch 4:  88%|████████▊ | 425/484 [55:25<08:02,  8.18s/it, training_loss=0.002]\u001b[A\n",
            "Epoch 4:  88%|████████▊ | 426/484 [55:25<07:26,  7.70s/it, training_loss=0.002]\u001b[A\n",
            "Epoch 4:  88%|████████▊ | 426/484 [55:34<07:26,  7.70s/it, training_loss=0.059]\u001b[A\n",
            "Epoch 4:  88%|████████▊ | 427/484 [55:34<07:34,  7.98s/it, training_loss=0.059]\u001b[A\n",
            "Epoch 4:  88%|████████▊ | 427/484 [55:41<07:34,  7.98s/it, training_loss=0.001]\u001b[A\n",
            "Epoch 4:  88%|████████▊ | 428/484 [55:41<07:17,  7.82s/it, training_loss=0.001]\u001b[A\n",
            "Epoch 4:  88%|████████▊ | 428/484 [55:48<07:17,  7.82s/it, training_loss=0.001]\u001b[A\n",
            "Epoch 4:  89%|████████▊ | 429/484 [55:48<06:55,  7.56s/it, training_loss=0.001]\u001b[A\n",
            "Epoch 4:  89%|████████▊ | 429/484 [55:57<06:55,  7.56s/it, training_loss=0.110]\u001b[A\n",
            "Epoch 4:  89%|████████▉ | 430/484 [55:57<07:11,  7.99s/it, training_loss=0.110]\u001b[A\n",
            "Epoch 4:  89%|████████▉ | 430/484 [56:04<07:11,  7.99s/it, training_loss=0.001]\u001b[A\n",
            "Epoch 4:  89%|████████▉ | 431/484 [56:04<06:40,  7.55s/it, training_loss=0.001]\u001b[A\n",
            "Epoch 4:  89%|████████▉ | 431/484 [56:13<06:40,  7.55s/it, training_loss=0.001]\u001b[A\n",
            "Epoch 4:  89%|████████▉ | 432/484 [56:13<07:03,  8.14s/it, training_loss=0.001]\u001b[A\n",
            "Epoch 4:  89%|████████▉ | 432/484 [56:20<07:03,  8.14s/it, training_loss=0.004]\u001b[A\n",
            "Epoch 4:  89%|████████▉ | 433/484 [56:20<06:30,  7.66s/it, training_loss=0.004]\u001b[A\n",
            "Epoch 4:  89%|████████▉ | 433/484 [56:28<06:30,  7.66s/it, training_loss=0.001]\u001b[A\n",
            "Epoch 4:  90%|████████▉ | 434/484 [56:28<06:31,  7.83s/it, training_loss=0.001]\u001b[A\n",
            "Epoch 4:  90%|████████▉ | 434/484 [56:36<06:31,  7.83s/it, training_loss=0.001]\u001b[A\n",
            "Epoch 4:  90%|████████▉ | 435/484 [56:36<06:22,  7.81s/it, training_loss=0.001]\u001b[A\n",
            "Epoch 4:  90%|████████▉ | 435/484 [56:42<06:22,  7.81s/it, training_loss=0.013]\u001b[A\n",
            "Epoch 4:  90%|█████████ | 436/484 [56:42<05:58,  7.46s/it, training_loss=0.013]\u001b[A\n",
            "Epoch 4:  90%|█████████ | 436/484 [56:52<05:58,  7.46s/it, training_loss=0.224]\u001b[A\n",
            "Epoch 4:  90%|█████████ | 437/484 [56:52<06:18,  8.05s/it, training_loss=0.224]\u001b[A\n",
            "Epoch 4:  90%|█████████ | 437/484 [56:58<06:18,  8.05s/it, training_loss=0.043]\u001b[A\n",
            "Epoch 4:  90%|█████████ | 438/484 [56:58<05:49,  7.60s/it, training_loss=0.043]\u001b[A\n",
            "Epoch 4:  90%|█████████ | 438/484 [57:08<05:49,  7.60s/it, training_loss=0.001]\u001b[A\n",
            "Epoch 4:  91%|█████████ | 439/484 [57:08<06:05,  8.11s/it, training_loss=0.001]\u001b[A\n",
            "Epoch 4:  91%|█████████ | 439/484 [57:14<06:05,  8.11s/it, training_loss=0.002]\u001b[A\n",
            "Epoch 4:  91%|█████████ | 440/484 [57:14<05:39,  7.71s/it, training_loss=0.002]\u001b[A\n",
            "Epoch 4:  91%|█████████ | 440/484 [57:22<05:39,  7.71s/it, training_loss=0.002]\u001b[A\n",
            "Epoch 4:  91%|█████████ | 441/484 [57:22<05:32,  7.74s/it, training_loss=0.002]\u001b[A\n",
            "Epoch 4:  91%|█████████ | 441/484 [57:31<05:32,  7.74s/it, training_loss=0.001]\u001b[A\n",
            "Epoch 4:  91%|█████████▏| 442/484 [57:31<05:33,  7.95s/it, training_loss=0.001]\u001b[A\n",
            "Epoch 4:  91%|█████████▏| 442/484 [57:37<05:33,  7.95s/it, training_loss=0.006]\u001b[A\n",
            "Epoch 4:  92%|█████████▏| 443/484 [57:37<05:07,  7.49s/it, training_loss=0.006]\u001b[A\n",
            "Epoch 4:  92%|█████████▏| 443/484 [57:47<05:07,  7.49s/it, training_loss=0.001]\u001b[A\n",
            "Epoch 4:  92%|█████████▏| 444/484 [57:47<05:26,  8.17s/it, training_loss=0.001]\u001b[A\n",
            "Epoch 4:  92%|█████████▏| 444/484 [57:53<05:26,  8.17s/it, training_loss=0.159]\u001b[A\n",
            "Epoch 4:  92%|█████████▏| 445/484 [57:53<05:00,  7.70s/it, training_loss=0.159]\u001b[A\n",
            "Epoch 4:  92%|█████████▏| 445/484 [58:02<05:00,  7.70s/it, training_loss=0.002]\u001b[A\n",
            "Epoch 4:  92%|█████████▏| 446/484 [58:02<05:06,  8.06s/it, training_loss=0.002]\u001b[A\n",
            "Epoch 4:  92%|█████████▏| 446/484 [58:09<05:06,  8.06s/it, training_loss=0.001]\u001b[A\n",
            "Epoch 4:  92%|█████████▏| 447/484 [58:09<04:47,  7.77s/it, training_loss=0.001]\u001b[A\n",
            "Epoch 4:  92%|█████████▏| 447/484 [58:17<04:47,  7.77s/it, training_loss=0.009]\u001b[A\n",
            "Epoch 4:  93%|█████████▎| 448/484 [58:17<04:34,  7.62s/it, training_loss=0.009]\u001b[A\n",
            "Epoch 4:  93%|█████████▎| 448/484 [58:25<04:34,  7.62s/it, training_loss=0.001]\u001b[A\n",
            "Epoch 4:  93%|█████████▎| 449/484 [58:25<04:36,  7.90s/it, training_loss=0.001]\u001b[A\n",
            "Epoch 4:  93%|█████████▎| 449/484 [58:32<04:36,  7.90s/it, training_loss=0.001]\u001b[A\n",
            "Epoch 4:  93%|█████████▎| 450/484 [58:32<04:15,  7.50s/it, training_loss=0.001]\u001b[A\n",
            "Epoch 4:  93%|█████████▎| 450/484 [58:42<04:15,  7.50s/it, training_loss=0.001]\u001b[A\n",
            "Epoch 4:  93%|█████████▎| 451/484 [58:42<04:29,  8.16s/it, training_loss=0.001]\u001b[A\n",
            "Epoch 4:  93%|█████████▎| 451/484 [58:48<04:29,  8.16s/it, training_loss=0.031]\u001b[A\n",
            "Epoch 4:  93%|█████████▎| 452/484 [58:48<04:05,  7.67s/it, training_loss=0.031]\u001b[A\n",
            "Epoch 4:  93%|█████████▎| 452/484 [58:57<04:05,  7.67s/it, training_loss=0.545]\u001b[A\n",
            "Epoch 4:  94%|█████████▎| 453/484 [58:57<04:07,  7.99s/it, training_loss=0.545]\u001b[A\n",
            "Epoch 4:  94%|█████████▎| 453/484 [59:04<04:07,  7.99s/it, training_loss=0.004]\u001b[A\n",
            "Epoch 4:  94%|█████████▍| 454/484 [59:04<03:54,  7.80s/it, training_loss=0.004]\u001b[A\n",
            "Epoch 4:  94%|█████████▍| 454/484 [59:11<03:54,  7.80s/it, training_loss=0.001]\u001b[A\n",
            "Epoch 4:  94%|█████████▍| 455/484 [59:11<03:41,  7.63s/it, training_loss=0.001]\u001b[A\n",
            "Epoch 4:  94%|█████████▍| 455/484 [59:20<03:41,  7.63s/it, training_loss=0.001]\u001b[A\n",
            "Epoch 4:  94%|█████████▍| 456/484 [59:20<03:42,  7.95s/it, training_loss=0.001]\u001b[A\n",
            "Epoch 4:  94%|█████████▍| 456/484 [59:27<03:42,  7.95s/it, training_loss=0.001]\u001b[A\n",
            "Epoch 4:  94%|█████████▍| 457/484 [59:27<03:22,  7.51s/it, training_loss=0.001]\u001b[A\n",
            "Epoch 4:  94%|█████████▍| 457/484 [59:36<03:22,  7.51s/it, training_loss=0.175]\u001b[A\n",
            "Epoch 4:  95%|█████████▍| 458/484 [59:36<03:31,  8.14s/it, training_loss=0.175]\u001b[A\n",
            "Epoch 4:  95%|█████████▍| 458/484 [59:43<03:31,  8.14s/it, training_loss=0.001]\u001b[A\n",
            "Epoch 4:  95%|█████████▍| 459/484 [59:43<03:11,  7.65s/it, training_loss=0.001]\u001b[A\n",
            "Epoch 4:  95%|█████████▍| 459/484 [59:51<03:11,  7.65s/it, training_loss=0.001]\u001b[A\n",
            "Epoch 4:  95%|█████████▌| 460/484 [59:51<03:09,  7.90s/it, training_loss=0.001]\u001b[A\n",
            "Epoch 4:  95%|█████████▌| 460/484 [59:59<03:09,  7.90s/it, training_loss=0.001]\u001b[A\n",
            "Epoch 4:  95%|█████████▌| 461/484 [59:59<02:59,  7.79s/it, training_loss=0.001]\u001b[A\n",
            "Epoch 4:  95%|█████████▌| 461/484 [1:00:05<02:59,  7.79s/it, training_loss=0.033]\u001b[A\n",
            "Epoch 4:  95%|█████████▌| 462/484 [1:00:05<02:44,  7.49s/it, training_loss=0.033]\u001b[A\n",
            "Epoch 4:  95%|█████████▌| 462/484 [1:00:15<02:44,  7.49s/it, training_loss=0.001]\u001b[A\n",
            "Epoch 4:  96%|█████████▌| 463/484 [1:00:15<02:47,  7.99s/it, training_loss=0.001]\u001b[A\n",
            "Epoch 4:  96%|█████████▌| 463/484 [1:00:21<02:47,  7.99s/it, training_loss=0.001]\u001b[A\n",
            "Epoch 4:  96%|█████████▌| 464/484 [1:00:21<02:31,  7.55s/it, training_loss=0.001]\u001b[A\n",
            "Epoch 4:  96%|█████████▌| 464/484 [1:00:31<02:31,  7.55s/it, training_loss=0.014]\u001b[A\n",
            "Epoch 4:  96%|█████████▌| 465/484 [1:00:31<02:34,  8.14s/it, training_loss=0.014]\u001b[A\n",
            "Epoch 4:  96%|█████████▌| 465/484 [1:00:37<02:34,  8.14s/it, training_loss=0.004]\u001b[A\n",
            "Epoch 4:  96%|█████████▋| 466/484 [1:00:37<02:18,  7.70s/it, training_loss=0.004]\u001b[A\n",
            "Epoch 4:  96%|█████████▋| 466/484 [1:00:45<02:18,  7.70s/it, training_loss=0.001]\u001b[A\n",
            "Epoch 4:  96%|█████████▋| 467/484 [1:00:45<02:13,  7.82s/it, training_loss=0.001]\u001b[A\n",
            "Epoch 4:  96%|█████████▋| 467/484 [1:00:53<02:13,  7.82s/it, training_loss=0.001]\u001b[A\n",
            "Epoch 4:  97%|█████████▋| 468/484 [1:00:53<02:05,  7.85s/it, training_loss=0.001]\u001b[A\n",
            "Epoch 4:  97%|█████████▋| 468/484 [1:01:00<02:05,  7.85s/it, training_loss=0.010]\u001b[A\n",
            "Epoch 4:  97%|█████████▋| 469/484 [1:01:00<01:52,  7.47s/it, training_loss=0.010]\u001b[A\n",
            "Epoch 4:  97%|█████████▋| 469/484 [1:01:09<01:52,  7.47s/it, training_loss=0.007]\u001b[A\n",
            "Epoch 4:  97%|█████████▋| 470/484 [1:01:09<01:52,  8.07s/it, training_loss=0.007]\u001b[A\n",
            "Epoch 4:  97%|█████████▋| 470/484 [1:01:16<01:52,  8.07s/it, training_loss=0.237]\u001b[A\n",
            "Epoch 4:  97%|█████████▋| 471/484 [1:01:16<01:38,  7.61s/it, training_loss=0.237]\u001b[A\n",
            "Epoch 4:  97%|█████████▋| 471/484 [1:01:25<01:38,  7.61s/it, training_loss=0.004]\u001b[A\n",
            "Epoch 4:  98%|█████████▊| 472/484 [1:01:25<01:36,  8.07s/it, training_loss=0.004]\u001b[A\n",
            "Epoch 4:  98%|█████████▊| 472/484 [1:01:32<01:36,  8.07s/it, training_loss=0.072]\u001b[A\n",
            "Epoch 4:  98%|█████████▊| 473/484 [1:01:32<01:24,  7.72s/it, training_loss=0.072]\u001b[A\n",
            "Epoch 4:  98%|█████████▊| 473/484 [1:01:40<01:24,  7.72s/it, training_loss=0.003]\u001b[A\n",
            "Epoch 4:  98%|█████████▊| 474/484 [1:01:40<01:16,  7.66s/it, training_loss=0.003]\u001b[A\n",
            "Epoch 4:  98%|█████████▊| 474/484 [1:01:48<01:16,  7.66s/it, training_loss=0.002]\u001b[A\n",
            "Epoch 4:  98%|█████████▊| 475/484 [1:01:48<01:10,  7.86s/it, training_loss=0.002]\u001b[A\n",
            "Epoch 4:  98%|█████████▊| 475/484 [1:01:54<01:10,  7.86s/it, training_loss=0.237]\u001b[A\n",
            "Epoch 4:  98%|█████████▊| 476/484 [1:01:54<00:59,  7.45s/it, training_loss=0.237]\u001b[A\n",
            "Epoch 4:  98%|█████████▊| 476/484 [1:02:04<00:59,  7.45s/it, training_loss=0.012]\u001b[A\n",
            "Epoch 4:  99%|█████████▊| 477/484 [1:02:04<00:56,  8.12s/it, training_loss=0.012]\u001b[A\n",
            "Epoch 4:  99%|█████████▊| 477/484 [1:02:11<00:56,  8.12s/it, training_loss=0.002]\u001b[A\n",
            "Epoch 4:  99%|█████████▉| 478/484 [1:02:11<00:45,  7.64s/it, training_loss=0.002]\u001b[A\n",
            "Epoch 4:  99%|█████████▉| 478/484 [1:02:19<00:45,  7.64s/it, training_loss=0.002]\u001b[A\n",
            "Epoch 4:  99%|█████████▉| 479/484 [1:02:19<00:40,  8.00s/it, training_loss=0.002]\u001b[A\n",
            "Epoch 4:  99%|█████████▉| 479/484 [1:02:27<00:40,  8.00s/it, training_loss=0.001]\u001b[A\n",
            "Epoch 4:  99%|█████████▉| 480/484 [1:02:27<00:31,  7.77s/it, training_loss=0.001]\u001b[A\n",
            "Epoch 4:  99%|█████████▉| 480/484 [1:02:34<00:31,  7.77s/it, training_loss=0.001]\u001b[A\n",
            "Epoch 4:  99%|█████████▉| 481/484 [1:02:34<00:22,  7.62s/it, training_loss=0.001]\u001b[A\n",
            "Epoch 4:  99%|█████████▉| 481/484 [1:02:43<00:22,  7.62s/it, training_loss=0.001]\u001b[A\n",
            "Epoch 4: 100%|█████████▉| 482/484 [1:02:43<00:15,  7.95s/it, training_loss=0.001]\u001b[A\n",
            "Epoch 4: 100%|█████████▉| 482/484 [1:02:49<00:15,  7.95s/it, training_loss=0.006]\u001b[A\n",
            "Epoch 4: 100%|█████████▉| 483/484 [1:02:49<00:07,  7.52s/it, training_loss=0.006]\u001b[A\n",
            "Epoch 4: 100%|█████████▉| 483/484 [1:02:57<00:07,  7.52s/it, training_loss=0.001]\u001b[A\n",
            "Epoch 4: 100%|██████████| 484/484 [1:02:57<00:00,  7.57s/it, training_loss=0.001]\u001b[A\n",
            " 60%|██████    | 3/5 [4:26:47<2:15:51, 4075.81s/it]"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            " Epoch {epoch}\n",
            "Training loss: {loss_train_avg}\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n",
            "  0%|          | 0/121 [00:00<?, ?it/s]\u001b[A\n",
            "  1%|          | 1/121 [00:02<04:14,  2.12s/it]\u001b[A\n",
            "  2%|▏         | 2/121 [00:04<03:59,  2.01s/it]\u001b[A\n",
            "  2%|▏         | 3/121 [00:05<03:53,  1.98s/it]\u001b[A\n",
            "  3%|▎         | 4/121 [00:08<04:03,  2.08s/it]\u001b[A\n",
            "  4%|▍         | 5/121 [00:12<05:36,  2.90s/it]\u001b[A\n",
            "  5%|▍         | 6/121 [00:15<05:41,  2.97s/it]\u001b[A\n",
            "  6%|▌         | 7/121 [00:18<05:25,  2.85s/it]\u001b[A\n",
            "  7%|▋         | 8/121 [00:20<04:49,  2.56s/it]\u001b[A\n",
            "  7%|▋         | 9/121 [00:22<04:24,  2.36s/it]\u001b[A\n",
            "  8%|▊         | 10/121 [00:25<04:38,  2.51s/it]\u001b[A\n",
            "  9%|▉         | 11/121 [00:28<04:53,  2.66s/it]\u001b[A\n",
            " 10%|▉         | 12/121 [00:31<05:15,  2.90s/it]\u001b[A\n",
            " 11%|█         | 13/121 [00:34<05:18,  2.95s/it]\u001b[A\n",
            " 12%|█▏        | 14/121 [00:37<05:05,  2.85s/it]\u001b[A\n",
            " 12%|█▏        | 15/121 [00:39<04:33,  2.58s/it]\u001b[A\n",
            " 13%|█▎        | 16/121 [00:41<04:10,  2.39s/it]\u001b[A\n",
            " 14%|█▍        | 17/121 [00:42<03:54,  2.25s/it]\u001b[A\n",
            " 15%|█▍        | 18/121 [00:44<03:42,  2.16s/it]\u001b[A\n",
            " 16%|█▌        | 19/121 [00:47<03:42,  2.18s/it]\u001b[A\n",
            " 17%|█▋        | 20/121 [00:50<04:12,  2.50s/it]\u001b[A\n",
            " 17%|█▋        | 21/121 [00:53<04:24,  2.65s/it]\u001b[A\n",
            " 18%|█▊        | 22/121 [00:55<04:16,  2.60s/it]\u001b[A\n",
            " 19%|█▉        | 23/121 [00:57<03:55,  2.40s/it]\u001b[A\n",
            " 20%|█▉        | 24/121 [00:59<03:39,  2.27s/it]\u001b[A\n",
            " 21%|██        | 25/121 [01:01<03:27,  2.17s/it]\u001b[A\n",
            " 21%|██▏       | 26/121 [01:03<03:19,  2.10s/it]\u001b[A\n",
            " 22%|██▏       | 27/121 [01:05<03:22,  2.16s/it]\u001b[A\n",
            " 23%|██▎       | 28/121 [01:09<03:50,  2.48s/it]\u001b[A\n",
            " 24%|██▍       | 29/121 [01:12<04:02,  2.63s/it]\u001b[A\n",
            " 25%|██▍       | 30/121 [01:14<03:54,  2.58s/it]\u001b[A\n",
            " 26%|██▌       | 31/121 [01:16<03:34,  2.39s/it]\u001b[A\n",
            " 26%|██▋       | 32/121 [01:18<03:21,  2.26s/it]\u001b[A\n",
            " 27%|██▋       | 33/121 [01:20<03:10,  2.16s/it]\u001b[A\n",
            " 28%|██▊       | 34/121 [01:22<03:02,  2.10s/it]\u001b[A\n",
            " 29%|██▉       | 35/121 [01:24<03:09,  2.20s/it]\u001b[A\n",
            " 30%|██▉       | 36/121 [01:28<03:33,  2.51s/it]\u001b[A\n",
            " 31%|███       | 37/121 [01:31<03:44,  2.67s/it]\u001b[A\n",
            " 31%|███▏      | 38/121 [01:33<03:33,  2.57s/it]\u001b[A\n",
            " 32%|███▏      | 39/121 [01:35<03:15,  2.38s/it]\u001b[A\n",
            " 33%|███▎      | 40/121 [01:37<03:02,  2.25s/it]\u001b[A\n",
            " 34%|███▍      | 41/121 [01:39<02:52,  2.16s/it]\u001b[A\n",
            " 35%|███▍      | 42/121 [01:41<02:46,  2.10s/it]\u001b[A\n",
            " 36%|███▌      | 43/121 [01:43<02:55,  2.26s/it]\u001b[A\n",
            " 36%|███▋      | 44/121 [01:47<03:16,  2.56s/it]\u001b[A\n",
            " 37%|███▋      | 45/121 [01:50<03:23,  2.68s/it]\u001b[A\n",
            " 38%|███▊      | 46/121 [01:52<03:10,  2.53s/it]\u001b[A\n",
            " 39%|███▉      | 47/121 [01:54<02:54,  2.36s/it]\u001b[A\n",
            " 40%|███▉      | 48/121 [01:56<02:43,  2.24s/it]\u001b[A\n",
            " 40%|████      | 49/121 [01:58<02:35,  2.16s/it]\u001b[A\n",
            " 41%|████▏     | 50/121 [02:00<02:28,  2.10s/it]\u001b[A\n",
            " 42%|████▏     | 51/121 [02:02<02:40,  2.29s/it]\u001b[A\n",
            " 43%|████▎     | 52/121 [02:06<02:58,  2.58s/it]\u001b[A\n",
            " 44%|████▍     | 53/121 [02:09<03:04,  2.71s/it]\u001b[A\n",
            " 45%|████▍     | 54/121 [02:11<02:49,  2.53s/it]\u001b[A\n",
            " 45%|████▌     | 55/121 [02:13<02:36,  2.37s/it]\u001b[A\n",
            " 46%|████▋     | 56/121 [02:15<02:26,  2.25s/it]\u001b[A\n",
            " 47%|████▋     | 57/121 [02:17<02:19,  2.18s/it]\u001b[A\n",
            " 48%|████▊     | 58/121 [02:19<02:13,  2.12s/it]\u001b[A\n",
            " 49%|████▉     | 59/121 [02:22<02:27,  2.38s/it]\u001b[A\n",
            " 50%|████▉     | 60/121 [02:25<02:39,  2.62s/it]\u001b[A\n",
            " 50%|█████     | 61/121 [02:28<02:41,  2.69s/it]\u001b[A\n",
            " 51%|█████     | 62/121 [02:30<02:26,  2.48s/it]\u001b[A\n",
            " 52%|█████▏    | 63/121 [02:32<02:15,  2.33s/it]\u001b[A\n",
            " 53%|█████▎    | 64/121 [02:34<02:06,  2.23s/it]\u001b[A\n",
            " 54%|█████▎    | 65/121 [02:36<01:59,  2.14s/it]\u001b[A\n",
            " 55%|█████▍    | 66/121 [02:38<01:55,  2.09s/it]\u001b[A\n",
            " 55%|█████▌    | 67/121 [02:41<02:11,  2.44s/it]\u001b[A\n",
            " 56%|█████▌    | 68/121 [02:44<02:19,  2.64s/it]\u001b[A\n",
            " 57%|█████▋    | 69/121 [02:47<02:17,  2.65s/it]\u001b[A\n",
            " 58%|█████▊    | 70/121 [02:49<02:04,  2.44s/it]\u001b[A\n",
            " 59%|█████▊    | 71/121 [02:51<01:54,  2.30s/it]\u001b[A\n",
            " 60%|█████▉    | 72/121 [02:53<01:48,  2.21s/it]\u001b[A\n",
            " 60%|██████    | 73/121 [02:55<01:42,  2.14s/it]\u001b[A\n",
            " 61%|██████    | 74/121 [02:57<01:42,  2.18s/it]\u001b[A\n",
            " 62%|██████▏   | 75/121 [03:00<01:55,  2.50s/it]\u001b[A\n",
            " 63%|██████▎   | 76/121 [03:03<02:00,  2.67s/it]\u001b[A\n",
            " 64%|██████▎   | 77/121 [03:06<01:55,  2.62s/it]\u001b[A\n",
            " 64%|██████▍   | 78/121 [03:08<01:44,  2.42s/it]\u001b[A\n",
            " 65%|██████▌   | 79/121 [03:10<01:36,  2.29s/it]\u001b[A\n",
            " 66%|██████▌   | 80/121 [03:11<01:29,  2.19s/it]\u001b[A\n",
            " 67%|██████▋   | 81/121 [03:13<01:25,  2.13s/it]\u001b[A\n",
            " 68%|██████▊   | 82/121 [03:16<01:28,  2.27s/it]\u001b[A\n",
            " 69%|██████▊   | 83/121 [03:19<01:37,  2.56s/it]\u001b[A\n",
            " 69%|██████▉   | 84/121 [03:22<01:39,  2.68s/it]\u001b[A\n",
            " 70%|███████   | 85/121 [03:25<01:31,  2.54s/it]\u001b[A\n",
            " 71%|███████   | 86/121 [03:26<01:22,  2.37s/it]\u001b[A\n",
            " 72%|███████▏  | 87/121 [03:28<01:16,  2.26s/it]\u001b[A\n",
            " 73%|███████▎  | 88/121 [03:30<01:11,  2.17s/it]\u001b[A\n",
            " 74%|███████▎  | 89/121 [03:32<01:07,  2.10s/it]\u001b[A\n",
            " 74%|███████▍  | 90/121 [03:35<01:11,  2.30s/it]\u001b[A\n",
            " 75%|███████▌  | 91/121 [03:38<01:17,  2.57s/it]\u001b[A\n",
            " 76%|███████▌  | 92/121 [03:41<01:18,  2.71s/it]\u001b[A\n",
            " 77%|███████▋  | 93/121 [03:43<01:10,  2.51s/it]\u001b[A\n",
            " 78%|███████▊  | 94/121 [03:45<01:03,  2.34s/it]\u001b[A\n",
            " 79%|███████▊  | 95/121 [03:47<00:57,  2.23s/it]\u001b[A\n",
            " 79%|███████▉  | 96/121 [03:49<00:53,  2.15s/it]\u001b[A\n",
            " 80%|████████  | 97/121 [03:51<00:50,  2.11s/it]\u001b[A\n",
            " 81%|████████  | 98/121 [03:54<00:54,  2.38s/it]\u001b[A\n",
            " 82%|████████▏ | 99/121 [03:58<00:57,  2.62s/it]\u001b[A\n",
            " 83%|████████▎ | 100/121 [04:00<00:56,  2.69s/it]\u001b[A\n",
            " 83%|████████▎ | 101/121 [04:02<00:49,  2.47s/it]\u001b[A\n",
            " 84%|████████▍ | 102/121 [04:04<00:44,  2.33s/it]\u001b[A\n",
            " 85%|████████▌ | 103/121 [04:06<00:39,  2.22s/it]\u001b[A\n",
            " 86%|████████▌ | 104/121 [04:08<00:36,  2.14s/it]\u001b[A\n",
            " 87%|████████▋ | 105/121 [04:10<00:33,  2.09s/it]\u001b[A\n",
            " 88%|████████▊ | 106/121 [04:13<00:36,  2.42s/it]\u001b[A\n",
            " 88%|████████▊ | 107/121 [04:17<00:36,  2.64s/it]\u001b[A\n",
            " 89%|████████▉ | 108/121 [04:19<00:34,  2.66s/it]\u001b[A\n",
            " 90%|█████████ | 109/121 [04:21<00:29,  2.45s/it]\u001b[A\n",
            " 91%|█████████ | 110/121 [04:23<00:25,  2.30s/it]\u001b[A\n",
            " 92%|█████████▏| 111/121 [04:25<00:21,  2.19s/it]\u001b[A\n",
            " 93%|█████████▎| 112/121 [04:27<00:19,  2.11s/it]\u001b[A\n",
            " 93%|█████████▎| 113/121 [04:29<00:16,  2.12s/it]\u001b[A\n",
            " 94%|█████████▍| 114/121 [04:32<00:17,  2.46s/it]\u001b[A\n",
            " 95%|█████████▌| 115/121 [04:35<00:15,  2.64s/it]\u001b[A\n",
            " 96%|█████████▌| 116/121 [04:38<00:13,  2.61s/it]\u001b[A\n",
            " 97%|█████████▋| 117/121 [04:40<00:09,  2.41s/it]\u001b[A\n",
            " 98%|█████████▊| 118/121 [04:42<00:06,  2.27s/it]\u001b[A\n",
            " 98%|█████████▊| 119/121 [04:44<00:04,  2.18s/it]\u001b[A\n",
            " 99%|█████████▉| 120/121 [04:46<00:02,  2.11s/it]\u001b[A\n",
            "100%|██████████| 121/121 [04:48<00:00,  2.39s/it]\n",
            " 80%|████████  | 4/5 [4:31:36<1:07:53, 4073.12s/it]"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Validation loss: 0.7398327911505476\n",
            "F1 Score (weighted): 0.8504164040431486\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "Epoch 5:   0%|          | 0/484 [00:00<?, ?it/s]\u001b[A\n",
            "Epoch 5:   0%|          | 0/484 [00:09<?, ?it/s, training_loss=0.001]\u001b[A\n",
            "Epoch 5:   0%|          | 1/484 [00:09<1:17:18,  9.60s/it, training_loss=0.001]\u001b[A\n",
            "Epoch 5:   0%|          | 1/484 [00:16<1:17:18,  9.60s/it, training_loss=0.003]\u001b[A\n",
            "Epoch 5:   0%|          | 2/484 [00:16<1:02:35,  7.79s/it, training_loss=0.003]\u001b[A\n",
            "Epoch 5:   0%|          | 2/484 [00:25<1:02:35,  7.79s/it, training_loss=0.001]\u001b[A\n",
            "Epoch 5:   1%|          | 3/484 [00:25<1:08:37,  8.56s/it, training_loss=0.001]\u001b[A\n",
            "Epoch 5:   1%|          | 3/484 [00:32<1:08:37,  8.56s/it, training_loss=0.002]\u001b[A\n",
            "Epoch 5:   1%|          | 4/484 [00:32<1:02:35,  7.82s/it, training_loss=0.002]\u001b[A\n",
            "Epoch 5:   1%|          | 4/484 [00:40<1:02:35,  7.82s/it, training_loss=0.005]\u001b[A\n",
            "Epoch 5:   1%|          | 5/484 [00:40<1:03:02,  7.90s/it, training_loss=0.005]\u001b[A\n",
            "Epoch 5:   1%|          | 5/484 [00:48<1:03:02,  7.90s/it, training_loss=0.001]\u001b[A\n",
            "Epoch 5:   1%|          | 6/484 [00:48<1:03:11,  7.93s/it, training_loss=0.001]\u001b[A\n",
            "Epoch 5:   1%|          | 6/484 [00:55<1:03:11,  7.93s/it, training_loss=0.225]\u001b[A\n",
            "Epoch 5:   1%|▏         | 7/484 [00:55<59:50,  7.53s/it, training_loss=0.225]  \u001b[A\n",
            "Epoch 5:   1%|▏         | 7/484 [01:04<59:50,  7.53s/it, training_loss=0.120]\u001b[A\n",
            "Epoch 5:   2%|▏         | 8/484 [01:04<1:04:20,  8.11s/it, training_loss=0.120]\u001b[A\n",
            "Epoch 5:   2%|▏         | 8/484 [01:10<1:04:20,  8.11s/it, training_loss=0.004]\u001b[A\n",
            "Epoch 5:   2%|▏         | 9/484 [01:10<1:00:13,  7.61s/it, training_loss=0.004]\u001b[A\n",
            "Epoch 5:   2%|▏         | 9/484 [01:20<1:00:13,  7.61s/it, training_loss=0.010]\u001b[A\n",
            "Epoch 5:   2%|▏         | 10/484 [01:20<1:04:13,  8.13s/it, training_loss=0.010]\u001b[A\n",
            "Epoch 5:   2%|▏         | 10/484 [01:26<1:04:13,  8.13s/it, training_loss=0.001]\u001b[A\n",
            "Epoch 5:   2%|▏         | 11/484 [01:26<1:00:51,  7.72s/it, training_loss=0.001]\u001b[A\n",
            "Epoch 5:   2%|▏         | 11/484 [01:34<1:00:51,  7.72s/it, training_loss=0.004]\u001b[A\n",
            "Epoch 5:   2%|▏         | 12/484 [01:34<1:00:52,  7.74s/it, training_loss=0.004]\u001b[A\n",
            "Epoch 5:   2%|▏         | 12/484 [01:42<1:00:52,  7.74s/it, training_loss=0.002]\u001b[A\n",
            "Epoch 5:   3%|▎         | 13/484 [01:42<1:01:35,  7.85s/it, training_loss=0.002]\u001b[A\n",
            "Epoch 5:   3%|▎         | 13/484 [01:49<1:01:35,  7.85s/it, training_loss=0.001]\u001b[A\n",
            "Epoch 5:   3%|▎         | 14/484 [01:49<58:19,  7.45s/it, training_loss=0.001]  \u001b[A\n",
            "Epoch 5:   3%|▎         | 14/484 [01:59<58:19,  7.45s/it, training_loss=0.155]\u001b[A\n",
            "Epoch 5:   3%|▎         | 15/484 [01:59<1:03:23,  8.11s/it, training_loss=0.155]\u001b[A\n",
            "Epoch 5:   3%|▎         | 15/484 [02:05<1:03:23,  8.11s/it, training_loss=0.027]\u001b[A\n",
            "Epoch 5:   3%|▎         | 16/484 [02:05<59:21,  7.61s/it, training_loss=0.027]  \u001b[A\n",
            "Epoch 5:   3%|▎         | 16/484 [02:14<59:21,  7.61s/it, training_loss=0.003]\u001b[A\n",
            "Epoch 5:   4%|▎         | 17/484 [02:14<1:02:08,  7.98s/it, training_loss=0.003]\u001b[A\n",
            "Epoch 5:   4%|▎         | 17/484 [02:21<1:02:08,  7.98s/it, training_loss=0.001]\u001b[A\n",
            "Epoch 5:   4%|▎         | 18/484 [02:21<1:00:05,  7.74s/it, training_loss=0.001]\u001b[A\n",
            "Epoch 5:   4%|▎         | 18/484 [02:28<1:00:05,  7.74s/it, training_loss=0.001]\u001b[A\n",
            "Epoch 5:   4%|▍         | 19/484 [02:28<58:58,  7.61s/it, training_loss=0.001]  \u001b[A\n",
            "Epoch 5:   4%|▍         | 19/484 [02:37<58:58,  7.61s/it, training_loss=0.001]\u001b[A\n",
            "Epoch 5:   4%|▍         | 20/484 [02:37<1:01:08,  7.91s/it, training_loss=0.001]\u001b[A\n",
            "Epoch 5:   4%|▍         | 20/484 [02:43<1:01:08,  7.91s/it, training_loss=0.003]\u001b[A\n",
            "Epoch 5:   4%|▍         | 21/484 [02:43<57:48,  7.49s/it, training_loss=0.003]  \u001b[A\n",
            "Epoch 5:   4%|▍         | 21/484 [02:53<57:48,  7.49s/it, training_loss=0.040]\u001b[A\n",
            "Epoch 5:   5%|▍         | 22/484 [02:53<1:02:45,  8.15s/it, training_loss=0.040]\u001b[A\n",
            "Epoch 5:   5%|▍         | 22/484 [03:00<1:02:45,  8.15s/it, training_loss=0.160]\u001b[A\n",
            "Epoch 5:   5%|▍         | 23/484 [03:00<58:56,  7.67s/it, training_loss=0.160]  \u001b[A\n",
            "Epoch 5:   5%|▍         | 23/484 [03:08<58:56,  7.67s/it, training_loss=0.001]\u001b[A\n",
            "Epoch 5:   5%|▍         | 24/484 [03:08<1:01:23,  8.01s/it, training_loss=0.001]\u001b[A\n",
            "Epoch 5:   5%|▍         | 24/484 [03:16<1:01:23,  8.01s/it, training_loss=0.005]\u001b[A\n",
            "Epoch 5:   5%|▌         | 25/484 [03:16<59:44,  7.81s/it, training_loss=0.005]  \u001b[A\n",
            "Epoch 5:   5%|▌         | 25/484 [03:23<59:44,  7.81s/it, training_loss=0.135]\u001b[A\n",
            "Epoch 5:   5%|▌         | 26/484 [03:23<58:09,  7.62s/it, training_loss=0.135]\u001b[A\n",
            "Epoch 5:   5%|▌         | 26/484 [03:32<58:09,  7.62s/it, training_loss=0.001]\u001b[A\n",
            "Epoch 5:   6%|▌         | 27/484 [03:32<1:00:34,  7.95s/it, training_loss=0.001]\u001b[A\n",
            "Epoch 5:   6%|▌         | 27/484 [03:38<1:00:34,  7.95s/it, training_loss=0.003]\u001b[A\n",
            "Epoch 5:   6%|▌         | 28/484 [03:38<57:01,  7.50s/it, training_loss=0.003]  \u001b[A\n",
            "Epoch 5:   6%|▌         | 28/484 [03:48<57:01,  7.50s/it, training_loss=0.089]\u001b[A\n",
            "Epoch 5:   6%|▌         | 29/484 [03:48<1:01:28,  8.11s/it, training_loss=0.089]\u001b[A\n",
            "Epoch 5:   6%|▌         | 29/484 [03:54<1:01:28,  8.11s/it, training_loss=0.001]\u001b[A\n",
            "Epoch 5:   6%|▌         | 30/484 [03:54<57:39,  7.62s/it, training_loss=0.001]  \u001b[A\n",
            "Epoch 5:   6%|▌         | 30/484 [04:03<57:39,  7.62s/it, training_loss=0.012]\u001b[A\n",
            "Epoch 5:   6%|▋         | 31/484 [04:03<59:12,  7.84s/it, training_loss=0.012]\u001b[A\n",
            "Epoch 5:   6%|▋         | 31/484 [04:10<59:12,  7.84s/it, training_loss=0.001]\u001b[A\n",
            "Epoch 5:   7%|▋         | 32/484 [04:10<58:40,  7.79s/it, training_loss=0.001]\u001b[A\n",
            "Epoch 5:   7%|▋         | 32/484 [04:17<58:40,  7.79s/it, training_loss=0.018]\u001b[A\n",
            "Epoch 5:   7%|▋         | 33/484 [04:17<55:56,  7.44s/it, training_loss=0.018]\u001b[A\n",
            "Epoch 5:   7%|▋         | 33/484 [04:26<55:56,  7.44s/it, training_loss=0.001]\u001b[A\n",
            "Epoch 5:   7%|▋         | 34/484 [04:26<59:56,  7.99s/it, training_loss=0.001]\u001b[A\n",
            "Epoch 5:   7%|▋         | 34/484 [04:33<59:56,  7.99s/it, training_loss=0.152]\u001b[A\n",
            "Epoch 5:   7%|▋         | 35/484 [04:33<56:30,  7.55s/it, training_loss=0.152]\u001b[A\n",
            "Epoch 5:   7%|▋         | 35/484 [04:42<56:30,  7.55s/it, training_loss=0.001]\u001b[A\n",
            "Epoch 5:   7%|▋         | 36/484 [04:42<1:00:06,  8.05s/it, training_loss=0.001]\u001b[A\n",
            "Epoch 5:   7%|▋         | 36/484 [04:49<1:00:06,  8.05s/it, training_loss=0.002]\u001b[A\n",
            "Epoch 5:   8%|▊         | 37/484 [04:49<57:12,  7.68s/it, training_loss=0.002]  \u001b[A\n",
            "Epoch 5:   8%|▊         | 37/484 [04:56<57:12,  7.68s/it, training_loss=0.051]\u001b[A\n",
            "Epoch 5:   8%|▊         | 38/484 [04:56<57:09,  7.69s/it, training_loss=0.051]\u001b[A\n",
            "Epoch 5:   8%|▊         | 38/484 [05:05<57:09,  7.69s/it, training_loss=0.001]\u001b[A\n",
            "Epoch 5:   8%|▊         | 39/484 [05:05<58:10,  7.84s/it, training_loss=0.001]\u001b[A\n",
            "Epoch 5:   8%|▊         | 39/484 [05:11<58:10,  7.84s/it, training_loss=0.001]\u001b[A\n",
            "Epoch 5:   8%|▊         | 40/484 [05:11<55:02,  7.44s/it, training_loss=0.001]\u001b[A\n",
            "Epoch 5:   8%|▊         | 40/484 [05:21<55:02,  7.44s/it, training_loss=0.005]\u001b[A\n",
            "Epoch 5:   8%|▊         | 41/484 [05:21<59:55,  8.12s/it, training_loss=0.005]\u001b[A\n",
            "Epoch 5:   8%|▊         | 41/484 [05:28<59:55,  8.12s/it, training_loss=0.004]\u001b[A\n",
            "Epoch 5:   9%|▊         | 42/484 [05:28<56:55,  7.73s/it, training_loss=0.004]\u001b[A\n",
            "Epoch 5:   9%|▊         | 42/484 [05:37<56:55,  7.73s/it, training_loss=0.001]\u001b[A\n",
            "Epoch 5:   9%|▉         | 43/484 [05:37<1:01:04,  8.31s/it, training_loss=0.001]\u001b[A\n",
            "Epoch 5:   9%|▉         | 43/484 [05:44<1:01:04,  8.31s/it, training_loss=0.001]\u001b[A\n",
            "Epoch 5:   9%|▉         | 44/484 [05:44<57:43,  7.87s/it, training_loss=0.001]  \u001b[A\n",
            "Epoch 5:   9%|▉         | 44/484 [05:52<57:43,  7.87s/it, training_loss=0.001]\u001b[A\n",
            "Epoch 5:   9%|▉         | 45/484 [05:52<57:07,  7.81s/it, training_loss=0.001]\u001b[A\n",
            "Epoch 5:   9%|▉         | 45/484 [06:00<57:07,  7.81s/it, training_loss=0.004]\u001b[A\n",
            "Epoch 5:  10%|▉         | 46/484 [06:00<57:56,  7.94s/it, training_loss=0.004]\u001b[A\n",
            "Epoch 5:  10%|▉         | 46/484 [06:07<57:56,  7.94s/it, training_loss=0.001]\u001b[A\n",
            "Epoch 5:  10%|▉         | 47/484 [06:07<54:45,  7.52s/it, training_loss=0.001]\u001b[A\n",
            "Epoch 5:  10%|▉         | 47/484 [06:16<54:45,  7.52s/it, training_loss=0.242]\u001b[A\n",
            "Epoch 5:  10%|▉         | 48/484 [06:16<59:26,  8.18s/it, training_loss=0.242]\u001b[A\n",
            "Epoch 5:  10%|▉         | 48/484 [06:23<59:26,  8.18s/it, training_loss=0.179]\u001b[A\n",
            "Epoch 5:  10%|█         | 49/484 [06:23<55:43,  7.69s/it, training_loss=0.179]\u001b[A\n",
            "Epoch 5:  10%|█         | 49/484 [06:32<55:43,  7.69s/it, training_loss=0.001]\u001b[A\n",
            "Epoch 5:  10%|█         | 50/484 [06:32<58:34,  8.10s/it, training_loss=0.001]\u001b[A\n",
            "Epoch 5:  10%|█         | 50/484 [06:39<58:34,  8.10s/it, training_loss=0.001]\u001b[A\n",
            "Epoch 5:  11%|█         | 51/484 [06:39<56:12,  7.79s/it, training_loss=0.001]\u001b[A\n",
            "Epoch 5:  11%|█         | 51/484 [06:46<56:12,  7.79s/it, training_loss=0.002]\u001b[A\n",
            "Epoch 5:  11%|█         | 52/484 [06:46<55:29,  7.71s/it, training_loss=0.002]\u001b[A\n",
            "Epoch 5:  11%|█         | 52/484 [06:55<55:29,  7.71s/it, training_loss=0.001]\u001b[A\n",
            "Epoch 5:  11%|█         | 53/484 [06:55<57:01,  7.94s/it, training_loss=0.001]\u001b[A\n",
            "Epoch 5:  11%|█         | 53/484 [07:01<57:01,  7.94s/it, training_loss=0.002]\u001b[A\n",
            "Epoch 5:  11%|█         | 54/484 [07:01<53:59,  7.53s/it, training_loss=0.002]\u001b[A\n",
            "Epoch 5:  11%|█         | 54/484 [07:11<53:59,  7.53s/it, training_loss=0.001]\u001b[A\n",
            "Epoch 5:  11%|█▏        | 55/484 [07:11<58:31,  8.19s/it, training_loss=0.001]\u001b[A\n",
            "Epoch 5:  11%|█▏        | 55/484 [07:18<58:31,  8.19s/it, training_loss=0.274]\u001b[A\n",
            "Epoch 5:  12%|█▏        | 56/484 [07:18<54:49,  7.68s/it, training_loss=0.274]\u001b[A\n",
            "Epoch 5:  12%|█▏        | 56/484 [07:27<54:49,  7.68s/it, training_loss=0.001]\u001b[A\n",
            "Epoch 5:  12%|█▏        | 57/484 [07:27<57:13,  8.04s/it, training_loss=0.001]\u001b[A\n",
            "Epoch 5:  12%|█▏        | 57/484 [07:34<57:13,  8.04s/it, training_loss=0.001]\u001b[A\n",
            "Epoch 5:  12%|█▏        | 58/484 [07:34<55:13,  7.78s/it, training_loss=0.001]\u001b[A\n",
            "Epoch 5:  12%|█▏        | 58/484 [07:41<55:13,  7.78s/it, training_loss=0.001]\u001b[A\n",
            "Epoch 5:  12%|█▏        | 59/484 [07:41<53:42,  7.58s/it, training_loss=0.001]\u001b[A\n",
            "Epoch 5:  12%|█▏        | 59/484 [07:50<53:42,  7.58s/it, training_loss=0.001]\u001b[A\n",
            "Epoch 5:  12%|█▏        | 60/484 [07:50<55:57,  7.92s/it, training_loss=0.001]\u001b[A\n",
            "Epoch 5:  12%|█▏        | 60/484 [07:56<55:57,  7.92s/it, training_loss=0.001]\u001b[A\n",
            "Epoch 5:  13%|█▎        | 61/484 [07:56<52:45,  7.48s/it, training_loss=0.001]\u001b[A\n",
            "Epoch 5:  13%|█▎        | 61/484 [08:06<52:45,  7.48s/it, training_loss=0.095]\u001b[A\n",
            "Epoch 5:  13%|█▎        | 62/484 [08:06<57:05,  8.12s/it, training_loss=0.095]\u001b[A\n",
            "Epoch 5:  13%|█▎        | 62/484 [08:12<57:05,  8.12s/it, training_loss=0.005]\u001b[A\n",
            "Epoch 5:  13%|█▎        | 63/484 [08:12<53:31,  7.63s/it, training_loss=0.005]\u001b[A\n",
            "Epoch 5:  13%|█▎        | 63/484 [08:21<53:31,  7.63s/it, training_loss=0.001]\u001b[A\n",
            "Epoch 5:  13%|█▎        | 64/484 [08:21<55:16,  7.90s/it, training_loss=0.001]\u001b[A\n",
            "Epoch 5:  13%|█▎        | 64/484 [08:28<55:16,  7.90s/it, training_loss=0.003]\u001b[A\n",
            "Epoch 5:  13%|█▎        | 65/484 [08:28<54:17,  7.78s/it, training_loss=0.003]\u001b[A\n",
            "Epoch 5:  13%|█▎        | 65/484 [08:35<54:17,  7.78s/it, training_loss=0.073]\u001b[A\n",
            "Epoch 5:  14%|█▎        | 66/484 [08:35<52:02,  7.47s/it, training_loss=0.073]\u001b[A\n",
            "Epoch 5:  14%|█▎        | 66/484 [08:44<52:02,  7.47s/it, training_loss=0.001]\u001b[A\n",
            "Epoch 5:  14%|█▍        | 67/484 [08:44<55:26,  7.98s/it, training_loss=0.001]\u001b[A\n",
            "Epoch 5:  14%|█▍        | 67/484 [08:51<55:26,  7.98s/it, training_loss=0.002]\u001b[A\n",
            "Epoch 5:  14%|█▍        | 68/484 [08:51<52:27,  7.57s/it, training_loss=0.002]\u001b[A\n",
            "Epoch 5:  14%|█▍        | 68/484 [09:00<52:27,  7.57s/it, training_loss=0.001]\u001b[A\n",
            "Epoch 5:  14%|█▍        | 69/484 [09:00<56:30,  8.17s/it, training_loss=0.001]\u001b[A\n",
            "Epoch 5:  14%|█▍        | 69/484 [09:07<56:30,  8.17s/it, training_loss=0.201]\u001b[A\n",
            "Epoch 5:  14%|█▍        | 70/484 [09:07<53:13,  7.71s/it, training_loss=0.201]\u001b[A\n",
            "Epoch 5:  14%|█▍        | 70/484 [09:15<53:13,  7.71s/it, training_loss=0.001]\u001b[A\n",
            "Epoch 5:  15%|█▍        | 71/484 [09:15<53:52,  7.83s/it, training_loss=0.001]\u001b[A\n",
            "Epoch 5:  15%|█▍        | 71/484 [09:23<53:52,  7.83s/it, training_loss=0.001]\u001b[A\n",
            "Epoch 5:  15%|█▍        | 72/484 [09:23<53:51,  7.84s/it, training_loss=0.001]\u001b[A\n",
            "Epoch 5:  15%|█▍        | 72/484 [09:30<53:51,  7.84s/it, training_loss=0.001]\u001b[A\n",
            "Epoch 5:  15%|█▌        | 73/484 [09:30<51:16,  7.49s/it, training_loss=0.001]\u001b[A\n",
            "Epoch 5:  15%|█▌        | 73/484 [09:39<51:16,  7.49s/it, training_loss=0.001]\u001b[A\n",
            "Epoch 5:  15%|█▌        | 74/484 [09:39<54:57,  8.04s/it, training_loss=0.001]\u001b[A\n",
            "Epoch 5:  15%|█▌        | 74/484 [09:45<54:57,  8.04s/it, training_loss=0.266]\u001b[A\n",
            "Epoch 5:  15%|█▌        | 75/484 [09:45<51:36,  7.57s/it, training_loss=0.266]\u001b[A\n",
            "Epoch 5:  15%|█▌        | 75/484 [09:56<51:36,  7.57s/it, training_loss=0.002]\u001b[A\n",
            "Epoch 5:  16%|█▌        | 76/484 [09:56<58:13,  8.56s/it, training_loss=0.002]\u001b[A\n",
            "Epoch 5:  16%|█▌        | 76/484 [10:03<58:13,  8.56s/it, training_loss=0.015]\u001b[A\n",
            "Epoch 5:  16%|█▌        | 77/484 [10:03<54:32,  8.04s/it, training_loss=0.015]\u001b[A\n",
            "Epoch 5:  16%|█▌        | 77/484 [10:11<54:32,  8.04s/it, training_loss=0.001]\u001b[A\n",
            "Epoch 5:  16%|█▌        | 78/484 [10:11<53:31,  7.91s/it, training_loss=0.001]\u001b[A\n",
            "Epoch 5:  16%|█▌        | 78/484 [10:19<53:31,  7.91s/it, training_loss=0.003]\u001b[A\n",
            "Epoch 5:  16%|█▋        | 79/484 [10:19<54:03,  8.01s/it, training_loss=0.003]\u001b[A\n",
            "Epoch 5:  16%|█▋        | 79/484 [10:25<54:03,  8.01s/it, training_loss=0.003]\u001b[A\n",
            "Epoch 5:  17%|█▋        | 80/484 [10:25<50:52,  7.55s/it, training_loss=0.003]\u001b[A\n",
            "Epoch 5:  17%|█▋        | 80/484 [10:35<50:52,  7.55s/it, training_loss=0.010]\u001b[A\n",
            "Epoch 5:  17%|█▋        | 81/484 [10:35<55:01,  8.19s/it, training_loss=0.010]\u001b[A\n",
            "Epoch 5:  17%|█▋        | 81/484 [10:42<55:01,  8.19s/it, training_loss=0.001]\u001b[A\n",
            "Epoch 5:  17%|█▋        | 82/484 [10:42<51:35,  7.70s/it, training_loss=0.001]\u001b[A\n",
            "Epoch 5:  17%|█▋        | 82/484 [10:51<51:35,  7.70s/it, training_loss=0.165]\u001b[A\n",
            "Epoch 5:  17%|█▋        | 83/484 [10:51<54:08,  8.10s/it, training_loss=0.165]\u001b[A\n",
            "Epoch 5:  17%|█▋        | 83/484 [10:58<54:08,  8.10s/it, training_loss=0.001]\u001b[A\n",
            "Epoch 5:  17%|█▋        | 84/484 [10:58<52:14,  7.84s/it, training_loss=0.001]\u001b[A\n",
            "Epoch 5:  17%|█▋        | 84/484 [11:05<52:14,  7.84s/it, training_loss=0.003]\u001b[A\n",
            "Epoch 5:  18%|█▊        | 85/484 [11:05<51:17,  7.71s/it, training_loss=0.003]\u001b[A\n",
            "Epoch 5:  18%|█▊        | 85/484 [11:14<51:17,  7.71s/it, training_loss=0.001]\u001b[A\n",
            "Epoch 5:  18%|█▊        | 86/484 [11:14<52:43,  7.95s/it, training_loss=0.001]\u001b[A\n",
            "Epoch 5:  18%|█▊        | 86/484 [11:20<52:43,  7.95s/it, training_loss=0.001]\u001b[A\n",
            "Epoch 5:  18%|█▊        | 87/484 [11:20<49:49,  7.53s/it, training_loss=0.001]\u001b[A\n",
            "Epoch 5:  18%|█▊        | 87/484 [11:30<49:49,  7.53s/it, training_loss=0.007]\u001b[A\n",
            "Epoch 5:  18%|█▊        | 88/484 [11:30<53:58,  8.18s/it, training_loss=0.007]\u001b[A\n",
            "Epoch 5:  18%|█▊        | 88/484 [11:37<53:58,  8.18s/it, training_loss=0.009]\u001b[A\n",
            "Epoch 5:  18%|█▊        | 89/484 [11:37<50:35,  7.68s/it, training_loss=0.009]\u001b[A\n",
            "Epoch 5:  18%|█▊        | 89/484 [11:45<50:35,  7.68s/it, training_loss=0.001]\u001b[A\n",
            "Epoch 5:  19%|█▊        | 90/484 [11:45<52:34,  8.01s/it, training_loss=0.001]\u001b[A\n",
            "Epoch 5:  19%|█▊        | 90/484 [11:53<52:34,  8.01s/it, training_loss=0.001]\u001b[A\n",
            "Epoch 5:  19%|█▉        | 91/484 [11:53<51:01,  7.79s/it, training_loss=0.001]\u001b[A\n",
            "Epoch 5:  19%|█▉        | 91/484 [12:00<51:01,  7.79s/it, training_loss=0.003]\u001b[A\n",
            "Epoch 5:  19%|█▉        | 92/484 [12:00<49:37,  7.60s/it, training_loss=0.003]\u001b[A\n",
            "Epoch 5:  19%|█▉        | 92/484 [12:08<49:37,  7.60s/it, training_loss=0.001]\u001b[A\n",
            "Epoch 5:  19%|█▉        | 93/484 [12:08<51:46,  7.94s/it, training_loss=0.001]\u001b[A\n",
            "Epoch 5:  19%|█▉        | 93/484 [12:15<51:46,  7.94s/it, training_loss=0.001]\u001b[A\n",
            "Epoch 5:  19%|█▉        | 94/484 [12:15<48:53,  7.52s/it, training_loss=0.001]\u001b[A\n",
            "Epoch 5:  19%|█▉        | 94/484 [12:25<48:53,  7.52s/it, training_loss=0.003]\u001b[A\n",
            "Epoch 5:  20%|█▉        | 95/484 [12:25<52:54,  8.16s/it, training_loss=0.003]\u001b[A\n",
            "Epoch 5:  20%|█▉        | 95/484 [12:31<52:54,  8.16s/it, training_loss=0.001]\u001b[A\n",
            "Epoch 5:  20%|█▉        | 96/484 [12:31<49:36,  7.67s/it, training_loss=0.001]\u001b[A\n",
            "Epoch 5:  20%|█▉        | 96/484 [12:40<49:36,  7.67s/it, training_loss=0.001]\u001b[A\n",
            "Epoch 5:  20%|██        | 97/484 [12:40<50:50,  7.88s/it, training_loss=0.001]\u001b[A\n",
            "Epoch 5:  20%|██        | 97/484 [12:47<50:50,  7.88s/it, training_loss=0.004]\u001b[A\n",
            "Epoch 5:  20%|██        | 98/484 [12:47<50:20,  7.83s/it, training_loss=0.004]\u001b[A\n",
            "Epoch 5:  20%|██        | 98/484 [12:54<50:20,  7.83s/it, training_loss=0.001]\u001b[A\n",
            "Epoch 5:  20%|██        | 99/484 [12:54<48:14,  7.52s/it, training_loss=0.001]\u001b[A\n",
            "Epoch 5:  20%|██        | 99/484 [13:03<48:14,  7.52s/it, training_loss=0.095]\u001b[A\n",
            "Epoch 5:  21%|██        | 100/484 [13:03<51:30,  8.05s/it, training_loss=0.095]\u001b[A\n",
            "Epoch 5:  21%|██        | 100/484 [13:10<51:30,  8.05s/it, training_loss=0.297]\u001b[A\n",
            "Epoch 5:  21%|██        | 101/484 [13:10<48:21,  7.58s/it, training_loss=0.297]\u001b[A\n",
            "Epoch 5:  21%|██        | 101/484 [13:19<48:21,  7.58s/it, training_loss=0.002]\u001b[A\n",
            "Epoch 5:  21%|██        | 102/484 [13:19<51:42,  8.12s/it, training_loss=0.002]\u001b[A\n",
            "Epoch 5:  21%|██        | 102/484 [13:26<51:42,  8.12s/it, training_loss=0.001]\u001b[A\n",
            "Epoch 5:  21%|██▏       | 103/484 [13:26<48:51,  7.69s/it, training_loss=0.001]\u001b[A\n",
            "Epoch 5:  21%|██▏       | 103/484 [13:34<48:51,  7.69s/it, training_loss=0.004]\u001b[A\n",
            "Epoch 5:  21%|██▏       | 104/484 [13:34<49:04,  7.75s/it, training_loss=0.004]\u001b[A\n",
            "Epoch 5:  21%|██▏       | 104/484 [13:42<49:04,  7.75s/it, training_loss=0.001]\u001b[A\n",
            "Epoch 5:  22%|██▏       | 105/484 [13:42<49:18,  7.81s/it, training_loss=0.001]\u001b[A\n",
            "Epoch 5:  22%|██▏       | 105/484 [13:48<49:18,  7.81s/it, training_loss=0.001]\u001b[A\n",
            "Epoch 5:  22%|██▏       | 106/484 [13:48<46:41,  7.41s/it, training_loss=0.001]\u001b[A\n",
            "Epoch 5:  22%|██▏       | 106/484 [13:58<46:41,  7.41s/it, training_loss=0.001]\u001b[A\n",
            "Epoch 5:  22%|██▏       | 107/484 [13:58<50:38,  8.06s/it, training_loss=0.001]\u001b[A\n",
            "Epoch 5:  22%|██▏       | 107/484 [14:04<50:38,  8.06s/it, training_loss=0.080]\u001b[A\n",
            "Epoch 5:  22%|██▏       | 108/484 [14:04<47:31,  7.58s/it, training_loss=0.080]\u001b[A\n",
            "Epoch 5:  22%|██▏       | 108/484 [14:13<47:31,  7.58s/it, training_loss=0.001]\u001b[A\n",
            "Epoch 5:  23%|██▎       | 109/484 [14:13<50:00,  8.00s/it, training_loss=0.001]\u001b[A\n",
            "Epoch 5:  23%|██▎       | 109/484 [14:20<50:00,  8.00s/it, training_loss=0.243]\u001b[A\n",
            "Epoch 5:  23%|██▎       | 110/484 [14:20<48:03,  7.71s/it, training_loss=0.243]\u001b[A\n",
            "Epoch 5:  23%|██▎       | 110/484 [14:28<48:03,  7.71s/it, training_loss=0.003]\u001b[A\n",
            "Epoch 5:  23%|██▎       | 111/484 [14:28<47:15,  7.60s/it, training_loss=0.003]\u001b[A\n",
            "Epoch 5:  23%|██▎       | 111/484 [14:36<47:15,  7.60s/it, training_loss=0.001]\u001b[A\n",
            "Epoch 5:  23%|██▎       | 112/484 [14:36<48:52,  7.88s/it, training_loss=0.001]\u001b[A\n",
            "Epoch 5:  23%|██▎       | 112/484 [14:43<48:52,  7.88s/it, training_loss=0.001]\u001b[A\n",
            "Epoch 5:  23%|██▎       | 113/484 [14:43<46:12,  7.47s/it, training_loss=0.001]\u001b[A\n",
            "Epoch 5:  23%|██▎       | 113/484 [14:52<46:12,  7.47s/it, training_loss=0.001]\u001b[A\n",
            "Epoch 5:  24%|██▎       | 114/484 [14:52<50:07,  8.13s/it, training_loss=0.001]\u001b[A\n",
            "Epoch 5:  24%|██▎       | 114/484 [14:59<50:07,  8.13s/it, training_loss=0.001]\u001b[A\n",
            "Epoch 5:  24%|██▍       | 115/484 [14:59<47:06,  7.66s/it, training_loss=0.001]\u001b[A\n",
            "Epoch 5:  24%|██▍       | 115/484 [15:08<47:06,  7.66s/it, training_loss=0.001]\u001b[A\n",
            "Epoch 5:  24%|██▍       | 116/484 [15:08<49:02,  8.00s/it, training_loss=0.001]\u001b[A\n",
            "Epoch 5:  24%|██▍       | 116/484 [15:15<49:02,  8.00s/it, training_loss=0.002]\u001b[A\n",
            "Epoch 5:  24%|██▍       | 117/484 [15:15<47:31,  7.77s/it, training_loss=0.002]\u001b[A\n",
            "Epoch 5:  24%|██▍       | 117/484 [15:22<47:31,  7.77s/it, training_loss=0.002]\u001b[A\n",
            "Epoch 5:  24%|██▍       | 118/484 [15:22<46:26,  7.61s/it, training_loss=0.002]\u001b[A\n",
            "Epoch 5:  24%|██▍       | 118/484 [15:31<46:26,  7.61s/it, training_loss=0.002]\u001b[A\n",
            "Epoch 5:  25%|██▍       | 119/484 [15:31<48:20,  7.95s/it, training_loss=0.002]\u001b[A\n",
            "Epoch 5:  25%|██▍       | 119/484 [15:37<48:20,  7.95s/it, training_loss=0.001]\u001b[A\n",
            "Epoch 5:  25%|██▍       | 120/484 [15:37<45:29,  7.50s/it, training_loss=0.001]\u001b[A\n",
            "Epoch 5:  25%|██▍       | 120/484 [15:47<45:29,  7.50s/it, training_loss=0.004]\u001b[A\n",
            "Epoch 5:  25%|██▌       | 121/484 [15:47<49:09,  8.12s/it, training_loss=0.004]\u001b[A\n",
            "Epoch 5:  25%|██▌       | 121/484 [15:53<49:09,  8.12s/it, training_loss=0.001]\u001b[A\n",
            "Epoch 5:  25%|██▌       | 122/484 [15:53<46:07,  7.64s/it, training_loss=0.001]\u001b[A\n",
            "Epoch 5:  25%|██▌       | 122/484 [16:02<46:07,  7.64s/it, training_loss=0.001]\u001b[A\n",
            "Epoch 5:  25%|██▌       | 123/484 [16:02<47:18,  7.86s/it, training_loss=0.001]\u001b[A\n",
            "Epoch 5:  25%|██▌       | 123/484 [16:09<47:18,  7.86s/it, training_loss=0.001]\u001b[A\n",
            "Epoch 5:  26%|██▌       | 124/484 [16:09<46:42,  7.78s/it, training_loss=0.001]\u001b[A\n",
            "Epoch 5:  26%|██▌       | 124/484 [16:16<46:42,  7.78s/it, training_loss=0.002]\u001b[A\n",
            "Epoch 5:  26%|██▌       | 125/484 [16:16<44:34,  7.45s/it, training_loss=0.002]\u001b[A\n",
            "Epoch 5:  26%|██▌       | 125/484 [16:25<44:34,  7.45s/it, training_loss=0.001]\u001b[A\n",
            "Epoch 5:  26%|██▌       | 126/484 [16:25<47:35,  7.98s/it, training_loss=0.001]\u001b[A\n",
            "Epoch 5:  26%|██▌       | 126/484 [16:32<47:35,  7.98s/it, training_loss=0.001]\u001b[A\n",
            "Epoch 5:  26%|██▌       | 127/484 [16:32<44:46,  7.53s/it, training_loss=0.001]\u001b[A\n",
            "Epoch 5:  26%|██▌       | 127/484 [16:41<44:46,  7.53s/it, training_loss=0.001]\u001b[A\n",
            "Epoch 5:  26%|██▋       | 128/484 [16:41<47:56,  8.08s/it, training_loss=0.001]\u001b[A\n",
            "Epoch 5:  26%|██▋       | 128/484 [16:48<47:56,  8.08s/it, training_loss=0.039]\u001b[A\n",
            "Epoch 5:  27%|██▋       | 129/484 [16:48<45:27,  7.68s/it, training_loss=0.039]\u001b[A\n",
            "Epoch 5:  27%|██▋       | 129/484 [16:56<45:27,  7.68s/it, training_loss=0.284]\u001b[A\n",
            "Epoch 5:  27%|██▋       | 130/484 [16:56<45:52,  7.77s/it, training_loss=0.284]\u001b[A\n",
            "Epoch 5:  27%|██▋       | 130/484 [17:04<45:52,  7.77s/it, training_loss=0.021]\u001b[A\n",
            "Epoch 5:  27%|██▋       | 131/484 [17:04<46:15,  7.86s/it, training_loss=0.021]\u001b[A\n",
            "Epoch 5:  27%|██▋       | 131/484 [17:11<46:15,  7.86s/it, training_loss=0.001]\u001b[A\n",
            "Epoch 5:  27%|██▋       | 132/484 [17:11<43:55,  7.49s/it, training_loss=0.001]\u001b[A\n",
            "Epoch 5:  27%|██▋       | 132/484 [17:20<43:55,  7.49s/it, training_loss=0.001]\u001b[A\n",
            "Epoch 5:  27%|██▋       | 133/484 [17:20<47:30,  8.12s/it, training_loss=0.001]\u001b[A\n",
            "Epoch 5:  27%|██▋       | 133/484 [17:27<47:30,  8.12s/it, training_loss=0.001]\u001b[A\n",
            "Epoch 5:  28%|██▊       | 134/484 [17:27<44:34,  7.64s/it, training_loss=0.001]\u001b[A\n",
            "Epoch 5:  28%|██▊       | 134/484 [17:36<44:34,  7.64s/it, training_loss=0.292]\u001b[A\n",
            "Epoch 5:  28%|██▊       | 135/484 [17:36<47:08,  8.11s/it, training_loss=0.292]\u001b[A\n",
            "Epoch 5:  28%|██▊       | 135/484 [17:43<47:08,  8.11s/it, training_loss=0.001]\u001b[A\n",
            "Epoch 5:  28%|██▊       | 136/484 [17:43<44:50,  7.73s/it, training_loss=0.001]\u001b[A\n",
            "Epoch 5:  28%|██▊       | 136/484 [17:50<44:50,  7.73s/it, training_loss=0.001]\u001b[A\n",
            "Epoch 5:  28%|██▊       | 137/484 [17:50<44:23,  7.68s/it, training_loss=0.001]\u001b[A\n",
            "Epoch 5:  28%|██▊       | 137/484 [17:59<44:23,  7.68s/it, training_loss=0.001]\u001b[A\n",
            "Epoch 5:  29%|██▊       | 138/484 [17:59<45:24,  7.87s/it, training_loss=0.001]\u001b[A\n",
            "Epoch 5:  29%|██▊       | 138/484 [18:05<45:24,  7.87s/it, training_loss=0.005]\u001b[A\n",
            "Epoch 5:  29%|██▊       | 139/484 [18:05<42:53,  7.46s/it, training_loss=0.005]\u001b[A\n",
            "Epoch 5:  29%|██▊       | 139/484 [18:15<42:53,  7.46s/it, training_loss=0.004]\u001b[A\n",
            "Epoch 5:  29%|██▉       | 140/484 [18:15<46:32,  8.12s/it, training_loss=0.004]\u001b[A\n",
            "Epoch 5:  29%|██▉       | 140/484 [18:21<46:32,  8.12s/it, training_loss=0.114]\u001b[A\n",
            "Epoch 5:  29%|██▉       | 141/484 [18:21<43:40,  7.64s/it, training_loss=0.114]\u001b[A\n",
            "Epoch 5:  29%|██▉       | 141/484 [18:30<43:40,  7.64s/it, training_loss=0.000]\u001b[A\n",
            "Epoch 5:  29%|██▉       | 142/484 [18:30<45:46,  8.03s/it, training_loss=0.000]\u001b[A\n",
            "Epoch 5:  29%|██▉       | 142/484 [18:37<45:46,  8.03s/it, training_loss=0.033]\u001b[A\n",
            "Epoch 5:  30%|██▉       | 143/484 [18:37<44:08,  7.77s/it, training_loss=0.033]\u001b[A\n",
            "Epoch 5:  30%|██▉       | 143/484 [18:45<44:08,  7.77s/it, training_loss=0.001]\u001b[A\n",
            "Epoch 5:  30%|██▉       | 144/484 [18:45<43:25,  7.66s/it, training_loss=0.001]\u001b[A\n",
            "Epoch 5:  30%|██▉       | 144/484 [18:53<43:25,  7.66s/it, training_loss=0.218]\u001b[A\n",
            "Epoch 5:  30%|██▉       | 145/484 [18:53<44:51,  7.94s/it, training_loss=0.218]\u001b[A\n",
            "Epoch 5:  30%|██▉       | 145/484 [19:00<44:51,  7.94s/it, training_loss=0.001]\u001b[A\n",
            "Epoch 5:  30%|███       | 146/484 [19:00<42:29,  7.54s/it, training_loss=0.001]\u001b[A\n",
            "Epoch 5:  30%|███       | 146/484 [19:10<42:29,  7.54s/it, training_loss=0.001]\u001b[A\n",
            "Epoch 5:  30%|███       | 147/484 [19:10<45:58,  8.19s/it, training_loss=0.001]\u001b[A\n",
            "Epoch 5:  30%|███       | 147/484 [19:16<45:58,  8.19s/it, training_loss=0.024]\u001b[A\n",
            "Epoch 5:  31%|███       | 148/484 [19:16<43:02,  7.69s/it, training_loss=0.024]\u001b[A\n",
            "Epoch 5:  31%|███       | 148/484 [19:25<43:02,  7.69s/it, training_loss=0.001]\u001b[A\n",
            "Epoch 5:  31%|███       | 149/484 [19:25<44:55,  8.05s/it, training_loss=0.001]\u001b[A\n",
            "Epoch 5:  31%|███       | 149/484 [19:32<44:55,  8.05s/it, training_loss=0.131]\u001b[A\n",
            "Epoch 5:  31%|███       | 150/484 [19:32<43:25,  7.80s/it, training_loss=0.131]\u001b[A\n",
            "Epoch 5:  31%|███       | 150/484 [19:39<43:25,  7.80s/it, training_loss=0.054]\u001b[A\n",
            "Epoch 5:  31%|███       | 151/484 [19:39<42:07,  7.59s/it, training_loss=0.054]\u001b[A\n",
            "Epoch 5:  31%|███       | 151/484 [19:48<42:07,  7.59s/it, training_loss=0.001]\u001b[A\n",
            "Epoch 5:  31%|███▏      | 152/484 [19:48<43:47,  7.91s/it, training_loss=0.001]\u001b[A\n",
            "Epoch 5:  31%|███▏      | 152/484 [19:55<43:47,  7.91s/it, training_loss=0.004]\u001b[A\n",
            "Epoch 5:  32%|███▏      | 153/484 [19:55<41:13,  7.47s/it, training_loss=0.004]\u001b[A\n",
            "Epoch 5:  32%|███▏      | 153/484 [20:04<41:13,  7.47s/it, training_loss=0.001]\u001b[A\n",
            "Epoch 5:  32%|███▏      | 154/484 [20:04<44:32,  8.10s/it, training_loss=0.001]\u001b[A\n",
            "Epoch 5:  32%|███▏      | 154/484 [20:11<44:32,  8.10s/it, training_loss=0.000]\u001b[A\n",
            "Epoch 5:  32%|███▏      | 155/484 [20:11<41:38,  7.59s/it, training_loss=0.000]\u001b[A\n",
            "Epoch 5:  32%|███▏      | 155/484 [20:19<41:38,  7.59s/it, training_loss=0.082]\u001b[A\n",
            "Epoch 5:  32%|███▏      | 156/484 [20:19<42:50,  7.84s/it, training_loss=0.082]\u001b[A\n",
            "Epoch 5:  32%|███▏      | 156/484 [20:27<42:50,  7.84s/it, training_loss=0.008]\u001b[A\n",
            "Epoch 5:  32%|███▏      | 157/484 [20:27<42:21,  7.77s/it, training_loss=0.008]\u001b[A\n",
            "Epoch 5:  32%|███▏      | 157/484 [20:33<42:21,  7.77s/it, training_loss=0.028]\u001b[A\n",
            "Epoch 5:  33%|███▎      | 158/484 [20:33<40:42,  7.49s/it, training_loss=0.028]\u001b[A\n",
            "Epoch 5:  33%|███▎      | 158/484 [20:43<40:42,  7.49s/it, training_loss=0.001]\u001b[A\n",
            "Epoch 5:  33%|███▎      | 159/484 [20:43<43:24,  8.02s/it, training_loss=0.001]\u001b[A\n",
            "Epoch 5:  33%|███▎      | 159/484 [20:50<43:24,  8.02s/it, training_loss=0.001]\u001b[A\n",
            "Epoch 5:  33%|███▎      | 160/484 [20:50<42:26,  7.86s/it, training_loss=0.001]\u001b[A\n",
            "Epoch 5:  33%|███▎      | 160/484 [21:00<42:26,  7.86s/it, training_loss=0.002]\u001b[A\n",
            "Epoch 5:  33%|███▎      | 161/484 [21:00<45:17,  8.41s/it, training_loss=0.002]\u001b[A\n",
            "Epoch 5:  33%|███▎      | 161/484 [21:06<45:17,  8.41s/it, training_loss=0.001]\u001b[A\n",
            "Epoch 5:  33%|███▎      | 162/484 [21:06<42:04,  7.84s/it, training_loss=0.001]\u001b[A\n",
            "Epoch 5:  33%|███▎      | 162/484 [21:16<42:04,  7.84s/it, training_loss=0.001]\u001b[A\n",
            "Epoch 5:  34%|███▎      | 163/484 [21:16<44:04,  8.24s/it, training_loss=0.001]\u001b[A\n",
            "Epoch 5:  34%|███▎      | 163/484 [21:22<44:04,  8.24s/it, training_loss=0.001]\u001b[A\n",
            "Epoch 5:  34%|███▍      | 164/484 [21:22<41:10,  7.72s/it, training_loss=0.001]\u001b[A\n",
            "Epoch 5:  34%|███▍      | 164/484 [21:30<41:10,  7.72s/it, training_loss=0.001]\u001b[A\n",
            "Epoch 5:  34%|███▍      | 165/484 [21:30<42:01,  7.90s/it, training_loss=0.001]\u001b[A\n",
            "Epoch 5:  34%|███▍      | 165/484 [21:38<42:01,  7.90s/it, training_loss=0.006]\u001b[A\n",
            "Epoch 5:  34%|███▍      | 166/484 [21:38<40:45,  7.69s/it, training_loss=0.006]\u001b[A\n",
            "Epoch 5:  34%|███▍      | 166/484 [21:45<40:45,  7.69s/it, training_loss=0.002]\u001b[A\n",
            "Epoch 5:  35%|███▍      | 167/484 [21:45<39:38,  7.50s/it, training_loss=0.002]\u001b[A\n",
            "Epoch 5:  35%|███▍      | 167/484 [21:53<39:38,  7.50s/it, training_loss=0.001]\u001b[A\n",
            "Epoch 5:  35%|███▍      | 168/484 [21:53<40:41,  7.73s/it, training_loss=0.001]\u001b[A\n",
            "Epoch 5:  35%|███▍      | 168/484 [21:59<40:41,  7.73s/it, training_loss=0.001]\u001b[A\n",
            "Epoch 5:  35%|███▍      | 169/484 [21:59<38:44,  7.38s/it, training_loss=0.001]\u001b[A\n",
            "Epoch 5:  35%|███▍      | 169/484 [22:09<38:44,  7.38s/it, training_loss=0.001]\u001b[A\n",
            "Epoch 5:  35%|███▌      | 170/484 [22:09<41:24,  7.91s/it, training_loss=0.001]\u001b[A\n",
            "Epoch 5:  35%|███▌      | 170/484 [22:15<41:24,  7.91s/it, training_loss=0.001]\u001b[A\n",
            "Epoch 5:  35%|███▌      | 171/484 [22:15<39:06,  7.50s/it, training_loss=0.001]\u001b[A\n",
            "Epoch 5:  35%|███▌      | 171/484 [22:24<39:06,  7.50s/it, training_loss=0.001]\u001b[A\n",
            "Epoch 5:  36%|███▌      | 172/484 [22:24<41:37,  8.01s/it, training_loss=0.001]\u001b[A\n",
            "Epoch 5:  36%|███▌      | 172/484 [22:31<41:37,  8.01s/it, training_loss=0.001]\u001b[A\n",
            "Epoch 5:  36%|███▌      | 173/484 [22:31<39:06,  7.54s/it, training_loss=0.001]\u001b[A\n",
            "Epoch 5:  36%|███▌      | 173/484 [22:39<39:06,  7.54s/it, training_loss=0.001]\u001b[A\n",
            "Epoch 5:  36%|███▌      | 174/484 [22:39<40:21,  7.81s/it, training_loss=0.001]\u001b[A\n",
            "Epoch 5:  36%|███▌      | 174/484 [22:46<40:21,  7.81s/it, training_loss=0.273]\u001b[A\n",
            "Epoch 5:  36%|███▌      | 175/484 [22:46<39:08,  7.60s/it, training_loss=0.273]\u001b[A\n",
            "Epoch 5:  36%|███▌      | 175/484 [22:54<39:08,  7.60s/it, training_loss=0.201]\u001b[A\n",
            "Epoch 5:  36%|███▋      | 176/484 [22:54<38:29,  7.50s/it, training_loss=0.201]\u001b[A\n",
            "Epoch 5:  36%|███▋      | 176/484 [23:02<38:29,  7.50s/it, training_loss=0.183]\u001b[A\n",
            "Epoch 5:  37%|███▋      | 177/484 [23:02<39:21,  7.69s/it, training_loss=0.183]\u001b[A\n",
            "Epoch 5:  37%|███▋      | 177/484 [23:08<39:21,  7.69s/it, training_loss=0.001]\u001b[A\n",
            "Epoch 5:  37%|███▋      | 178/484 [23:08<37:23,  7.33s/it, training_loss=0.001]\u001b[A\n",
            "Epoch 5:  37%|███▋      | 178/484 [23:17<37:23,  7.33s/it, training_loss=0.001]\u001b[A\n",
            "Epoch 5:  37%|███▋      | 179/484 [23:17<40:03,  7.88s/it, training_loss=0.001]\u001b[A\n",
            "Epoch 5:  37%|███▋      | 179/484 [23:24<40:03,  7.88s/it, training_loss=0.015]\u001b[A\n",
            "Epoch 5:  37%|███▋      | 180/484 [23:24<37:50,  7.47s/it, training_loss=0.015]\u001b[A\n",
            "Epoch 5:  37%|███▋      | 180/484 [23:33<37:50,  7.47s/it, training_loss=0.011]\u001b[A\n",
            "Epoch 5:  37%|███▋      | 181/484 [23:33<40:13,  7.96s/it, training_loss=0.011]\u001b[A\n",
            "Epoch 5:  37%|███▋      | 181/484 [23:39<40:13,  7.96s/it, training_loss=0.001]\u001b[A\n",
            "Epoch 5:  38%|███▊      | 182/484 [23:39<37:45,  7.50s/it, training_loss=0.001]\u001b[A\n",
            "Epoch 5:  38%|███▊      | 182/484 [23:48<37:45,  7.50s/it, training_loss=0.179]\u001b[A\n",
            "Epoch 5:  38%|███▊      | 183/484 [23:48<38:50,  7.74s/it, training_loss=0.179]\u001b[A\n",
            "Epoch 5:  38%|███▊      | 183/484 [23:55<38:50,  7.74s/it, training_loss=0.001]\u001b[A\n",
            "Epoch 5:  38%|███▊      | 184/484 [23:55<37:57,  7.59s/it, training_loss=0.001]\u001b[A\n",
            "Epoch 5:  38%|███▊      | 184/484 [24:02<37:57,  7.59s/it, training_loss=0.002]\u001b[A\n",
            "Epoch 5:  38%|███▊      | 185/484 [24:02<37:17,  7.48s/it, training_loss=0.002]\u001b[A\n",
            "Epoch 5:  38%|███▊      | 185/484 [24:10<37:17,  7.48s/it, training_loss=0.126]\u001b[A\n",
            "Epoch 5:  38%|███▊      | 186/484 [24:10<38:08,  7.68s/it, training_loss=0.126]\u001b[A\n",
            "Epoch 5:  38%|███▊      | 186/484 [24:17<38:08,  7.68s/it, training_loss=0.002]\u001b[A\n",
            "Epoch 5:  39%|███▊      | 187/484 [24:17<36:17,  7.33s/it, training_loss=0.002]\u001b[A\n",
            "Epoch 5:  39%|███▊      | 187/484 [24:26<36:17,  7.33s/it, training_loss=0.001]\u001b[A\n",
            "Epoch 5:  39%|███▉      | 188/484 [24:26<38:52,  7.88s/it, training_loss=0.001]\u001b[A\n",
            "Epoch 5:  39%|███▉      | 188/484 [24:33<38:52,  7.88s/it, training_loss=0.054]\u001b[A\n",
            "Epoch 5:  39%|███▉      | 189/484 [24:33<36:45,  7.48s/it, training_loss=0.054]\u001b[A\n",
            "Epoch 5:  39%|███▉      | 189/484 [24:42<36:45,  7.48s/it, training_loss=0.139]\u001b[A\n",
            "Epoch 5:  39%|███▉      | 190/484 [24:42<38:58,  7.95s/it, training_loss=0.139]\u001b[A\n",
            "Epoch 5:  39%|███▉      | 190/484 [24:48<38:58,  7.95s/it, training_loss=0.001]\u001b[A\n",
            "Epoch 5:  39%|███▉      | 191/484 [24:48<36:44,  7.52s/it, training_loss=0.001]\u001b[A\n",
            "Epoch 5:  39%|███▉      | 191/484 [24:57<36:44,  7.52s/it, training_loss=0.001]\u001b[A\n",
            "Epoch 5:  40%|███▉      | 192/484 [24:57<37:55,  7.79s/it, training_loss=0.001]\u001b[A\n",
            "Epoch 5:  40%|███▉      | 192/484 [25:04<37:55,  7.79s/it, training_loss=0.001]\u001b[A\n",
            "Epoch 5:  40%|███▉      | 193/484 [25:04<37:00,  7.63s/it, training_loss=0.001]\u001b[A\n",
            "Epoch 5:  40%|███▉      | 193/484 [25:11<37:00,  7.63s/it, training_loss=0.006]\u001b[A\n",
            "Epoch 5:  40%|████      | 194/484 [25:11<36:06,  7.47s/it, training_loss=0.006]\u001b[A\n",
            "Epoch 5:  40%|████      | 194/484 [25:19<36:06,  7.47s/it, training_loss=0.002]\u001b[A\n",
            "Epoch 5:  40%|████      | 195/484 [25:19<37:05,  7.70s/it, training_loss=0.002]\u001b[A\n",
            "Epoch 5:  40%|████      | 195/484 [25:26<37:05,  7.70s/it, training_loss=0.001]\u001b[A\n",
            "Epoch 5:  40%|████      | 196/484 [25:26<35:08,  7.32s/it, training_loss=0.001]\u001b[A\n",
            "Epoch 5:  40%|████      | 196/484 [25:35<35:08,  7.32s/it, training_loss=0.001]\u001b[A\n",
            "Epoch 5:  41%|████      | 197/484 [25:35<37:37,  7.87s/it, training_loss=0.001]\u001b[A\n",
            "Epoch 5:  41%|████      | 197/484 [25:41<37:37,  7.87s/it, training_loss=0.002]\u001b[A\n",
            "Epoch 5:  41%|████      | 198/484 [25:41<35:33,  7.46s/it, training_loss=0.002]\u001b[A\n",
            "Epoch 5:  41%|████      | 198/484 [25:50<35:33,  7.46s/it, training_loss=0.001]\u001b[A\n",
            "Epoch 5:  41%|████      | 199/484 [25:50<37:39,  7.93s/it, training_loss=0.001]\u001b[A\n",
            "Epoch 5:  41%|████      | 199/484 [25:57<37:39,  7.93s/it, training_loss=0.015]\u001b[A\n",
            "Epoch 5:  41%|████▏     | 200/484 [25:57<35:27,  7.49s/it, training_loss=0.015]\u001b[A\n",
            "Epoch 5:  41%|████▏     | 200/484 [26:05<35:27,  7.49s/it, training_loss=0.001]\u001b[A\n",
            "Epoch 5:  42%|████▏     | 201/484 [26:05<36:21,  7.71s/it, training_loss=0.001]\u001b[A\n",
            "Epoch 5:  42%|████▏     | 201/484 [26:12<36:21,  7.71s/it, training_loss=0.001]\u001b[A\n",
            "Epoch 5:  42%|████▏     | 202/484 [26:12<35:45,  7.61s/it, training_loss=0.001]\u001b[A\n",
            "Epoch 5:  42%|████▏     | 202/484 [26:19<35:45,  7.61s/it, training_loss=0.001]\u001b[A\n",
            "Epoch 5:  42%|████▏     | 203/484 [26:19<34:37,  7.39s/it, training_loss=0.001]\u001b[A\n",
            "Epoch 5:  42%|████▏     | 203/484 [26:28<34:37,  7.39s/it, training_loss=0.002]\u001b[A\n",
            "Epoch 5:  42%|████▏     | 204/484 [26:28<36:01,  7.72s/it, training_loss=0.002]\u001b[A\n",
            "Epoch 5:  42%|████▏     | 204/484 [26:34<36:01,  7.72s/it, training_loss=0.001]\u001b[A\n",
            "Epoch 5:  42%|████▏     | 205/484 [26:34<34:15,  7.37s/it, training_loss=0.001]\u001b[A\n",
            "Epoch 5:  42%|████▏     | 205/484 [26:43<34:15,  7.37s/it, training_loss=0.327]\u001b[A\n",
            "Epoch 5:  43%|████▎     | 206/484 [26:43<36:39,  7.91s/it, training_loss=0.327]\u001b[A\n",
            "Epoch 5:  43%|████▎     | 206/484 [26:50<36:39,  7.91s/it, training_loss=0.001]\u001b[A\n",
            "Epoch 5:  43%|████▎     | 207/484 [26:50<34:35,  7.49s/it, training_loss=0.001]\u001b[A\n",
            "Epoch 5:  43%|████▎     | 207/484 [26:59<34:35,  7.49s/it, training_loss=0.001]\u001b[A\n",
            "Epoch 5:  43%|████▎     | 208/484 [26:59<36:35,  7.95s/it, training_loss=0.001]\u001b[A\n",
            "Epoch 5:  43%|████▎     | 208/484 [27:06<36:35,  7.95s/it, training_loss=0.001]\u001b[A\n",
            "Epoch 5:  43%|████▎     | 209/484 [27:06<34:33,  7.54s/it, training_loss=0.001]\u001b[A\n",
            "Epoch 5:  43%|████▎     | 209/484 [27:14<34:33,  7.54s/it, training_loss=0.001]\u001b[A\n",
            "Epoch 5:  43%|████▎     | 210/484 [27:14<35:14,  7.72s/it, training_loss=0.001]\u001b[A\n",
            "Epoch 5:  43%|████▎     | 210/484 [27:21<35:14,  7.72s/it, training_loss=0.001]\u001b[A\n",
            "Epoch 5:  44%|████▎     | 211/484 [27:21<34:48,  7.65s/it, training_loss=0.001]\u001b[A\n",
            "Epoch 5:  44%|████▎     | 211/484 [27:28<34:48,  7.65s/it, training_loss=0.014]\u001b[A\n",
            "Epoch 5:  44%|████▍     | 212/484 [27:28<33:43,  7.44s/it, training_loss=0.014]\u001b[A\n",
            "Epoch 5:  44%|████▍     | 212/484 [27:37<33:43,  7.44s/it, training_loss=0.001]\u001b[A\n",
            "Epoch 5:  44%|████▍     | 213/484 [27:37<35:06,  7.77s/it, training_loss=0.001]\u001b[A\n",
            "Epoch 5:  44%|████▍     | 213/484 [27:43<35:06,  7.77s/it, training_loss=0.004]\u001b[A\n",
            "Epoch 5:  44%|████▍     | 214/484 [27:43<33:11,  7.38s/it, training_loss=0.004]\u001b[A\n",
            "Epoch 5:  44%|████▍     | 214/484 [27:52<33:11,  7.38s/it, training_loss=0.004]\u001b[A\n",
            "Epoch 5:  44%|████▍     | 215/484 [27:52<35:25,  7.90s/it, training_loss=0.004]\u001b[A\n",
            "Epoch 5:  44%|████▍     | 215/484 [27:59<35:25,  7.90s/it, training_loss=0.001]\u001b[A\n",
            "Epoch 5:  45%|████▍     | 216/484 [27:59<33:26,  7.49s/it, training_loss=0.001]\u001b[A\n",
            "Epoch 5:  45%|████▍     | 216/484 [28:08<33:26,  7.49s/it, training_loss=0.001]\u001b[A\n",
            "Epoch 5:  45%|████▍     | 217/484 [28:08<35:12,  7.91s/it, training_loss=0.001]\u001b[A\n",
            "Epoch 5:  45%|████▍     | 217/484 [28:14<35:12,  7.91s/it, training_loss=0.001]\u001b[A\n",
            "Epoch 5:  45%|████▌     | 218/484 [28:14<33:21,  7.52s/it, training_loss=0.001]\u001b[A\n",
            "Epoch 5:  45%|████▌     | 218/484 [28:22<33:21,  7.52s/it, training_loss=0.001]\u001b[A\n",
            "Epoch 5:  45%|████▌     | 219/484 [28:22<33:41,  7.63s/it, training_loss=0.001]\u001b[A\n",
            "Epoch 5:  45%|████▌     | 219/484 [28:30<33:41,  7.63s/it, training_loss=0.032]\u001b[A\n",
            "Epoch 5:  45%|████▌     | 220/484 [28:30<33:34,  7.63s/it, training_loss=0.032]\u001b[A\n",
            "Epoch 5:  45%|████▌     | 220/484 [28:36<33:34,  7.63s/it, training_loss=0.127]\u001b[A\n",
            "Epoch 5:  46%|████▌     | 221/484 [28:37<32:14,  7.36s/it, training_loss=0.127]\u001b[A\n",
            "Epoch 5:  46%|████▌     | 221/484 [28:45<32:14,  7.36s/it, training_loss=0.001]\u001b[A\n",
            "Epoch 5:  46%|████▌     | 222/484 [28:45<34:01,  7.79s/it, training_loss=0.001]\u001b[A\n",
            "Epoch 5:  46%|████▌     | 222/484 [28:52<34:01,  7.79s/it, training_loss=0.058]\u001b[A\n",
            "Epoch 5:  46%|████▌     | 223/484 [28:52<32:14,  7.41s/it, training_loss=0.058]\u001b[A\n",
            "Epoch 5:  46%|████▌     | 223/484 [29:01<32:14,  7.41s/it, training_loss=0.004]\u001b[A\n",
            "Epoch 5:  46%|████▋     | 224/484 [29:01<34:25,  7.95s/it, training_loss=0.004]\u001b[A\n",
            "Epoch 5:  46%|████▋     | 224/484 [29:08<34:25,  7.95s/it, training_loss=0.004]\u001b[A\n",
            "Epoch 5:  46%|████▋     | 225/484 [29:08<32:29,  7.53s/it, training_loss=0.004]\u001b[A\n",
            "Epoch 5:  46%|████▋     | 225/484 [29:16<32:29,  7.53s/it, training_loss=0.256]\u001b[A\n",
            "Epoch 5:  47%|████▋     | 226/484 [29:16<33:59,  7.90s/it, training_loss=0.256]\u001b[A\n",
            "Epoch 5:  47%|████▋     | 226/484 [29:23<33:59,  7.90s/it, training_loss=0.001]\u001b[A\n",
            "Epoch 5:  47%|████▋     | 227/484 [29:23<32:24,  7.57s/it, training_loss=0.001]\u001b[A\n",
            "Epoch 5:  47%|████▋     | 227/484 [29:31<32:24,  7.57s/it, training_loss=0.001]\u001b[A\n",
            "Epoch 5:  47%|████▋     | 228/484 [29:31<32:26,  7.60s/it, training_loss=0.001]\u001b[A\n",
            "Epoch 5:  47%|████▋     | 228/484 [29:39<32:26,  7.60s/it, training_loss=0.016]\u001b[A\n",
            "Epoch 5:  47%|████▋     | 229/484 [29:39<32:25,  7.63s/it, training_loss=0.016]\u001b[A\n",
            "Epoch 5:  47%|████▋     | 229/484 [29:45<32:25,  7.63s/it, training_loss=0.057]\u001b[A\n",
            "Epoch 5:  48%|████▊     | 230/484 [29:45<30:58,  7.32s/it, training_loss=0.057]\u001b[A\n",
            "Epoch 5:  48%|████▊     | 230/484 [29:54<30:58,  7.32s/it, training_loss=0.001]\u001b[A\n",
            "Epoch 5:  48%|████▊     | 231/484 [29:54<32:52,  7.79s/it, training_loss=0.001]\u001b[A\n",
            "Epoch 5:  48%|████▊     | 231/484 [30:01<32:52,  7.79s/it, training_loss=0.212]\u001b[A\n",
            "Epoch 5:  48%|████▊     | 232/484 [30:01<31:06,  7.41s/it, training_loss=0.212]\u001b[A\n",
            "Epoch 5:  48%|████▊     | 232/484 [30:10<31:06,  7.41s/it, training_loss=0.533]\u001b[A\n",
            "Epoch 5:  48%|████▊     | 233/484 [30:10<33:10,  7.93s/it, training_loss=0.533]\u001b[A\n",
            "Epoch 5:  48%|████▊     | 233/484 [30:16<33:10,  7.93s/it, training_loss=0.031]\u001b[A\n",
            "Epoch 5:  48%|████▊     | 234/484 [30:16<31:10,  7.48s/it, training_loss=0.031]\u001b[A\n",
            "Epoch 5:  48%|████▊     | 234/484 [30:25<31:10,  7.48s/it, training_loss=0.009]\u001b[A\n",
            "Epoch 5:  49%|████▊     | 235/484 [30:25<32:26,  7.82s/it, training_loss=0.009]\u001b[A\n",
            "Epoch 5:  49%|████▊     | 235/484 [30:32<32:26,  7.82s/it, training_loss=0.004]\u001b[A\n",
            "Epoch 5:  49%|████▉     | 236/484 [30:32<31:17,  7.57s/it, training_loss=0.004]\u001b[A\n",
            "Epoch 5:  49%|████▉     | 236/484 [30:43<31:17,  7.57s/it, training_loss=0.002]\u001b[A\n",
            "Epoch 5:  49%|████▉     | 237/484 [30:43<35:22,  8.59s/it, training_loss=0.002]\u001b[A\n",
            "Epoch 5:  49%|████▉     | 237/484 [30:50<35:22,  8.59s/it, training_loss=0.001]\u001b[A\n",
            "Epoch 5:  49%|████▉     | 238/484 [30:50<33:44,  8.23s/it, training_loss=0.001]\u001b[A\n",
            "Epoch 5:  49%|████▉     | 238/484 [30:58<33:44,  8.23s/it, training_loss=0.002]\u001b[A\n",
            "Epoch 5:  49%|████▉     | 239/484 [30:58<32:41,  8.00s/it, training_loss=0.002]\u001b[A\n",
            "Epoch 5:  49%|████▉     | 239/484 [31:05<32:41,  8.00s/it, training_loss=0.001]\u001b[A\n",
            "Epoch 5:  50%|████▉     | 240/484 [31:05<32:26,  7.98s/it, training_loss=0.001]\u001b[A\n",
            "Epoch 5:  50%|████▉     | 240/484 [31:12<32:26,  7.98s/it, training_loss=0.001]\u001b[A\n",
            "Epoch 5:  50%|████▉     | 241/484 [31:12<30:34,  7.55s/it, training_loss=0.001]\u001b[A\n",
            "Epoch 5:  50%|████▉     | 241/484 [31:21<30:34,  7.55s/it, training_loss=0.001]\u001b[A\n",
            "Epoch 5:  50%|█████     | 242/484 [31:21<32:16,  8.00s/it, training_loss=0.001]\u001b[A\n",
            "Epoch 5:  50%|█████     | 242/484 [31:28<32:16,  8.00s/it, training_loss=0.001]\u001b[A\n",
            "Epoch 5:  50%|█████     | 243/484 [31:28<30:16,  7.54s/it, training_loss=0.001]\u001b[A\n",
            "Epoch 5:  50%|█████     | 243/484 [31:37<30:16,  7.54s/it, training_loss=0.001]\u001b[A\n",
            "Epoch 5:  50%|█████     | 244/484 [31:37<32:00,  8.00s/it, training_loss=0.001]\u001b[A\n",
            "Epoch 5:  50%|█████     | 244/484 [31:43<32:00,  8.00s/it, training_loss=0.001]\u001b[A\n",
            "Epoch 5:  51%|█████     | 245/484 [31:43<30:01,  7.54s/it, training_loss=0.001]\u001b[A\n",
            "Epoch 5:  51%|█████     | 245/484 [31:52<30:01,  7.54s/it, training_loss=0.000]\u001b[A\n",
            "Epoch 5:  51%|█████     | 246/484 [31:52<31:00,  7.82s/it, training_loss=0.000]\u001b[A\n",
            "Epoch 5:  51%|█████     | 246/484 [31:59<31:00,  7.82s/it, training_loss=0.125]\u001b[A\n",
            "Epoch 5:  51%|█████     | 247/484 [31:59<30:01,  7.60s/it, training_loss=0.125]\u001b[A\n",
            "Epoch 5:  51%|█████     | 247/484 [32:06<30:01,  7.60s/it, training_loss=0.001]\u001b[A\n",
            "Epoch 5:  51%|█████     | 248/484 [32:06<29:27,  7.49s/it, training_loss=0.001]\u001b[A\n",
            "Epoch 5:  51%|█████     | 248/484 [32:14<29:27,  7.49s/it, training_loss=0.277]\u001b[A\n",
            "Epoch 5:  51%|█████▏    | 249/484 [32:14<30:12,  7.71s/it, training_loss=0.277]\u001b[A\n",
            "Epoch 5:  51%|█████▏    | 249/484 [32:21<30:12,  7.71s/it, training_loss=0.108]\u001b[A\n",
            "Epoch 5:  52%|█████▏    | 250/484 [32:21<28:43,  7.36s/it, training_loss=0.108]\u001b[A\n",
            "Epoch 5:  52%|█████▏    | 250/484 [32:30<28:43,  7.36s/it, training_loss=0.001]\u001b[A\n",
            "Epoch 5:  52%|█████▏    | 251/484 [32:30<30:39,  7.90s/it, training_loss=0.001]\u001b[A\n",
            "Epoch 5:  52%|█████▏    | 251/484 [32:36<30:39,  7.90s/it, training_loss=0.001]\u001b[A\n",
            "Epoch 5:  52%|█████▏    | 252/484 [32:36<28:55,  7.48s/it, training_loss=0.001]\u001b[A\n",
            "Epoch 5:  52%|█████▏    | 252/484 [32:45<28:55,  7.48s/it, training_loss=0.001]\u001b[A\n",
            "Epoch 5:  52%|█████▏    | 253/484 [32:45<30:46,  8.00s/it, training_loss=0.001]\u001b[A\n",
            "Epoch 5:  52%|█████▏    | 253/484 [32:52<30:46,  8.00s/it, training_loss=0.001]\u001b[A\n",
            "Epoch 5:  52%|█████▏    | 254/484 [32:52<29:00,  7.57s/it, training_loss=0.001]\u001b[A\n",
            "Epoch 5:  52%|█████▏    | 254/484 [33:01<29:00,  7.57s/it, training_loss=0.001]\u001b[A\n",
            "Epoch 5:  53%|█████▎    | 255/484 [33:01<29:57,  7.85s/it, training_loss=0.001]\u001b[A\n",
            "Epoch 5:  53%|█████▎    | 255/484 [33:08<29:57,  7.85s/it, training_loss=0.001]\u001b[A\n",
            "Epoch 5:  53%|█████▎    | 256/484 [33:08<29:00,  7.63s/it, training_loss=0.001]\u001b[A\n",
            "Epoch 5:  53%|█████▎    | 256/484 [33:15<29:00,  7.63s/it, training_loss=0.001]\u001b[A\n",
            "Epoch 5:  53%|█████▎    | 257/484 [33:15<28:34,  7.55s/it, training_loss=0.001]\u001b[A\n",
            "Epoch 5:  53%|█████▎    | 257/484 [33:23<28:34,  7.55s/it, training_loss=0.005]\u001b[A\n",
            "Epoch 5:  53%|█████▎    | 258/484 [33:23<28:59,  7.70s/it, training_loss=0.005]\u001b[A\n",
            "Epoch 5:  53%|█████▎    | 258/484 [33:30<28:59,  7.70s/it, training_loss=0.001]\u001b[A\n",
            "Epoch 5:  54%|█████▎    | 259/484 [33:30<27:29,  7.33s/it, training_loss=0.001]\u001b[A\n",
            "Epoch 5:  54%|█████▎    | 259/484 [33:39<27:29,  7.33s/it, training_loss=0.001]\u001b[A\n",
            "Epoch 5:  54%|█████▎    | 260/484 [33:39<29:20,  7.86s/it, training_loss=0.001]\u001b[A\n",
            "Epoch 5:  54%|█████▎    | 260/484 [33:45<29:20,  7.86s/it, training_loss=0.001]\u001b[A\n",
            "Epoch 5:  54%|█████▍    | 261/484 [33:45<27:39,  7.44s/it, training_loss=0.001]\u001b[A\n",
            "Epoch 5:  54%|█████▍    | 261/484 [33:54<27:39,  7.44s/it, training_loss=0.153]\u001b[A\n",
            "Epoch 5:  54%|█████▍    | 262/484 [33:54<29:24,  7.95s/it, training_loss=0.153]\u001b[A\n",
            "Epoch 5:  54%|█████▍    | 262/484 [34:01<29:24,  7.95s/it, training_loss=0.000]\u001b[A\n",
            "Epoch 5:  54%|█████▍    | 263/484 [34:01<27:41,  7.52s/it, training_loss=0.000]\u001b[A\n",
            "Epoch 5:  54%|█████▍    | 263/484 [34:09<27:41,  7.52s/it, training_loss=0.001]\u001b[A\n",
            "Epoch 5:  55%|█████▍    | 264/484 [34:09<28:32,  7.79s/it, training_loss=0.001]\u001b[A\n",
            "Epoch 5:  55%|█████▍    | 264/484 [34:16<28:32,  7.79s/it, training_loss=0.001]\u001b[A\n",
            "Epoch 5:  55%|█████▍    | 265/484 [34:16<27:41,  7.59s/it, training_loss=0.001]\u001b[A\n",
            "Epoch 5:  55%|█████▍    | 265/484 [34:24<27:41,  7.59s/it, training_loss=0.001]\u001b[A\n",
            "Epoch 5:  55%|█████▍    | 266/484 [34:24<27:17,  7.51s/it, training_loss=0.001]\u001b[A\n",
            "Epoch 5:  55%|█████▍    | 266/484 [34:32<27:17,  7.51s/it, training_loss=0.001]\u001b[A\n",
            "Epoch 5:  55%|█████▌    | 267/484 [34:32<27:47,  7.69s/it, training_loss=0.001]\u001b[A\n",
            "Epoch 5:  55%|█████▌    | 267/484 [34:38<27:47,  7.69s/it, training_loss=0.001]\u001b[A\n",
            "Epoch 5:  55%|█████▌    | 268/484 [34:38<26:19,  7.31s/it, training_loss=0.001]\u001b[A\n",
            "Epoch 5:  55%|█████▌    | 268/484 [34:47<26:19,  7.31s/it, training_loss=0.006]\u001b[A\n",
            "Epoch 5:  56%|█████▌    | 269/484 [34:47<28:12,  7.87s/it, training_loss=0.006]\u001b[A\n",
            "Epoch 5:  56%|█████▌    | 269/484 [34:54<28:12,  7.87s/it, training_loss=0.045]\u001b[A\n",
            "Epoch 5:  56%|█████▌    | 270/484 [34:54<26:36,  7.46s/it, training_loss=0.045]\u001b[A\n",
            "Epoch 5:  56%|█████▌    | 270/484 [35:03<26:36,  7.46s/it, training_loss=0.001]\u001b[A\n",
            "Epoch 5:  56%|█████▌    | 271/484 [35:03<28:15,  7.96s/it, training_loss=0.001]\u001b[A\n",
            "Epoch 5:  56%|█████▌    | 271/484 [35:09<28:15,  7.96s/it, training_loss=0.236]\u001b[A\n",
            "Epoch 5:  56%|█████▌    | 272/484 [35:09<26:32,  7.51s/it, training_loss=0.236]\u001b[A\n",
            "Epoch 5:  56%|█████▌    | 272/484 [35:18<26:32,  7.51s/it, training_loss=0.002]\u001b[A\n",
            "Epoch 5:  56%|█████▋    | 273/484 [35:18<27:16,  7.75s/it, training_loss=0.002]\u001b[A\n",
            "Epoch 5:  56%|█████▋    | 273/484 [35:25<27:16,  7.75s/it, training_loss=0.001]\u001b[A\n",
            "Epoch 5:  57%|█████▋    | 274/484 [35:25<26:34,  7.59s/it, training_loss=0.001]\u001b[A\n",
            "Epoch 5:  57%|█████▋    | 274/484 [35:32<26:34,  7.59s/it, training_loss=0.002]\u001b[A\n",
            "Epoch 5:  57%|█████▋    | 275/484 [35:32<25:56,  7.45s/it, training_loss=0.002]\u001b[A\n",
            "Epoch 5:  57%|█████▋    | 275/484 [35:40<25:56,  7.45s/it, training_loss=0.002]\u001b[A\n",
            "Epoch 5:  57%|█████▋    | 276/484 [35:40<26:37,  7.68s/it, training_loss=0.002]\u001b[A\n",
            "Epoch 5:  57%|█████▋    | 276/484 [35:47<26:37,  7.68s/it, training_loss=0.001]\u001b[A\n",
            "Epoch 5:  57%|█████▋    | 277/484 [35:47<25:14,  7.32s/it, training_loss=0.001]\u001b[A\n",
            "Epoch 5:  57%|█████▋    | 277/484 [35:56<25:14,  7.32s/it, training_loss=0.001]\u001b[A\n",
            "Epoch 5:  57%|█████▋    | 278/484 [35:56<27:00,  7.86s/it, training_loss=0.001]\u001b[A\n",
            "Epoch 5:  57%|█████▋    | 278/484 [36:02<27:00,  7.86s/it, training_loss=0.001]\u001b[A\n",
            "Epoch 5:  58%|█████▊    | 279/484 [36:02<25:30,  7.47s/it, training_loss=0.001]\u001b[A\n",
            "Epoch 5:  58%|█████▊    | 279/484 [36:12<25:30,  7.47s/it, training_loss=0.126]\u001b[A\n",
            "Epoch 5:  58%|█████▊    | 280/484 [36:12<27:04,  7.96s/it, training_loss=0.126]\u001b[A\n",
            "Epoch 5:  58%|█████▊    | 280/484 [36:18<27:04,  7.96s/it, training_loss=0.004]\u001b[A\n",
            "Epoch 5:  58%|█████▊    | 281/484 [36:18<25:49,  7.63s/it, training_loss=0.004]\u001b[A\n",
            "Epoch 5:  58%|█████▊    | 281/484 [36:27<25:49,  7.63s/it, training_loss=0.001]\u001b[A\n",
            "Epoch 5:  58%|█████▊    | 282/484 [36:27<26:34,  7.89s/it, training_loss=0.001]\u001b[A\n",
            "Epoch 5:  58%|█████▊    | 282/484 [36:34<26:34,  7.89s/it, training_loss=0.003]\u001b[A\n",
            "Epoch 5:  58%|█████▊    | 283/484 [36:34<25:40,  7.67s/it, training_loss=0.003]\u001b[A\n",
            "Epoch 5:  58%|█████▊    | 283/484 [36:41<25:40,  7.67s/it, training_loss=0.001]\u001b[A\n",
            "Epoch 5:  59%|█████▊    | 284/484 [36:41<25:15,  7.58s/it, training_loss=0.001]\u001b[A\n",
            "Epoch 5:  59%|█████▊    | 284/484 [36:50<25:15,  7.58s/it, training_loss=0.003]\u001b[A\n",
            "Epoch 5:  59%|█████▉    | 285/484 [36:50<25:40,  7.74s/it, training_loss=0.003]\u001b[A\n",
            "Epoch 5:  59%|█████▉    | 285/484 [36:56<25:40,  7.74s/it, training_loss=0.002]\u001b[A\n",
            "Epoch 5:  59%|█████▉    | 286/484 [36:56<24:22,  7.39s/it, training_loss=0.002]\u001b[A\n",
            "Epoch 5:  59%|█████▉    | 286/484 [37:05<24:22,  7.39s/it, training_loss=0.001]\u001b[A\n",
            "Epoch 5:  59%|█████▉    | 287/484 [37:05<26:00,  7.92s/it, training_loss=0.001]\u001b[A\n",
            "Epoch 5:  59%|█████▉    | 287/484 [37:12<26:00,  7.92s/it, training_loss=0.001]\u001b[A\n",
            "Epoch 5:  60%|█████▉    | 288/484 [37:12<24:30,  7.50s/it, training_loss=0.001]\u001b[A\n",
            "Epoch 5:  60%|█████▉    | 288/484 [37:21<24:30,  7.50s/it, training_loss=0.003]\u001b[A\n",
            "Epoch 5:  60%|█████▉    | 289/484 [37:21<25:59,  8.00s/it, training_loss=0.003]\u001b[A\n",
            "Epoch 5:  60%|█████▉    | 289/484 [37:27<25:59,  8.00s/it, training_loss=0.001]\u001b[A\n",
            "Epoch 5:  60%|█████▉    | 290/484 [37:27<24:24,  7.55s/it, training_loss=0.001]\u001b[A\n",
            "Epoch 5:  60%|█████▉    | 290/484 [37:36<24:24,  7.55s/it, training_loss=0.244]\u001b[A\n",
            "Epoch 5:  60%|██████    | 291/484 [37:36<25:12,  7.84s/it, training_loss=0.244]\u001b[A\n",
            "Epoch 5:  60%|██████    | 291/484 [37:43<25:12,  7.84s/it, training_loss=0.001]\u001b[A\n",
            "Epoch 5:  60%|██████    | 292/484 [37:43<24:18,  7.60s/it, training_loss=0.001]\u001b[A\n",
            "Epoch 5:  60%|██████    | 292/484 [37:50<24:18,  7.60s/it, training_loss=0.001]\u001b[A\n",
            "Epoch 5:  61%|██████    | 293/484 [37:50<23:54,  7.51s/it, training_loss=0.001]\u001b[A\n",
            "Epoch 5:  61%|██████    | 293/484 [37:58<23:54,  7.51s/it, training_loss=0.001]\u001b[A\n",
            "Epoch 5:  61%|██████    | 294/484 [37:58<24:15,  7.66s/it, training_loss=0.001]\u001b[A\n",
            "Epoch 5:  61%|██████    | 294/484 [38:05<24:15,  7.66s/it, training_loss=0.002]\u001b[A\n",
            "Epoch 5:  61%|██████    | 295/484 [38:05<23:01,  7.31s/it, training_loss=0.002]\u001b[A\n",
            "Epoch 5:  61%|██████    | 295/484 [38:14<23:01,  7.31s/it, training_loss=0.222]\u001b[A\n",
            "Epoch 5:  61%|██████    | 296/484 [38:14<24:38,  7.86s/it, training_loss=0.222]\u001b[A\n",
            "Epoch 5:  61%|██████    | 296/484 [38:20<24:38,  7.86s/it, training_loss=0.001]\u001b[A\n",
            "Epoch 5:  61%|██████▏   | 297/484 [38:20<23:13,  7.45s/it, training_loss=0.001]\u001b[A\n",
            "Epoch 5:  61%|██████▏   | 297/484 [38:30<23:13,  7.45s/it, training_loss=0.006]\u001b[A\n",
            "Epoch 5:  62%|██████▏   | 298/484 [38:30<24:39,  7.95s/it, training_loss=0.006]\u001b[A\n",
            "Epoch 5:  62%|██████▏   | 298/484 [38:36<24:39,  7.95s/it, training_loss=0.263]\u001b[A\n",
            "Epoch 5:  62%|██████▏   | 299/484 [38:36<23:09,  7.51s/it, training_loss=0.263]\u001b[A\n",
            "Epoch 5:  62%|██████▏   | 299/484 [38:45<23:09,  7.51s/it, training_loss=0.251]\u001b[A\n",
            "Epoch 5:  62%|██████▏   | 300/484 [38:45<23:51,  7.78s/it, training_loss=0.251]\u001b[A\n",
            "Epoch 5:  62%|██████▏   | 300/484 [38:52<23:51,  7.78s/it, training_loss=0.001]\u001b[A\n",
            "Epoch 5:  62%|██████▏   | 301/484 [38:52<23:12,  7.61s/it, training_loss=0.001]\u001b[A\n",
            "Epoch 5:  62%|██████▏   | 301/484 [38:59<23:12,  7.61s/it, training_loss=0.003]\u001b[A\n",
            "Epoch 5:  62%|██████▏   | 302/484 [38:59<22:43,  7.49s/it, training_loss=0.003]\u001b[A\n",
            "Epoch 5:  62%|██████▏   | 302/484 [39:07<22:43,  7.49s/it, training_loss=0.001]\u001b[A\n",
            "Epoch 5:  63%|██████▎   | 303/484 [39:07<23:16,  7.72s/it, training_loss=0.001]\u001b[A\n",
            "Epoch 5:  63%|██████▎   | 303/484 [39:14<23:16,  7.72s/it, training_loss=0.001]\u001b[A\n",
            "Epoch 5:  63%|██████▎   | 304/484 [39:14<22:02,  7.35s/it, training_loss=0.001]\u001b[A\n",
            "Epoch 5:  63%|██████▎   | 304/484 [39:23<22:02,  7.35s/it, training_loss=0.001]\u001b[A\n",
            "Epoch 5:  63%|██████▎   | 305/484 [39:23<23:32,  7.89s/it, training_loss=0.001]\u001b[A\n",
            "Epoch 5:  63%|██████▎   | 305/484 [39:29<23:32,  7.89s/it, training_loss=0.001]\u001b[A\n",
            "Epoch 5:  63%|██████▎   | 306/484 [39:29<22:08,  7.46s/it, training_loss=0.001]\u001b[A\n",
            "Epoch 5:  63%|██████▎   | 306/484 [39:38<22:08,  7.46s/it, training_loss=0.004]\u001b[A\n",
            "Epoch 5:  63%|██████▎   | 307/484 [39:38<23:27,  7.95s/it, training_loss=0.004]\u001b[A\n",
            "Epoch 5:  63%|██████▎   | 307/484 [39:45<23:27,  7.95s/it, training_loss=0.001]\u001b[A\n",
            "Epoch 5:  64%|██████▎   | 308/484 [39:45<21:59,  7.50s/it, training_loss=0.001]\u001b[A\n",
            "Epoch 5:  64%|██████▎   | 308/484 [39:53<21:59,  7.50s/it, training_loss=0.001]\u001b[A\n",
            "Epoch 5:  64%|██████▍   | 309/484 [39:53<22:35,  7.75s/it, training_loss=0.001]\u001b[A\n",
            "Epoch 5:  64%|██████▍   | 309/484 [40:00<22:35,  7.75s/it, training_loss=0.023]\u001b[A\n",
            "Epoch 5:  64%|██████▍   | 310/484 [40:00<21:58,  7.58s/it, training_loss=0.023]\u001b[A\n",
            "Epoch 5:  64%|██████▍   | 310/484 [40:07<21:58,  7.58s/it, training_loss=0.001]\u001b[A\n",
            "Epoch 5:  64%|██████▍   | 311/484 [40:07<21:25,  7.43s/it, training_loss=0.001]\u001b[A\n",
            "Epoch 5:  64%|██████▍   | 311/484 [40:16<21:25,  7.43s/it, training_loss=0.153]\u001b[A\n",
            "Epoch 5:  64%|██████▍   | 312/484 [40:16<22:01,  7.68s/it, training_loss=0.153]\u001b[A\n",
            "Epoch 5:  64%|██████▍   | 312/484 [40:22<22:01,  7.68s/it, training_loss=0.001]\u001b[A\n",
            "Epoch 5:  65%|██████▍   | 313/484 [40:22<20:52,  7.33s/it, training_loss=0.001]\u001b[A\n",
            "Epoch 5:  65%|██████▍   | 313/484 [40:31<20:52,  7.33s/it, training_loss=0.002]\u001b[A\n",
            "Epoch 5:  65%|██████▍   | 314/484 [40:31<22:19,  7.88s/it, training_loss=0.002]\u001b[A\n",
            "Epoch 5:  65%|██████▍   | 314/484 [40:38<22:19,  7.88s/it, training_loss=0.260]\u001b[A\n",
            "Epoch 5:  65%|██████▌   | 315/484 [40:38<21:00,  7.46s/it, training_loss=0.260]\u001b[A\n",
            "Epoch 5:  65%|██████▌   | 315/484 [40:47<21:00,  7.46s/it, training_loss=0.001]\u001b[A\n",
            "Epoch 5:  65%|██████▌   | 316/484 [40:47<22:19,  7.97s/it, training_loss=0.001]\u001b[A\n",
            "Epoch 5:  65%|██████▌   | 316/484 [40:53<22:19,  7.97s/it, training_loss=0.011]\u001b[A\n",
            "Epoch 5:  65%|██████▌   | 317/484 [40:54<20:57,  7.53s/it, training_loss=0.011]\u001b[A\n",
            "Epoch 5:  65%|██████▌   | 317/484 [41:02<20:57,  7.53s/it, training_loss=0.006]\u001b[A\n",
            "Epoch 5:  66%|██████▌   | 318/484 [41:02<21:27,  7.76s/it, training_loss=0.006]\u001b[A\n",
            "Epoch 5:  66%|██████▌   | 318/484 [41:09<21:27,  7.76s/it, training_loss=0.001]\u001b[A\n",
            "Epoch 5:  66%|██████▌   | 319/484 [41:09<20:55,  7.61s/it, training_loss=0.001]\u001b[A\n",
            "Epoch 5:  66%|██████▌   | 319/484 [41:16<20:55,  7.61s/it, training_loss=0.001]\u001b[A\n",
            "Epoch 5:  66%|██████▌   | 320/484 [41:16<20:16,  7.42s/it, training_loss=0.001]\u001b[A\n",
            "Epoch 5:  66%|██████▌   | 320/484 [41:24<20:16,  7.42s/it, training_loss=0.001]\u001b[A\n",
            "Epoch 5:  66%|██████▋   | 321/484 [41:24<20:57,  7.72s/it, training_loss=0.001]\u001b[A\n",
            "Epoch 5:  66%|██████▋   | 321/484 [41:31<20:57,  7.72s/it, training_loss=0.004]\u001b[A\n",
            "Epoch 5:  67%|██████▋   | 322/484 [41:31<19:49,  7.34s/it, training_loss=0.004]\u001b[A\n",
            "Epoch 5:  67%|██████▋   | 322/484 [41:40<19:49,  7.34s/it, training_loss=0.001]\u001b[A\n",
            "Epoch 5:  67%|██████▋   | 323/484 [41:40<21:08,  7.88s/it, training_loss=0.001]\u001b[A\n",
            "Epoch 5:  67%|██████▋   | 323/484 [41:47<21:08,  7.88s/it, training_loss=0.002]\u001b[A\n",
            "Epoch 5:  67%|██████▋   | 324/484 [41:47<19:55,  7.47s/it, training_loss=0.002]\u001b[A\n",
            "Epoch 5:  67%|██████▋   | 324/484 [41:56<19:55,  7.47s/it, training_loss=0.001]\u001b[A\n",
            "Epoch 5:  67%|██████▋   | 325/484 [41:56<21:18,  8.04s/it, training_loss=0.001]\u001b[A\n",
            "Epoch 5:  67%|██████▋   | 325/484 [42:02<21:18,  8.04s/it, training_loss=0.001]\u001b[A\n",
            "Epoch 5:  67%|██████▋   | 326/484 [42:02<19:57,  7.58s/it, training_loss=0.001]\u001b[A\n",
            "Epoch 5:  67%|██████▋   | 326/484 [42:11<19:57,  7.58s/it, training_loss=0.001]\u001b[A\n",
            "Epoch 5:  68%|██████▊   | 327/484 [42:11<20:17,  7.76s/it, training_loss=0.001]\u001b[A\n",
            "Epoch 5:  68%|██████▊   | 327/484 [42:18<20:17,  7.76s/it, training_loss=0.000]\u001b[A\n",
            "Epoch 5:  68%|██████▊   | 328/484 [42:18<19:54,  7.65s/it, training_loss=0.000]\u001b[A\n",
            "Epoch 5:  68%|██████▊   | 328/484 [42:25<19:54,  7.65s/it, training_loss=0.008]\u001b[A\n",
            "Epoch 5:  68%|██████▊   | 329/484 [42:25<19:17,  7.47s/it, training_loss=0.008]\u001b[A\n",
            "Epoch 5:  68%|██████▊   | 329/484 [42:33<19:17,  7.47s/it, training_loss=0.150]\u001b[A\n",
            "Epoch 5:  68%|██████▊   | 330/484 [42:33<19:53,  7.75s/it, training_loss=0.150]\u001b[A\n",
            "Epoch 5:  68%|██████▊   | 330/484 [42:40<19:53,  7.75s/it, training_loss=0.002]\u001b[A\n",
            "Epoch 5:  68%|██████▊   | 331/484 [42:40<18:51,  7.40s/it, training_loss=0.002]\u001b[A\n",
            "Epoch 5:  68%|██████▊   | 331/484 [42:49<18:51,  7.40s/it, training_loss=0.001]\u001b[A\n",
            "Epoch 5:  69%|██████▊   | 332/484 [42:49<20:10,  7.96s/it, training_loss=0.001]\u001b[A\n",
            "Epoch 5:  69%|██████▊   | 332/484 [42:56<20:10,  7.96s/it, training_loss=0.004]\u001b[A\n",
            "Epoch 5:  69%|██████▉   | 333/484 [42:56<18:57,  7.54s/it, training_loss=0.004]\u001b[A\n",
            "Epoch 5:  69%|██████▉   | 333/484 [43:05<18:57,  7.54s/it, training_loss=0.017]\u001b[A\n",
            "Epoch 5:  69%|██████▉   | 334/484 [43:05<20:03,  8.03s/it, training_loss=0.017]\u001b[A\n",
            "Epoch 5:  69%|██████▉   | 334/484 [43:11<20:03,  8.03s/it, training_loss=0.001]\u001b[A\n",
            "Epoch 5:  69%|██████▉   | 335/484 [43:12<18:46,  7.56s/it, training_loss=0.001]\u001b[A\n",
            "Epoch 5:  69%|██████▉   | 335/484 [43:20<18:46,  7.56s/it, training_loss=0.002]\u001b[A\n",
            "Epoch 5:  69%|██████▉   | 336/484 [43:20<19:15,  7.80s/it, training_loss=0.002]\u001b[A\n",
            "Epoch 5:  69%|██████▉   | 336/484 [43:27<19:15,  7.80s/it, training_loss=0.001]\u001b[A\n",
            "Epoch 5:  70%|██████▉   | 337/484 [43:27<18:45,  7.65s/it, training_loss=0.001]\u001b[A\n",
            "Epoch 5:  70%|██████▉   | 337/484 [43:34<18:45,  7.65s/it, training_loss=0.001]\u001b[A\n",
            "Epoch 5:  70%|██████▉   | 338/484 [43:34<18:15,  7.51s/it, training_loss=0.001]\u001b[A\n",
            "Epoch 5:  70%|██████▉   | 338/484 [43:43<18:15,  7.51s/it, training_loss=0.001]\u001b[A\n",
            "Epoch 5:  70%|███████   | 339/484 [43:43<18:40,  7.73s/it, training_loss=0.001]\u001b[A\n",
            "Epoch 5:  70%|███████   | 339/484 [43:49<18:40,  7.73s/it, training_loss=0.003]\u001b[A\n",
            "Epoch 5:  70%|███████   | 340/484 [43:49<17:39,  7.36s/it, training_loss=0.003]\u001b[A\n",
            "Epoch 5:  70%|███████   | 340/484 [43:58<17:39,  7.36s/it, training_loss=0.001]\u001b[A\n",
            "Epoch 5:  70%|███████   | 341/484 [43:58<18:50,  7.91s/it, training_loss=0.001]\u001b[A\n",
            "Epoch 5:  70%|███████   | 341/484 [44:05<18:50,  7.91s/it, training_loss=0.001]\u001b[A\n",
            "Epoch 5:  71%|███████   | 342/484 [44:05<17:45,  7.50s/it, training_loss=0.001]\u001b[A\n",
            "Epoch 5:  71%|███████   | 342/484 [44:14<17:45,  7.50s/it, training_loss=0.010]\u001b[A\n",
            "Epoch 5:  71%|███████   | 343/484 [44:14<18:46,  7.99s/it, training_loss=0.010]\u001b[A\n",
            "Epoch 5:  71%|███████   | 343/484 [44:20<18:46,  7.99s/it, training_loss=0.001]\u001b[A\n",
            "Epoch 5:  71%|███████   | 344/484 [44:20<17:35,  7.54s/it, training_loss=0.001]\u001b[A\n",
            "Epoch 5:  71%|███████   | 344/484 [44:29<17:35,  7.54s/it, training_loss=0.008]\u001b[A\n",
            "Epoch 5:  71%|███████▏  | 345/484 [44:29<18:05,  7.81s/it, training_loss=0.008]\u001b[A\n",
            "Epoch 5:  71%|███████▏  | 345/484 [44:36<18:05,  7.81s/it, training_loss=0.001]\u001b[A\n",
            "Epoch 5:  71%|███████▏  | 346/484 [44:36<17:33,  7.63s/it, training_loss=0.001]\u001b[A\n",
            "Epoch 5:  71%|███████▏  | 346/484 [44:43<17:33,  7.63s/it, training_loss=0.001]\u001b[A\n",
            "Epoch 5:  72%|███████▏  | 347/484 [44:43<17:09,  7.52s/it, training_loss=0.001]\u001b[A\n",
            "Epoch 5:  72%|███████▏  | 347/484 [44:52<17:09,  7.52s/it, training_loss=0.001]\u001b[A\n",
            "Epoch 5:  72%|███████▏  | 348/484 [44:52<17:31,  7.73s/it, training_loss=0.001]\u001b[A\n",
            "Epoch 5:  72%|███████▏  | 348/484 [44:58<17:31,  7.73s/it, training_loss=0.001]\u001b[A\n",
            "Epoch 5:  72%|███████▏  | 349/484 [44:58<16:34,  7.37s/it, training_loss=0.001]\u001b[A\n",
            "Epoch 5:  72%|███████▏  | 349/484 [45:07<16:34,  7.37s/it, training_loss=0.004]\u001b[A\n",
            "Epoch 5:  72%|███████▏  | 350/484 [45:07<17:40,  7.91s/it, training_loss=0.004]\u001b[A\n",
            "Epoch 5:  72%|███████▏  | 350/484 [45:14<17:40,  7.91s/it, training_loss=0.253]\u001b[A\n",
            "Epoch 5:  73%|███████▎  | 351/484 [45:14<16:36,  7.49s/it, training_loss=0.253]\u001b[A\n",
            "Epoch 5:  73%|███████▎  | 351/484 [45:23<16:36,  7.49s/it, training_loss=0.001]\u001b[A\n",
            "Epoch 5:  73%|███████▎  | 352/484 [45:23<17:34,  7.99s/it, training_loss=0.001]\u001b[A\n",
            "Epoch 5:  73%|███████▎  | 352/484 [45:29<17:34,  7.99s/it, training_loss=0.002]\u001b[A\n",
            "Epoch 5:  73%|███████▎  | 353/484 [45:29<16:28,  7.54s/it, training_loss=0.002]\u001b[A\n",
            "Epoch 5:  73%|███████▎  | 353/484 [45:38<16:28,  7.54s/it, training_loss=0.001]\u001b[A\n",
            "Epoch 5:  73%|███████▎  | 354/484 [45:38<16:53,  7.80s/it, training_loss=0.001]\u001b[A\n",
            "Epoch 5:  73%|███████▎  | 354/484 [45:45<16:53,  7.80s/it, training_loss=0.001]\u001b[A\n",
            "Epoch 5:  73%|███████▎  | 355/484 [45:45<16:23,  7.62s/it, training_loss=0.001]\u001b[A\n",
            "Epoch 5:  73%|███████▎  | 355/484 [45:52<16:23,  7.62s/it, training_loss=0.006]\u001b[A\n",
            "Epoch 5:  74%|███████▎  | 356/484 [45:52<15:59,  7.50s/it, training_loss=0.006]\u001b[A\n",
            "Epoch 5:  74%|███████▎  | 356/484 [46:00<15:59,  7.50s/it, training_loss=0.001]\u001b[A\n",
            "Epoch 5:  74%|███████▍  | 357/484 [46:00<16:19,  7.71s/it, training_loss=0.001]\u001b[A\n",
            "Epoch 5:  74%|███████▍  | 357/484 [46:07<16:19,  7.71s/it, training_loss=0.001]\u001b[A\n",
            "Epoch 5:  74%|███████▍  | 358/484 [46:08<15:45,  7.51s/it, training_loss=0.001]\u001b[A\n",
            "Epoch 5:  74%|███████▍  | 358/484 [46:17<15:45,  7.51s/it, training_loss=0.001]\u001b[A\n",
            "Epoch 5:  74%|███████▍  | 359/484 [46:17<16:35,  7.96s/it, training_loss=0.001]\u001b[A\n",
            "Epoch 5:  74%|███████▍  | 359/484 [46:23<16:35,  7.96s/it, training_loss=0.001]\u001b[A\n",
            "Epoch 5:  74%|███████▍  | 360/484 [46:23<15:35,  7.54s/it, training_loss=0.001]\u001b[A\n",
            "Epoch 5:  74%|███████▍  | 360/484 [46:32<15:35,  7.54s/it, training_loss=0.012]\u001b[A\n",
            "Epoch 5:  75%|███████▍  | 361/484 [46:32<16:26,  8.02s/it, training_loss=0.012]\u001b[A\n",
            "Epoch 5:  75%|███████▍  | 361/484 [46:39<16:26,  8.02s/it, training_loss=0.173]\u001b[A\n",
            "Epoch 5:  75%|███████▍  | 362/484 [46:39<15:24,  7.58s/it, training_loss=0.173]\u001b[A\n",
            "Epoch 5:  75%|███████▍  | 362/484 [46:47<15:24,  7.58s/it, training_loss=0.001]\u001b[A\n",
            "Epoch 5:  75%|███████▌  | 363/484 [46:47<15:58,  7.92s/it, training_loss=0.001]\u001b[A\n",
            "Epoch 5:  75%|███████▌  | 363/484 [46:54<15:58,  7.92s/it, training_loss=0.001]\u001b[A\n",
            "Epoch 5:  75%|███████▌  | 364/484 [46:54<15:15,  7.63s/it, training_loss=0.001]\u001b[A\n",
            "Epoch 5:  75%|███████▌  | 364/484 [47:02<15:15,  7.63s/it, training_loss=0.001]\u001b[A\n",
            "Epoch 5:  75%|███████▌  | 365/484 [47:02<15:08,  7.64s/it, training_loss=0.001]\u001b[A\n",
            "Epoch 5:  75%|███████▌  | 365/484 [47:10<15:08,  7.64s/it, training_loss=0.001]\u001b[A\n",
            "Epoch 5:  76%|███████▌  | 366/484 [47:10<15:12,  7.74s/it, training_loss=0.001]\u001b[A\n",
            "Epoch 5:  76%|███████▌  | 366/484 [47:17<15:12,  7.74s/it, training_loss=0.003]\u001b[A\n",
            "Epoch 5:  76%|███████▌  | 367/484 [47:17<14:29,  7.43s/it, training_loss=0.003]\u001b[A\n",
            "Epoch 5:  76%|███████▌  | 367/484 [47:26<14:29,  7.43s/it, training_loss=0.019]\u001b[A\n",
            "Epoch 5:  76%|███████▌  | 368/484 [47:26<15:14,  7.88s/it, training_loss=0.019]\u001b[A\n",
            "Epoch 5:  76%|███████▌  | 368/484 [47:32<15:14,  7.88s/it, training_loss=0.168]\u001b[A\n",
            "Epoch 5:  76%|███████▌  | 369/484 [47:32<14:19,  7.47s/it, training_loss=0.168]\u001b[A\n",
            "Epoch 5:  76%|███████▌  | 369/484 [47:41<14:19,  7.47s/it, training_loss=0.003]\u001b[A\n",
            "Epoch 5:  76%|███████▋  | 370/484 [47:41<15:11,  7.99s/it, training_loss=0.003]\u001b[A\n",
            "Epoch 5:  76%|███████▋  | 370/484 [47:48<15:11,  7.99s/it, training_loss=0.002]\u001b[A\n",
            "Epoch 5:  77%|███████▋  | 371/484 [47:48<14:15,  7.57s/it, training_loss=0.002]\u001b[A\n",
            "Epoch 5:  77%|███████▋  | 371/484 [47:57<14:15,  7.57s/it, training_loss=0.001]\u001b[A\n",
            "Epoch 5:  77%|███████▋  | 372/484 [47:57<14:47,  7.92s/it, training_loss=0.001]\u001b[A\n",
            "Epoch 5:  77%|███████▋  | 372/484 [48:04<14:47,  7.92s/it, training_loss=0.002]\u001b[A\n",
            "Epoch 5:  77%|███████▋  | 373/484 [48:04<14:05,  7.62s/it, training_loss=0.002]\u001b[A\n",
            "Epoch 5:  77%|███████▋  | 373/484 [48:11<14:05,  7.62s/it, training_loss=0.066]\u001b[A\n",
            "Epoch 5:  77%|███████▋  | 374/484 [48:11<14:01,  7.65s/it, training_loss=0.066]\u001b[A\n",
            "Epoch 5:  77%|███████▋  | 374/484 [48:19<14:01,  7.65s/it, training_loss=0.283]\u001b[A\n",
            "Epoch 5:  77%|███████▋  | 375/484 [48:19<13:57,  7.68s/it, training_loss=0.283]\u001b[A\n",
            "Epoch 5:  77%|███████▋  | 375/484 [48:26<13:57,  7.68s/it, training_loss=0.267]\u001b[A\n",
            "Epoch 5:  78%|███████▊  | 376/484 [48:26<13:15,  7.37s/it, training_loss=0.267]\u001b[A\n",
            "Epoch 5:  78%|███████▊  | 376/484 [48:35<13:15,  7.37s/it, training_loss=0.001]\u001b[A\n",
            "Epoch 5:  78%|███████▊  | 377/484 [48:35<13:57,  7.83s/it, training_loss=0.001]\u001b[A\n",
            "Epoch 5:  78%|███████▊  | 377/484 [48:41<13:57,  7.83s/it, training_loss=0.001]\u001b[A\n",
            "Epoch 5:  78%|███████▊  | 378/484 [48:41<13:12,  7.47s/it, training_loss=0.001]\u001b[A\n",
            "Epoch 5:  78%|███████▊  | 378/484 [48:51<13:12,  7.47s/it, training_loss=0.001]\u001b[A\n",
            "Epoch 5:  78%|███████▊  | 379/484 [48:51<14:01,  8.01s/it, training_loss=0.001]\u001b[A\n",
            "Epoch 5:  78%|███████▊  | 379/484 [48:57<14:01,  8.01s/it, training_loss=0.002]\u001b[A\n",
            "Epoch 5:  79%|███████▊  | 380/484 [48:57<13:07,  7.57s/it, training_loss=0.002]\u001b[A\n",
            "Epoch 5:  79%|███████▊  | 380/484 [49:06<13:07,  7.57s/it, training_loss=0.001]\u001b[A\n",
            "Epoch 5:  79%|███████▊  | 381/484 [49:06<13:41,  7.98s/it, training_loss=0.001]\u001b[A\n",
            "Epoch 5:  79%|███████▊  | 381/484 [49:13<13:41,  7.98s/it, training_loss=0.076]\u001b[A\n",
            "Epoch 5:  79%|███████▉  | 382/484 [49:13<12:55,  7.60s/it, training_loss=0.076]\u001b[A\n",
            "Epoch 5:  79%|███████▉  | 382/484 [49:21<12:55,  7.60s/it, training_loss=0.000]\u001b[A\n",
            "Epoch 5:  79%|███████▉  | 383/484 [49:21<12:57,  7.69s/it, training_loss=0.000]\u001b[A\n",
            "Epoch 5:  79%|███████▉  | 383/484 [49:28<12:57,  7.69s/it, training_loss=0.001]\u001b[A\n",
            "Epoch 5:  79%|███████▉  | 384/484 [49:28<12:47,  7.68s/it, training_loss=0.001]\u001b[A\n",
            "Epoch 5:  79%|███████▉  | 384/484 [49:35<12:47,  7.68s/it, training_loss=0.020]\u001b[A\n",
            "Epoch 5:  80%|███████▉  | 385/484 [49:35<12:10,  7.38s/it, training_loss=0.020]\u001b[A\n",
            "Epoch 5:  80%|███████▉  | 385/484 [49:44<12:10,  7.38s/it, training_loss=0.001]\u001b[A\n",
            "Epoch 5:  80%|███████▉  | 386/484 [49:44<12:44,  7.80s/it, training_loss=0.001]\u001b[A\n",
            "Epoch 5:  80%|███████▉  | 386/484 [49:50<12:44,  7.80s/it, training_loss=0.001]\u001b[A\n",
            "Epoch 5:  80%|███████▉  | 387/484 [49:50<11:59,  7.42s/it, training_loss=0.001]\u001b[A\n",
            "Epoch 5:  80%|███████▉  | 387/484 [50:00<11:59,  7.42s/it, training_loss=0.090]\u001b[A\n",
            "Epoch 5:  80%|████████  | 388/484 [50:00<12:42,  7.95s/it, training_loss=0.090]\u001b[A\n",
            "Epoch 5:  80%|████████  | 388/484 [50:06<12:42,  7.95s/it, training_loss=0.001]\u001b[A\n",
            "Epoch 5:  80%|████████  | 389/484 [50:06<11:53,  7.51s/it, training_loss=0.001]\u001b[A\n",
            "Epoch 5:  80%|████████  | 389/484 [50:15<11:53,  7.51s/it, training_loss=0.001]\u001b[A\n",
            "Epoch 5:  81%|████████  | 390/484 [50:15<12:22,  7.89s/it, training_loss=0.001]\u001b[A\n",
            "Epoch 5:  81%|████████  | 390/484 [50:22<12:22,  7.89s/it, training_loss=0.003]\u001b[A\n",
            "Epoch 5:  81%|████████  | 391/484 [50:22<11:44,  7.58s/it, training_loss=0.003]\u001b[A\n",
            "Epoch 5:  81%|████████  | 391/484 [50:29<11:44,  7.58s/it, training_loss=0.009]\u001b[A\n",
            "Epoch 5:  81%|████████  | 392/484 [50:29<11:43,  7.65s/it, training_loss=0.009]\u001b[A\n",
            "Epoch 5:  81%|████████  | 392/484 [50:37<11:43,  7.65s/it, training_loss=0.001]\u001b[A\n",
            "Epoch 5:  81%|████████  | 393/484 [50:37<11:39,  7.68s/it, training_loss=0.001]\u001b[A\n",
            "Epoch 5:  81%|████████  | 393/484 [50:44<11:39,  7.68s/it, training_loss=0.001]\u001b[A\n",
            "Epoch 5:  81%|████████▏ | 394/484 [50:44<11:05,  7.39s/it, training_loss=0.001]\u001b[A\n",
            "Epoch 5:  81%|████████▏ | 394/484 [50:53<11:05,  7.39s/it, training_loss=0.001]\u001b[A\n",
            "Epoch 5:  82%|████████▏ | 395/484 [50:53<11:35,  7.82s/it, training_loss=0.001]\u001b[A\n",
            "Epoch 5:  82%|████████▏ | 395/484 [50:59<11:35,  7.82s/it, training_loss=0.002]\u001b[A\n",
            "Epoch 5:  82%|████████▏ | 396/484 [50:59<10:55,  7.45s/it, training_loss=0.002]\u001b[A\n",
            "Epoch 5:  82%|████████▏ | 396/484 [51:09<10:55,  7.45s/it, training_loss=0.021]\u001b[A\n",
            "Epoch 5:  82%|████████▏ | 397/484 [51:09<11:34,  7.98s/it, training_loss=0.021]\u001b[A\n",
            "Epoch 5:  82%|████████▏ | 397/484 [51:15<11:34,  7.98s/it, training_loss=0.001]\u001b[A\n",
            "Epoch 5:  82%|████████▏ | 398/484 [51:15<10:48,  7.54s/it, training_loss=0.001]\u001b[A\n",
            "Epoch 5:  82%|████████▏ | 398/484 [51:24<10:48,  7.54s/it, training_loss=0.001]\u001b[A\n",
            "Epoch 5:  82%|████████▏ | 399/484 [51:24<11:16,  7.96s/it, training_loss=0.001]\u001b[A\n",
            "Epoch 5:  82%|████████▏ | 399/484 [51:31<11:16,  7.96s/it, training_loss=0.157]\u001b[A\n",
            "Epoch 5:  83%|████████▎ | 400/484 [51:31<10:35,  7.57s/it, training_loss=0.157]\u001b[A\n",
            "Epoch 5:  83%|████████▎ | 400/484 [51:39<10:35,  7.57s/it, training_loss=0.001]\u001b[A\n",
            "Epoch 5:  83%|████████▎ | 401/484 [51:39<10:35,  7.66s/it, training_loss=0.001]\u001b[A\n",
            "Epoch 5:  83%|████████▎ | 401/484 [51:46<10:35,  7.66s/it, training_loss=0.002]\u001b[A\n",
            "Epoch 5:  83%|████████▎ | 402/484 [51:46<10:26,  7.65s/it, training_loss=0.002]\u001b[A\n",
            "Epoch 5:  83%|████████▎ | 402/484 [51:53<10:26,  7.65s/it, training_loss=0.122]\u001b[A\n",
            "Epoch 5:  83%|████████▎ | 403/484 [51:53<09:55,  7.36s/it, training_loss=0.122]\u001b[A\n",
            "Epoch 5:  83%|████████▎ | 403/484 [52:02<09:55,  7.36s/it, training_loss=0.001]\u001b[A\n",
            "Epoch 5:  83%|████████▎ | 404/484 [52:02<10:22,  7.78s/it, training_loss=0.001]\u001b[A\n",
            "Epoch 5:  83%|████████▎ | 404/484 [52:08<10:22,  7.78s/it, training_loss=0.001]\u001b[A\n",
            "Epoch 5:  84%|████████▎ | 405/484 [52:08<09:45,  7.41s/it, training_loss=0.001]\u001b[A\n",
            "Epoch 5:  84%|████████▎ | 405/484 [52:17<09:45,  7.41s/it, training_loss=0.003]\u001b[A\n",
            "Epoch 5:  84%|████████▍ | 406/484 [52:17<10:23,  7.99s/it, training_loss=0.003]\u001b[A\n",
            "Epoch 5:  84%|████████▍ | 406/484 [52:24<10:23,  7.99s/it, training_loss=0.001]\u001b[A\n",
            "Epoch 5:  84%|████████▍ | 407/484 [52:24<09:40,  7.54s/it, training_loss=0.001]\u001b[A\n",
            "Epoch 5:  84%|████████▍ | 407/484 [52:33<09:40,  7.54s/it, training_loss=0.001]\u001b[A\n",
            "Epoch 5:  84%|████████▍ | 408/484 [52:33<10:01,  7.91s/it, training_loss=0.001]\u001b[A\n",
            "Epoch 5:  84%|████████▍ | 408/484 [52:40<10:01,  7.91s/it, training_loss=0.001]\u001b[A\n",
            "Epoch 5:  85%|████████▍ | 409/484 [52:40<09:29,  7.59s/it, training_loss=0.001]\u001b[A\n",
            "Epoch 5:  85%|████████▍ | 409/484 [52:47<09:29,  7.59s/it, training_loss=0.010]\u001b[A\n",
            "Epoch 5:  85%|████████▍ | 410/484 [52:47<09:25,  7.65s/it, training_loss=0.010]\u001b[A\n",
            "Epoch 5:  85%|████████▍ | 410/484 [52:55<09:25,  7.65s/it, training_loss=0.001]\u001b[A\n",
            "Epoch 5:  85%|████████▍ | 411/484 [52:55<09:21,  7.69s/it, training_loss=0.001]\u001b[A\n",
            "Epoch 5:  85%|████████▍ | 411/484 [53:02<09:21,  7.69s/it, training_loss=0.001]\u001b[A\n",
            "Epoch 5:  85%|████████▌ | 412/484 [53:02<08:52,  7.40s/it, training_loss=0.001]\u001b[A\n",
            "Epoch 5:  85%|████████▌ | 412/484 [53:11<08:52,  7.40s/it, training_loss=0.227]\u001b[A\n",
            "Epoch 5:  85%|████████▌ | 413/484 [53:11<09:14,  7.81s/it, training_loss=0.227]\u001b[A\n",
            "Epoch 5:  85%|████████▌ | 413/484 [53:17<09:14,  7.81s/it, training_loss=0.001]\u001b[A\n",
            "Epoch 5:  86%|████████▌ | 414/484 [53:17<08:40,  7.44s/it, training_loss=0.001]\u001b[A\n",
            "Epoch 5:  86%|████████▌ | 414/484 [53:26<08:40,  7.44s/it, training_loss=0.001]\u001b[A\n",
            "Epoch 5:  86%|████████▌ | 415/484 [53:26<09:10,  7.97s/it, training_loss=0.001]\u001b[A\n",
            "Epoch 5:  86%|████████▌ | 415/484 [53:33<09:10,  7.97s/it, training_loss=0.006]\u001b[A\n",
            "Epoch 5:  86%|████████▌ | 416/484 [53:33<08:32,  7.54s/it, training_loss=0.006]\u001b[A\n",
            "Epoch 5:  86%|████████▌ | 416/484 [53:42<08:32,  7.54s/it, training_loss=0.074]\u001b[A\n",
            "Epoch 5:  86%|████████▌ | 417/484 [53:42<08:49,  7.90s/it, training_loss=0.074]\u001b[A\n",
            "Epoch 5:  86%|████████▌ | 417/484 [53:49<08:49,  7.90s/it, training_loss=0.001]\u001b[A\n",
            "Epoch 5:  86%|████████▋ | 418/484 [53:49<08:19,  7.57s/it, training_loss=0.001]\u001b[A\n",
            "Epoch 5:  86%|████████▋ | 418/484 [53:56<08:19,  7.57s/it, training_loss=0.001]\u001b[A\n",
            "Epoch 5:  87%|████████▋ | 419/484 [53:56<08:15,  7.63s/it, training_loss=0.001]\u001b[A\n",
            "Epoch 5:  87%|████████▋ | 419/484 [54:04<08:15,  7.63s/it, training_loss=0.128]\u001b[A\n",
            "Epoch 5:  87%|████████▋ | 420/484 [54:04<08:10,  7.67s/it, training_loss=0.128]\u001b[A\n",
            "Epoch 5:  87%|████████▋ | 420/484 [54:11<08:10,  7.67s/it, training_loss=0.001]\u001b[A\n",
            "Epoch 5:  87%|████████▋ | 421/484 [54:11<07:43,  7.35s/it, training_loss=0.001]\u001b[A\n",
            "Epoch 5:  87%|████████▋ | 421/484 [54:20<07:43,  7.35s/it, training_loss=0.001]\u001b[A\n",
            "Epoch 5:  87%|████████▋ | 422/484 [54:20<08:03,  7.80s/it, training_loss=0.001]\u001b[A\n",
            "Epoch 5:  87%|████████▋ | 422/484 [54:26<08:03,  7.80s/it, training_loss=0.001]\u001b[A\n",
            "Epoch 5:  87%|████████▋ | 423/484 [54:26<07:32,  7.42s/it, training_loss=0.001]\u001b[A\n",
            "Epoch 5:  87%|████████▋ | 423/484 [54:35<07:32,  7.42s/it, training_loss=0.021]\u001b[A\n",
            "Epoch 5:  88%|████████▊ | 424/484 [54:35<07:56,  7.94s/it, training_loss=0.021]\u001b[A\n",
            "Epoch 5:  88%|████████▊ | 424/484 [54:42<07:56,  7.94s/it, training_loss=0.001]\u001b[A\n",
            "Epoch 5:  88%|████████▊ | 425/484 [54:42<07:23,  7.51s/it, training_loss=0.001]\u001b[A\n",
            "Epoch 5:  88%|████████▊ | 425/484 [54:50<07:23,  7.51s/it, training_loss=0.001]\u001b[A\n",
            "Epoch 5:  88%|████████▊ | 426/484 [54:50<07:37,  7.89s/it, training_loss=0.001]\u001b[A\n",
            "Epoch 5:  88%|████████▊ | 426/484 [54:57<07:37,  7.89s/it, training_loss=0.001]\u001b[A\n",
            "Epoch 5:  88%|████████▊ | 427/484 [54:57<07:13,  7.60s/it, training_loss=0.001]\u001b[A\n",
            "Epoch 5:  88%|████████▊ | 427/484 [55:05<07:13,  7.60s/it, training_loss=0.161]\u001b[A\n",
            "Epoch 5:  88%|████████▊ | 428/484 [55:05<07:06,  7.62s/it, training_loss=0.161]\u001b[A\n",
            "Epoch 5:  88%|████████▊ | 428/484 [55:13<07:06,  7.62s/it, training_loss=0.006]\u001b[A\n",
            "Epoch 5:  89%|████████▊ | 429/484 [55:13<07:01,  7.66s/it, training_loss=0.006]\u001b[A\n",
            "Epoch 5:  89%|████████▊ | 429/484 [55:19<07:01,  7.66s/it, training_loss=0.004]\u001b[A\n",
            "Epoch 5:  89%|████████▉ | 430/484 [55:19<06:37,  7.36s/it, training_loss=0.004]\u001b[A\n",
            "Epoch 5:  89%|████████▉ | 430/484 [55:28<06:37,  7.36s/it, training_loss=0.001]\u001b[A\n",
            "Epoch 5:  89%|████████▉ | 431/484 [55:28<06:54,  7.82s/it, training_loss=0.001]\u001b[A\n",
            "Epoch 5:  89%|████████▉ | 431/484 [55:35<06:54,  7.82s/it, training_loss=0.001]\u001b[A\n",
            "Epoch 5:  89%|████████▉ | 432/484 [55:35<06:25,  7.42s/it, training_loss=0.001]\u001b[A\n",
            "Epoch 5:  89%|████████▉ | 432/484 [55:44<06:25,  7.42s/it, training_loss=0.006]\u001b[A\n",
            "Epoch 5:  89%|████████▉ | 433/484 [55:44<06:45,  7.95s/it, training_loss=0.006]\u001b[A\n",
            "Epoch 5:  89%|████████▉ | 433/484 [55:51<06:45,  7.95s/it, training_loss=0.001]\u001b[A\n",
            "Epoch 5:  90%|████████▉ | 434/484 [55:51<06:15,  7.52s/it, training_loss=0.001]\u001b[A\n",
            "Epoch 5:  90%|████████▉ | 434/484 [55:59<06:15,  7.52s/it, training_loss=0.047]\u001b[A\n",
            "Epoch 5:  90%|████████▉ | 435/484 [55:59<06:25,  7.88s/it, training_loss=0.047]\u001b[A\n",
            "Epoch 5:  90%|████████▉ | 435/484 [56:06<06:25,  7.88s/it, training_loss=0.001]\u001b[A\n",
            "Epoch 5:  90%|█████████ | 436/484 [56:06<06:03,  7.58s/it, training_loss=0.001]\u001b[A\n",
            "Epoch 5:  90%|█████████ | 436/484 [56:14<06:03,  7.58s/it, training_loss=0.001]\u001b[A\n",
            "Epoch 5:  90%|█████████ | 437/484 [56:14<05:55,  7.57s/it, training_loss=0.001]\u001b[A\n",
            "Epoch 5:  90%|█████████ | 437/484 [56:22<05:55,  7.57s/it, training_loss=0.001]\u001b[A\n",
            "Epoch 5:  90%|█████████ | 438/484 [56:22<05:52,  7.66s/it, training_loss=0.001]\u001b[A\n",
            "Epoch 5:  90%|█████████ | 438/484 [56:28<05:52,  7.66s/it, training_loss=0.001]\u001b[A\n",
            "Epoch 5:  91%|█████████ | 439/484 [56:28<05:30,  7.35s/it, training_loss=0.001]\u001b[A\n",
            "Epoch 5:  91%|█████████ | 439/484 [56:37<05:30,  7.35s/it, training_loss=0.002]\u001b[A\n",
            "Epoch 5:  91%|█████████ | 440/484 [56:37<05:45,  7.86s/it, training_loss=0.002]\u001b[A\n",
            "Epoch 5:  91%|█████████ | 440/484 [56:44<05:45,  7.86s/it, training_loss=0.058]\u001b[A\n",
            "Epoch 5:  91%|█████████ | 441/484 [56:44<05:21,  7.48s/it, training_loss=0.058]\u001b[A\n",
            "Epoch 5:  91%|█████████ | 441/484 [56:53<05:21,  7.48s/it, training_loss=0.001]\u001b[A\n",
            "Epoch 5:  91%|█████████▏| 442/484 [56:53<05:36,  8.01s/it, training_loss=0.001]\u001b[A\n",
            "Epoch 5:  91%|█████████▏| 442/484 [57:00<05:36,  8.01s/it, training_loss=0.001]\u001b[A\n",
            "Epoch 5:  92%|█████████▏| 443/484 [57:00<05:11,  7.59s/it, training_loss=0.001]\u001b[A\n",
            "Epoch 5:  92%|█████████▏| 443/484 [57:09<05:11,  7.59s/it, training_loss=0.001]\u001b[A\n",
            "Epoch 5:  92%|█████████▏| 444/484 [57:09<05:18,  7.96s/it, training_loss=0.001]\u001b[A\n",
            "Epoch 5:  92%|█████████▏| 444/484 [57:15<05:18,  7.96s/it, training_loss=0.013]\u001b[A\n",
            "Epoch 5:  92%|█████████▏| 445/484 [57:15<04:57,  7.64s/it, training_loss=0.013]\u001b[A\n",
            "Epoch 5:  92%|█████████▏| 445/484 [57:23<04:57,  7.64s/it, training_loss=0.148]\u001b[A\n",
            "Epoch 5:  92%|█████████▏| 446/484 [57:23<04:52,  7.70s/it, training_loss=0.148]\u001b[A\n",
            "Epoch 5:  92%|█████████▏| 446/484 [57:31<04:52,  7.70s/it, training_loss=0.003]\u001b[A\n",
            "Epoch 5:  92%|█████████▏| 447/484 [57:31<04:46,  7.74s/it, training_loss=0.003]\u001b[A\n",
            "Epoch 5:  92%|█████████▏| 447/484 [57:38<04:46,  7.74s/it, training_loss=0.001]\u001b[A\n",
            "Epoch 5:  93%|█████████▎| 448/484 [57:38<04:26,  7.41s/it, training_loss=0.001]\u001b[A\n",
            "Epoch 5:  93%|█████████▎| 448/484 [57:47<04:26,  7.41s/it, training_loss=0.001]\u001b[A\n",
            "Epoch 5:  93%|█████████▎| 449/484 [57:47<04:34,  7.83s/it, training_loss=0.001]\u001b[A\n",
            "Epoch 5:  93%|█████████▎| 449/484 [57:53<04:34,  7.83s/it, training_loss=0.141]\u001b[A\n",
            "Epoch 5:  93%|█████████▎| 450/484 [57:53<04:12,  7.43s/it, training_loss=0.141]\u001b[A\n",
            "Epoch 5:  93%|█████████▎| 450/484 [58:02<04:12,  7.43s/it, training_loss=0.010]\u001b[A\n",
            "Epoch 5:  93%|█████████▎| 451/484 [58:02<04:23,  7.97s/it, training_loss=0.010]\u001b[A\n",
            "Epoch 5:  93%|█████████▎| 451/484 [58:09<04:23,  7.97s/it, training_loss=0.000]\u001b[A\n",
            "Epoch 5:  93%|█████████▎| 452/484 [58:09<04:00,  7.52s/it, training_loss=0.000]\u001b[A\n",
            "Epoch 5:  93%|█████████▎| 452/484 [58:17<04:00,  7.52s/it, training_loss=0.001]\u001b[A\n",
            "Epoch 5:  94%|█████████▎| 453/484 [58:17<04:04,  7.87s/it, training_loss=0.001]\u001b[A\n",
            "Epoch 5:  94%|█████████▎| 453/484 [58:24<04:04,  7.87s/it, training_loss=0.001]\u001b[A\n",
            "Epoch 5:  94%|█████████▍| 454/484 [58:24<03:47,  7.59s/it, training_loss=0.001]\u001b[A\n",
            "Epoch 5:  94%|█████████▍| 454/484 [58:32<03:47,  7.59s/it, training_loss=0.001]\u001b[A\n",
            "Epoch 5:  94%|█████████▍| 455/484 [58:32<03:40,  7.60s/it, training_loss=0.001]\u001b[A\n",
            "Epoch 5:  94%|█████████▍| 455/484 [58:40<03:40,  7.60s/it, training_loss=0.278]\u001b[A\n",
            "Epoch 5:  94%|█████████▍| 456/484 [58:40<03:34,  7.67s/it, training_loss=0.278]\u001b[A\n",
            "Epoch 5:  94%|█████████▍| 456/484 [58:46<03:34,  7.67s/it, training_loss=0.000]\u001b[A\n",
            "Epoch 5:  94%|█████████▍| 457/484 [58:46<03:18,  7.36s/it, training_loss=0.000]\u001b[A\n",
            "Epoch 5:  94%|█████████▍| 457/484 [58:55<03:18,  7.36s/it, training_loss=0.001]\u001b[A\n",
            "Epoch 5:  95%|█████████▍| 458/484 [58:55<03:23,  7.83s/it, training_loss=0.001]\u001b[A\n",
            "Epoch 5:  95%|█████████▍| 458/484 [59:02<03:23,  7.83s/it, training_loss=0.001]\u001b[A\n",
            "Epoch 5:  95%|█████████▍| 459/484 [59:02<03:06,  7.46s/it, training_loss=0.001]\u001b[A\n",
            "Epoch 5:  95%|█████████▍| 459/484 [59:11<03:06,  7.46s/it, training_loss=0.002]\u001b[A\n",
            "Epoch 5:  95%|█████████▌| 460/484 [59:11<03:11,  7.99s/it, training_loss=0.002]\u001b[A\n",
            "Epoch 5:  95%|█████████▌| 460/484 [59:18<03:11,  7.99s/it, training_loss=0.002]\u001b[A\n",
            "Epoch 5:  95%|█████████▌| 461/484 [59:18<02:53,  7.55s/it, training_loss=0.002]\u001b[A\n",
            "Epoch 5:  95%|█████████▌| 461/484 [59:27<02:53,  7.55s/it, training_loss=0.007]\u001b[A\n",
            "Epoch 5:  95%|█████████▌| 462/484 [59:27<02:54,  7.94s/it, training_loss=0.007]\u001b[A\n",
            "Epoch 5:  95%|█████████▌| 462/484 [59:33<02:54,  7.94s/it, training_loss=0.001]\u001b[A\n",
            "Epoch 5:  96%|█████████▌| 463/484 [59:33<02:39,  7.61s/it, training_loss=0.001]\u001b[A\n",
            "Epoch 5:  96%|█████████▌| 463/484 [59:41<02:39,  7.61s/it, training_loss=0.247]\u001b[A\n",
            "Epoch 5:  96%|█████████▌| 464/484 [59:41<02:32,  7.64s/it, training_loss=0.247]\u001b[A\n",
            "Epoch 5:  96%|█████████▌| 464/484 [59:49<02:32,  7.64s/it, training_loss=0.018]\u001b[A\n",
            "Epoch 5:  96%|█████████▌| 465/484 [59:49<02:25,  7.68s/it, training_loss=0.018]\u001b[A\n",
            "Epoch 5:  96%|█████████▌| 465/484 [59:55<02:25,  7.68s/it, training_loss=0.001]\u001b[A\n",
            "Epoch 5:  96%|█████████▋| 466/484 [59:56<02:12,  7.36s/it, training_loss=0.001]\u001b[A\n",
            "Epoch 5:  96%|█████████▋| 466/484 [1:00:04<02:12,  7.36s/it, training_loss=0.001]\u001b[A\n",
            "Epoch 5:  96%|█████████▋| 467/484 [1:00:04<02:12,  7.81s/it, training_loss=0.001]\u001b[A\n",
            "Epoch 5:  96%|█████████▋| 467/484 [1:00:11<02:12,  7.81s/it, training_loss=0.011]\u001b[A\n",
            "Epoch 5:  97%|█████████▋| 468/484 [1:00:11<01:58,  7.39s/it, training_loss=0.011]\u001b[A\n",
            "Epoch 5:  97%|█████████▋| 468/484 [1:00:20<01:58,  7.39s/it, training_loss=0.001]\u001b[A\n",
            "Epoch 5:  97%|█████████▋| 469/484 [1:00:20<01:59,  7.94s/it, training_loss=0.001]\u001b[A\n",
            "Epoch 5:  97%|█████████▋| 469/484 [1:00:27<01:59,  7.94s/it, training_loss=0.002]\u001b[A\n",
            "Epoch 5:  97%|█████████▋| 470/484 [1:00:27<01:45,  7.52s/it, training_loss=0.002]\u001b[A\n",
            "Epoch 5:  97%|█████████▋| 470/484 [1:00:35<01:45,  7.52s/it, training_loss=0.181]\u001b[A\n",
            "Epoch 5:  97%|█████████▋| 471/484 [1:00:35<01:42,  7.90s/it, training_loss=0.181]\u001b[A\n",
            "Epoch 5:  97%|█████████▋| 471/484 [1:00:42<01:42,  7.90s/it, training_loss=0.001]\u001b[A\n",
            "Epoch 5:  98%|█████████▊| 472/484 [1:00:42<01:30,  7.58s/it, training_loss=0.001]\u001b[A\n",
            "Epoch 5:  98%|█████████▊| 472/484 [1:00:50<01:30,  7.58s/it, training_loss=0.001]\u001b[A\n",
            "Epoch 5:  98%|█████████▊| 473/484 [1:00:50<01:23,  7.63s/it, training_loss=0.001]\u001b[A\n",
            "Epoch 5:  98%|█████████▊| 473/484 [1:00:58<01:23,  7.63s/it, training_loss=0.001]\u001b[A\n",
            "Epoch 5:  98%|█████████▊| 474/484 [1:00:58<01:16,  7.68s/it, training_loss=0.001]\u001b[A\n",
            "Epoch 5:  98%|█████████▊| 474/484 [1:01:04<01:16,  7.68s/it, training_loss=0.214]\u001b[A\n",
            "Epoch 5:  98%|█████████▊| 475/484 [1:01:04<01:06,  7.38s/it, training_loss=0.214]\u001b[A\n",
            "Epoch 5:  98%|█████████▊| 475/484 [1:01:13<01:06,  7.38s/it, training_loss=0.001]\u001b[A\n",
            "Epoch 5:  98%|█████████▊| 476/484 [1:01:13<01:02,  7.84s/it, training_loss=0.001]\u001b[A\n",
            "Epoch 5:  98%|█████████▊| 476/484 [1:01:20<01:02,  7.84s/it, training_loss=0.001]\u001b[A\n",
            "Epoch 5:  99%|█████████▊| 477/484 [1:01:20<00:52,  7.45s/it, training_loss=0.001]\u001b[A\n",
            "Epoch 5:  99%|█████████▊| 477/484 [1:01:29<00:52,  7.45s/it, training_loss=0.218]\u001b[A\n",
            "Epoch 5:  99%|█████████▉| 478/484 [1:01:29<00:47,  7.98s/it, training_loss=0.218]\u001b[A\n",
            "Epoch 5:  99%|█████████▉| 478/484 [1:01:36<00:47,  7.98s/it, training_loss=0.007]\u001b[A\n",
            "Epoch 5:  99%|█████████▉| 479/484 [1:01:36<00:37,  7.53s/it, training_loss=0.007]\u001b[A\n",
            "Epoch 5:  99%|█████████▉| 479/484 [1:01:44<00:37,  7.53s/it, training_loss=0.002]\u001b[A\n",
            "Epoch 5:  99%|█████████▉| 480/484 [1:01:44<00:31,  7.88s/it, training_loss=0.002]\u001b[A\n",
            "Epoch 5:  99%|█████████▉| 480/484 [1:01:51<00:31,  7.88s/it, training_loss=0.001]\u001b[A\n",
            "Epoch 5:  99%|█████████▉| 481/484 [1:01:51<00:22,  7.57s/it, training_loss=0.001]\u001b[A\n",
            "Epoch 5:  99%|█████████▉| 481/484 [1:01:59<00:22,  7.57s/it, training_loss=0.002]\u001b[A\n",
            "Epoch 5: 100%|█████████▉| 482/484 [1:01:59<00:15,  7.57s/it, training_loss=0.002]\u001b[A\n",
            "Epoch 5: 100%|█████████▉| 482/484 [1:02:07<00:15,  7.57s/it, training_loss=0.038]\u001b[A\n",
            "Epoch 5: 100%|█████████▉| 483/484 [1:02:07<00:07,  7.73s/it, training_loss=0.038]\u001b[A\n",
            "Epoch 5: 100%|█████████▉| 483/484 [1:02:12<00:07,  7.73s/it, training_loss=0.001]\u001b[A\n",
            "Epoch 5: 100%|██████████| 484/484 [1:02:12<00:00,  6.94s/it, training_loss=0.001]\u001b[A\n",
            " 80%|████████  | 4/5 [5:33:52<1:07:53, 4073.12s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            " Epoch {epoch}\n",
            "Training loss: {loss_train_avg}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "  0%|          | 0/121 [00:00<?, ?it/s]\u001b[A\n",
            "  1%|          | 1/121 [00:03<06:02,  3.02s/it]\u001b[A\n",
            "  2%|▏         | 2/121 [00:05<05:24,  2.73s/it]\u001b[A\n",
            "  2%|▏         | 3/121 [00:07<04:46,  2.43s/it]\u001b[A\n",
            "  3%|▎         | 4/121 [00:10<04:44,  2.43s/it]\u001b[A\n",
            "  4%|▍         | 5/121 [00:12<04:38,  2.40s/it]\u001b[A\n",
            "  5%|▍         | 6/121 [00:14<04:18,  2.25s/it]\u001b[A\n",
            "  6%|▌         | 7/121 [00:17<04:44,  2.49s/it]\u001b[A\n",
            "  7%|▋         | 8/121 [00:20<05:00,  2.66s/it]\u001b[A\n",
            "  7%|▋         | 9/121 [00:22<04:51,  2.61s/it]\u001b[A\n",
            "  8%|▊         | 10/121 [00:24<04:26,  2.40s/it]\u001b[A\n",
            "  9%|▉         | 11/121 [00:26<04:08,  2.25s/it]\u001b[A\n",
            " 10%|▉         | 12/121 [00:28<03:54,  2.16s/it]\u001b[A\n",
            " 11%|█         | 13/121 [00:30<03:45,  2.09s/it]\u001b[A\n",
            " 12%|█▏        | 14/121 [00:32<03:50,  2.15s/it]\u001b[A\n",
            " 12%|█▏        | 15/121 [00:36<04:20,  2.45s/it]\u001b[A\n",
            " 13%|█▎        | 16/121 [00:39<05:03,  2.89s/it]\u001b[A\n",
            " 14%|█▍        | 17/121 [00:42<04:50,  2.80s/it]\u001b[A\n",
            " 15%|█▍        | 18/121 [00:45<05:03,  2.95s/it]\u001b[A\n",
            " 16%|█▌        | 19/121 [00:47<04:30,  2.65s/it]\u001b[A\n",
            " 17%|█▋        | 20/121 [00:49<04:06,  2.44s/it]\u001b[A\n",
            " 17%|█▋        | 21/121 [00:52<04:05,  2.46s/it]\u001b[A\n",
            " 18%|█▊        | 22/121 [00:55<04:21,  2.64s/it]\u001b[A\n",
            " 19%|█▉        | 23/121 [00:58<04:27,  2.73s/it]\u001b[A\n",
            " 20%|█▉        | 24/121 [01:00<04:03,  2.51s/it]\u001b[A\n",
            " 21%|██        | 25/121 [01:02<03:45,  2.35s/it]\u001b[A\n",
            " 21%|██▏       | 26/121 [01:04<03:31,  2.23s/it]\u001b[A\n",
            " 22%|██▏       | 27/121 [01:06<03:21,  2.14s/it]\u001b[A\n",
            " 23%|██▎       | 28/121 [01:08<03:13,  2.08s/it]\u001b[A\n",
            " 24%|██▍       | 29/121 [01:10<03:34,  2.33s/it]\u001b[A\n",
            " 25%|██▍       | 30/121 [01:13<03:51,  2.54s/it]\u001b[A\n",
            " 26%|██▌       | 31/121 [01:16<03:49,  2.55s/it]\u001b[A\n",
            " 26%|██▋       | 32/121 [01:18<03:30,  2.36s/it]\u001b[A\n",
            " 27%|██▋       | 33/121 [01:20<03:16,  2.24s/it]\u001b[A\n",
            " 28%|██▊       | 34/121 [01:22<03:06,  2.15s/it]\u001b[A\n",
            " 29%|██▉       | 35/121 [01:24<02:59,  2.08s/it]\u001b[A\n",
            " 30%|██▉       | 36/121 [01:26<02:58,  2.10s/it]\u001b[A\n",
            " 31%|███       | 37/121 [01:29<03:24,  2.43s/it]\u001b[A\n",
            " 31%|███▏      | 38/121 [01:32<03:34,  2.59s/it]\u001b[A\n",
            " 32%|███▏      | 39/121 [01:34<03:21,  2.46s/it]\u001b[A\n",
            " 33%|███▎      | 40/121 [01:36<03:06,  2.30s/it]\u001b[A\n",
            " 34%|███▍      | 41/121 [01:38<02:55,  2.19s/it]\u001b[A\n",
            " 35%|███▍      | 42/121 [01:40<02:47,  2.12s/it]\u001b[A\n",
            " 36%|███▌      | 43/121 [01:42<02:41,  2.07s/it]\u001b[A\n",
            " 36%|███▋      | 44/121 [01:45<02:55,  2.28s/it]\u001b[A\n",
            " 37%|███▋      | 45/121 [01:48<03:11,  2.52s/it]\u001b[A\n",
            " 38%|███▊      | 46/121 [01:51<03:13,  2.58s/it]\u001b[A\n",
            " 39%|███▉      | 47/121 [01:53<02:56,  2.39s/it]\u001b[A\n",
            " 40%|███▉      | 48/121 [01:54<02:44,  2.25s/it]\u001b[A\n",
            " 40%|████      | 49/121 [01:56<02:35,  2.16s/it]\u001b[A\n",
            " 41%|████▏     | 50/121 [01:58<02:28,  2.09s/it]\u001b[A\n",
            " 42%|████▏     | 51/121 [02:00<02:24,  2.07s/it]\u001b[A\n",
            " 43%|████▎     | 52/121 [02:04<02:46,  2.41s/it]\u001b[A\n",
            " 44%|████▍     | 53/121 [02:07<02:54,  2.57s/it]\u001b[A\n",
            " 45%|████▍     | 54/121 [02:09<02:46,  2.48s/it]\u001b[A\n",
            " 45%|████▌     | 55/121 [02:11<02:32,  2.31s/it]\u001b[A\n",
            " 46%|████▋     | 56/121 [02:13<02:23,  2.20s/it]\u001b[A\n",
            " 47%|████▋     | 57/121 [02:15<02:16,  2.13s/it]\u001b[A\n",
            " 48%|████▊     | 58/121 [02:17<02:11,  2.09s/it]\u001b[A\n",
            " 49%|████▉     | 59/121 [02:19<02:19,  2.25s/it]\u001b[A\n",
            " 50%|████▉     | 60/121 [02:22<02:32,  2.50s/it]\u001b[A\n",
            " 50%|█████     | 61/121 [02:25<02:36,  2.60s/it]\u001b[A\n",
            " 51%|█████     | 62/121 [02:27<02:22,  2.41s/it]\u001b[A\n",
            " 52%|█████▏    | 63/121 [02:29<02:11,  2.27s/it]\u001b[A\n",
            " 53%|█████▎    | 64/121 [02:31<02:04,  2.18s/it]\u001b[A\n",
            " 54%|█████▎    | 65/121 [02:33<01:58,  2.11s/it]\u001b[A\n",
            " 55%|█████▍    | 66/121 [02:35<01:54,  2.07s/it]\u001b[A\n",
            " 55%|█████▌    | 67/121 [02:38<02:10,  2.41s/it]\u001b[A\n",
            " 56%|█████▌    | 68/121 [02:41<02:16,  2.58s/it]\u001b[A\n",
            " 57%|█████▋    | 69/121 [02:43<02:10,  2.50s/it]\u001b[A\n",
            " 58%|█████▊    | 70/121 [02:45<01:59,  2.34s/it]\u001b[A\n",
            " 59%|█████▊    | 71/121 [02:47<01:51,  2.24s/it]\u001b[A\n",
            " 60%|█████▉    | 72/121 [02:49<01:45,  2.15s/it]\u001b[A\n",
            " 60%|██████    | 73/121 [02:51<01:40,  2.09s/it]\u001b[A\n",
            " 61%|██████    | 74/121 [02:54<01:44,  2.23s/it]\u001b[A\n",
            " 62%|██████▏   | 75/121 [02:57<01:54,  2.50s/it]\u001b[A\n",
            " 63%|██████▎   | 76/121 [03:00<01:56,  2.59s/it]\u001b[A\n",
            " 64%|██████▎   | 77/121 [03:02<01:45,  2.40s/it]\u001b[A\n",
            " 64%|██████▍   | 78/121 [03:04<01:37,  2.27s/it]\u001b[A\n",
            " 65%|██████▌   | 79/121 [03:06<01:31,  2.17s/it]\u001b[A\n",
            " 66%|██████▌   | 80/121 [03:08<01:26,  2.10s/it]\u001b[A\n",
            " 67%|██████▋   | 81/121 [03:10<01:22,  2.06s/it]\u001b[A\n",
            " 68%|██████▊   | 82/121 [03:13<01:33,  2.40s/it]\u001b[A\n",
            " 69%|██████▊   | 83/121 [03:16<01:37,  2.58s/it]\u001b[A\n",
            " 69%|██████▉   | 84/121 [03:18<01:32,  2.51s/it]\u001b[A\n",
            " 70%|███████   | 85/121 [03:20<01:24,  2.34s/it]\u001b[A\n",
            " 71%|███████   | 86/121 [03:22<01:17,  2.22s/it]\u001b[A\n",
            " 72%|███████▏  | 87/121 [03:24<01:12,  2.14s/it]\u001b[A\n",
            " 73%|███████▎  | 88/121 [03:26<01:08,  2.08s/it]\u001b[A\n",
            " 74%|███████▎  | 89/121 [03:28<01:10,  2.21s/it]\u001b[A\n",
            " 74%|███████▍  | 90/121 [03:32<01:17,  2.49s/it]\u001b[A\n",
            " 75%|███████▌  | 91/121 [03:34<01:18,  2.61s/it]\u001b[A\n",
            " 76%|███████▌  | 92/121 [03:36<01:09,  2.41s/it]\u001b[A\n",
            " 77%|███████▋  | 93/121 [03:38<01:03,  2.27s/it]\u001b[A\n",
            " 78%|███████▊  | 94/121 [03:40<00:58,  2.17s/it]\u001b[A\n",
            " 79%|███████▊  | 95/121 [03:42<00:54,  2.10s/it]\u001b[A\n",
            " 79%|███████▉  | 96/121 [03:44<00:51,  2.05s/it]\u001b[A\n",
            " 80%|████████  | 97/121 [03:47<00:56,  2.36s/it]\u001b[A\n",
            " 81%|████████  | 98/121 [03:50<00:58,  2.55s/it]\u001b[A\n",
            " 82%|████████▏ | 99/121 [03:53<00:55,  2.52s/it]\u001b[A\n",
            " 83%|████████▎ | 100/121 [03:55<00:49,  2.35s/it]\u001b[A\n",
            " 83%|████████▎ | 101/121 [03:57<00:44,  2.23s/it]\u001b[A\n",
            " 84%|████████▍ | 102/121 [03:58<00:40,  2.14s/it]\u001b[A\n",
            " 85%|████████▌ | 103/121 [04:00<00:37,  2.08s/it]\u001b[A\n",
            " 86%|████████▌ | 104/121 [04:03<00:36,  2.17s/it]\u001b[A\n",
            " 87%|████████▋ | 105/121 [04:06<00:39,  2.46s/it]\u001b[A\n",
            " 88%|████████▊ | 106/121 [04:09<00:39,  2.61s/it]\u001b[A\n",
            " 88%|████████▊ | 107/121 [04:11<00:33,  2.42s/it]\u001b[A\n",
            " 89%|████████▉ | 108/121 [04:13<00:29,  2.28s/it]\u001b[A\n",
            " 90%|█████████ | 109/121 [04:15<00:26,  2.18s/it]\u001b[A\n",
            " 91%|█████████ | 110/121 [04:17<00:23,  2.11s/it]\u001b[A\n",
            " 92%|█████████▏| 111/121 [04:19<00:20,  2.07s/it]\u001b[A\n",
            " 93%|█████████▎| 112/121 [04:22<00:20,  2.33s/it]\u001b[A\n",
            " 93%|█████████▎| 113/121 [04:25<00:20,  2.54s/it]\u001b[A\n",
            " 94%|█████████▍| 114/121 [04:27<00:17,  2.55s/it]\u001b[A\n",
            " 95%|█████████▌| 115/121 [04:29<00:14,  2.37s/it]\u001b[A\n",
            " 96%|█████████▌| 116/121 [04:31<00:11,  2.24s/it]\u001b[A\n",
            " 97%|█████████▋| 117/121 [04:33<00:08,  2.15s/it]\u001b[A\n",
            " 98%|█████████▊| 118/121 [04:35<00:06,  2.09s/it]\u001b[A\n",
            " 98%|█████████▊| 119/121 [04:37<00:04,  2.17s/it]\u001b[A\n",
            " 99%|█████████▉| 120/121 [04:41<00:02,  2.47s/it]\u001b[A\n",
            "100%|██████████| 121/121 [04:44<00:00,  2.35s/it]\n",
            "100%|██████████| 5/5 [5:38:36<00:00, 4063.25s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Validation loss: 0.7625145806742386\n",
            "F1 Score (weighted): 0.8499893543939103\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "_, predictions, true_vals = evaluate(dataloader_val)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tPQEu0MvcrLJ",
        "outputId": "50a4442c-ec8e-4d7b-88c6-563bfdffac84"
      },
      "execution_count": 55,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 121/121 [05:13<00:00,  2.59s/it]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "true_vals.shape\n",
        "accuracy_per_class(predictions, true_vals)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uAaDclgnspW3",
        "outputId": "c603075e-043f-4d37-af22-ee96423d1005"
      },
      "execution_count": 56,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy:106/120\n",
            " -> 0.8833333333333333\n",
            "Accuracy:498/575\n",
            " -> 0.8660869565217392\n",
            "Accuracy:218/273\n",
            " -> 0.7985347985347986\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "path = F\"/content/gdrive/MyDrive/NLP/BERT_ft_epoch5.model\"\n",
        "model.load_state_dict(torch.load(path))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zcm5wY4-i-Dy",
        "outputId": "019e07bb-1fe1-4497-a209-1415b04a0e3e"
      },
      "execution_count": 52,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<All keys matched successfully>"
            ]
          },
          "metadata": {},
          "execution_count": 52
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import TextClassificationPipeline\n",
        "\n",
        "pipe = TextClassificationPipeline(model=model, tokenizer=tokenizer, return_all_scores=True)"
      ],
      "metadata": {
        "id": "kozbV9TAi-GP",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2948a180-a787-426f-a885-8409b4f385f1"
      },
      "execution_count": 53,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/pipelines/text_classification.py:104: UserWarning: `return_all_scores` is now deprecated,  if want a similar funcionality use `top_k=None` instead of `return_all_scores=True` or `top_k=1` instead of `return_all_scores=False`.\n",
            "  warnings.warn(\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# preprocess the sentence\n",
        "sentence = \"The Emirates Financial Market Index increased during yesterday’s session by 1.44% to close at 12.2663 points, and the market value increased by 50.5 billion dirhams to reach 67.386 billion dirhams. 0.85 billion shares, with a total value of 1.32 billion dirhams, through 14,654 transactions.\"\n",
        "input_ids = torch.tensor(tokenizer.encode(sentence, add_special_tokens=True)).unsqueeze(0)\n",
        "attention_mask = torch.tensor([1] * input_ids.shape[1]).unsqueeze(0)\n",
        "\n",
        "# get the predicted sentiment label\n",
        "with torch.no_grad():\n",
        "    outputs = model(input_ids=input_ids, attention_mask=attention_mask)\n",
        "    _, predicted_label = torch.max(outputs[0], dim=1)\n"
      ],
      "metadata": {
        "id": "7pyHwdyKi-LH"
      },
      "execution_count": 54,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "predicted_label"
      ],
      "metadata": {
        "id": "8HgSqUXVi-Nt",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1ff3a59b-4842-46e1-8917-1f3628e38841"
      },
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([2])"
            ]
          },
          "metadata": {},
          "execution_count": 31
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# End\n"
      ],
      "metadata": {
        "id": "-vfxcPDmttis"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model.summary()\n"
      ],
      "metadata": {
        "id": "qp_4qBVmoC5x",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 287
        },
        "outputId": "53006c3a-ccc6-4b83-deef-658bbc804395"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "AttributeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-64-5f15418b3570>\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msummary\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__getattr__\u001b[0;34m(self, name)\u001b[0m\n\u001b[1;32m   1612\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mname\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mmodules\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1613\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mmodules\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1614\u001b[0;31m         raise AttributeError(\"'{}' object has no attribute '{}'\".format(\n\u001b[0m\u001b[1;32m   1615\u001b[0m             type(self).__name__, name))\n\u001b[1;32m   1616\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mAttributeError\u001b[0m: 'BertForSequenceClassification' object has no attribute 'summary'"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from simpletransformers.classification import ClassificationModel\n",
        "\n",
        "\n",
        "# Create a TransformerModel\n",
        "model = ClassificationModel('bert', 'bert-base-cased', num_labels=3, args={'reprocess_input_data': True, 'overwrite_output_dir': True},use_cuda=False)"
      ],
      "metadata": {
        "id": "qnq13_yW_TX1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 0,1,2 : positive,negative\n",
        "def making_label(st):\n",
        "    if(st=='positive'):\n",
        "        return 0\n",
        "    elif(st=='neutral'):\n",
        "        return 2\n",
        "    else:\n",
        "        return 1\n",
        "    \n",
        "train['label'] = train['Sentiment'].apply(making_label)\n",
        "test['label'] = test['Sentiment'].apply(making_label)\n",
        "print(train.shape)"
      ],
      "metadata": {
        "id": "nS7bRBKb_WG7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_df = pd.DataFrame({\n",
        "    'text': train['Sentence'][:1500].replace(r'\\n', ' ', regex=True),\n",
        "    'label': train['label'][:1500]\n",
        "})\n",
        "\n",
        "eval_df = pd.DataFrame({\n",
        "    'text': test['Sentence'][-400:].replace(r'\\n', ' ', regex=True),\n",
        "    'label': test['label'][-400:]\n",
        "})"
      ],
      "metadata": {
        "id": "jF-ruRta_4C1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.train_model(train_df)"
      ],
      "metadata": {
        "id": "mdvEoYNO_-cG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "result, model_outputs, wrong_predictions = model.eval_model(eval_df)"
      ],
      "metadata": {
        "id": "f8eKnc76AEOs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "lst = []\n",
        "for arr in model_outputs:\n",
        "    lst.append(np.argmax(arr))"
      ],
      "metadata": {
        "id": "fOmt_agRzMyH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "true = eval_df['label'].tolist()\n",
        "predicted = lst"
      ],
      "metadata": {
        "id": "o5Er_aNnzaZu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import sklearn\n",
        "sklearn.metrics.accuracy_score(true,predicted)"
      ],
      "metadata": {
        "id": "nojvATamza0V"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "predictions, raw_outputs = model.predict(\"Almost all the region's markets reversed in yesterday's session trading from the trend they were in the previous session in light of the dominance of buying operations in the markets throughout the trading period almost with the encouragement of some dealers to take financial positions on selected shares for the purpose of investment or speculation after the prices became more attractive and in Under the return of relative stability to the regional and global climate. Where only the Jordanian market declined under pressure from the services stocks, as it declined by 0.27%, to close its general index at the level of 2350.91 points. The Kuwaiti market bounced back to recover most of the losses of the previous session, supported by almost all sectors, amid a decline in liquidity, as it rose by 0.66%, to close at 6914.40 points. The Saudi stock market maintained its upward trend, with the support of the main sectors and stocks in the market, as it rose by 0.36%, to close at 43.6332 points. Buying forces returned to control the Qatari Stock Exchange to recoup most of the losses of the previous session, rising by 0.59% to close at 81158.87 points. With the rebound of heavy stocks in the Bahraini market from the levels of the previous session, the Bahraini market recovered all the losses, to close its index at 1438.87 points, with a gain of 0.83%. The Omani market continued its rise, supported by a number of its best stocks, as it rose by 0.31%, to close at 6602.95 points.\")"
      ],
      "metadata": {
        "id": "rIbPgdUW0XIu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "np.average(predictions)"
      ],
      "metadata": {
        "id": "YGz_1jQX1Fa6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Uploading the MarianMTModel Translator"
      ],
      "metadata": {
        "id": "XGq5DTV-EMVn"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import MarianTokenizer, MarianMTModel\n",
        "mname = \"marefa-nlp/marefa-mt-en-ar\"\n",
        "tokenizer = MarianTokenizer.from_pretrained(mname)\n",
        "model = MarianMTModel.from_pretrained(mname)"
      ],
      "metadata": {
        "id": "kaVnG-iuyugI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Translating the dataset"
      ],
      "metadata": {
        "id": "9jYWLnnxEo0F"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# English Text\n",
        "input = \"With the new production plant the company would increase its capacity to meet the expected increase in demand and would improve the use of raw materials and therefore increase the production profitability.\"\n",
        "\n",
        "translated_tokens = model.generate(**tokenizer.prepare_seq2seq_batch([input], return_tensors=\"pt\"))\n",
        "translated_text = [tokenizer.decode(t, skip_special_tokens=True) for t in translated_tokens]\n",
        "\n",
        "# translated Arabic Text\n",
        "print(translated_text)\n"
      ],
      "metadata": {
        "id": "aGfkclBC0wxq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Directory containing the text files to merge\n",
        "dir_path = 'gdrive/My Drive/Finance/'\n",
        "\n",
        "# List of all the text files in the directory\n",
        "files = os.listdir(dir_path)\n",
        "print(files)\n",
        "\n",
        "# Open the CSV file for writing\n",
        "with open('merged_file.csv', 'w', newline='') as csvfile:\n",
        "    writer = csv.writer(csvfile)\n",
        "\n",
        "    # Write the header row to the CSV file\n",
        "    writer.writerow(['filename', 'content'])\n",
        "\n",
        "    # Iterate through all the text files in the directory\n",
        "    for file in files:\n",
        "        if file.endswith('.txt'):\n",
        "            # Open the text file for reading\n",
        "            with open(os.path.join(dir_path, file), 'r') as f:\n",
        "                content = f.read()\n",
        "                \n",
        "            # Write the filename and content to the CSV file\n",
        "            writer.writerow([file, content])\n",
        "\n",
        "# Close the CSV file\n",
        "csvfile.close()"
      ],
      "metadata": {
        "id": "OepVekXDBQ14"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df = pd.read_csv(\"merged_file.csv\")\n",
        "print(df.describe)"
      ],
      "metadata": {
        "id": "vG2Mz3dbDeis"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}